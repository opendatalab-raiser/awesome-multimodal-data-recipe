# Awesome å¤šæ¨¡æ€æ•°æ®åˆæˆæ–¹æ³• [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<div align="center">
  <img src="https://img.shields.io/github/stars/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Stars">
  <img src="https://img.shields.io/github/forks/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Forks">
  <img src="https://img.shields.io/github/license/opendatalab-raiser/awesome-multimodal-data-recipe" alt="License">
  <img src="https://img.shields.io/github/last-commit/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Last Commit">
  <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome">
</div>

<p align="center">
  <a href="README.md">English</a> | <a href="README_zh.md">ä¸­æ–‡</a>
</p>

<p align="center">
  <b>ç²¾é€‰çš„å¤šæ¨¡æ€æ•°æ®åˆæˆæ–¹æ³•ä¸èµ„æºåˆ—è¡¨ï¼Œä¸“æ³¨äºè§†è§‰-è¯­è¨€æ¨¡å‹</b>
</p>

---

## ç»Ÿè®¡ä¿¡æ¯

- **è®ºæ–‡æ€»æ•°ï¼š** 101ç¯‡ï¼ˆæ•°æ®åˆæˆ/æ„å»ºæ–¹æ³•ï¼‰
- **å¤§å‚æŠ¥å‘Šï¼š** 9ç¯‡ï¼ˆç™¾åº¦ã€å¾®è½¯ã€é˜¿é‡Œå·´å·´ã€å­—èŠ‚è·³åŠ¨ã€è…¾è®¯ç­‰ï¼‰
- **æ•°æ®åˆæˆæ–¹æ³•ï¼š**
  - å›¾åƒç”Ÿæˆ - åˆæˆæ–°è§†è§‰å†…å®¹(22ç¯‡): å‡ ä½•/æ•°å­¦æ¨ç† + æ–‡æ¡£/æ–‡æœ¬å¯†é›†åœºæ™¯(OCR-freeåœºæ™¯æ–‡æœ¬ã€æ–‡æ¡£å¸ƒå±€åˆ†æ) + åœºæ™¯æ–‡æœ¬æ£€æµ‹ + å¤šæ¨¡æ€å¯¹è¯(any-to-anyç”Ÿæˆå¼åˆæˆ) + æ–‡æœ¬é©±åŠ¨å›¾åƒåˆæˆ + ChatGPTå¼•å¯¼åˆæˆ + è‡ªåŠ¨é©¾é©¶ + å®Œå…¨åˆæˆå›¾æ–‡ç”Ÿæˆ + 3Dç‰©ç†ä»¿çœŸ + 3Dåœºæ™¯åˆæˆ(3Dè§†è§‰æŒ‡ä»¤æ•°æ®) + æœºå™¨äººåŠ¨ä½œåˆæˆ
  - å›¾åƒç¼–è¾‘(5ç¯‡): éåˆšæ€§è¿åŠ¨ã€ç»Ÿä¸€ç¼–è¾‘ã€æŒ‡ç§°è¡¨è¾¾å¼å¼•å¯¼ç¼–è¾‘ã€ç”Ÿæˆå¼è§†è§‰æŒ‡ä»¤å¾®è°ƒ
  - ç»„åˆæ€§/åå¥½å¯¼å‘åˆæˆ(6ç¯‡): å¢å¼ºç»„åˆç†è§£èƒ½åŠ› + å¤šæ¦‚å¿µç»„åˆ + å¤šå›¾åƒå®šåˆ¶ + éš¾è´Ÿæ ·æœ¬å¯¹æ¯”å­¦ä¹  + å¤šæ¨¡æ€åäº‹å®æ ·æœ¬ + 3Dç‰©ç†ä»¿çœŸVLCå¢å¼º
  - äº¤é”™å›¾æ–‡Â·è¿è´¯æ€§ä¸ä¸€è‡´æ€§(5ç¯‡): å¤šè§†è§’è´¨é‡è¿‡æ»¤ + è¿­ä»£ç²¾ç‚¼ + å¤šæ¨¡æ€åµŒå…¥ç›¸å…³æ€§è¯†åˆ« + æ•™å­¦è§†é¢‘æå–(è§†é¢‘è½¬æ•™ç§‘ä¹¦)
  - å›¾åƒä»‹å…¥æ¨ç†(2ç¯‡): å›¾åƒä¸»åŠ¨å‚ä¸æ¨ç†è¿‡ç¨‹ + å¤§è§„æ¨¡æ¨ç†è½¨è¿¹åˆæˆ
  - VLMè‡ªæˆ‘æ”¹è¿›ä¸å¼ºåŒ–å­¦ä¹ (4ç¯‡): æ ¡å‡†è‡ªå¥–åŠ±VLM + æ¸¸æˆåŒ–è‡ªå¯¹å¼ˆæ¡†æ¶ + å›¾è¡¨ç†è§£è‡ªæˆ‘æ”¹è¿›(ä»£ç é©±åŠ¨åˆæˆ)
  - å›¾åƒä¸å˜ - æ–‡æœ¬å¢å¼º(48ç¯‡): å›ºå®šå›¾åƒï¼Œä»…ä¸°å¯Œæ–‡æœ¬ + è‡ªé€‚åº”æƒé‡åˆæˆæ ‡æ³¨ + åŒ»å­¦é¢†åŸŸçº¯åˆæˆæ•°æ® + æˆæœ¬é«˜æ•ˆLVLMæ•°æ®ç²¾åŒ– + ç©ºé—´æ¨ç†å¢å¼º + VLMä¸ªæ€§åŒ– + æŒç»­å­¦ä¹  + å¤šæ¨¡æ€RAGè®­ç»ƒ + è‡ªæŒ‡å¯¼ä»£ç æ ¼å¼åŒ– + å¤šè¯­è¨€åµŒå…¥å¢å¼º + MLLMæ•°æ®ç”Ÿæˆå™¨ + ç¨‹åºåŒ–æŒ‡ä»¤ç”Ÿæˆ + ä¿¡æ¯ç“¶é¢ˆæ¦‚å¿µé€‰æ‹© + å›¾åƒç†è§£è‡ªè®­ç»ƒ + å¤šæ¨¡æ€æŒ‡ä»¤éµå¾ª(çº¦æŸé©±åŠ¨) + ç»„åˆå›¾åƒæ£€ç´¢ä¸‰å…ƒç»„åˆæˆ + å¤šæ¨¡æ€é—®ç­”ç”Ÿæˆ(é£æ ¼ä¸æ¨¡æ€å¯æ§) + å›¾è¡¨ç†è§£(GPT-4é©±åŠ¨å¤šä»»åŠ¡æŒ‡ä»¤ç”Ÿæˆ) + ç§‘å­¦å›¾è¡¨ç†è§£(GPT-4Vç”ŸæˆQA) + é¢†åŸŸè‡ªé€‚åº”åè®­ç»ƒ(å¼€æºMLLMé©±åŠ¨ç”Ÿæˆ-è¿‡æ»¤) + ä»»åŠ¡ç±»å‹å±‚çº§æ‰©å±•(GPT-4oè‡ªåŠ¨åŒ–ç”Ÿæˆ)
  - è§†é¢‘ - æŒ‡ä»¤å¾®è°ƒï¼ˆåˆæˆæ•°æ®ï¼‰(1ç¯‡): åŸºäºè§†é¢‘çš„æŒ‡ä»¤è·Ÿéšï¼ˆæè¿°+QAï¼‰
  - è·¨é¢†åŸŸæ–¹æ³•è®ºæ´å¯Ÿ(2ç¯‡): å¤šæ¨¡æ€æ¨¡å‹åå¡Œåˆ†æ + åˆæˆæ•°æ®è´¨é‡è¯„ä¼°
- **å…¸å‹æ•°æ®é›†ï¼š**
  - 4ä¸ªäº¤é”™å›¾æ–‡æ•°æ®é›†ï¼ˆOmniCorpusã€OBELICSã€MMC4ã€CoMMï¼‰
  - 2ä¸ªé¢†åŸŸç‰¹å®šæ•°æ®é›†ï¼ˆMMM-RSã€MESEDï¼‰
  - 4ä¸ªå›¾åƒç¼–è¾‘æ•°æ®é›†ï¼ˆByteMorph-6Mã€ImgEditã€RefEditã€RefCOCO-Editï¼‰
  - 4ä¸ªå¤§è§„æ¨¡é€šç”¨è®­ç»ƒæ•°æ®é›†
  - 5ä¸ªå›¾è¡¨æ¨ç†æ•°æ®é›†ï¼ˆChartInstructã€Synthesize Step-by-Stepã€ECDã€ChartGenã€MMC-Instructionï¼‰
  - 2ä¸ªå¤šæ¨¡æ€å¯¹è¯æ•°æ®é›†ï¼ˆMAGIDã€AnyInstruct-108kï¼‰
- **å¼€æºæ•°æ®é›†ï¼š** 29+ä¸ªæ•°æ®é›†å®Œå…¨å¼€æº

---

## ğŸ“‹ ç›®å½•

- [ç®€ä»‹](#-ç®€ä»‹)
- [å¤§å‚ä¸å¼€æºé¡¹ç›®çš„æ•°æ®åˆæˆæ–¹æ³•](#-å¤§å‚ä¸å¼€æºé¡¹ç›®çš„æ•°æ®åˆæˆæ–¹æ³•)
- [æŒ‰å›¾åƒå¤„ç†æ–¹å¼åˆ†ç±»](#-æŒ‰å›¾åƒå¤„ç†æ–¹å¼åˆ†ç±»)
  - [å›¾åƒç”Ÿæˆ - åˆæˆæ–°è§†è§‰å†…å®¹](#-å›¾åƒç”Ÿæˆ---åˆæˆæ–°è§†è§‰å†…å®¹)
    - [å‡ ä½•ä¸æ•°å­¦æ¨ç†](#-å‡ ä½•ä¸æ•°å­¦æ¨ç†)
    - [æ–‡æ¡£/æ–‡æœ¬å¯†é›†åœºæ™¯](#-æ–‡æ¡£æ–‡æœ¬å¯†é›†åœºæ™¯)
  - [å›¾åƒä»‹å…¥æ¨ç†](#-å›¾åƒä»‹å…¥æ¨ç†)
  - [å›¾åƒç¼–è¾‘ï¼ˆæ–¹æ³•+æ•°æ®ï¼‰](#-å›¾åƒç¼–è¾‘æ–¹æ³•æ•°æ®)
  - [ç»„åˆæ€§/åå¥½å¯¼å‘åˆæˆ](#-ç»„åˆæ€§åå¥½å¯¼å‘åˆæˆ)
  - [äº¤é”™å›¾æ–‡Â·è¿è´¯æ€§ä¸ä¸€è‡´æ€§](#-äº¤é”™å›¾æ–‡è¿è´¯æ€§ä¸ä¸€è‡´æ€§)
  - [å›¾åƒä¸å˜æ–‡æœ¬å¢å¼º](#å›¾åƒä¸å˜æ–‡æœ¬å¢å¼º)
  - [VLMè‡ªæˆ‘æ”¹è¿›ä¸å¼ºåŒ–å­¦ä¹ ](#-vlmè‡ªæˆ‘æ”¹è¿›ä¸å¼ºåŒ–å­¦ä¹ )
    - [ç©ºé—´æ¨ç†å¢å¼º](#-ç©ºé—´æ¨ç†å¢å¼º)
    - [æŒç»­å­¦ä¹ ä¸ç¾éš¾æ€§é—å¿˜ç¼“è§£](#-æŒç»­å­¦ä¹ ä¸ç¾éš¾æ€§é—å¿˜ç¼“è§£)
    - [VLMä¸ªæ€§åŒ–ä¸æ¦‚å¿µå­¦ä¹ ](#-vlmä¸ªæ€§åŒ–ä¸æ¦‚å¿µå­¦ä¹ )
- [è·¨é¢†åŸŸæ–¹æ³•è®ºæ´å¯Ÿ](#-è·¨é¢†åŸŸæ–¹æ³•è®ºæ´å¯Ÿ)
- [å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†](#-å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†)
  - [äº¤é”™å›¾æ–‡æ•°æ®é›†](#-äº¤é”™å›¾æ–‡æ•°æ®é›†)
  - [é¢†åŸŸç‰¹å®šä¸çŸ¥è¯†å¯¼å‘æ•°æ®é›†](#-é¢†åŸŸç‰¹å®šä¸çŸ¥è¯†å¯¼å‘æ•°æ®é›†)
  - [å¤§è§„æ¨¡é€šç”¨è®­ç»ƒæ•°æ®é›†](#-å¤§è§„æ¨¡é€šç”¨è®­ç»ƒæ•°æ®é›†)
  - [å›¾åƒç¼–è¾‘æ•°æ®é›†](#-å›¾åƒç¼–è¾‘æ•°æ®é›†)
- [åŸºå‡†æ•°æ®é›†](#-åŸºå‡†æ•°æ®é›†)
- [èµ„æº](#-èµ„æº)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)

---

## ğŸ¯ ç®€ä»‹

å¤šæ¨¡æ€æ•°æ®åˆæˆæ˜¯æå‡è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)æ€§èƒ½çš„å…³é”®æŠ€æœ¯ã€‚æœ¬ä»“åº“æ”¶é›†å¹¶æ•´ç†ï¼š

- ğŸ¢ **å¤§å‚æŠ¥å‘Š**ï¼šæ¥è‡ªé¢†å…ˆç§‘æŠ€å…¬å¸çš„è¯¦ç»†æ•°æ®åˆæˆpipelineå’Œæœ€ä½³å®è·µ
- ğŸ“š **å­¦æœ¯è®ºæ–‡**ï¼šæœ€å…ˆè¿›çš„ç ”ç©¶æ–¹æ³•å’Œåˆ›æ–°æŠ€æœ¯
- ğŸ› ï¸ **å·¥å…·ä¸æ¡†æ¶**ï¼šå®ç”¨çš„æ•°æ®åˆæˆå·¥å…·å’Œä»£ç åº“
- ğŸ“Š **æ•°æ®é›†**ï¼šé«˜è´¨é‡çš„å¤šæ¨¡æ€æ•°æ®é›†

**å…³é”®è§‚å¯Ÿ**ï¼šå½“å‰å¤šæ¨¡æ€æ•°æ®åˆæˆä¸»è¦éµå¾ª"å›¾åƒä¸å˜+æ–‡æœ¬å¢å¼º"èŒƒå¼ï¼Œåˆ©ç”¨Webèµ„æºã€å·¥å…·APIæˆ–å…¶ä»–å¤§æ¨¡å‹æ¥æå‡å›¾åƒ-æ–‡æœ¬å¯¹çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

---

## ğŸ¢ å¤§å‚ä¸å¼€æºé¡¹ç›®çš„æ•°æ®åˆæˆæ–¹æ³•

> æœ¬èŠ‚åŒ…å«æ˜ç¡®è®°å½•äº†æ•°æ®åˆæˆpipelineçš„å·¥ä½œã€‚**ä»…æ”¶å½•å…·æœ‰è¯¦ç»†æ•°æ®æ„å»ºå’Œåˆæˆæ–¹æ³•æè¿°çš„é¡¹ç›®ã€‚**

### ç™¾åº¦ - åƒå¸†-VL

# Awesome Multimodal Data Recipe [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<div align="center">
  <img src="https://img.shields.io/github/stars/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Stars">
  <img src="https://img.shields.io/github/forks/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Forks">
  <img src="https://img.shields.io/github/license/opendatalab-raiser/awesome-multimodal-data-recipe" alt="License">
  <img src="https://img.shields.io/github/last-commit/opendatalab-raiser/awesome-multimodal-data-recipe" alt="Last Commit">
  <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome">
</div>

<p align="center">
  <a href="README.md">English</a> | <a href="README_zh.md">ä¸­æ–‡</a>
</p>

<p align="center">
  <b>A curated list of multimodal data synthesis methods and resources for Vision-Language Models</b>
</p>

---

## ğŸ“Š Statistics

- **Total Papers:** 101 (data synthesis/construction methods)
- **Industrial Reports:** 9 (Baidu, Microsoft, Alibaba, ByteDance, Tencent, Hunyuan, etc.)
- **Data Synthesis Methods:**
  - Image Generation - Synthesizing New Visual Content (22): Geometric/mathematical reasoning + document/text-dense scenes (OCR-free scene text, document layout analysis) + scene text detection + multimodal dialogue (any-to-any generative synthesis) + text-driven image synthesis + ChatGPT-guided synthesis + autonomous driving + fully synthetic image-text generation + 3D physics simulation + 3D scene synthesis (3D visual instruction data) + robotic action synthesis
  - Image Editing (5): Non-rigid motion, unified editing, referring expression-guided editing, generative visual instruction tuning
  - Compositionality / Preference-Guided Synthesis (6): Enhancing compositional understanding + multi-concept composition + multi-image customization + hard negative contrastive learning + multimodal counterfactual samples + 3D physics simulation VLC enhancement
  - Interleaved Image-Text Â· Coherence & Consistency (5): Multi-perspective quality filtering + iterative refinement + multimodal embedding-based correlation + instructional video extraction (video-to-textbook)
  - Think with Image (2): Interleaved multimodal reasoning with image manipulation + large-scale reasoning trajectory synthesis
  - VLM Self-Improvement & Reinforcement Learning (4): Calibrated self-rewarding VLM + gamified self-play frameworks + chart understanding self-improvement (code-driven synthesis)
  - Image-Invariant - Text Enhancement (48): Fixed images, enriched text only + adaptive weighted synthetic captions + medical domain purely synthetic data + cost-efficient LVLM data refinement + spatial reasoning enhancement + VLM personalization + continual learning + multimodal RAG training + self-instructed code formatting + multilingual embedding enhancement + MLLM data generators + programmatic instruction generation + information bottleneck concept selection + image comprehension self-training + multimodal instruction following (constraint-driven) + composed image retrieval triplet synthesis + multimodal question generation (style & modality controllable) + chart understanding (GPT-4-driven multi-task instruction generation) + scientific figure understanding (GPT-4V generated QA) + domain-adaptive post-training (open-source MLLM-driven generate-then-filter) + task type hierarchical expansion (GPT-4o automated generation)
  - Video - Instruction Tuning (Synthetic Data) (1): Synthetic video instruction-following data (captions + QA)
  - Cross-Domain Methodology Insights (2): Multi-modal model collapse analysis + synthetic data quality assessment
- **Notable Datasets:**
  - 4 interleaved image-text datasets (OmniCorpus, OBELICS, MMC4, CoMM)
  - 2 domain-specific datasets (MMM-RS, MESED)
  - 4 image editing datasets (ByteMorph-6M, ImgEdit, RefEdit, RefCOCO-Edit)
  - 4 large-scale general training datasets
  - 5 chart reasoning datasets (ChartInstruct, Synthesize Step-by-Step, ECD, ChartGen, MMC-Instruction)
  - 2 multimodal dialogue datasets (MAGID, AnyInstruct-108k)
- **Open Source Datasets:** 29+ datasets fully open-sourced

---

## ğŸ“‹ Table of Contents

- [Introduction](#-introduction)
- [Industrial & Open-Source Data Synthesis](#-industrial--open-source-data-synthesis)
- [Methods by Image Processing Type](#-methods-by-image-processing-type)
  - [Image Generation - Synthesizing New Visual Content](#-image-generation---synthesizing-new-visual-content)
    - [Geometric & Mathematical Reasoning](#-geometric--mathematical-reasoning)
    - [Document / Text-Dense Scenes](#-document--text-dense-scenes)
  - [Think with Image](#-think-with-image)
  - [Image Editing (Method + Data)](#-image-editing-method--data)
  - [Compositionality / Preference-Guided Synthesis](#-compositionality--preference-guided-synthesis)
  - [Interleaved Image-Text Â· Coherence & Consistency](#-interleaved-image-text--coherence--consistency)
  - [Image-Invariant Text Enhancement](#image-invariant-text-enhancement)
  - [VLM Self-Improvement & Reinforcement Learning](#-vlm-self-improvement--reinforcement-learning)
    - [Spatial Reasoning Enhancement](#-spatial-reasoning-enhancement)
    - [Continual Learning & Catastrophic Forgetting Mitigation](#-continual-learning--catastrophic-forgetting-mitigation)
    - [VLM Personalization & Concept Learning](#-vlm-personalization--concept-learning)
- [Cross-Domain Methodology Insights](#-cross-domain-methodology-insights)
- [Notable Multimodal Datasets](#-notable-multimodal-datasets)
  - [Interleaved Image-Text Datasets](#-interleaved-image-text-datasets)
  - [Domain-Specific & Knowledge-Oriented Datasets](#-domain-specific--knowledge-oriented-datasets)
  - [Large-Scale General Training Datasets](#-large-scale-general-training-datasets)
  - [Image Editing Datasets](#-image-editing-datasets)
- [Benchmark Datasets](#-benchmark-datasets)
- [Resources](#-resources)
- [Contributing](#-contributing)

---

## ğŸ¯ Introduction

Multimodal data synthesis is a critical technique for enhancing the performance of Vision-Language Models (VLMs). This repository collects and organizes:

- ğŸ¢ **Industrial Reports**: Detailed data synthesis pipelines and best practices from leading tech companies
- ğŸ“š **Academic Papers**: State-of-the-art research methods and innovative techniques
- ğŸ› ï¸ **Tools & Frameworks**: Practical data synthesis tools and codebases
- ğŸ“Š **Datasets**: High-quality multimodal datasets

**Key Observation**: Current multimodal data synthesis predominantly follows an "image-invariant + text-enhancement" paradigm, leveraging web resources, tool APIs, or other large models to improve the quality and diversity of image-text pairs.

---

## ğŸ¢ å¤§å‚ä¸å¼€æºé¡¹ç›®çš„æ•°æ®åˆæˆæ–¹æ³•

> This section features works with explicitly documented data synthesis pipelines. **Only includes projects with detailed descriptions of data construction and synthesis methods.**

### Baidu - Qianfan-VL

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [Qianfan-VL: Domain-Enhanced Universal Vision-Language Models](https://arxiv.org/abs/2509.18189)

**å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´9æœˆ

**æœºæ„**: ç™¾åº¦AIäº‘åƒå¸†å›¢é˜Ÿ

**ğŸ“Š æ•°æ®åˆæˆæ–¹æ³•ï¼ˆIntroduction & Section 3.2ï¼‰**:

åƒå¸†-VLä¸ºå…³é”®ä¼ä¸šåœºæ™¯å¼€å‘äº†**comprehensive data synthesis pipelines**ï¼Œæ¶µç›–å…­å¤§ä»»åŠ¡ç±»åˆ«ï¼š

**1. åˆæˆèŒƒå›´**ï¼ˆIntroductionæ˜ç¡®æŒ‡å‡ºï¼‰:
> "Our synthesis covers **six major task categories**: document OCR, mathematical problem-solving, chart understanding, table recognition, formula recognition, and natural scene OCR."

**ä»»åŠ¡ç±»åˆ«**:
- **æ–‡æ¡£OCR**: åˆæˆæ–‡æ¡£å›¾åƒç”ŸæˆåŠæ ‡æ³¨
- **æ•°å­¦é—®é¢˜æ±‚è§£**: è‡ªåŠ¨åŒ–æ•°å­¦é—®é¢˜å’Œè§£ç­”ç”Ÿæˆ
- **å›¾è¡¨ç†è§£**: ç¨‹åºåŒ–å›¾è¡¨ç”ŸæˆåŠQAå¯¹
- **è¡¨æ ¼è¯†åˆ«**: åˆæˆè¡¨æ ¼ç»“æ„å’Œå†…å®¹ç”Ÿæˆ
- **å…¬å¼è¯†åˆ«**: æ•°å­¦å…¬å¼æ¸²æŸ“å’Œæ ‡æ³¨
- **è‡ªç„¶åœºæ™¯OCR**: åœºæ™¯æ–‡å­—å›¾åƒåˆæˆ

**2. åˆæˆæ–¹æ³•**ï¼ˆIntroductionï¼‰:
> "By **combining traditional computer vision models with programmatic generation techniques**, we create high-quality training data at scale."

**å…³é”®æŠ€æœ¯**:
- **ä¼ ç»ŸCVæ¨¡å‹**: åˆ©ç”¨ç°æœ‰è®¡ç®—æœºè§†è§‰æ¨¡å‹è¿›è¡Œæ ‡æ³¨
- **ç¨‹åºåŒ–ç”Ÿæˆ**: ä½¿ç”¨åŸºäºä»£ç çš„ç”Ÿæˆæ–¹æ³•å¤„ç†ç»“æ„åŒ–å†…å®¹
- **é¢†åŸŸç‰¹å®šå¢å¼º**: é’ˆå¯¹æ¯ç§ä»»åŠ¡ç±»å‹çš„å®šåˆ¶å¢å¼ºç­–ç•¥
- **è´¨é‡éªŒè¯æœºåˆ¶**: è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥ç¡®ä¿æ•°æ®å¯é æ€§

**3. è®­ç»ƒæ•°æ®è§„æ¨¡**ï¼ˆSection 3.1 - å››é˜¶æ®µæ¸è¿›å¼è®­ç»ƒï¼‰:
- è·¨æ¨¡æ€å¯¹é½: 100B tokens
- é€šç”¨çŸ¥è¯†æ³¨å…¥: 2.66T tokens
- **é¢†åŸŸå¢å¼º: 0.32T tokens**ï¼ˆåˆæˆæ•°æ®åº”ç”¨äºæ­¤é˜¶æ®µï¼‰
- æŒ‡ä»¤å¾®è°ƒ: 1B tokens

**4. è´¨é‡ä¿è¯**ï¼ˆIntroductionï¼‰:
> "Each pipeline incorporates **domain-specific augmentation strategies and quality verification mechanisms** to ensure data reliability."

**æ¨¡å‹å˜ä½“ä¸èƒ½åŠ›**:
- **Qianfan-VL-3B**: 32Kä¸Šä¸‹æ–‡ï¼Œä¼˜åŒ–ç”¨äºè¾¹ç¼˜è®¾å¤‡å’Œå®æ—¶OCR
- **Qianfan-VL-8B**: 32Kä¸Šä¸‹æ–‡ï¼Œå¸¦æ€ç»´é“¾ï¼Œç”¨äºæœåŠ¡å™¨å’Œé€šç”¨åº”ç”¨
- **Qianfan-VL-70B**: 32Kä¸Šä¸‹æ–‡ï¼Œå¸¦æ€ç»´é“¾ï¼Œç”¨äºäº‘ç«¯å’Œå¤æ‚æ¨ç†

**å®éªŒç»“æœ**:
- **OCRBench**: 873åˆ†ï¼ˆ70Bç‰ˆæœ¬ï¼‰
- **DocVQA**: 94.75%å‡†ç¡®ç‡ï¼ˆ70Bç‰ˆæœ¬ï¼‰
- **MathVista**: 78.6%åˆ†æ•°ï¼ˆ70Bç‰ˆæœ¬ï¼‰
- é€šç”¨åŸºå‡†å¼ºåŠ²è¡¨ç°: CCBench, SEEDBench_IMG, ScienceQA, MMStar

**è®­ç»ƒåŸºç¡€è®¾æ–½**:
- å®Œå…¨åœ¨ç™¾åº¦**æ˜†ä»‘P800èŠ¯ç‰‡**ä¸Šè®­ç»ƒ
- åœ¨5000+èŠ¯ç‰‡é›†ç¾¤ä¸Šå®ç°**>90%æ‰©å±•æ•ˆç‡**
- éªŒè¯äº†ä¸“æœ‰ç¡¬ä»¶è®­ç»ƒSOTAæ¨¡å‹çš„å¯è¡Œæ€§

**âœ… æŠ€æœ¯æŠ¥å‘Š**:
- [arXiv:2509.18189](https://arxiv.org/abs/2509.18189)
- é¢†åŸŸå¢å¼ºå¤šæ¨¡æ€æ¨¡å‹çš„ç»¼åˆæ–¹æ³•è®º

**æ„ä¹‰**:
- **å¤šé¢†åŸŸåˆæˆ**: è¦†ç›–å…­å¤§å…³é”®ä¼ä¸šä»»åŠ¡ç±»åˆ«
- **æ··åˆæ–¹æ³•**: ç»“åˆCVæ¨¡å‹å’Œç¨‹åºåŒ–ç”Ÿæˆ
- **å¤§è§„æ¨¡åº”ç”¨**: 0.32T tokensçš„é¢†åŸŸç‰¹å®šåˆæˆæ•°æ®
- **è´¨é‡ä¼˜å…ˆ**: æ•´ä¸ªpipelineèå…¥éªŒè¯æœºåˆ¶
- **ä¼ä¸šå°±ç»ª**: ä¸ºä¼ä¸šéƒ¨ç½²åœºæ™¯è€Œè®¾è®¡

</details>

### Alibaba - Qwen-VL Series

<details>
<summary>Click to expand</summary>

**Papers**:
- [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](https://arxiv.org/abs/2308.12966)

**ğŸ“Š Data Synthesis Method (Section 3.1.2)**:

Qwen-VL paper describes grounding data construction in Section 3.1.2:

1. **Grounding Data Synthesis** (Section 3.1.2):
   - Utilizes existing detection datasets (COCO, Objects365) with bbox annotations
   - **Converts bbox coordinates to normalized text format** (e.g., `<box>0.1,0.2,0.3,0.4</box>`)
   - **Generates instructions**: Creates instruction-response pairs like "find X in the image"
   - This is a data synthesis method that converts structured annotations to text format

**âš ï¸ Note**:
- This is **data format conversion and instruction generation**, classified as data synthesis
- The paper does not fully disclose prompt templates or generation methods
- Other parts (data sources, cleaning) are mainly data collection and filtering, not synthesis

</details>

### Alibaba - MMEvol (2024)

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct](https://arxiv.org/abs/2409.05840)

**æœºæ„**: é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢ï¼ˆFei Huang, Yongbin Liç­‰ï¼‰

**ğŸ“Š æ•°æ®åˆæˆæ–¹æ³•ï¼ˆæ˜ç¡®æè¿°ï¼‰**:

MMEvolæå‡ºäº†ä¸€ç§**å¤šæ¨¡æ€æŒ‡ä»¤è¿›åŒ–æ¡†æ¶**ï¼Œé€šè¿‡è¿­ä»£æå‡æ•°æ®è´¨é‡å’Œå¤æ‚åº¦ï¼š

1. **æ ¸å¿ƒæ–¹æ³• - Evol-InstructèŒƒå¼**ï¼ˆåŸºäºæ–‡æœ¬é¢†åŸŸçš„Evol-Instructï¼‰:
   - ä»åˆå§‹ç§å­æ•°æ®**SEED-163K**å¼€å§‹
   - **è¿­ä»£è¿›åŒ–**: é€šè¿‡å¤šè½®æŒç»­æ”¹è¿›æŒ‡ä»¤æ•°æ®
   - ä¸‰ä¸ªè¿›åŒ–ç»´åº¦:
     a) **ç»†ç²’åº¦æ„ŸçŸ¥**: æŒ–æ˜å›¾åƒä¸­çš„è¯¦ç»†ä¿¡æ¯
     b) **è®¤çŸ¥æ¨ç†**: æ‰©å±•è§†è§‰æ¨ç†æ­¥éª¤ï¼Œå¢å¼ºæ¨ç†èƒ½åŠ›
     c) **äº¤äº’è¿›åŒ–**: æå‡æŒ‡ä»¤ç±»å‹çš„å¤šæ ·æ€§

2. **æ•°æ®è¿›åŒ–Pipeline**:
   - åˆå§‹æŒ‡ä»¤ â†’ è¿›åŒ–æ“ä½œ â†’ æ›´å¤æ‚/å¤šæ ·çš„æŒ‡ä»¤
   - ç³»ç»ŸåŒ–æ‰©å±•æŒ‡ä»¤ç±»å‹å¤šæ ·æ€§
   - é€æ­¥æå‡è§†è§‰æ¨ç†å¤æ‚åº¦
   - æ·±å…¥æ¢ç´¢å›¾åƒä¸­çš„ç»†ç²’åº¦ä¿¡æ¯

3. **å®éªŒç»“æœ**ï¼ˆSection 5ï¼‰:
   - ç›¸æ¯”åŸºçº¿æ¨¡å‹ï¼ˆä½¿ç”¨ç§å­æ•°æ®ï¼‰ï¼Œ**å¹³å‡å‡†ç¡®ç‡æå‡3.1ä¸ªç™¾åˆ†ç‚¹**
   - **åœ¨9ä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°SOTA**ï¼Œä½¿ç”¨æ›´å°‘æ•°æ®
   - åœ¨13ä¸ªè§†è§‰-è¯­è¨€ä»»åŠ¡ä¸Šå…¨é¢è¯„ä¼°

**æ•°æ®è§„æ¨¡**:
- åˆå§‹ç§å­: SEED-163K
- é€šè¿‡è¿›åŒ–ç”Ÿæˆæ›´å¤šæ ·åŒ–å’Œå¤æ‚çš„æ•°æ®

**âœ… è®ºæ–‡**:
- [arXiv:2409.05840](https://arxiv.org/abs/2409.05840)
- æœ€æ–°ç‰ˆæœ¬: v5ï¼ˆ2024å¹´12æœˆ31æ—¥ï¼‰

**ä¸Oasisçš„å…³ç³»**:
- Oasisè®ºæ–‡å°†MMEvolä½œä¸ºå¯¹æ¯”æ–¹æ³•ä¹‹ä¸€
- MMEvolä¸“æ³¨äºè¿­ä»£è¿›åŒ–å·²æœ‰æ•°æ®ï¼Œè€ŒOasisä¸“æ³¨äºä»å•å›¾ç”Ÿæˆæ•°æ®
- ä¸¤ç§æ–¹æ³•éƒ½èƒ½æå‡æ•°æ®å¤šæ ·æ€§å’Œè´¨é‡

</details>

### ByteDance - Oasis

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis](https://arxiv.org/html/2503.08741v2)

**ğŸ“Š æ•°æ®åˆæˆæ–¹æ³•ï¼ˆSection 3.2è¯¦ç»†æè¿°ï¼‰**:

**è¿™æ˜¯æœ€æ–°çš„çªç ´æ€§å·¥ä½œï¼** Oasisæå‡ºäº†ä¸€ç§æç®€çš„æ•°æ®åˆæˆæ–¹æ³•ï¼Œçµæ„Ÿæ¥è‡ªMagpieï¼Œä½†åº”ç”¨äºå¤šæ¨¡æ€é¢†åŸŸï¼š

1. **æ ¸å¿ƒåˆ›æ–° - "Hooking" Prompt**ï¼ˆSection 3.2 Step 1ï¼‰:

   **å…³é”®çªç ´**:
   - **åªè¾“å…¥å›¾åƒ**ï¼Œä¸éœ€è¦ä»»ä½•æ–‡æœ¬promptï¼
   - è®©MLLMï¼ˆå¦‚Qwen2-VLï¼‰è‡ªå·±ç”Ÿæˆinstruction
   - åˆ©ç”¨æ¨¡å‹çš„è‡ªå›å½’ç‰¹æ€§ï¼ŒåŸºäºå›¾åƒè‡ªåŠ¨ç”Ÿæˆå¤šæ ·åŒ–çš„é—®é¢˜

   **ä¸ºä»€ä¹ˆæœ‰æ•ˆ**:
   - æ‰“ç ´ä¼ ç»Ÿçš„å›ºå®špromptæ¨¡å¼ï¼Œå¤§å¹…æå‡æ•°æ®å¤šæ ·æ€§
   - æ¨¡å‹æ ¹æ®è‡ªå·±çš„çŸ¥è¯†åº“ç”Ÿæˆé—®é¢˜ï¼Œè¦†ç›–é¢æ›´å¹¿
   - ç®€å•é«˜æ•ˆï¼Œä¸éœ€è¦äººå·¥è®¾è®¡å¤æ‚çš„prompt

2. **æ•°æ®åˆ†ç±»**ï¼ˆSection 3.2 Step 2ï¼‰:
   - ä½¿ç”¨LLMè¿‡æ»¤æ‰éæŒ‡ä»¤ç±»æ•°æ®ï¼ˆå¦‚çº¯æè¿°æ€§æ–‡æœ¬ï¼‰
   - ç¡®ä¿ç”Ÿæˆçš„éƒ½æ˜¯question-answeræ ¼å¼

3. **å››ç»´è´¨é‡æ§åˆ¶**ï¼ˆSection 3.2 Step 3ï¼Œé™„å½•B.2å®Œæ•´å…¬å¼€ï¼‰:

   è®ºæ–‡è®¾è®¡äº†ä¸¥æ ¼çš„è´¨é‡è¯„ä¼°æ ‡å‡†ï¼ˆ1-5åˆ†ï¼‰ï¼š

   a) **Solvabilityï¼ˆå¯è§£æ€§ï¼‰**: å›¾åƒæ˜¯å¦åŒ…å«è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜
   b) **Hallucinationï¼ˆå¹»è§‰ï¼‰**: é—®é¢˜æ˜¯å¦ä¸å›¾åƒå†…å®¹ä¸€è‡´
   c) **Clarityï¼ˆæ¸…æ™°åº¦ï¼‰**: é—®é¢˜è¡¨è¿°æ˜¯å¦æ˜ç¡®
   d) **Nonsenseï¼ˆæ— æ„ä¹‰ï¼‰**: é—®é¢˜æ˜¯å¦è¯­æ³•æ­£ç¡®ã€é€»è¾‘åˆç†

   - æ¯ä¸ªç»´åº¦éƒ½æœ‰è¯¦ç»†çš„è¯„åˆ†æ ‡å‡†ï¼ˆé™„å½•B.2å®Œæ•´promptï¼‰
   - å¤šç»´åº¦ç»¼åˆè¯„ä¼°ï¼Œç¡®ä¿é«˜è´¨é‡

**æ•°æ®è§„æ¨¡**:
- ç”Ÿæˆäº†500Ké«˜è´¨é‡æŒ‡ä»¤æ•°æ®
- åœ¨LLaVA-NeXTä¸ŠéªŒè¯æœ‰æ•ˆæ€§

**é¢†åŸŸå®šåˆ¶èƒ½åŠ›**:
- ç”±äºåªä¾èµ–å›¾åƒï¼Œå¯ä»¥é€šè¿‡æ§åˆ¶å›¾åƒæ¥æºæ¥ç”Ÿæˆç‰¹å®šé¢†åŸŸæ•°æ®
- è®ºæ–‡å±•ç¤ºäº†OCRé¢†åŸŸçš„æ¡ˆä¾‹ï¼ˆSection 4.3ï¼‰

**å®éªŒç»“æœ**ï¼ˆSection 4.2ï¼‰:
- åœ¨14ä¸ªbenchmarkä¸Šæ˜¾è‘—æå‡æ€§èƒ½
- ä¼˜äºå…¶ä»–æ•°æ®åˆæˆæ–¹æ³•ï¼ˆåŒ…æ‹¬LLaVAã€ALLAVAã€MMEvolç­‰ï¼‰

**Oasisè®ºæ–‡ä¸­æåˆ°çš„å¯¹æ¯”æ–¹æ³•**ï¼ˆSection 4.2ï¼‰:
- **LLaVA** [24]: GPT-4è¾…åŠ©ç”Ÿæˆï¼ˆè§ä¸‹æ–¹"LLaVAç³»åˆ—"æ¡ç›®ï¼‰
- **MMEvol** [29]: é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢çš„å›¾åƒ-æ–‡æœ¬æŒ‡ä»¤è¿›åŒ–æ¡†æ¶ï¼ˆè§ä¸Šæ–¹"é˜¿é‡Œå·´å·´ - MMEvol"æ¡ç›®ï¼‰
- **ALLaVA** [4]: Captioning-then-QAæ–¹å¼ï¼ˆè§ä¸‹æ–¹"æŒ‰å›¾åƒå¤„ç†æ–¹å¼åˆ†ç±»"æ¡ç›®ï¼‰

**Oasisçµæ„Ÿæ¥æº**:
- **Magpie** [43]: æ–‡æœ¬é¢†åŸŸè‡ªå¯¹é½æŒ‡ä»¤ç”Ÿæˆæ–¹æ³•ï¼ˆå¯å‘äº†Oasisçš„"hooking prompt"æ ¸å¿ƒæ€æƒ³ï¼‰
  - Oasiså°†Magpieçš„æ€æƒ³æ‰©å±•åˆ°å¤šæ¨¡æ€é¢†åŸŸï¼Œå®ç°äº†ä»…ç”¨å›¾åƒçš„æŒ‡ä»¤ç”Ÿæˆ

**âœ… å®Œå…¨å¼€æº**:
- è®ºæ–‡æ‰¿è¯ºå¼€æº500Kæ•°æ®å’Œæ¨¡å‹
- æ‰€æœ‰è´¨é‡æ§åˆ¶çš„promptéƒ½åœ¨é™„å½•Bå…¬å¼€

**é‡è¦æ€§**:
- **æç®€æ–¹æ³•è®º**: åªéœ€è¦å›¾åƒï¼Œä¸éœ€è¦captionæˆ–å…¶ä»–æ–‡æœ¬
- **è´¨é‡ä¿è¯**: å››ç»´è´¨é‡æ§åˆ¶éå¸¸ç³»ç»Ÿ
- **å¯å¤ç°**: æ‰€æœ‰promptå’Œæ–¹æ³•éƒ½å®Œæ•´å…¬å¼€

</details>

### Microsoft - Florence-2

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks](https://arxiv.org/abs/2311.06242)

**å‘å¸ƒæ—¶é—´**: arXiv 2023å¹´11æœˆ

**æœºæ„**: Azure AI, Microsoft

**ğŸ“Š æ•°æ®åˆæˆæ–¹æ³•ï¼ˆIntroduction & Section 2ï¼‰**:

Florence-2å¼€å‘äº†ä¸€ä¸ª**è‡ªåŠ¨åŒ–æ•°æ®å¼•æ“**æ¥ç”Ÿæˆå¤§è§„æ¨¡**FLD-5B**æ•°æ®é›†ï¼š

1. **æ•°æ®è§„æ¨¡**ï¼ˆAbstractï¼‰:
   - **54äº¿comprehensive visual annotations**
   - è¦†ç›–**1.26äº¿images**
   - æœ€å¤§è§„æ¨¡çš„è‡ªåŠ¨æ ‡æ³¨å¤šæ¨¡æ€æ•°æ®é›†ä¹‹ä¸€

2. **è‡ªåŠ¨åŒ–æ•°æ®å¼•æ“ - åŒæ¨¡å—Pipeline**ï¼ˆIntroductionï¼Œç¬¬2é¡µï¼‰:

   **æ¨¡å—1 - åä½œè‡ªåŠ¨æ ‡æ³¨**:
   > "uses specialized models to collaboratively and autonomously annotate images, moving away from the traditional single and manual annotation approach. Multiple models work together to reach a consensus"

   - åˆ©ç”¨å¤šä¸ªä¸“é—¨æ¨¡å‹åä½œè¿›è¡Œå›¾åƒæ ‡æ³¨
   - æ¨¡å‹é€šè¿‡å¤šæ¨¡å‹ä¸€è‡´æ€§è¾¾æˆå…±è¯†ï¼ˆå—"ç¾¤ä½“æ™ºæ…§"æ¦‚å¿µå¯å‘ï¼‰
   - ç¡®ä¿æ›´å¯é å’Œæ— åçš„å›¾åƒç†è§£
   - å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œæ¶ˆé™¤äººå·¥æ ‡æ³¨éœ€æ±‚

   **æ¨¡å—2 - è¿­ä»£ç²¾ç‚¼ä¸è¿‡æ»¤**:
   > "iteratively refines and filters these automated annotations using well-trained foundational models"

   - ä½¿ç”¨è®­ç»ƒè‰¯å¥½çš„åŸºç¡€æ¨¡å‹è¿­ä»£ç²¾ç‚¼å’Œè¿‡æ»¤æ ‡æ³¨
   - **è¿­ä»£ç­–ç•¥**: æ¨¡å‹æ ‡æ³¨ â†’ ç²¾ç‚¼ â†’ æ¨¡å‹é‡è®­ç»ƒ â†’ å†æ ‡æ³¨å¾ªç¯
   - æŒç»­æå‡æ ‡æ³¨è´¨é‡

3. **æ ‡æ³¨è¦†ç›–èŒƒå›´**ï¼ˆIntroductionï¼‰:
   FLD-5Bæ•°æ®é›†æ¶µç›–å¤šä¸ªè§†è§‰ä»»åŠ¡ï¼š
   - **å›¾åƒcaptioning**ï¼ˆå„ç§è¯­ä¹‰ç²’åº¦ï¼‰
   - **ç‰©ä½“æ£€æµ‹**ï¼ˆç©ºé—´å±‚æ¬¡ç†è§£ï¼‰
   - **Grounding**ï¼ˆæ–‡æœ¬-åŒºåŸŸå¯¹é½ï¼‰
   - **åˆ†å‰²**ï¼ˆç»†ç²’åº¦è§†è§‰ç†è§£ï¼‰

4. **æ ¸å¿ƒåˆ›æ–°**:
   - **å®Œå…¨è‡ªåŠ¨åŒ–pipeline**: æ— éœ€äººå·¥æ ‡æ³¨
   - **å¤šä»»åŠ¡ç»Ÿä¸€æ ¼å¼**: æ‰€æœ‰æ ‡æ³¨è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ç”¨äºç»Ÿä¸€å­¦ä¹ 
   - **è¿­ä»£æ”¹è¿›**: é€šè¿‡æ¨¡å‹-æ ‡æ³¨å…±åŒè¿›åŒ–æŒç»­æå‡è´¨é‡
   - **Billionçº§è§„æ¨¡**: è¾¾åˆ°å‰æ‰€æœªæœ‰çš„æ ‡æ³¨è§„æ¨¡

**æ¨¡å‹æ¶æ„**:
- Sequence-to-sequence (seq2seq)ç»“æ„
- ç»Ÿä¸€çš„åŸºäºpromptçš„è¡¨ç¤ºç”¨äºå¤šç§è§†è§‰ä»»åŠ¡
- å•ä¸€æ¨¡å‹å¤„ç†å¤šä¸ªä»»åŠ¡ï¼Œæ— éœ€ä»»åŠ¡ç‰¹å®šæ¶æ„ä¿®æ”¹

**å®éªŒç»“æœ**:
- **Zero-shot SOTA**: åœ¨COCO captioningã€Flickr30k visual groundingã€RefCOCO/+/g referring expression comprehensionä¸Šè¾¾åˆ°æ–°çš„zero-shot SOTA
- **è¿ç§»å­¦ä¹ **: å¤§å¹…è¶…è¶ŠImageNeté¢„è®­ç»ƒï¼Œåœ¨COCOå’ŒADE20Kæ•°æ®é›†ä¸Šæå‡6.9ã€5.5å’Œ5.9ä¸ªç‚¹
- **è®­ç»ƒæ•ˆç‡**: æ¯”ç›‘ç£é¢„è®­ç»ƒå¿«4Ã—

**âœ… å¼€æº**:
- æ¨¡å‹: åœ¨HuggingFaceå¯ç”¨
- ä»£ç : [Microsoft Florence](https://github.com/microsoft/Florence)

**æ„ä¹‰**:
- **å·¥ä¸šè§„æ¨¡æ•°æ®å¼•æ“**: å±•ç¤ºäº†å®Œå…¨è‡ªåŠ¨åŒ–å¤§è§„æ¨¡æ ‡æ³¨çš„å¯è¡Œæ€§
- **å¤šä»»åŠ¡åˆæˆ**: ç»Ÿä¸€æ–¹æ³•ç”Ÿæˆå¤šç§æ ‡æ³¨ç±»å‹
- **é€šè¿‡å…±è¯†ä¿è¯è´¨é‡**: å¤šæ¨¡å‹åä½œç¡®ä¿æ ‡æ³¨å¯é æ€§

</details>

### Tencent Hunyuan - Bee, HoneyPipe & DataStudio

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs](https://arxiv.org/abs/2510.13795)

**å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´10æœˆ

**æœºæ„**: è…¾è®¯æ··å…ƒå›¢é˜Ÿ & æ¸…åå¤§å­¦

**ä½œè€…**: Yi Zhang, Bolin Ni, Xin-Sheng Chen, Heng-Rui Zhang, Yongming Rao, Houwen Peng, Qinglin Lu, Han Hu, Meng-Hao Guo, Shi-Min Hu

**ğŸ“Š ä¸‰å¤§æ ¸å¿ƒè´¡çŒ®**:

**1. Honey-Data-15M**: 1500ä¸‡æ ·æœ¬çš„SFTæ•°æ®é›†ï¼Œç»è¿‡ç²¾å¿ƒæ¸…æ´—å¹¶enriched withåŒå±‚æ€ç»´é“¾æ¨ç†

**2. HoneyPipe + DataStudio**: æ•°æ®ç­›é€‰pipelineåŠå…¶åº•å±‚æ¨¡å—åŒ–æ¡†æ¶ï¼Œæä¾›é€æ˜ä¸”å¯é€‚åº”çš„æ–¹æ³•è®º

**3. Bee-8B**: 8Bæ¨¡å‹ï¼Œåœ¨å®Œå…¨å¼€æºMLLMä¸­å»ºç«‹æ–°SOTAï¼Œä¸åŠå¼€æºæ¨¡å‹ï¼ˆå¦‚InternVL3.5-8Bï¼‰ç«äº‰

---

**ğŸ“Š æ•°æ®åˆæˆæ–¹æ³• - HoneyPipeï¼ˆSection 2ï¼‰**:

HoneyPipeæ˜¯ä¸€ä¸ª**è‡ªåŠ¨åŒ–ä¸”å¯å¤ç°çš„å·¥ä½œæµ**ï¼ŒåŸºäº**DataStudioçš„æ¨¡å—åŒ–ç»„ä»¶**æ„å»ºï¼Œé‡‡ç”¨ç²¾å¦™çš„**åŒå±‚æ¨ç†å¢å¼ºç­–ç•¥**ï¼šå¤§è§„æ¨¡çŸ­CoTå¢å¼ºçš„åŸºç¡€è·¯å¾„ + é’ˆå¯¹å¤æ‚æŒ‡ä»¤çš„é•¿CoTä¸“ç”¨å¾ªç¯ã€‚

**ğŸ”§ é˜¶æ®µ1ï¼šæ•°æ®èšåˆä¸å‡†å¤‡**
- **åˆå§‹æ± **: çº¦2400ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œæ¥è‡ªå¤šä¸ªç¤¾åŒºæ•°æ®é›†
  - æ¥æºï¼šLLaVA-OneVisionã€PixMoã€MAmmoTH-VLç­‰
  - æŒ‘æˆ˜ï¼šæ˜¾è‘—çš„å†…å®¹é‡å 
- **ä¸¥æ ¼å»é‡**ï¼ˆpairçº§åˆ«ï¼‰:
  - æ–¹æ³•ï¼šæ„ŸçŸ¥å“ˆå¸Œï¼ˆå›¾åƒï¼‰+ Simhashï¼ˆæŒ‡ä»¤ï¼‰
  - ç§»é™¤æ ‡å‡†ï¼šå›¾åƒ**å’Œ**æŒ‡ä»¤**éƒ½**å¿…é¡»ç›¸åŒ
  - ç›®çš„ï¼šæœ€å¤§åŒ–å¤šæ ·æ€§ï¼Œæå‡å¤„ç†æ•ˆç‡
- **é¢†åŸŸæ ‡æ³¨**: äººå·¥æ£€æŸ¥å’Œåˆ†ç±»
  - é¢†åŸŸï¼šGeneralã€Chartã€OCRã€STEMç­‰
  - ç›®çš„ï¼šæŒ‡å¯¼åç»­å¤„ç†
- **è¾“å‡º**: å¸¦é¢†åŸŸæ ‡ç­¾çš„æ¸…æ´ã€å”¯ä¸€å›¾åƒ-æŒ‡ä»¤-å“åº”ä¸‰å…ƒç»„

**ğŸ”§ é˜¶æ®µ2ï¼šå™ªå£°ä¸æ— å…³æ€§è¿‡æ»¤**
- **åŸºäºè§„åˆ™çš„ç®—å­**ï¼ˆæ ¼å¼é—®é¢˜ï¼‰:
  - ç§»é™¤éå¸¸å°çš„å›¾åƒ
  - è¿‡æ»¤æç«¯é•¿å®½æ¯”
  - æ¶ˆé™¤æŒ‡ä»¤ä¸­çš„é‡å¤æ–‡æœ¬
- **åŸºäºæ¨¡å‹çš„è¿‡æ»¤ç®—å­**ï¼ˆä½¿ç”¨**Qwen2.5-VL-72B**ï¼‰:
  - è¯„ä¼°ï¼šæŒ‡ä»¤æ˜¯å¦é€»è¾‘åˆç†ä¸”å¯å›ç­”ï¼Ÿ
  - éªŒè¯ï¼šæŒ‡ä»¤ä¸è§†è§‰å†…å®¹æ˜¯å¦è¯­ä¹‰ç›¸å…³ï¼Ÿ
  - ç¤ºä¾‹ï¼šå°†"è§£å†³è¿™ä¸ªå‡½æ•°é—®é¢˜"æ ‡è®°ä¸ºä¸æ©™å­å›¾åƒæ— å…³
- **ç»“æœ**: æœ‰æ•ˆå‰ªææœ‰ç¼ºé™·çš„æ ·æœ¬ï¼Œäº§ç”Ÿæ¸…æ´çš„å›¾åƒ-æŒ‡ä»¤å¯¹

**ğŸ”§ é˜¶æ®µ3ï¼šçŸ­CoTå¢å¼ºä¸éªŒè¯**ï¼ˆåŸºç¡€è·¯å¾„ï¼‰

*æ­¤é˜¶æ®µé’ˆå¯¹éœ€è¦ä¸­ç­‰æ¨ç†çš„æŒ‡ä»¤*

**æ•°æ®åˆ†æµ**:
- CVä»»åŠ¡ï¼ˆOCRã€ç‰©ä½“æ£€æµ‹ï¼‰â†’ **è·³è¿‡å¢å¼º** â†’ æœ€ç»ˆæ•°æ®é›†
- å…¶ä»–æ ·æœ¬ â†’ è¿›å…¥CoTå¢å¼ºæµç¨‹

**çŸ­CoTå¢å¼º**ï¼ˆçº¦1220ä¸‡æ ·æœ¬ï¼‰:
- **é¢„å¤„ç†**: ç§»é™¤æŠ‘åˆ¶æ¨ç†çš„æç¤º
  - ç§»é™¤ï¼š"ç›´æ¥å›ç­”"ç­‰å¤´å°¾æç¤º
  - ç›®çš„ï¼šæ¿€å‘å…¨é¢çš„ã€é€æ­¥çš„å“åº”
- **ç”Ÿæˆ**: ä½¿ç”¨**Qwen2.5-VL-72B/32B**ï¼ˆå¼ºå¤§çš„å¼€æºMLLMsï¼‰
  - å°†ç®€å•çŸ­å“åº” â†’ è¯¦ç»†æ¨ç†è·¯å¾„
  - **æ— é¢å¤–ç³»ç»Ÿæç¤º**: æ¨¡å‹å·²æ“…é•¿å¤šæ­¥éª¤å“åº”
  - é¿å…çº¦æŸï¼šä¿æŒè¾“å‡ºå¤šæ ·æ€§
- 12.2MçŸ­CoTæ ·æœ¬çš„**ä¸»è¦æ¥æº**

**ä¿çœŸåº¦éªŒè¯**ï¼ˆLLM-as-a-Judgeï¼‰:
- **éªŒè¯å™¨æ¨¡å‹**: Qwen2.5-VL-72B
- **æ–¹æ³•**: æ–°ç”ŸæˆCoTæœ€ç»ˆç»“è®ºä¸åŸå§‹å“åº”ä¹‹é—´çš„è¯­ä¹‰æ¯”è¾ƒ
- **è¯„ä¼°æ ‡å‡†**ï¼ˆåŒé‡ï¼‰:
  - **äº‹å®æ€§æŸ¥è¯¢**ï¼ˆå®¢è§‚ï¼‰: æœ€ç»ˆå“åº”å¿…é¡»**ç²¾ç¡®**åŒ¹é…
  - **æè¿°æ€§æŸ¥è¯¢**ï¼ˆä¸»è§‚ï¼‰: éœ€è¦ä¸»é¢˜ç›¸å…³æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§
- **é€šè¿‡** â†’ åŠ å…¥æœ€ç»ˆæ•°æ®é›†
- **å¤±è´¥** â†’ **ä¸ä¸¢å¼ƒ**ï¼Œè·¯ç”±åˆ°é•¿CoTå¢å¼ºå¾ªç¯è¿›è¡Œä¸“é—¨å¢å¼º

**ğŸ”§ é˜¶æ®µ4ï¼šé•¿CoTå¢å¼ºå¾ªç¯**ï¼ˆå¤æ‚æŒ‡ä»¤ä¸“ç”¨è·¯å¾„ï¼‰

*ä¸“ä¸ºéœ€è¦æ·±åº¦ã€å¤šæ­¥éª¤é—®é¢˜è§£å†³çš„æœ€å¤æ‚æŒ‡ä»¤è®¾è®¡*

**è¾“å…¥æ¥æº**ï¼ˆ3ç§ä¸»è¦ç±»å‹ï¼‰:
1. **å¤±è´¥æ ·æœ¬**: é˜¶æ®µ3ä¿çœŸåº¦éªŒè¯å¤±è´¥çš„æ ·æœ¬
2. **ç‰¹å®šæ•°æ®æº**: è¯†åˆ«ä¸ºå›ºæœ‰å¤æ‚çš„æ•°æ®æº
   - ä¾‹å¦‚ï¼šVisualWebInstruct
   - ç­–ç•¥ï¼šä¸»åŠ¨ç”Ÿæˆé•¿CoT**å¹¶ä¸”**åŒæ—¶ç”ŸæˆçŸ­CoT
3. **éªŒè¯æ•°æ®é›†**: å…ˆå‰ç ”ç©¶éªŒè¯çš„æ•°æ®é›†
   - ä¾‹å¦‚ï¼šVision-R1
   - æ ‡å‡†ï¼šç‰¹åˆ«é€‚åˆç”Ÿæˆæ·±åº¦æ¨ç†é“¾

**æ·±åº¦æ¨ç†ç”Ÿæˆ**ï¼ˆçº¦270ä¸‡æ ·æœ¬ï¼‰:
- **æ¨¡å‹**: åˆ©ç”¨**é¡¶çº§ä¸“æœ‰MLLMs**ç”Ÿæˆæ›´è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆ
- **è¿‡ç¨‹**:
  - é¦–å…ˆç”Ÿæˆæ·±åº¦æ¨ç†ï¼ˆé€šå¸¸ä½¿ç”¨`<think></think>`æ ‡ç­¾ç»“æ„åŒ–ï¼‰
  - ç„¶åè¾“å‡ºæœ€ç»ˆå“åº”
- **èƒ½åŠ›**: å¤„ç†åˆå§‹å¼€æºæ¨¡å‹æ— æ³•èƒœä»»çš„å¤æ‚æŒ‡ä»¤

**æœ€ç»ˆä¿çœŸåº¦éªŒè¯**:
- ä¸é˜¶æ®µ3ç›¸åŒçš„éªŒè¯è¿‡ç¨‹
- **é€šè¿‡** â†’ æ„æˆHoney-Data-15Mä¸­çº¦270ä¸‡é•¿CoTæ•°æ®ç‚¹
- **å¤±è´¥** â†’ **ä¸¢å¼ƒ**ï¼ˆå‡å®šä¸ºé”™è¯¯ã€æ— è§£æˆ–æ ‡æ³¨æˆæœ¬è¿‡é«˜ï¼‰

---

**ğŸ“¦ æœ€ç»ˆæ•°æ®é›† - Honey-Data-15M**:

**è§„æ¨¡**: 1500ä¸‡ç²¾å¿ƒç­›é€‰æ ·æœ¬

**ç»„æˆ**ï¼ˆ7å¤§é¢†åŸŸï¼‰:
- Generalï¼ˆ36.8%ï¼‰: åŸºç¡€è§†è§‰ç†è§£
- Chartï¼ˆ24.6%ï¼‰: å›¾è¡¨ç†è§£ä¸æ¨ç†
- Captionï¼ˆ15.1%ï¼‰: å›¾åƒæè¿°
- STEMï¼ˆ7.6%ï¼‰: ç¬¦å·æ¨ç†ï¼ˆæ•°å­¦ã€ç§‘å­¦ã€å‡ ä½•ï¼‰
- Documentï¼ˆ5.9%ï¼‰: æ–‡æ¡£ç†è§£ä¸OCR
- Grounding & Countingï¼ˆ5.1%ï¼‰: ç‰©ä½“æ£€æµ‹ä¸è®¡æ•°
- OCRï¼ˆ4.9%ï¼‰: å„ç§åœºæ™¯æ–‡æœ¬è¯†åˆ«

**åŒå±‚CoTä¸»å¹²**:
- **çº¦1220ä¸‡çŸ­CoTæ ·æœ¬**: ä¸­ç­‰æ¨ç†çš„åŸºç¡€æ€§ã€é€æ­¥é€»è¾‘æ¨æ–­
- **çº¦270ä¸‡é•¿CoTæ ·æœ¬**: å¤æ‚é—®é¢˜è§£å†³çš„å¤æ‚ã€å¤šæ­¥æ¨ç†ï¼Œéœ€è¦æ›´æ·±å…¥çš„ç»¼åˆ
- **é’ˆå¯¹æ€§æ–¹æ³•**: æ ¹æ®æŒ‡ä»¤å¤æ‚åº¦å®šåˆ¶å“åº”æ·±åº¦
- **å›ºæœ‰è§£å†³æ–¹æ¡ˆ**: è¯†åˆ«å“ªäº›æŒ‡ä»¤éœ€è¦è¯¦ç»†çš„å¤šæ­¥éª¤è§£å†³æ–¹æ¡ˆ

---

**ğŸ¤– Bee-8Bæ¨¡å‹ - éªŒè¯ä¸æ€§èƒ½**:

**æ¶æ„**:
- LLM: Qwen3-8Bï¼ˆæ¨ç†å’Œæ–‡æœ¬ç”Ÿæˆï¼‰
- è§†è§‰ç¼–ç å™¨: SigLIP2-so400m-patch14-384
- åˆ†è¾¨ç‡ç­–ç•¥: Anyresï¼ˆå¤„ç†å¯å˜åˆ†è¾¨ç‡ï¼Œä¿ç•™ç»†ç²’åº¦ç»†èŠ‚ï¼‰
- æŠ•å½±å™¨: å¸¦GELUæ¿€æ´»çš„ä¸¤å±‚MLP

**è®­ç»ƒ**: 5é˜¶æ®µæ¸è¿›å¼è¿‡ç¨‹ï¼ˆè¯¦è§Section 3.2ï¼‰

**æ€§èƒ½äº®ç‚¹**ï¼ˆåœ¨å®Œå…¨å¼€æºMLLMä¸­å»ºç«‹æ–°SOTAï¼‰:

*é€šç”¨VQA*:
- **MMMU**: 66.8ï¼ˆä¸åŠå¼€æºæ¨¡å‹ç«äº‰ï¼‰
- **MMMU-Pro**: 50.7ï¼ˆ**é¢†å…ˆQwen2.5-VL-7B 3.6%**ï¼‰
- **MMStar**: 71.4
- **MMVet**: 83.9
- **MMVP**: 82.0

*æ•°å­¦ä¸æ¨ç†*ï¼ˆçªå‡ºè¡¨ç°ï¼‰:
- **MathVista mini**: 81.4
- **MathVerse**ï¼ˆvision_onlyï¼‰: 67.0
- **MathVision**: 50.0
- **LogicVista**: 61.3
- **DynaMath**ï¼ˆworstï¼‰: 40.5
- **WeMath**: 59.8

*å…³é”®è§‚å¯Ÿ*: åœ¨**äº‹å®å‡†ç¡®æ€§**å’Œ**å¤æ‚å¤šæ­¥æ¨ç†**æ–¹é¢ä¼˜åŠ¿æœ€æ˜¾è‘—ï¼Œç›´æ¥åæ˜ Honey-Data-15Mçš„ä¼˜åŠ¿

**å…¨é¢æ¶ˆèç ”ç©¶**:
- é‡åŒ–æ¯ä¸ªç­›é€‰é˜¶æ®µçš„å½±å“
- åœ¨å¤šä¸ªbenchmarkä¸Šæ˜¾ç¤ºæ˜¾è‘—æ”¹è¿›
- è¯å®ï¼šå…³æ³¨æ•°æ®è´¨é‡ > ç«äº‰æ•°æ®é‡
- è¯æ®ï¼šæ•°æ®æ¸…æ´— + CoTå¢å¼ºè‡³å…³é‡è¦

---

**ğŸ¯ æ ¸å¿ƒåˆ›æ–° - åŒå±‚CoTç­–ç•¥**:

1. **æ¸è¿›å¼å¢å¼º**: é€æ­¥æå‡è´¨é‡è€Œéç®€å•ä¸¢å¼ƒ
2. **å¤±è´¥æ ·æœ¬æ¢å¤**: çŸ­CoTéªŒè¯å¤±è´¥çš„æ ·æœ¬è·å¾—ä¸“é—¨çš„é•¿CoTå¢å¼º
3. **æ¨¡å‹é©±åŠ¨è¿‡ç¨‹**: MLLMè‡ªåŠ¨åŒ–å·¥ä½œæµï¼ˆäººå·¥æ ‡æ³¨çš„å¯æ‰©å±•ã€ç»æµæ›¿ä»£æ–¹æ¡ˆï¼‰
4. **å¤æ‚åº¦è¯†åˆ«**: å›ºæœ‰åœ°è§£å†³äº†è¯†åˆ«å“ªäº›æŒ‡ä»¤éœ€è¦æ·±åº¦æ¨ç†çš„æŒ‘æˆ˜

---

**âœ… å¼€æºèµ„æº**:
- **é¡¹ç›®ä¸»é¡µ**: https://open-bee.github.io
- **è®ºæ–‡**: [arXiv:2510.13795](https://arxiv.org/abs/2510.13795)
- **æ‰¿è¯ºå‘å¸ƒ**ï¼ˆå®Œæ•´å¥—ä»¶ï¼‰:
  - Honey-Data-15Mè¯­æ–™åº“
  - HoneyPipe + DataStudioæ¡†æ¶
  - è®­ç»ƒrecipes
  - è¯„ä¼°å·¥å…·
  - Bee-8Bæ¨¡å‹æƒé‡

---

**ğŸ’¡ é‡è¦æ„ä¹‰**:

- **ç¼©å°å·®è·**: è¯æ˜å®Œå…¨å¼€æºMLLMå¯é€šè¿‡å…³æ³¨æ•°æ®è´¨é‡ä¸åŠå¼€æºæ¨¡å‹ç«äº‰
- **é€æ˜æ–¹æ³•è®º**: è¶…è¶Šé™æ€æ•°æ®é›†å‘å¸ƒï¼Œæä¾›ä¸æ–­æ¼”è¿›ã€å¯é€‚åº”çš„ç­›é€‰æ–¹æ³•
- **ç¤¾åŒºåŸºçŸ³**: ä¸ºå®Œå…¨å¼€æºMLLMç¤¾åŒºæä¾›æ–°çš„åŸºç¡€èµ„æº
- **å¯æ‰©å±•æ€§**: æ¨¡å‹é©±åŠ¨pipelineä½¿å¼€æºç¤¾åŒºçš„é«˜è´¨é‡æ•°æ®æ„å»ºå˜å¾—å¯è¡Œ
- **éªŒè¯**: Bee-8Bçš„SOTAæ€§èƒ½ç¡®è®¤æ•°æ®ç­›é€‰ç­–ç•¥çš„æœ‰æ•ˆæ€§

**æ ¸å¿ƒè®ºç‚¹å¾—åˆ°è¯å®**: *å¯¹æ•°æ®è´¨é‡çš„åŸåˆ™æ€§å…³æ³¨æ˜¯å¼€å‘ä¸åŠå¼€æºæ¨¡å‹é«˜åº¦ç«äº‰çš„å®Œå…¨å¼€æºMLLMçš„å…³é”®é€”å¾„*

</details>

### ByteDance - ByteMorph

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2506.03107">ğŸ“„ ByteMorph</a></b><br>
<code>arXiv 2506.03107</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **éåˆšæ€§è¿åŠ¨ç¼–è¾‘** - é¦–ä¸ªå¤§è§„æ¨¡æ•°æ®é›†è§£å†³ç›¸æœºè¿åŠ¨ã€ç‰©ä½“å½¢å˜ã€äººä½“å…³èŠ‚è¿åŠ¨å’Œäººç‰©-ç‰©ä½“äº¤äº’
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è¿åŠ¨å¼•å¯¼çš„åˆ†å±‚åˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç»“åˆ**VFXå¯å‘çš„åˆ†å±‚åˆæˆ**ä¸**GPT-4oè¿åŠ¨è¯­ä¹‰æ ‡æ³¨**çš„è‡ªåŠ¨åŒ–pipeline
      - **4é˜¶æ®µPipeline**:
        1. **è§†é¢‘æºæ”¶é›†**: ç½‘ç»œè§„æ¨¡è§†é¢‘è¯­æ–™åº“ â†’ è¿åŠ¨æ£€æµ‹ï¼ˆå…‰æµï¼‰ â†’ é«˜åˆ†è¾¨ç‡ï¼ˆâ‰¥720pï¼‰è¿åŠ¨ä¸°å¯Œç‰‡æ®µ
        2. **åˆ†å±‚åˆæˆ**: å‰æ™¯åˆ†å‰² â†’ èƒŒæ™¯ç¨³å®š â†’ ä¿ç•™è¿åŠ¨çš„å±‚åˆæˆ
        3. **GPT-4oæ ‡æ³¨ç”Ÿæˆ**: å¤šæ¨¡æ€ç†è§£ â†’ è¿åŠ¨æ„ŸçŸ¥çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤
        4. **è´¨é‡ä¿è¯**: CLIPç¾å­¦è¯„åˆ† + å…‰æµè¿è´¯æ€§ + LLMæŒ‡ä»¤-ç¼–è¾‘å¯¹é½éªŒè¯
      - **å…³é”®ä¼˜åŠ¿**: å¤§è§„æ¨¡ä¿ç•™çœŸå®è¿åŠ¨åŠ¨æ€ï¼ˆè‡ªåŠ¨åŒ–æ‰‹å·¥VFXå·¥ä½œæµï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **ByteMorph-6M**: 600ä¸‡é«˜åˆ†è¾¨ç‡ç¼–è¾‘ä¸‰å…ƒç»„ï¼ˆæºå›¾åƒã€æŒ‡ä»¤ã€ç¼–è¾‘å›¾åƒï¼‰
      - **åˆ†å¸ƒ**: 180ä¸‡ç›¸æœºè¿åŠ¨ã€150ä¸‡ç‰©ä½“å½¢å˜ã€180ä¸‡äººä½“å…³èŠ‚è¿åŠ¨ã€90ä¸‡HOI
      - **åˆ†è¾¨ç‡**: å¤§éƒ¨åˆ†1024Ã—1024ï¼Œæœ€å°512Ã—512
  - **åŸºå‡†**: ByteMorph-Benchï¼ˆ613ä¸ªä¸“å®¶éªŒè¯æµ‹è¯•æ ·æœ¬ï¼Œéš¾åº¦åˆ†çº§ï¼‰
  - **æ¨¡å‹**: ByteMorpherï¼ˆæ‰©æ•£TransformeråŸºçº¿ï¼‰
  - **å®éªŒç»“æœ**:
      - åœ¨è¿åŠ¨æŒ‡æ ‡ä¸Šè¶…è¶ŠInstructPix2Pix/MagicBrush **+18.3%**
      - äººå·¥åå¥½: **73.5%** vs. åŸºçº¿
      - è¯æ˜è¿åŠ¨ç‰¹å®šè®­ç»ƒè‡³å…³é‡è¦ï¼ˆé™æ€æ•°æ®é›†æ¨¡å‹: 32.1%æˆåŠŸç‡ï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´6æœˆ
  - **æœºæ„**: å­—èŠ‚è·³åŠ¨Seedã€USCã€ä¸œäº¬å¤§å­¦ã€UCä¼¯å…‹åˆ©ã€æ–¯å¦ç¦ã€UCLA
  - **å¼€æº**: âœ… æ•°æ®é›†ï¼ˆ600ä¸‡ä¸‰å…ƒç»„ï¼‰ã€åŸºå‡†ï¼ˆ613æ ·æœ¬ï¼‰ã€æ¨¡å‹ã€ä»£ç  - è®¡åˆ’åœ¨OpenDataLab/HuggingFaceå‘å¸ƒ
  

</details>

### ByteDance & NTU - LLaVA-OneVision

<details>
<summary>ç‚¹å‡»å±•å¼€</summary>

**è®ºæ–‡**: [LLaVA-OneVision: Easy Visual Task Transfer](https://arxiv.org/abs/2408.03326)

**å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´8æœˆ (v3: 2024å¹´10æœˆ)

**æœºæ„**: å­—èŠ‚è·³åŠ¨ã€å—æ´‹ç†å·¥å¤§å­¦S-Labã€é¦™æ¸¯ä¸­æ–‡å¤§å­¦ã€é¦™æ¸¯ç§‘æŠ€å¤§å­¦

**ä½œè€…**: Bo Li, Yuanhan Zhang, Dong Guo, Renrui Zhang, Feng Li, Hao Zhang, Kaichen Zhang, Peiyuan Zhang, Yanwei Li, Ziwei Liu, Chunyuan Li

**ğŸ“Š æ•°æ®æ„å»ºæ–¹æ³•ï¼ˆSection 4 - ç»¼åˆæ•°æ®ç­–ç•¥ï¼‰**:

LLaVA-OneVisionä»£è¡¨äº†ä¸€ç§é‡è¦çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œåœ¨å¤šæ¨¡æ€è®­ç»ƒä¸­å¼ºè°ƒ**"è´¨é‡é‡äºæ•°é‡"**ã€‚è®ºæ–‡æ•´åˆäº†LLaVA-NeXTåšå®¢ç³»åˆ—çš„è§è§£ï¼Œé…åˆç²¾å¿ƒç­›é€‰çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ2024å¹´1æœˆè‡³6æœˆç§¯ç´¯ï¼‰ã€‚

---

**ğŸ”¬ é«˜è´¨é‡çŸ¥è¯†å­¦ä¹ ï¼ˆ470ä¸‡æ ·æœ¬ï¼‰**

*æ ¸å¿ƒåŸåˆ™*: åœ¨æœ‰é™è®¡ç®—é¢„ç®—ä¸‹ï¼Œä¸“æ³¨äºé«˜è´¨é‡çŸ¥è¯†å­¦ä¹ è€Œéç½‘ç»œè§„æ¨¡çš„ä½è´¨é‡æ•°æ®ã€‚

**å…³é”®æ´å¯Ÿ**: **99.8%çš„é«˜è´¨é‡çŸ¥è¯†æ•°æ®æ˜¯åˆæˆçš„**ï¼Œè¿™æ˜¯ç”±äºæ”¶é›†å¤§è§„æ¨¡é«˜è´¨é‡é‡ç”Ÿæ•°æ®çš„é«˜æˆæœ¬å’Œç‰ˆæƒé™åˆ¶ã€‚

**ä¸‰å¤§æ•°æ®ç±»åˆ«**:

**1. é‡æ–°æè¿°çš„è¯¦ç»†æè¿°æ•°æ®ï¼ˆ350ä¸‡æ ·æœ¬ï¼‰**
- **æ–¹æ³•**: **è‡ªæˆ‘æ”¹è¿›AI**æ–¹æ³•
- **æ¨¡å‹**: ä½¿ç”¨**LLaVA-NeXT-34B**ï¼ˆä»¥å¼ºå¤§çš„è¯¦ç»†æè¿°èƒ½åŠ›è‘—ç§°ï¼‰
- **è¿‡ç¨‹**: ä¸ºç°æœ‰å›¾åƒç”Ÿæˆæ–°çš„è¯¦ç»†captions
- **æ¥æº**: COCO118K, BLIP558K, CC3M
- **åˆ›æ–°**: è®­ç»ƒæ•°æ®ç”±æ¨¡å‹æ—©æœŸç‰ˆæœ¬è‡ªå·±ç”Ÿæˆ

**2. æ–‡æ¡£/OCRæ•°æ®ï¼ˆ110ä¸‡æ ·æœ¬ï¼‰**
- **æ–‡æœ¬é˜…è¯»å­é›†**: UReaderæ•°æ®é›†ï¼ˆ10ä¸‡ï¼‰ï¼Œé€šè¿‡PDFæ¸²æŸ“è½»æ¾è®¿é—®
- **åˆæˆæ•°æ®**: SynDOG EN/CNç”¨äºæ–‡æ¡£ç†è§£
- **ç›®çš„**: å¢å¼ºæ–‡æœ¬é˜…è¯»å’Œæ–‡æ¡£ç†è§£èƒ½åŠ›

**3. ä¸­æ–‡å’Œè¯­è¨€æ•°æ®ï¼ˆ23.5ä¸‡æ ·æœ¬ï¼‰**
- **ä¸­æ–‡Captionç”Ÿæˆï¼ˆ9.2ä¸‡ï¼‰**:
  - å›¾åƒï¼šåŸå§‹ShareGPT4Vå›¾åƒ
  - æ¨¡å‹ï¼š**GPT-4Vï¼ˆAzure APIï¼‰**ç”Ÿæˆè¯¦ç»†ä¸­æ–‡æè¿°
  - ç›®æ ‡ï¼šæå‡ä¸­æ–‡èƒ½åŠ›
- **è¯­è¨€å¹³è¡¡ï¼ˆ14.3ä¸‡ï¼‰**:
  - æ¥æºï¼šEvo-Instructæ•°æ®é›†
  - ç›®çš„ï¼šåœ¨è§†è§‰æè¿°ä¹‹å¤–å¹³è¡¡è¯­è¨€ç†è§£èƒ½åŠ›

---

**ğŸ“¦ è§†è§‰æŒ‡ä»¤å¾®è°ƒæ•°æ®ï¼ˆ480ä¸‡æ ·æœ¬ï¼‰**

*ç›®æ ‡*: ä½¿LMMèƒ½å¤Ÿç†è§£å¹¶æ‰§è¡Œè·¨ä¸åŒåœºæ™¯çš„è§†è§‰æŒ‡ä»¤

**æ•°æ®æ”¶é›†ç­–ç•¥**:

**åˆ†ç±»æ¡†æ¶**ï¼ˆä¸‰å±‚å±‚æ¬¡ç»“æ„ï¼‰:

1. **è§†è§‰è¾“å…¥**: å•å›¾åƒ / å¤šå›¾åƒ / è§†é¢‘
2. **è¯­è¨€æŒ‡ä»¤**: é€šç”¨QAã€é€šç”¨OCRã€æ–‡æ¡£/å›¾è¡¨/å±å¹•ã€æ•°å­¦æ¨ç†ã€è¯­è¨€
3. **è¯­è¨€å“åº”**: è‡ªç”±å½¢å¼ï¼ˆGPT-4V/oã€Geminiæ ‡æ³¨ï¼‰vs å›ºå®šå½¢å¼ï¼ˆå­¦æœ¯æ•°æ®é›†ï¼‰

**ç­›é€‰è¿‡ç¨‹**:
- ä»å„ç§åŸå§‹æ¥æºæ”¶é›†ï¼Œåˆå§‹æ¯”ä¾‹ä¸å¹³è¡¡
- çº³å…¥Cauldronå’ŒCambriané›†åˆçš„æ–°å­é›†
- **äººå·¥å®¡æŸ¥å’Œæ ¼å¼åŒ–**:
  - ä¿®æ­£é—®ç­”æ ¼å¼
  - éµå¾ªLLaVA-1.5çš„promptingç­–ç•¥ï¼ˆå¤šé€‰ã€ç®€ç­”ã€OCRï¼‰
  - é˜²æ­¢ä¸åŒæ•°æ®æºçš„å†²çª
  - å¼•å¯¼æ¨¡å‹è¡Œä¸ºï¼šå¹³è¡¡QAæ€§èƒ½ã€å¯¹è¯èƒ½åŠ›ã€æ¨ç†æŠ€èƒ½

**æ•°æ®ç»„æˆ**:

**å•å›¾åƒæ•°æ®ï¼ˆ320ä¸‡æ ·æœ¬ï¼‰** - äº”å¤§ç±»åˆ«:
- **é€šç”¨ï¼ˆ36.1%ï¼‰**: 70+æ•°æ®é›†ï¼ŒåŒ…æ‹¬ALLaVAInstã€AOKVQAã€Cambrianã€LLaVA-158Kã€ShareGPT4V/4oã€VisionFLANç­‰
- **æ–‡æ¡£/å›¾è¡¨/å±å¹•ï¼ˆ20.6%ï¼‰**: AI2Dã€ChartQAã€DocVQAã€UReaderç³»åˆ—ã€Chart2Textç­‰
- **æ•°å­¦/æ¨ç†ï¼ˆ20.1%ï¼‰**: MAVISç³»åˆ—ã€Geo170Kã€GeoQA+ã€GeoMVerseã€MathV360Kç­‰
- **é€šç”¨OCRï¼ˆ8.9%ï¼‰**: ChromeWritingã€HME100Kã€OCR-VQAã€SynthDog-ENã€TextCapsã€TextOCRç­‰
- **è¯­è¨€ï¼ˆ14.3%ï¼‰**: MagpieProï¼ˆL3MTã€L3STã€Qwen2STï¼‰- æ€»è®¡45ä¸‡æ ·æœ¬

**OneVisionæ··åˆæ•°æ®ï¼ˆ160ä¸‡æ ·æœ¬ï¼‰** - ä¸‰ç§åœºæ™¯:
- **å•å›¾åƒï¼ˆ31.2%ï¼Œçº¦50ä¸‡ï¼‰**: ä»ä¹‹å‰å•å›¾åƒæ•°æ®ä¸­é«˜è´¨é‡é‡‡æ ·
  - MagpieProã€VisionFLANã€ImageTextualizationã€Cauldronã€UReaderã€ShareGPT4V/4oç­‰
- **å¤šå›¾åƒï¼ˆ43.0%ï¼Œçº¦68.8ä¸‡ï¼‰**: 30+æ•°æ®é›†
  - NLVRã€Co-Instructã€ScanNetã€RAVENã€IconQAã€VISTã€ContrastiveCaptionç­‰
- **è§†é¢‘ï¼ˆ25.9%ï¼Œçº¦41.5ä¸‡ï¼‰**: 6ä¸ªæ•°æ®é›†
  - ShareGPT4Videoï¼ˆ25.5ä¸‡ï¼‰ã€Youcook2ã€ActivityNetã€Charadesã€NextQAã€Ego4D

---

**ğŸ¯ æ ¸å¿ƒåˆ›æ–°ä¸æ´å¯Ÿ**:

1. **åˆæˆæ•°æ®ä¸»å¯¼**: 99.8%çš„çŸ¥è¯†æ•°æ®æ˜¯æ¨¡å‹ç”Ÿæˆçš„
   - æˆæœ¬æ›´ä½ï¼Œæ›´å®¹æ˜“æ‰©å±•
   - "éšç€AIæ¨¡å‹è¶Šæ¥è¶Šå¼ºå¤§ï¼Œä»å¤§è§„æ¨¡åˆæˆæ•°æ®å­¦ä¹ æ­£åœ¨æˆä¸ºè¶‹åŠ¿"

2. **è‡ªæˆ‘æ”¹è¿›AI**: ä½¿ç”¨LLaVA-NeXT-34Bä¸ºä¸‹ä¸€ä»£ç”Ÿæˆè®­ç»ƒæ•°æ®
   - ä¸º350ä¸‡å›¾åƒé‡æ–°ç”Ÿæˆæ›´è¯¦ç»†çš„æè¿°
   - è¯æ˜ä»è‡ªå·±æ¨¡å‹è¾“å‡ºå¼•å¯¼çš„å¯è¡Œæ€§

3. **ç²¾å¿ƒçš„æ•°æ®å¹³è¡¡**:
   - ä»»åŠ¡åˆ†ç±»ä»¥ç»´æŒæŠ€èƒ½åˆ†å¸ƒ
   - äººå·¥å®¡æŸ¥ä»¥é˜²æ­¢æ•°æ®æºå†²çª
   - è·¨å¼‚æ„æ¥æºçš„ç»Ÿä¸€promptingç­–ç•¥

4. **è·¨åœºæ™¯è¿ç§»è®¾è®¡**:
   - æ´å¯Ÿï¼šæ›´å¼ºçš„å›¾åƒæ¨¡å‹ â†’ æ›´å¥½åœ°è¿ç§»åˆ°å¤šå›¾åƒ/è§†é¢‘ä»»åŠ¡
   - è®­ç»ƒç­–ç•¥ï¼šå…ˆå•å›¾åƒï¼Œå†æ··åˆåœºæ™¯
   - æ•°æ®åˆ†é…ï¼šä¸ºå•å›¾åƒåˆ†é…æ›´å¤štokenä»¥æ¨¡æ‹Ÿè§†é¢‘è¡¨ç¤º

5. **è´¨é‡é‡äºæ•°é‡ç†å¿µ**:
   - ä¸“æ³¨äºç­›é€‰è€Œéä½“é‡
   - è®¤å¯é¢„è®­ç»ƒLLM/ViTçš„çŸ¥è¯†åº“
   - æŒç»­æ¥è§¦æ–°çš„é«˜è´¨é‡æ•°æ®

---

**ğŸ“ˆ è®­ç»ƒç­–ç•¥ï¼ˆSection 5ï¼‰**:

**ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ **:
- **Stage-1**: è¯­è¨€-å›¾åƒå¯¹é½
- **Stage-1.5**: é«˜è´¨é‡çŸ¥è¯†å­¦ä¹ ï¼ˆä½¿ç”¨470ä¸‡åˆæˆæ•°æ®ï¼‰
- **Stage-2**: å•å›¾åƒæŒ‡ä»¤å¾®è°ƒï¼ˆ320ä¸‡æ ·æœ¬ï¼‰
- **Stage-3**: OneVisionæ··åˆè®­ç»ƒï¼ˆ160ä¸‡æ ·æœ¬ï¼‰

**æ¨¡å‹æ¶æ„**:
- LLM: Qwen-2ï¼ˆå¼ºå¤§çš„è¯­è¨€èƒ½åŠ›ï¼‰
- è§†è§‰ç¼–ç å™¨: SigLIPï¼ˆå¼€æºç¼–ç å™¨ä¸­æ€§èƒ½æ›´é«˜ï¼‰
- æŠ•å½±å™¨: 2å±‚MLP
- è§†è§‰è¡¨ç¤º: Higher AnyResç­–ç•¥é…åˆåŒçº¿æ€§æ’å€¼

---

**âœ… æ€§èƒ½ä¸æˆå°±**:

- **é¦–ä¸ªå•ä¸€å¼€æºæ¨¡å‹**åœ¨ä¸‰ç§åœºæ™¯ä¸­åŒæ—¶æ¨åŠ¨æ€§èƒ½è¾¹ç•Œ:
  - å•å›¾åƒ
  - å¤šå›¾åƒ
  - è§†é¢‘ç†è§£
- è·¨æ¨¡æ€çš„å¼ºå¤§ä»»åŠ¡è¿ç§»èƒ½åŠ›
- é€šè¿‡è·¨åœºæ™¯è¿ç§»å±•ç¤ºæ–°å…´èƒ½åŠ›
- é€šè¿‡ä»å›¾åƒè¿ç§»ä»»åŠ¡å®ç°è§†é¢‘ç†è§£

---

**âœ… å¼€æºèµ„æº**:
- **è®ºæ–‡**: [arXiv:2408.03326](https://arxiv.org/abs/2408.03326)
- **é¡¹ç›®**: https://llava-vl.github.io/blog/llava-onevision
- **æ•°æ®é›†**: [ğŸ¤— HuggingFace](https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data)
- **æ¨¡å‹**: æ¨¡å‹æ£€æŸ¥ç‚¹å·²å‘å¸ƒ
- **ä»£ç **: ä»£ç åº“å¼€æº
- **Demo**: å¯ç”¨çš„è§†è§‰èŠå¤©æ¼”ç¤º

---

**ğŸ’¡ é‡è¦æ„ä¹‰**:

- **ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•**: å°†LLaVA-NeXTåšå®¢ç³»åˆ—çš„æ´å¯Ÿæ•´åˆä¸ºç»¼åˆæ•°æ®é›†
- **åˆæˆæ•°æ®éªŒè¯**: è¯æ˜å¤§è§„æ¨¡åˆæˆæ•°æ®ï¼ˆ99.8%ï¼‰å¯ä»¥è¾¾åˆ°SOTAæ€§èƒ½
- **è‡ªæˆ‘æ”¹è¿›è·¯å¾„**: å±•ç¤ºä½¿ç”¨è‡ªå·±æ¨¡å‹è¾“å‡ºè¿›è¡Œä¸‹ä¸€ä»£è®­ç»ƒ
- **ç»Ÿä¸€å¤šåœºæ™¯**: å•ä¸€æ¨¡å‹åœ¨å›¾åƒ/å¤šå›¾åƒ/è§†é¢‘ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ— éœ€æƒè¡¡
- **ç¤¾åŒºå½±å“**: å®Œæ•´å¼€æºæ•°æ®ã€æ¨¡å‹ã€ä»£ç ï¼Œå®ç°å¯å¤ç°æ€§

**æ ¸å¿ƒè®ºç‚¹**: *é€šè¿‡æ•°æ®ç­›é€‰ä¸­çš„è´¨é‡é‡äºæ•°é‡ï¼Œç»“åˆæˆ˜ç•¥æ€§ä½¿ç”¨åˆæˆæ•°æ®å’Œè‡ªæˆ‘æ”¹è¿›ï¼Œèƒ½å¤Ÿæ„å»ºä¸ä¸“æœ‰æ¨¡å‹ç«äº‰çš„å¤šåŠŸèƒ½å¼€æºLMMã€‚*

</details>

### LLaVA Series (Wisconsin-Madison & Microsoft)

<details>
<summary>Click to expand</summary>

**Papers**:
- [Visual Instruction Tuning (LLaVA)](https://arxiv.org/abs/2304.08485)
- [Improved Baselines with Visual Instruction Tuning (LLaVA-1.5)](https://arxiv.org/abs/2310.03744)

**ğŸ“Š Data Synthesis Method (Section 3 Detailed Description)**:

**One of the most influential works in multimodal data synthesis!** LLaVA paper Section 3 "GPT-assisted Visual Instruction Data Generation" provides complete pipeline details:

1. **Data Generation Pipeline** (Figure 2 shows complete flow):

   **Input Materials**:
   - COCO images
   - COCO human-annotated captions (5 per image)
   - COCO bbox annotations

   **Using GPT-4 to Generate Three Types of Data**:

   a) **Conversation** (Multi-turn dialogue, 58K):
   - Prompt template: Appendix A.2.1 provides complete prompt
   - Input: Caption list
   - Output: Multi-turn Q&A about image content

   b) **Detailed Description** (Detailed description, 23K):
   - Prompt template: Appendix A.2.2
   - Requires GPT-4 to generate more detailed descriptions than original captions

   c) **Complex Reasoning** (Complex reasoning, 77K):
   - Prompt template: Appendix A.2.3
   - Based on bbox, generates reasoning-required questions (e.g., counting, spatial relationships)

2. **Complete Data Scale**:
   - Total: 158K instruction-response pairs
   - Based on approximately 80K COCO images

3. **Prompt Engineering Details** (Fully disclosed in Appendix):
   - Appendix A fully discloses all prompt templates
   - Includes system prompts, few-shot examples
   - Fully reproducible

**LLaVA-1.5 Data Improvements**:
- Adds more academic task datasets (VQAv2, GQA, OKVQA, etc.)
- Enhances data diversity
- Maintains same generation method

**âœ… Data Fully Open Source**:
- [HuggingFace Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)
- Prompt templates directly usable

**Impact**:
This method has been adopted or improved by almost all subsequent open-source VLM projects (ShareGPT4V, SVIT, InternVL, etc. are based on this paradigm).

</details>

---

## ğŸ“‚ æŒ‰å›¾åƒå¤„ç†æ–¹å¼åˆ†ç±»

### ğŸ¨ å›¾åƒç”Ÿæˆ - åˆæˆæ–°è§†è§‰å†…å®¹

This category focuses on **generating new images from scratch** as part of the data synthesis pipeline. These methods create synthetic visual content (geometric diagrams, mathematical figures, text-dense scenes, etc.) programmatically or through generative models, paired with corresponding textual annotations.

#### ğŸ”„ æ–‡æœ¬é©±åŠ¨å›¾åƒåˆæˆ

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2407.20756">ğŸ“„ SynthVLM</a></b><br>
<code>arXiv 2407.20756</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ACM_Multimedia_2025-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **åå‘åˆæˆï¼šä»æ–‡æœ¬ç”Ÿæˆå›¾åƒ** - ä¸åŒäºä¼ ç»Ÿ"å›¾åƒâ†’caption"ï¼ŒSynthVLMé‡‡ç”¨"captionâ†’å›¾åƒ"èŒƒå¼ï¼Œä½¿ç”¨é«˜è´¨é‡captioné©±åŠ¨Diffusionæ¨¡å‹ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸¤é˜¶æ®µç­›é€‰-ç”Ÿæˆ-å†ç­›é€‰**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æå‡ºä»captionç”Ÿæˆå›¾åƒçš„VLMé¢„è®­ç»ƒæ•°æ®åˆæˆæ¡†æ¶ï¼Œè§£å†³Webæ•°æ®"æ°´å°/å¹¿å‘Š/ä½è´¨é‡"ä¸‰å¤§ç—›ç‚¹
      - **Stage 1: Captionç­›é€‰**ï¼ˆæ„å»ºé«˜è´¨é‡ç§å­ï¼‰:
        - **æ•°æ®æº**: æ±‡èšäººå·¥æ ‡æ³¨ï¼ˆLAIONã€CCã€SBUï¼‰+ æ¨¡å‹ç”Ÿæˆï¼ˆBLIP2å¯¹DataCompé‡æ–°æ ‡æ³¨ï¼‰
        - **ä¸¤è½®è¿‡æ»¤**:
          1. **è´¨é‡è¿‡æ»¤**: ChatGPT + ç»Ÿè®¡æŒ‡æ ‡ï¼ˆN-gramã€Perplexityï¼‰ç§»é™¤å¹¿å‘Šã€é‡å¤ã€è¯­æ³•é”™è¯¯
          2. **å¯¹é½è¿‡æ»¤**: è®¡ç®—captionä¸åŸå§‹å›¾åƒçš„CLIPScoreï¼Œé€‰æ‹©top 40%ï¼ˆ1M captionï¼‰
      - **Stage 2: å›¾åƒç”Ÿæˆ+è´¨é‡ç­›é€‰**:
        - **ç”Ÿæˆ**: ä½¿ç”¨**Stable Diffusion XL (SDXL)** ä¸º1M captionç”Ÿæˆ**1024Ã—1024é«˜åˆ†è¾¨ç‡å›¾åƒ**ï¼ˆ60 sampling stepsï¼Œç½‘æ ¼æœç´¢è¶…å‚ï¼‰
        - **åŒæŒ‡æ ‡ç­›é€‰**:
          - **CLIPScore(I, C)**: è¯„ä¼°å›¾åƒ-æ–‡æœ¬è¯­ä¹‰å¯¹é½
          - **SSIMScore(I, I_resized)**: è¯„ä¼°å›¾åƒè´¨é‡ï¼ˆæ¨¡æ‹Ÿ336px resizeæŸå¤±ï¼‰
          - **åŠ æƒå…¬å¼**: Weighted_Score = CLIPScore + 0.5 Ã— SSIMScore
        - **é€‰æ‹©**: Top 100K pairs â†’ **SynthVLM-100K**
      - **å…³é”®æŠ€æœ¯ç»†èŠ‚**:
        - **é¿å…ä¼ªå½±**: ç”Ÿæˆå›¾åƒå¤©ç„¶æ— æ°´å°ã€æ— å¹¿å‘Šï¼ˆWebå›¾åƒå¸¸è§é—®é¢˜ï¼‰
        - **æ›´é«˜åˆ†è¾¨ç‡**: 1024Ã—1024 vs. Webå›¾åƒé€šå¸¸336Ã—520
        - **æ›´å¥½å¯¹é½**: SynthVLM-100Kçš„å¹³å‡CLIPScore=0.36ã€SSIMScore=0.86ï¼Œæ˜¾è‘—é«˜äºCOCO-Caption(0.31/0.73)ã€BLIP-LCS(0.32/0.75)ã€ShareGPT4V(0.32/0.79)
  - **è¯„ä¼°ä¸éªŒè¯**:
      - **GPT-4V + InternVL2 + äººå·¥è¯„ä¼°**: 1Kæ ·æœ¬ç›²æµ‹ï¼Œåˆæˆå›¾åƒèƒœç‡ **63.3%(GPT-4V)ã€69.2%(InternVL2)ã€75.8%(äººå·¥)**
      - **ä¸‹æ¸¸ä»»åŠ¡**: SynthVLM-7B/13Bä»…ç”¨100Ké¢„è®­ç»ƒæ•°æ®ï¼ˆLLaVAçš„18%ï¼‰è¾¾åˆ°SOTAï¼Œåœ¨VQAv2ã€GQAã€MMBenchã€MMEç­‰å…¨é¢è¶…è¶ŠLLaVA
      - **è¯­è¨€èƒ½åŠ›ä¿æŒ**: MMLUåŸºå‡†ä¸ŠSynthVLM-7Bè¾¾41.2ï¼ˆvs. LLaVA 36.3ï¼‰ï¼Œè¯æ˜åˆæˆæ•°æ®ä¸æŸå®³è¯­è¨€ç†è§£
  - **æ•°æ®è§„æ¨¡**:
      - **ä¸­é—´æ± **: 1Mé«˜è´¨é‡caption
      - **æœ€ç»ˆæ•°æ®é›†**: **SynthVLM-100K**ï¼ˆ100Kåˆæˆå›¾åƒ-æ–‡æœ¬å¯¹ï¼‰
  - **å¼€æº**: âœ… [GitHub](https://github.com/starriver030515/SynthVLM)
  - **æœºæ„**: åŒ—äº¬å¤§å­¦ + åä¸ºæŠ€æœ¯ + ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤
  - **å‘å¸ƒæ—¶é—´**: ACM MM 2025 | arXiv 2024å¹´7æœˆ
  

</details>
---

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Enhanced%20Visual%20Instruction%20Tuning">ğŸ“„ Enhanced Visual Instruction Tuning</a></b><br>
<code>Paper</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ACL_Findings_2024-red?style=flat-square"/>
</summary>

  - **Focus**: **Synthesized Image-Dialogue Data for Visual Instruction Tuning** - Generate comprehensive image-dialogue datasets using ChatGPT and Stable Diffusion to enhance multimodal LLM capabilities across diverse visual tasks
  - **Data Synthesis Method** - **Dual-Stage ChatGPT-Guided Generation Pipeline**:
      - **Core Innovation**: First systematic approach leveraging LLM (ChatGPT) to generate both Stable Diffusion prompts and corresponding dialogue data, addressing limitations in existing visual instruction datasets' capability coverage and dialogue diversity
      - **Stage 1: ChatGPT Prompt & Dialogue Generation**:
        - **Prompt Generation**: Use **ChatGPT** with capability-specific instructions to generate Stable Diffusion prompts targeting 11 visual abilities
        - **Capability Categories**: Animal, Action, Color, Abnormal Detection, Scene, Style, Food, Profession, Vehicle, Furniture, Plant recognition
        - **Prompt Engineering Techniques**:
          - **Length Control**: Max 10 keywords per prompt to ensure clear focus and accurate image generation
          - **Keyword Prioritization**: Most crucial keywords at beginning, double-bracketed for emphasis
          - **Stability Enhancements**: Add capability-specific instructions and cautions to encourage diversity
          - **Abnormal Image Guidance**: For joke understanding tasks, direct ChatGPT to create prompts for "abnormal images" (e.g., "giraffe walking through narrow corridor")
        - **Dialogue Generation**: Generate corresponding question-answer pairs with constraints:
          - **Length Limit**: â‰¤500 characters per dialogue for conciseness
          - **Diversity Requirements**: Include misleading either-or questions to increase complexity
          - **Task-Specific Restrictions**: Address model biases (e.g., construction workers â†’ add human attributes to avoid building focus)
      - **Stage 2: Stable Diffusion Image Generation**:
        - **Model**: **Stable Diffusion v1.4** for text-to-image generation
        - **Generation Settings**: Multiple candidates per prompt, select best based on alignment scores
        - **Multi-Image Data**: Generate paired prompts simultaneously for image similarity/difference/logical relation tasks (3K pairs)
        - **Quality Control**: CLIP-based alignment verification with threshold Î³=0.25
      - **Advanced Data Types**:
        - **Interleaved Multi-Turn Dialogues**: Step-by-step instructional conversations with image inputs at each turn
        - **Multi-Image Tasks**: Similarity comparison, difference analysis, logical relationship reasoning
        - **Specialized Content**: Abnormal image detection, profession recognition, fine-grained attribute understanding
  - **Technical Architecture Integration**:
      - **Base Model**: LLaVA architecture with CLIP visual encoder + projection layer + LLM (Vicuna)
      - **Training Strategy**: Two-stage fine-tuning (modality alignment + visual instruction tuning)
      - **Token Processing**: Convert visual features to language embedding tokens through linear/MLP projection
  - **Data Scale**:
      - **Primary Dataset**: **38K image-dialogue pairs** across 11 capability categories
      - **Multi-Image Data**: **3K specialized multi-image instances**
      - **Interleaved Dialogues**: Step-by-step instructional conversations with visual feedback
      - **Total Coverage**: Comprehensive training set combined with raw LLaVA dataset for enhanced capabilities
  - **Evaluation & Results**:
      - **Benchmarks**: VizWiz (58.4% vs 53.6% LLaVA-1.5), MM-Vet (36.1% vs 35.4%), MME (1532.3 vs 1531.3), MMBench (69.4% vs 67.7%)
      - **Manual Evaluation**: Significant improvements across all 11 capabilities, especially abnormal detection (+25%), style recognition (+50%)
      - **GPT-4 Scoring**: Consistent performance gains with detailed capability-specific analysis
      - **Multi-Image Tasks**: Substantial improvements in difference detection (2.7â†’3.6), similarity analysis (2.2â†’2.8), logical relations (3.1â†’3.7)
  - **Key Technical Contributions**:
      - **Automated Pipeline**: First fully automated approach combining LLM prompt generation with diffusion model image synthesis
      - **Capability-Specific Design**: Targeted generation for underrepresented visual tasks (jokes, abnormal detection, multi-image reasoning)
      - **Quality Assurance**: Multi-level filtering including CLIP alignment, length constraints, and task-specific restrictions
      - **Scalability**: Template-based approach easily extensible to new capabilities and domains
  - **Institution**: University of Technology Sydney, Tencent, Nanyang Technological University, Zhejiang University, Beijing Jiaotong University, Westlake University, PengCheng Laboratory
  - **Open Source**: âœ… Dataset and generation templates (see supplementary materials)
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.08513">ğŸ“„ Ultimate3D</a></b><br>
<code>arXiv 2507.08513</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡3Dè§†è§‰æŒ‡ä»¤æ•°æ®é›†ç”Ÿæˆç”¨äºç›¸æœº-ç‰©ä½“å…³ç³»ç†è§£** - ä½¿ç”¨3Dèµ„äº§+æ¸²æŸ“+æ‰©æ•£æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆ240Kå¸¦ç²¾ç¡®ç›¸æœº-ç‰©ä½“å…³ç³»æ ‡æ³¨çš„VQAæ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **3Dæ¸²æŸ“ + å¤šControlNetæ‰©æ•£ + LLMå››æ­¥Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»ŸåŒ–åˆ©ç”¨3Dèµ„äº§ç”Ÿæˆå…‰çœŸå®æ„Ÿå›¾åƒå’Œç›¸æœº-ç‰©ä½“å…³ç³»VQAæ•°æ®çš„å®Œæ•´æ¡†æ¶ï¼Œè§£å†³MLLMsåœ¨ç©ºé—´å…³ç³»ç†è§£ä¸Šçš„æ•°æ®é›†åå·®é—®é¢˜
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰MLLMsåœ¨ç›¸æœº-ç‰©ä½“å…³ç³»ç†è§£ä¸Šå­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼ˆGPT-4oåœ¨ç‰©ä½“æ–¹å‘ä»»åŠ¡ä¸Šä»…43.1%å‡†ç¡®ç‡ï¼‰
        - æ ¹æºï¼šè®­ç»ƒæ•°æ®é›†å­˜åœ¨ä¸¥é‡åå·®ï¼ˆå¤§å¤šæ•°å›¾åƒä»æ­£é¢ã€ä¾§é¢æˆ–ä¸Šæ–¹è§†è§’æ‹æ‘„ï¼‰
        - ç¼ºä¹å¤šæ ·åŒ–ç›¸æœº-ç‰©ä½“å…³ç³»çš„é«˜è´¨é‡æ ‡æ³¨æ•°æ®
      - **å››æ­¥ç”ŸæˆPipeline**:
        1. **3Dè§†è§‰å…ˆéªŒæ¸²æŸ“ï¼ˆStage 1ï¼‰**:
           - **è¾“å…¥**: 3Dèµ„äº§Aï¼ˆæ¥è‡ªObjaverseç­‰å¼€æºåº“ï¼‰ï¼Œä»»æ„ç›¸æœº-ç‰©ä½“å…³ç³»å‚æ•°Î²
           - **ç›¸æœº-ç‰©ä½“å…³ç³»å®šä¹‰**:
             - **æ–¹ä½è§’Ï†**: ç‰©ä½“ç›¸å¯¹ç›¸æœºçš„æ—‹è½¬è§’åº¦ï¼Œåˆ†ä¸º8ä¸ªæ–¹å‘ï¼ˆå³ã€å³å‰ã€å‰ã€å·¦å‰ã€å·¦ã€å·¦åã€åã€å³åï¼‰ï¼Œæ¯ä¸ªè¦†ç›–Ï€/4å¼§åº¦
             - **è§†è§’Î¸**: ç›¸æœºä»°è§’ï¼Œåˆ†ä¸º3ç±»ï¼ˆä¿¯è§†ã€æ°´å¹³ã€ä»°è§†ï¼‰
             - **è·ç¦»**: ç›¸æœºåˆ°ç‰©ä½“è·ç¦»ï¼Œåˆ†ä¸º3ç±»ï¼ˆç‰¹å†™ã€ä¸­æ™¯ã€è¿œæ™¯ï¼‰
           - **æ¸²æŸ“å™¨**: Blender 3Då¼•æ“
           - **è¾“å‡ºå¤šæ¨¡æ€è§†è§‰å…ˆéªŒI_Î²**:
             - RGBå›¾åƒ
             - åƒç´ çº§æ·±åº¦å›¾ï¼ˆDepthAnyThing V2ï¼‰
             - è¯­ä¹‰åˆ†å‰²mask
             - Cannyè¾¹ç¼˜æ£€æµ‹å›¾
           - **å…³é”®ä¼˜åŠ¿**: ä¿ç•™ç²¾ç¡®çš„ground truthç›¸æœº-ç‰©ä½“å…³ç³»Î²ï¼Œä½œä¸ºåç»­å›¾åƒç”Ÿæˆçš„å¼ºçº¦æŸæ¡ä»¶
        2. **å¤šæ ·å›¾åƒæè¿°ç”Ÿæˆï¼ˆStage 2ï¼‰**:
           - **LLM**: GPT-4o
           - **æç¤ºå·¥ç¨‹**:
             - **ç³»ç»Ÿæç¤º**: å¼•å¯¼LLMç”ŸæˆèƒŒæ™¯ä¸Šä¸‹æ–‡å’Œç‰©ä½“å¤–è§‚ç»†èŠ‚çš„å¤šæ ·åŒ–æè¿°
             - **Few-shotç¤ºä¾‹**: æä¾›é£æ ¼å‚è€ƒç¡®ä¿æè¿°è‡ªç„¶æ€§
           - **è¾“å‡ºT_img**: è¯¦ç»†çš„å›¾åƒæè¿°æ–‡æœ¬ï¼ŒåŒ…å«ï¼š
             - èƒŒæ™¯åœºæ™¯æè¿°ï¼ˆå®¤å†…/å®¤å¤–ã€å…‰ç…§æ¡ä»¶ã€ç¯å¢ƒæ°›å›´ï¼‰
             - ç‰©ä½“ç»†èŠ‚æè¿°ï¼ˆæè´¨ã€é¢œè‰²ã€çŠ¶æ€ï¼‰
             - ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç‰©ä½“åœ¨åœºæ™¯ä¸­çš„ä½œç”¨ï¼‰
           - **å¤šæ ·æ€§ä¿è¯**: é’ˆå¯¹åŒä¸€3Dèµ„äº§ç±»åˆ«ç”Ÿæˆå¤šç§ä¸åŒçš„åœºæ™¯æè¿°ï¼Œå¢å¼ºæ•°æ®å¤šæ ·æ€§
        3. **å—æ§å…‰çœŸå®æ„Ÿå›¾åƒç”Ÿæˆï¼ˆStage 3ï¼‰**:
           - **æ ¸å¿ƒæŠ€æœ¯**: å¤šControlNetå †å  + SDXLæ‰©æ•£æ¨¡å‹
           - **æ¡ä»¶è¾“å…¥**:
             - è§†è§‰æ¡ä»¶ï¼šæ·±åº¦å›¾ + Cannyè¾¹ç¼˜å›¾ï¼ˆæ¥è‡ªStage 1ï¼‰
             - æ–‡æœ¬æ¡ä»¶ï¼šå›¾åƒæè¿°T_imgï¼ˆæ¥è‡ªStage 2ï¼‰
           - **å¤šControlNetæ¶æ„**:
             - **æ·±åº¦ControlNet**: æƒé‡0.5ï¼Œä¿æŒç‰©ä½“3Då‡ ä½•ç»“æ„
             - **Canny ControlNet**: æƒé‡0.8ï¼Œä¿æŒç‰©ä½“è¾¹ç¼˜å’Œè½®å»“
             - **å…¬å¼**: z_{t-1} = G_Î¸(T_img, z_t, t, Î£w_kÂ·C^k(I^k_Î²))
           - **æ‰©æ•£æ­¥æ•°T=30**: å¹³è¡¡ç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦
           - **è¾“å‡ºI_syn**: ä¿æŒç²¾ç¡®ç›¸æœº-ç‰©ä½“å…³ç³»Î²çš„å…‰çœŸå®æ„Ÿå›¾åƒ
           - **è´¨é‡ä¿è¯**:
             - é€šè¿‡3Då…ˆéªŒçš„å¼ºçº¦æŸï¼Œç¡®ä¿ç”Ÿæˆå›¾åƒçš„ç›¸æœº-ç‰©ä½“å…³ç³»ä¸Î²ä¸€è‡´
             - ç”Ÿæˆå›¾åƒå…·æœ‰é€¼çœŸçš„å…‰ç…§ã€çº¹ç†å’ŒèƒŒæ™¯
        4. **3Dæ„ŸçŸ¥æ–‡æœ¬æŒ‡ä»¤ç”Ÿæˆï¼ˆStage 4ï¼‰**:
           - **LLM**: GPT-4o
           - **è¾“å…¥**: Ground truthç›¸æœº-ç‰©ä½“å…³ç³»Î²ï¼ˆæ–¹ä½è§’Ï†ã€è§†è§’Î¸ã€è·ç¦»ï¼‰
           - **ä¸‰ç±»é—®é¢˜ç”Ÿæˆ**:
             a) **ç‰©ä½“æ–¹å‘é—®é¢˜**:
                - ç¤ºä¾‹ï¼š"è¿™ä¸ªç‰©ä½“æœå‘å“ªä¸ªæ–¹å‘ï¼Ÿ"ã€"ç‰©ä½“æ˜¯é¢å‘ç›¸æœºè¿˜æ˜¯èƒŒå¯¹ç›¸æœºï¼Ÿ"
                - ç­”æ¡ˆï¼šåŸºäºÏ†ç”Ÿæˆåˆ†ç±»ç­”æ¡ˆï¼ˆ8ä¸ªæ–¹å‘ç±»åˆ«ï¼‰
             b) **ç›¸æœºè§†è§’é—®é¢˜**:
                - ç¤ºä¾‹ï¼š"ç…§ç‰‡æ˜¯ä»ç‰©ä½“ä¸Šæ–¹æ‹æ‘„è¿˜æ˜¯ä¾§é¢æ‹æ‘„ï¼Ÿ"ã€"ç›¸æœºè§†è§’æ˜¯ä»€ä¹ˆï¼Ÿ"
                - ç­”æ¡ˆï¼šåŸºäºÎ¸ç”Ÿæˆåˆ†ç±»ç­”æ¡ˆï¼ˆä¿¯è§†/æ°´å¹³/ä»°è§†ï¼‰
             c) **é•œå¤´è·ç¦»é—®é¢˜**:
                - ç¤ºä¾‹ï¼š"ç…§ç‰‡æ˜¯è¿‘è·ç¦»æ‹æ‘„è¿˜æ˜¯è¿œè·ç¦»æ‹æ‘„ï¼Ÿ"ã€"è¿™æ˜¯ç‰¹å†™é•œå¤´è¿˜æ˜¯è¿œæ™¯é•œå¤´ï¼Ÿ"
                - ç­”æ¡ˆï¼šåŸºäºè·ç¦»ç”Ÿæˆåˆ†ç±»ç­”æ¡ˆï¼ˆç‰¹å†™/ä¸­æ™¯/è¿œæ™¯ï¼‰
           - **æç¤ºå·¥ç¨‹æŠ€å·§**:
             - ä½¿ç”¨ç³»ç»Ÿæç¤ºå’Œfew-shotç¤ºä¾‹ç¡®ä¿é—®é¢˜è‡ªç„¶æ€§å’Œå¤šæ ·æ€§
             - ä¸ºæ¯ä¸ªç›¸æœº-ç‰©ä½“å…³ç³»ç”Ÿæˆæœ€å¤š3ä¸ªVQAå¯¹ï¼ˆæ¯ç§é—®é¢˜ç±»å‹1ä¸ªï¼‰
           - **è¾“å‡ºT_qa**: é«˜è´¨é‡é—®ç­”å¯¹ï¼Œç­”æ¡ˆç²¾ç¡®åŒ¹é…ground truth
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç²¾ç¡®æ ‡æ³¨**: é€šè¿‡3Dæ¸²æŸ“ä¿è¯ç›¸æœº-ç‰©ä½“å…³ç³»çš„ground truthå‡†ç¡®æ€§ï¼Œé¿å…äººå·¥æ ‡æ³¨è¯¯å·®
        - **å…‰çœŸå®æ„Ÿ**: å¤šControlNet+SDXLç”Ÿæˆçš„å›¾åƒè´¨é‡æ¥è¿‘çœŸå®ç…§ç‰‡
        - **å®Œå…¨è‡ªåŠ¨åŒ–**: ä»3Dèµ„äº§åˆ°VQAæ•°æ®çš„å…¨è‡ªåŠ¨pipelineï¼Œæ— éœ€äººå·¥ä»‹å…¥
        - **å¯æ‰©å±•æ€§**: å¯åº”ç”¨äºä»»ä½•3Dèµ„äº§åº“ï¼ˆObjaverseã€ShapeNetç­‰ï¼‰ï¼Œç†è®ºä¸Šå¯æ— é™æ‰©å±•
        - **å¤šæ ·æ€§**: æ¯ä¸ª3Dèµ„äº§ç”Ÿæˆ72ç§ç›¸æœº-ç‰©ä½“å…³ç³»ç»„åˆï¼ˆ8æ–¹å‘Ã—3è§†è§’Ã—3è·ç¦»ï¼‰ï¼Œæ¶µç›–å¹¿æ³›çš„ç©ºé—´é…ç½®
  - **Ultimate3Dæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 240K VQAå¯¹
      - **ç»„æˆ**:
        - **åˆæˆæ•°æ®**: 85Kå›¾åƒï¼ˆæ¥è‡ª1180ä¸ª3Dèµ„äº§ï¼‰
        - **çœŸå®æ•°æ®**: 18Kå›¾åƒï¼ˆä»MEBOWæ•°æ®é›†è£å‰ªçš„å•äººç…§ç‰‡+äººä½“æ–¹å‘æ ‡æ³¨ï¼‰
      - **3Dèµ„äº§åº“**: 1180ä¸ª3Dæ¨¡å‹ï¼Œè¦†ç›–100ä¸ªç‰©ä½“ç±»åˆ«
      - **ç›¸æœº-ç‰©ä½“å…³ç³»è¦†ç›–**:
        - æ¯ä¸ª3Dèµ„äº§ï¼š72ç§é…ç½®ï¼ˆ8æ–¹å‘Ã—3è§†è§’Ã—3è·ç¦»ï¼‰
        - æ¯ä¸ªé…ç½®ï¼šæœ€å¤š3ä¸ªVQAå¯¹ï¼ˆå¯¹åº”3ç§é—®é¢˜ç±»å‹ï¼‰
      - **åŸºå‡†æµ‹è¯•é›†**: 8Ké«˜è´¨é‡æ ·æœ¬ç”¨äºè¯„ä¼°
      - **æ•°æ®æ ¼å¼**: (å›¾åƒI_syn, é—®é¢˜T_qa, ç­”æ¡ˆ, ç±»åˆ«æ ‡ç­¾, ground truth Î²)
  - **å®éªŒç»“æœ** - **å¼€æºæ¨¡å‹å¾®è°ƒåè¶…è¶Šæ‰€æœ‰å•†ä¸šSOTA**:
      - **åŸºçº¿æ¨¡å‹è¡¨ç°ï¼ˆæœªå¾®è°ƒï¼‰**:
        - LLaVA-1.5-7B: ç‰©ä½“æ–¹å‘18.3%ï¼Œè§†è§’25.0%ï¼Œé•œå¤´è·ç¦»29.2%
        - LLaVA-1.6-13B: ç‰©ä½“æ–¹å‘16.1%ï¼Œè§†è§’15.9%ï¼Œé•œå¤´è·ç¦»33.3%
        - Llama-3.2-Vision-11B: ç‰©ä½“æ–¹å‘5.6%ï¼Œè§†è§’6.8%ï¼Œé•œå¤´è·ç¦»38.1%
        - **ç»“è®º**: æ‰€æœ‰åŸºçº¿æ¨¡å‹åœ¨ç›¸æœº-ç‰©ä½“å…³ç³»ç†è§£ä¸Šæ¥è¿‘éšæœºçŒœæµ‹æ°´å¹³ï¼ˆ<40%ï¼‰
      - **å¾®è°ƒåæ€§èƒ½ï¼ˆåœ¨Ultimate3Dä¸Šè®­ç»ƒï¼‰**:
        - **ç‰©ä½“æ–¹å‘ä»»åŠ¡**:
          - å¾®è°ƒLLaVA-1.6-13B: **72.4%** (åˆæˆ) / 63.1% (çœŸå®) vs GPT-4o 43.1%ï¼ˆ+29.3%ï¼‰
          - å¾®è°ƒLlama-3.2-V-11B: **74.2%** (åˆæˆ) / 66.4% (çœŸå®)
        - **ç›¸æœºè§†è§’ä»»åŠ¡**:
          - å¾®è°ƒLLaVA-1.6-13B: **72.3%** (åˆæˆ) / 61.8% (çœŸå®) vs GPT-4o 54.1%ï¼ˆ+18.2%ï¼‰
          - å¾®è°ƒLlama-3.2-V-11B: **69.1%** (åˆæˆ) / 58.7% (çœŸå®)
        - **é•œå¤´è·ç¦»ä»»åŠ¡**:
          - å¾®è°ƒLLaVA-1.6-13B: **94.8%** (åˆæˆ) / 71.4% (çœŸå®) vs GPT-4o 41.7%ï¼ˆ+53.1%ï¼‰
          - å¾®è°ƒLLaVA-1.5-7B: **94.0%** (åˆæˆ) / 66.7% (çœŸå®)
      - **å•†ä¸šæ¨¡å‹è¡¨ç°å¯¹æ¯”**:
        - GPT-4o: ç‰©ä½“æ–¹å‘43.1%ï¼Œè§†è§’54.1%ï¼Œé•œå¤´è·ç¦»41.7%
        - Claude-3-Sonnet: ç‰©ä½“æ–¹å‘43.1%ï¼Œè§†è§’54.3%ï¼Œé•œå¤´è·ç¦»41.7%
        - Claude-3.5-Sonnet: ç‰©ä½“æ–¹å‘40.3%ï¼Œè§†è§’55.6%ï¼Œé•œå¤´è·ç¦»41.8%
        - **ç»“è®º**: æ‰€æœ‰å•†ä¸šæ¨¡å‹åœ¨Ultimate3DåŸºå‡†ä¸Šè¡¨ç°ä¸ä½³ï¼Œæ­ç¤ºç›¸æœº-ç‰©ä½“å…³ç³»ç†è§£æ˜¯å½“å‰MLLMsçš„æ™®éå¼±ç‚¹
      - **è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼ˆMMVPåŸºå‡†ï¼‰**:
        - å¾®è°ƒåæ¨¡å‹åœ¨MMVPä¸Šä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œè¯æ˜å­¦åˆ°çš„ç©ºé—´ç†è§£èƒ½åŠ›å¯è¿ç§»
      - **ç”¨æˆ·ç ”ç©¶**:
        - 93.07%çš„ç”Ÿæˆå›¾åƒè¢«è¯„ä¼°ä¸ºæˆåŠŸä¿æŒäº†3Då‡ ä½•ç»“æ„å’Œç›¸æœº-ç‰©ä½“å…³ç³»
        - è¿œé«˜äºåŸºçº¿æ–¹æ³•ï¼ˆä»…55.11%æˆåŠŸç‡ï¼‰
  - **æ¶ˆèå®éªŒå…³é”®å‘ç°**:
      - **å¤šControlNetå¿…è¦æ€§**: åŒæ—¶ä½¿ç”¨æ·±åº¦+Cannyè¾¹ç¼˜è¾¾åˆ°æœ€ä½³æ•ˆæœï¼ˆå•ç‹¬ä½¿ç”¨ä»»ä¸€å…ˆéªŒæ•ˆæœä¸‹é™ï¼‰
      - **3Då…ˆéªŒçš„é‡è¦æ€§**: ç§»é™¤3Dè§†è§‰å…ˆéªŒï¼Œç›¸æœº-ç‰©ä½“å…³ç³»ä¿æŒç‡å¤§å¹…ä¸‹é™
      - **åˆæˆæ•°æ®vsçœŸå®æ•°æ®**:
        - ä»…åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨åˆæˆæµ‹è¯•é›†ä¸Šè¡¨ç°æœ€ä½³
        - åœ¨çœŸå®æµ‹è¯•é›†ä¸Šï¼Œåˆæˆæ•°æ®è®­ç»ƒçš„æ¨¡å‹ä¾ç„¶æ˜¾è‘—ä¼˜äºæœªå¾®è°ƒåŸºçº¿
      - **æ•°æ®è§„æ¨¡å½±å“**: ä»100Kå¢åŠ åˆ°240Kï¼Œæ€§èƒ½æŒç»­æå‡æ— é¥±å’Œè¿¹è±¡
  - **å®šæ€§åˆ†æ**:
      - **åå·®è¯†åˆ«**:
        - GPT-4oå’ŒClaudeå€¾å‘äºä½ä¼°è§†è§’è§’åº¦ï¼ˆå°†ä¿¯è§†è¯¯åˆ¤ä¸ºæ°´å¹³ï¼‰
        - å€¾å‘äºé«˜ä¼°é•œå¤´è·ç¦»ï¼ˆå°†ä¸­æ™¯è¯¯åˆ¤ä¸ºè¿œæ™¯ï¼‰
        - åœ¨ç‰©ä½“æ–¹å‘åˆ¤æ–­ä¸Šæ¥è¿‘éšæœº
      - **LLaVAåŸºçº¿åå·®**: åŸå§‹LLaVAæ¨¡å‹å¯¹æ‰€æœ‰é—®é¢˜ç»™å‡ºå›ºå®šç­”æ¡ˆï¼ˆ"å·¦å‰"ã€"ä¿¯è§†"ã€"ç‰¹å†™"ï¼‰ï¼Œæ˜¾ç¤ºä¸¥é‡çš„æ•°æ®é›†åå·®
      - **å¾®è°ƒåæ”¹è¿›**: å¾®è°ƒåçš„LLaVAæ¨¡å‹èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«å„ç§ç›¸æœº-ç‰©ä½“å…³ç³»ï¼Œæ— æ˜æ˜¾åå·®
  - **æœºæ„**: Purdue Universityã€Amazon
  - **ä½œè€…**: Shengyuan Ding, Xiaoyi Dong, Yuhang Zang, Haodong Duan, Min Sun, Cheng-Hao Kuo, Daniel Aliagaç­‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´7æœˆï¼ˆv2ï¼‰
  - **å¼€æº**: âœ… [ä»£ç ã€æ•°æ®å’Œæ¨¡å‹](https://github.com/opendatalab/Ultimate3D)
  - **æ„ä¹‰**:
      - **é—®é¢˜è¯†åˆ«**: é¦–æ¬¡ç³»ç»ŸåŒ–æ­ç¤ºMLLMsï¼ˆåŒ…æ‹¬GPT-4oã€Claudeç­‰ï¼‰åœ¨ç›¸æœº-ç‰©ä½“å…³ç³»ç†è§£ä¸Šçš„ä¸¥é‡ç¼ºé™·
      - **æ•°æ®é›†è´¡çŒ®**: æä¾›é¦–ä¸ªå¤§è§„æ¨¡ã€ç²¾ç¡®æ ‡æ³¨çš„3Dç›¸æœº-ç‰©ä½“å…³ç³»VQAæ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†
      - **æ–¹æ³•åˆ›æ–°**: æå‡ºå®Œæ•´çš„3Dèµ„äº§é©±åŠ¨çš„è§†è§‰æŒ‡ä»¤æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œå¯æ‰©å±•åˆ°å…¶ä»–3Dç†è§£ä»»åŠ¡
      - **æ€§èƒ½çªç ´**: è¯æ˜ä»…éœ€240Ké«˜è´¨é‡åˆæˆæ•°æ®å³å¯ä½¿å¼€æº7Bæ¨¡å‹è¶…è¶Šæ‰€æœ‰å•†ä¸šSOTAï¼ˆå¹³å‡æå‡33.4%ï¼‰
      - **åå·®çº æ­£**: ä¸ºçº æ­£ç°æœ‰MLLMsè®­ç»ƒæ•°æ®ä¸­çš„ç©ºé—´å…³ç³»åå·®æä¾›è§£å†³æ–¹æ¡ˆ
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2303.17590">ğŸ“„ SyViC</a></b><br>
<code>arXiv 2303.17590</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2023å¹´3æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **è¶…è¶Šåè¯çš„è§†è§‰è¯­è¨€æ¨¡å‹åˆæˆæ•°æ®å¢å¼º** - ä½¿ç”¨ç‰©ç†ä»¿çœŸå’Œäººä½“åŠ¨ä½œåˆæˆå¢å¼ºVLMå¯¹å±æ€§ã€åŠ¨ä½œã€å…³ç³»å’ŒçŠ¶æ€çš„ç†è§£
  - **æ•°æ®åˆæˆæ–¹æ³•** - **3Dç‰©ç†ä»¿çœŸ + äººä½“è¿åŠ¨åˆæˆ + ç©ºé—´å…³ç³»å»ºæ¨¡**:
      - **æ ¸å¿ƒåˆ›æ–°**: æ„å»ºç™¾ä¸‡çº§åˆæˆæ•°æ®é›†ï¼Œä¸“æ³¨äº"è¶…è¶Šåè¯"çš„è§†è§‰è¯­è¨€æ¦‚å¿µ(VLC)ï¼Œè§£å†³VLMåœ¨ç»„åˆæ¨ç†å’Œéå¯¹è±¡è¯ç†è§£æ–¹é¢çš„å¼±ç‚¹
      - **åŸºç¡€å¹³å°**: **ThreeDWorld (TDW)** - å¤šæ¨¡æ€ç‰©ç†ä»¿çœŸå¹³å°
        - **3Dèµ„æº**: 2,304ä¸ªå¯¹è±¡æ¨¡å‹ï¼Œ585ç§ç‹¬ç‰¹æè´¨ï¼Œ30+å®¤å†…å’Œ9ä¸ªå®¤å¤–åœºæ™¯
        - **æè´¨ç±»å‹**: é‡‘å±ã€çº¸æ¿ã€æœ¨æã€é™¶ç“·ã€ç»ç’ƒç­‰å¤šæ ·åŒ–çº¹ç†
        - **ç‰©ç†å¼•æ“**: æ”¯æŒçœŸå®ç‰©ç†äº¤äº’å’Œç¢°æ’æ£€æµ‹
      - **ä¸‰å¤§åˆæˆç»„ä»¶**:
        1. **å¤šå¯¹è±¡åœºæ™¯åˆæˆ**:
           - **å¯¹è±¡æ”¾ç½®**: æ¯åœºæ™¯éšæœºæ”¾ç½®1-8ä¸ª3Då¯¹è±¡æ¨¡å‹ï¼Œä½¿ç”¨ç¢°æ’å™¨ç¡®ä¿åˆç†å¸ƒå±€
           - **å¤šè§†è§’æ¸²æŸ“**: åŒæ—¶éƒ¨ç½²4-12ä¸ªç›¸æœºä½ç½®ï¼Œè·å–åŒä¸€åœºæ™¯çš„ä¸åŒè§†è§’
           - **å±æ€§éšæœºåŒ–**: ç¨‹åºåŒ–éšæœºåŒ–å¯¹è±¡é¢œè‰²ã€å¤§å°ã€æè´¨
           - **ç©ºé—´å…³ç³»**: åŸºäº3Dä¸–ç•Œåæ ‡è‡ªåŠ¨ç”Ÿæˆä½ç½®å…³ç³»æè¿°(å·¦/å³ã€å‰/åã€ä¸Š/ä¸‹)
        2. **äººä½“è¿åŠ¨ä¸äº¤äº’åˆæˆ**:
           - **èº«ä½“æ¨¡å‹**: ä½¿ç”¨**SMPL-X**å‚æ•°åŒ–äººä½“æ¨¡å‹è¿›è¡Œç²¾ç¡®å§¿æ€æ§åˆ¶
           - **è¿åŠ¨æ•°æ®æº**: æ•´åˆ**AMASS**ã€**BABEL**ã€**TEACH**å¤§è§„æ¨¡è¿åŠ¨æ•æ‰æ•°æ®åº“
           - **å¤šæ ·æ€§è®¾è®¡**:
             - **æ€§åˆ«å¤šæ ·æ€§**: ç”·æ€§å’Œå¥³æ€§é¢„åˆ¶ä»¶(Unity Prefabs)
             - **æœè£…å¤šæ ·æ€§**: SURREAL + Multi-Garmentç³»ç»Ÿæ”¯æŒå¤šå±‚æœè£…ç»„åˆ
             - **è¿åŠ¨å¤šæ ·æ€§**: æ¶µç›–æ—¥å¸¸æ´»åŠ¨(èµ°è·¯ã€è·‘æ­¥ã€è·³è·ƒã€èˆè¹ˆ)å’Œå¤æ‚äº¤äº’
           - **äººç‰©-å¯¹è±¡äº¤äº’**: äººä¸åœºæ™¯å¯¹è±¡çš„ç‰©ç†äº¤äº’(æŠ“å–ã€ç§»åŠ¨ã€é¿è®©)
        3. **å¯†é›†æ ‡æ³¨ç”Ÿæˆ**:
           - **åŸºäºè§„åˆ™çš„è¯­æ³•**: å¼€å‘å…ƒæ•°æ®é©±åŠ¨çš„è¯­æ³•ç³»ç»Ÿï¼Œä»åœºæ™¯å…ƒæ•°æ®è‡ªåŠ¨ç”Ÿæˆè¯¦ç»†æ ‡æ³¨
           - **å¤šå±‚æ¬¡æè¿°**:
             - **å¯¹è±¡æè¿°**: å½¢çŠ¶ã€é¢œè‰²ã€æè´¨ã€ä½ç½®
             - **äººç‰©æè¿°**: æ€§åˆ«ã€æœè£…ã€å‘å‹ã€åŠ¨ä½œçŠ¶æ€
             - **å…³ç³»æè¿°**: å¯¹è±¡é—´ç©ºé—´å…³ç³»ã€äººç‰©-å¯¹è±¡å…³ç³»
             - **åœºæ™¯æè¿°**: ç¯å¢ƒèƒŒæ™¯ã€æ•´ä½“å¸ƒå±€
           - **é•¿æ ‡æ³¨å¤„ç†**: å¼€å‘æ ‡æ³¨åˆ†å‰²æ¨¡å—å¤„ç†è¶…å‡ºCLIPæ–‡æœ¬ç¼–ç å™¨ä¸Šä¸‹æ–‡é•¿åº¦çš„æ ‡æ³¨
      - **æ•°æ®å¢å¼ºç­–ç•¥**:
        - **é¢†åŸŸè‡ªé€‚åº”é£æ ¼åŒ–**: ä½¿ç”¨é£æ ¼è¿ç§»å‡å°‘åˆæˆ-çœŸå®æ•°æ®åŸŸå·®è·
        - **å‚æ•°é«˜æ•ˆå¾®è°ƒ**: LoRAé€‚é…å™¨è¿›è¡Œä½å‚æ•°æ›´æ–°ï¼Œé¿å…ç¾éš¾æ€§é—å¿˜
        - **æ¨¡å‹å¹³å‡**: ç»„åˆå¤šä¸ªæ£€æŸ¥ç‚¹æƒé‡ï¼Œå¹³è¡¡VLCç†è§£å¢ç›Šå’Œé›¶æ ·æœ¬èƒ½åŠ›ä¿æŒ
  - **æ•°æ®è§„æ¨¡**:
      - **SyViCæ•°æ®é›†**: 767,000å›¾åƒ-æ–‡æœ¬å¯¹
      - **æ ‡æ³¨è´¨é‡**: å¹³å‡å¤šå¥æè¿°ï¼Œæ¶µç›–å¯¹è±¡ã€å±æ€§ã€åŠ¨ä½œã€å…³ç³»ã€çŠ¶æ€
      - **å¤šæ ·æ€§**: æ¶µç›–æ•°åƒç§å¯¹è±¡-å±æ€§-åŠ¨ä½œç»„åˆï¼Œç¡®ä¿ç»„åˆæ¨ç†è®­ç»ƒè¦†ç›–åº¦
  - **è®­ç»ƒç­–ç•¥**:
      - **LoRAå¾®è°ƒ**: å†»ç»“åŸºç¡€æ¨¡å‹å‚æ•°ï¼Œä»…è®­ç»ƒä½ç§©é€‚åº”å±‚
      - **æ ‡æ³¨åˆ†å‰²**: å°†é•¿æ ‡æ³¨åˆ†å‰²ä¸ºå­æ ‡æ³¨ï¼Œåˆ†åˆ«ç¼–ç åå¹³å‡ç‰¹å¾
      - **å¯¹æ¯”å­¦ä¹ **: ä¿æŒåŸå§‹æ¨¡å‹(CLIP/CyCLIP)å¯¹æ¯”æŸå¤±å‡½æ•°
      - **é¢†åŸŸé€‚åº”**: ç»“åˆé£æ ¼åŒ–å’Œå‚æ•°é«˜æ•ˆæ–¹æ³•å‡å°‘é—å¿˜
  - **å®éªŒç»“æœ**:
      - **ç»„åˆç†è§£åŸºå‡†**:
        - **VL-Checklist**: syn-CLIP vs CLIPæ˜¾ç¤ºå…³ç³»ç†è§£+5.82%ï¼Œå±æ€§ç†è§£+2.86%
        - **AROåŸºå‡†**: VG-Relation +12.56%ï¼ŒVG-Attribution +3.75%
        - **Winoground**: ç»„åˆæ¨ç†ä»»åŠ¡ä¸ŠæŒç»­æ”¹è¿›ï¼ŒGroup Scoreæå‡+1.75%
      - **é›¶æ ·æœ¬ä»»åŠ¡ä¿æŒ**:
        - **Flickr30kæ£€ç´¢**: +11.5% vs CLIPåŸºçº¿
        - **COCOæ£€ç´¢**: +9.9% vs CLIPåŸºçº¿
        - **21ä¸ªé›¶æ ·æœ¬ä»»åŠ¡**: å¹³å‡æ€§èƒ½åŸºæœ¬ä¿æŒ(-0.8%)ï¼Œè¯æ˜æ— æ˜¾è‘—é—å¿˜
      - **æ¶ˆèç ”ç©¶å‘ç°**:
        - **äººä½“å¤´åƒé‡è¦æ€§**: åŒ…å«äººä½“è¿åŠ¨æ•°æ®æ˜¾è‘—æå‡å±æ€§å’Œå…³ç³»ç†è§£
        - **å¯¹è±¡å±æ€§éšæœºåŒ–**: é¢œè‰²ã€å¤§å°ã€æè´¨éšæœºåŒ–å‡æœ‰ç‹¬ç«‹è´¡çŒ®
        - **è®­ç»ƒç­–ç•¥ç»„åˆ**: LoRA + é¢†åŸŸé€‚åº”é£æ ¼åŒ– + æ ‡æ³¨åˆ†å‰²ç»„åˆæ•ˆæœæœ€ä½³
  - **å…³é”®å‘ç°**:
      - **"è¶…è¶Šåè¯"çªç ´**: é¦–æ¬¡ç³»ç»Ÿæ€§è§£å†³VLMåœ¨éå¯¹è±¡è¯(å±æ€§ã€åŠ¨ä½œã€å…³ç³»)ç†è§£ä¸Šçš„å±€é™
      - **ç‰©ç†ä»¿çœŸä¼˜åŠ¿**: 3Dç‰©ç†å¼•æ“ç”Ÿæˆçš„ç©ºé—´å…³ç³»æ¯”2Då›¾åƒæ›´å‡†ç¡®ã€æ›´å¤šæ ·
      - **åˆæˆæ•°æ®å……åˆ†æ€§**: çº¯åˆæˆæ•°æ®å³å¯æ˜¾è‘—æå‡ç»„åˆç†è§£ï¼Œæ— éœ€é¢å¤–çœŸå®æ•°æ®
      - **å‚æ•°æ•ˆç‡**: LoRAå¾®è°ƒåœ¨ä¿æŒé›¶æ ·æœ¬èƒ½åŠ›çš„åŒæ—¶å®ç°ç›®æ ‡æ”¹è¿›
  - **å‘å¸ƒæ—¶é—´**: arXiv 2023å¹´3æœˆ | MIT-IBM Watson AI Lab & Rice Universityç­‰
  - **å¼€æº**: âœ… ä»£ç ã€SyViCæ•°æ®é›†(767K)ã€è®­ç»ƒæ–¹æ³• - è®ºæ–‡ä¸­æä¾›è¯¦æƒ…
  - **é‡è¦æ„ä¹‰**:
      - **VLMå¼±ç‚¹é’ˆå¯¹æ€§è§£å†³**: ç›´æ¥è§£å†³ç°æœ‰VLMåœ¨ç»„åˆæ¨ç†ä¸Šçš„å·²çŸ¥å±€é™
      - **ç‰©ç†ä»¿çœŸæ•°æ®èŒƒå¼**: å»ºç«‹3Dç‰©ç†ä»¿çœŸç”ŸæˆVLè®­ç»ƒæ•°æ®çš„æ–¹æ³•è®º
      - **å¯æ‰©å±•æ¡†æ¶**: æä¾›å¯å¤ç”¨çš„åˆæˆæ•°æ®ç”Ÿæˆå’Œå¾®è°ƒæ¡†æ¶ï¼Œé€‚ç”¨äºå…¶ä»–VLM
  

</details>
---

#### ğŸ“ å‡ ä½•ä¸æ•°å­¦æ¨ç†

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.17885">ğŸ“„ R-CoT</a></b><br>
<code>arXiv 2410.17885 | ICLR 2025</code>
</summary>

  - **æ•°æ®åˆæˆæ–¹æ³•** - **å‡ ä½•æ¨ç†çš„é€†å‘æ€ç»´é“¾**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šç»“åˆ**å¼•æ“å‡†ç¡®æ€§**ä¸**LLMå¤šæ ·æ€§**çš„ä¸¤é˜¶æ®µå‡ ä½•é—®é¢˜ç”Ÿæˆç®¡é“
      - **é˜¶æ®µ1 - GeoChain**ï¼š**ç”Ÿæˆé«˜ä¿çœŸå‡ ä½•å›¾åƒ**åŠå…¶å¯¹åº”æè¿°
        - ä½¿ç”¨**åŸºäºä»£ç çš„å¼•æ“**é€æ­¥ç”Ÿæˆå‡†ç¡®çš„å‡ ä½•å›¾åƒ
        - ç”Ÿæˆè¯¦ç»†æè¿°ï¼Œçªå‡º**å‡ ä½•å…ƒç´ é—´çš„å…³ç³»**
        - å›¾åƒä¿çœŸåº¦é«˜äºç°æœ‰åˆæˆå‡ ä½•æ•°æ®
      - **é˜¶æ®µ2 - Reverse A&Q**ï¼šä»æ¨ç†ç»“æœé€†å‘ç”ŸæˆQ&Aå¯¹
        - **æ­¥éª¤1**ï¼šæè¿°å—æ¨ç† - ä»æè¿°è¿›è¡Œå•æ­¥æ¨ç†
        - **æ­¥éª¤2**ï¼šæ€ç»´é“¾èåˆ - é€æ­¥å°†å•æ­¥æ¨ç†èåˆä¸ºå¤šæ­¥æ¨ç†
        - **æ­¥éª¤3**ï¼šé—®é¢˜ç”Ÿæˆ - ä»æ¨ç†ç»“æœ**é€†å‘ç”Ÿæˆ**é—®é¢˜
        - é¿å…äº†ç›´æ¥ä½¿ç”¨LMMä»å›¾åƒç”ŸæˆQ&Aæ—¶çš„å‡†ç¡®æ€§é—®é¢˜
      - **æ ¸å¿ƒä¼˜åŠ¿**ï¼šå…ˆç”Ÿæˆç­”æ¡ˆ**å†ç”Ÿæˆ**é—®é¢˜ï¼Œå‡å°‘é”™è¯¯ç­”æ¡ˆ
  - **æ•°æ®è§„æ¨¡**ï¼šåˆ›å»ºGeoMMæ•°æ®é›†ï¼ŒåŒ…å«é«˜ä¿çœŸå‡ ä½•å›¾åƒå’Œå¤šæ ·åŒ–Q&Aå¯¹
  - **å®éªŒç»“æœ**ï¼š
      - R-CoT-8Båœ¨MathVistaä¸Šè¶…è¶Šä¹‹å‰çš„å¼€æºSOTAæ¨¡å‹**16.6%**ï¼Œåœ¨GeoQAä¸Šè¶…è¶Š**9.2%**
      - åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå¹³å‡è¶…è¶ŠGPT-4o **13%**
      - åœ¨2Bã€7Bå’Œ8Bè®¾ç½®ä¸‹å‡è¾¾åˆ°å‡ ä½•æ¨ç†æ–°SOTA
  - **å‘å¸ƒæ—¶é—´**ï¼šarXiv 2024å¹´10æœˆ
  - **æœºæ„**ï¼šç™¾åº¦å…¬å¸ã€åä¸­ç§‘æŠ€å¤§å­¦
  - **å¼€æº**ï¼šâœ… [ä»£ç å’Œæ¨¡å‹](https://github.com/dle666/r-cot)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=MAVIS">ğŸ“„ MAVIS</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Automatic Mathematical Visual Data Engine**:
      - **Core Innovation**: Fully automated, rule-based data engine **independent of human intervention or GPT API usage**
      - **Complete Data Generation Pipeline**:
        - **Diagram Drawing**: **Automatically creates math diagrams** (image generation)
        - **Caption Generation**: Generates diagram-caption pairs
        - **Q&A Synthesis**: Creates question-answer pairs
        - **CoT Rationale Production**: Produces chain-of-thought reasoning
      - **Key Features**:
        - Ensures **diagram-caption correspondence** through automated rules
        - Guarantees **question-answer correctness** via engine-based generation
        - Maintains **CoT reasoning quality** without relying on proprietary models
      - **Progressive 4-Stage Training Pipeline**:
        - Stage 1: Fine-tune **CLIP-Math** (math-specific vision encoder) with MAVIS-Caption
        - Stage 2: Align CLIP-Math with LLM using MAVIS-Caption
        - Stage 3: Instruction tuning with MAVIS-Instruct
        - Stage 4: DPO to enhance CoT capabilities
  - **Data Scale**:
      - **MAVIS-Caption**: 558K diagram-caption pairs for vision-language alignment
      - **MAVIS-Instruct**: 834K visual math problems with detailed CoT rationales
  - **Experimental Results**:
      - MAVIS-7B surpasses other 7B models by **+9.3%**
      - Outperforms LLaVA-NeXT-110B by **+6.9%**
      - Achieves leading results among open-source MLLMs on mathematical benchmarks
  - **Publication**: arXiv July 2024
  - **Institution**: CUHK, Peking University, Shanghai AI Lab, ByteDance, Oracle
  - **Open Source**: âœ… [Code & Data](https://github.com/ZrrSkywalker/MAVIS)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=ShareGPT-4o-Image">ğŸ“„ ShareGPT-4o-Image</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Distilling GPT-4o Image Generation Capabilities**:
      - **Core Innovation**: First dataset distilled from **GPT-4o's image generation** for both text-to-image and text-and-image-to-image tasks
      - **Text-to-Image Data Generation** (45K pairs) - **IMAGE GENERATION**:
        - **Prompt-First Pipeline**:
          - Define 6-dimensional attribute space (Objects, Background, Style, Camera Angle, etc.)
          - Sample attributes and use LLM (Gemini-Pro-2.5) to compose natural-language prompts
          - Pass prompts to **GPT-4o-Image** to **generate new paired images**
          - Ensures controlled diversity and complexity
        - **Image-First Pipeline**:
          - Source high-quality images from ALLaVA dataset
          - Use LLM to generate detailed descriptive prompts from images
          - Captures natural language needed for describing real-world scenes
      - **Instruction-Guided Image Editing Data** (46K triplets) - **IMAGE EDITING**:
        - Define taxonomy of **14 image editing tasks** across 5 categories (object manipulation, style transfer, conditional control, etc.)
        - For each (source image, editing task): LLM synthesizes specific natural-language instruction
        - **GPT-4o-Image** executes instruction to produce edited output
        - Creates (source image, instruction, edited image) triplets
      - **Key Features**:
        - Synthesized entirely using **GPT-4o** capabilities (no human annotation)
        - Covers wide range of styles and grounded visual reasoning
        - Reflects GPT-4o's strengths in instruction-following and visual aesthetics
  - **Data Scale**: **91K total** (45K text-to-image + 46K instruction-guided editing)
  - **Experimental Results**:
      - Janus-4o (trained on this data) improves over Janus-Pro by **+4 points** on EvalGen and **+1.6 points** on DPG-Bench
      - Achieves impressive text-and-image-to-image generation from scratch with only **91K samples** and **6 hours training** (8Ã—A800)
      - Human evaluations show strong preference for Janus-4o outputs
  - **Publication**: arXiv June 2025
  - **Institution**: The Chinese University of Hong Kong, Shenzhen
  - **Open Source**: âœ… [Code & Data](https://github.com/FreedomIntelligence/ShareGPT-4o-Image)
  
  #### ğŸ“„ æ–‡æ¡£/æ–‡æœ¬å¯†é›†åœºæ™¯
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2505.17778">ğŸ“„ TextFlux</a></b><br>
<code>arXiv 2505.17778</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
</summary>

  - **èšç„¦**: **æ— OCRç¼–ç å™¨çš„é«˜ä¿çœŸå¤šè¯­è¨€åœºæ™¯æ–‡æœ¬åˆæˆ** - åŸºäºDiTçš„OCR-freeæ¡†æ¶ï¼Œé€šè¿‡ç©ºé—´æ‹¼æ¥å­—å½¢æ¸²æŸ“å›¾å®ç°å¤šè¯­è¨€åœºæ™¯æ–‡æœ¬ç”Ÿæˆ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å­—å½¢å¼•å¯¼çš„ç©ºé—´æ‹¼æ¥ç­–ç•¥**:
      - **æ ¸å¿ƒåˆ›æ–°**: æ¶ˆé™¤å¯¹OCRç¼–ç å™¨çš„ä¾èµ–ï¼Œåˆ©ç”¨DiTæ¨¡å‹çš„ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›å®ç°æ–‡æœ¬åˆæˆ
      - **æ–¹æ³•Pipeline**:
        1. **å­—å½¢æ¸²æŸ“**:
           - å°†ç›®æ ‡æ–‡æœ¬æ¸²æŸ“ä¸ºç™½è‰²å‰æ™¯/é»‘è‰²èƒŒæ™¯çš„äºŒå€¼å­—å½¢mask `I_glyph`
           - ç¡®ä¿ä¸åœºæ™¯å›¾åƒ `I_scene` åˆ†è¾¨ç‡åŒ¹é…
        2. **ç©ºé—´æ‹¼æ¥**:
           - å°†å­—å½¢å›¾å’Œåœºæ™¯å›¾æ°´å¹³æˆ–å‚ç›´æ‹¼æ¥ï¼š`I_concat = Concat([I_glyph, I_scene], axis)`
           - å½¢æˆç»Ÿä¸€çš„è¾“å…¥å›¾åƒï¼Œæ— éœ€é¢å¤–çš„è§†è§‰æ¡ä»¶æ¨¡å—
        3. **Promptè®¾è®¡**ï¼ˆä¸Šä¸‹æ–‡å­¦ä¹ èŒƒå¼ï¼‰:
           - æ¨¡æ¿ï¼š"ä¸€å¯¹å›¾åƒçªå‡ºæ˜¾ç¤ºé»‘è‰²èƒŒæ™¯ä¸Šçš„ç™½è‰²å•è¯ï¼Œä»¥åŠå®ƒä»¬åœ¨çœŸå®ä¸–ç•Œåœºæ™¯å›¾åƒä¸­çš„é£æ ¼ã€‚[IMAGE1]æ˜¯æ¸²æŸ“æ–‡æœ¬çš„æ¨¡æ¿å›¾åƒï¼Œå•è¯ä¸º{words}ï¼›[IMAGE2]æ˜¾ç¤ºæ–‡æœ¬å†…å®¹{words}è‡ªç„¶ä¸”ç›¸åº”åœ°èå…¥å›¾åƒä¸­ã€‚"
           - å¼•å¯¼æ¨¡å‹ç†è§£å­—å½¢æ¨¡æ¿ä¸åœºæ™¯å›¾åƒçš„è¯­ä¹‰å…³ç³»
        4. **æ¨¡å‹æ¶æ„**:
           - åŸºäºé¢„è®­ç»ƒçš„FLUX.1-Fill-devï¼ˆDiTæ¶æ„ï¼Œlatent rectified flow transformerï¼‰
           - ç›´æ¥åˆ©ç”¨DiTçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ— éœ€ä¸“é—¨çš„OCRç¼–ç å™¨æˆ–é¢å¤–æŸå¤±å‡½æ•°
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **OCR-free**: å®Œå…¨æ¶ˆé™¤å¯¹OCRç¼–ç å™¨çš„éœ€æ±‚ï¼Œç®€åŒ–æ¨¡å‹æ¶æ„
        - **å¤šè¯­è¨€æ‰©å±•æ€§**: ä½èµ„æºè¯­è¨€ï¼ˆ<1000æ ·æœ¬ï¼‰ä¹Ÿèƒ½è¾¾åˆ°å¼ºæ€§èƒ½
        - **æ•°æ®é«˜æ•ˆ**: ä»…éœ€ç«äº‰æ–¹æ³•1%çš„è®­ç»ƒæ•°æ®ï¼ˆ30,405å¼  vs 300ä¸‡-1000ä¸‡å¼ ï¼‰
        - **å¯æ§å¤šè¡Œç”Ÿæˆ**: æ”¯æŒçµæ´»çš„å¤šè¡Œæ–‡æœ¬åˆæˆï¼Œç²¾ç¡®è¡Œçº§æ§åˆ¶ä½ç½®å’Œå†…å®¹
        - **Zero-shotèƒ½åŠ›**: èƒ½æ¸²æŸ“è®­ç»ƒæ—¶æœªè§è¿‡çš„è¯­è¨€ï¼ˆå¦‚å°‘æ•°æ°‘æ—è¯­è¨€ï¼‰
  - **è®­ç»ƒæ•°æ®è§„æ¨¡**:
      - **æ€»è®¡30,405å¼ å›¾åƒ**ï¼ˆvs AnyWord-3Mçš„300ä¸‡ã€MARIO-10Mçš„1000ä¸‡ï¼‰
        - è‹±æ–‡ï¼šçº¦10,000å¼ ï¼ˆMLT2017ã€TotalTextã€CTW1500ï¼‰
        - ä¸­æ–‡ï¼šçº¦15,000å¼ ï¼ˆReCTSã€RCTWï¼‰
        - å…¶ä»–è¯­è¨€ï¼šå„1,000å¼ ï¼ˆæ—¥è¯­ã€éŸ©è¯­ã€æ³•è¯­ã€å¾·è¯­ã€æ„å¤§åˆ©è¯­ï¼Œæ¥è‡ªMLT2019ï¼‰
      - **è®­ç»ƒé…ç½®**:
        - æ‰¹å¤§å°1ï¼Œæ¢¯åº¦ç´¯ç§¯8
        - AdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡2e-5
        - æ€»è¿­ä»£30,000æ¬¡
        - å¤šåˆ†è¾¨ç‡å¢å¼ºï¼ˆ512-1024ï¼‰
        - ä¸¤ä¸ªç‰ˆæœ¬ï¼šå…¨å‚æ•°ï¼ˆ2Ã—A100 80GBï¼‰+ LoRAï¼ˆ1Ã—A100 80GBï¼Œrank=128ï¼‰
  - **å®éªŒç»“æœ** - **4ä¸ªåŸºå‡†ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**:
      - **å¤šè¡Œæ–‡æœ¬ç”Ÿæˆï¼ˆæ ¸å¿ƒä»»åŠ¡ï¼‰**:
        - AnyWord(EN): TextFlux **80.3%** vs AnyText2 45.1% (+35.2%)
        - AnyWord(CH): TextFlux **62.3%** vs AnyText2 35.9% (+26.4%)
        - TotalText: TextFlux **65.3%** vs AnyText2 20.5% (+44.8%)
        - ReCTS: TextFlux **68.5%** vs AnyText2 41.5% (+27.0%)
      - **å•è¡Œæ–‡æœ¬ç”Ÿæˆ**:
        - è½»é‡çº§LoRAç‰ˆæœ¬å°±å…¨é¢è¶…è¶Šæ‰€æœ‰åŸºçº¿
        - FluxåŸºç¡€æ¨¡å‹ä¸­æ–‡å‡†ç¡®ç‡ä¸º0%ï¼Œåº”ç”¨TextFluxåè¾¾åˆ°62.3%
      - **å®šæ€§ç»“æœ**:
        - åœ¨å¤æ‚èƒŒæ™¯ã€æ›²çº¿æ–‡æœ¬ã€æ‰‹å†™é£æ ¼ç­‰æŒ‘æˆ˜æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•
        - ç”Ÿæˆç»“æœå‡ ä¹ä¸çœŸå®å›¾åƒæ— æ³•åŒºåˆ†
  - **æ¶ˆèå®éªŒå…³é”®å‘ç°**:
      - **å­—å½¢æ‹¼æ¥ç­–ç•¥å¿…è¦æ€§**: ä¸ä½¿ç”¨æ‹¼æ¥ç­–ç•¥ï¼Œä¸­æ–‡å‡†ç¡®ç‡ä»…5.2%
      - **è®­ç»ƒçš„é‡è¦æ€§**: ä»…æ‹¼æ¥ä¸è®­ç»ƒï¼Œå¤æ‚èƒŒæ™¯ä¸‹å®Œå…¨å¤±è´¥
      - **æ–‡æœ¬ç¼–ç å™¨å½±å“**: ç§»é™¤CLIPæˆ–T5ç¼–ç å™¨å¯¹éæ‹‰ä¸æ–‡å­—å½±å“è¾ƒå°ï¼Œè¯´æ˜è§†è§‰ä¸Šä¸‹æ–‡å¼•å¯¼è¶³å¤Ÿæœ‰æ•ˆ
  - **æœºæ„**: bilibiliå…¬å¸ã€è‹å·å¤§å­¦ã€åŒ—äº¬å¤§å­¦ç‹é€‰è®¡ç®—æœºç ”ç©¶æ‰€
  - **ä½œè€…**: Yu Xie, Jielei Zhang, Pengyu Chen, Ziyue Wang, Weihang Wang, Longwen Gao, Peiyi Li, Huyang Sun, Qiang Zhang, Qian Qiao, Jiaqing Fan, Zhouhui Lian
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´5æœˆï¼ˆv1ï¼‰
  - **é¡¹ç›®é¡µé¢**: [https://yyyyyxie.github.io/textflux-site/](https://yyyyyxie.github.io/textflux-site/)
  - **æ„ä¹‰**:
      - **æ¶æ„ç®€åŒ–**: è¯æ˜æ— éœ€å¤æ‚çš„OCRç¼–ç å™¨ï¼ŒDiTçš„ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›è¶³ä»¥æ”¯æŒé«˜è´¨é‡åœºæ™¯æ–‡æœ¬åˆæˆ
      - **æ•°æ®æ•ˆç‡**: ä»¥1%çš„æ•°æ®é‡è¾¾åˆ°SOTAï¼Œä¸ºä½èµ„æºåœºæ™¯æä¾›å¯è¡Œæ–¹æ¡ˆ
      - **å¤šè¯­è¨€çªç ´**: é¦–æ¬¡è¯æ˜æå°æ•°æ®é‡ï¼ˆ<1000æ ·æœ¬ï¼‰å³å¯å®ç°ä½èµ„æºè¯­è¨€çš„é«˜è´¨é‡æ–‡æœ¬æ¸²æŸ“
      - **å¯æ§æ€§æå‡**: æ”¯æŒå¤šè¡Œæ–‡æœ¬çš„çµæ´»æ§åˆ¶ï¼Œçªç ´ç°æœ‰æ–¹æ³•çš„å•è¡Œæˆ–å›ºå®šå¸ƒå±€é™åˆ¶
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.12628">ğŸ“„ DocLayout-YOLO</a></b><br>
<code>arXiv 2410.12628</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šè¿‡å¤šæ ·åŒ–åˆæˆæ•°æ®å’Œå…¨å±€åˆ°å±€éƒ¨è‡ªé€‚åº”æ„ŸçŸ¥å¢å¼ºæ–‡æ¡£å¸ƒå±€åˆ†æ** - ç”ŸæˆDocSynth-300Kå¤§è§„æ¨¡å¤šæ ·åŒ–æ–‡æ¡£åˆæˆæ•°æ®é›†ï¼Œå¹¶è®¾è®¡GL-CRMæ¨¡å—å¤„ç†æ–‡æ¡£å…ƒç´ å¤šå°ºåº¦å˜åŒ–
  - **æ•°æ®åˆæˆæ–¹æ³•** - **Mesh-candidate BestFitç®—æ³• + å…ƒç´ å¢å¼º**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªå°†æ–‡æ¡£åˆæˆè§†ä¸ºäºŒç»´è£…ç®±é—®é¢˜çš„æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£æœ€ä½³åŒ¹é…ç”Ÿæˆç¾è§‚ä¸”å¤šæ ·çš„æ–‡æ¡£å¸ƒå±€
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰å•æ¨¡æ€DLAæ–¹æ³•ï¼ˆå¦‚YOLOã€DINOï¼‰é€Ÿåº¦å¿«ä½†å‡†ç¡®ç‡è¾ƒä½
        - å¤šæ¨¡æ€æ–¹æ³•ï¼ˆå¦‚LayoutLMv3ã€DiTï¼‰å‡†ç¡®ç‡é«˜ä½†é€Ÿåº¦æ…¢ï¼ˆå»¶è¿Ÿæ˜¾è‘—ï¼‰
        - ç°æœ‰æ–‡æ¡£é¢„è®­ç»ƒæ•°æ®é›†ï¼ˆå¦‚PubLayNetã€DocBankï¼‰ç±»å‹å•ä¸€ï¼ˆä»…å­¦æœ¯è®ºæ–‡ï¼‰ï¼Œå…ƒç´ å¤šæ ·æ€§ä¸è¶³ï¼ˆ<10ç±»ï¼‰
        - Diffusionç­‰ç”Ÿæˆæ–¹æ³•ç”Ÿæˆå¸ƒå±€åŒè´¨åŒ–ä¸¥é‡ï¼Œæ— æ³•è¦†ç›–å¤šç§çœŸå®æ–‡æ¡£ç±»å‹
      - **ä¸‰é˜¶æ®µç”ŸæˆPipeline**:
        1. **é¢„å¤„ç†ï¼šç¡®ä¿å…ƒç´ å¤šæ ·æ€§ï¼ˆPreprocessingï¼‰**:
           - **æ•°æ®æº**: M6Docæµ‹è¯•é›†ï¼ˆ2800é¡µå¤šæ ·åŒ–æ–‡æ¡£ï¼Œ74ç§ç»†ç²’åº¦å…ƒç´ ç±»åˆ«ï¼‰
           - **å…ƒç´ æ± æ„å»º**:
             - æŒ‰ç»†ç²’åº¦ç±»åˆ«åˆ†å‰²é¡µé¢ï¼Œæå–å„ç±»åˆ«å…ƒç´ 
             - å¯¹æ•°é‡<100çš„ç¨€æœ‰ç±»åˆ«è¿›è¡Œå¢å¼º
           - **å¢å¼ºç­–ç•¥ï¼ˆ5ç§æŠ€æœ¯ï¼‰**:
             a) **æ ·å¼è¿ç§»**: åº”ç”¨ä¸åŒå­—ä½“ã€é¢œè‰²ã€æ ·å¼åˆ°æ–‡æœ¬å…ƒç´ 
             b) **LLMé‡å†™**: GPT-4é‡å†™æ–‡æœ¬å…ƒç´ å†…å®¹ï¼ˆä¿æŒè¯­ä¹‰ç›¸ä¼¼ï¼‰
             c) **èƒŒæ™¯æ›¿æ¢**: æ›¿æ¢å…ƒç´ èƒŒæ™¯
             d) **å¼¹æ€§å˜æ¢**: è½»å¾®æ‰­æ›²å…ƒç´ æ¨¡æ‹ŸæŠ–åŠ¨æˆ–ä½åˆ†è¾¨ç‡
             e) **é«˜æ–¯å™ªå£°**: æ·»åŠ å™ªå£°æ¨¡æ‹Ÿç°å®å¤±çœŸ
           - **ç»“æœ**: ç¡®ä¿æ¯ä¸ªç±»åˆ«è‡³å°‘100ä¸ªå¤šæ ·åŒ–å…ƒç´ 
        2. **å¸ƒå±€ç”Ÿæˆï¼šç¡®ä¿å¸ƒå±€å¤šæ ·æ€§ï¼ˆLayout Generationï¼‰**:
           - **ç®—æ³•**: **Mesh-candidate BestFit** - å—äºŒç»´è£…ç®±é—®é¢˜å¯å‘
           - **å…³é”®æ´å¯Ÿ**: éšæœºæ’åˆ—äº§ç”Ÿæ··ä¹±å¸ƒå±€ï¼›Diffusionæ¨¡å‹ç”ŸæˆåŒè´¨åŒ–å¸ƒå±€ï¼ˆä»…å­¦æœ¯è®ºæ–‡é£æ ¼ï¼‰
           - **æ ¸å¿ƒæ€æƒ³**: å°†å½“å‰å¸ƒå±€çš„å¯ç”¨ç½‘æ ¼è§†ä¸ºä¸åŒå¤§å°çš„"ç®±å­"ï¼Œè¿­ä»£æ‰§è¡Œæœ€ä½³åŒ¹é…
           - **è¯¦ç»†æ­¥éª¤**:
             a) **å€™é€‰é‡‡æ ·**: ä»å…ƒç´ æ± ä¸­è¿›è¡Œåˆ†å±‚é‡‡æ ·ï¼ˆåŸºäºå…ƒç´ å¤§å°ï¼‰ï¼Œå½¢æˆå€™é€‰é›†C_set
             b) **Meshå¼•æ“**: åˆ†æå½“å‰å¸ƒå±€Lï¼Œç”Ÿæˆæ‰€æœ‰å¯ç”¨ç½‘æ ¼ä½ç½®é›†åˆM
             c) **æœ€ä½³åŒ¹é…è¿­ä»£**:
                - å¯¹æ¯ä¸ªå€™é€‰å…ƒç´ e_iå’Œæ¯ä¸ªç½‘æ ¼g_jï¼Œè®¡ç®—å¡«å……ç‡fr = match(e_i, g_j)
                - é€‰æ‹©å¡«å……ç‡æœ€é«˜ä¸”>é˜ˆå€¼fr_thrçš„(e_i, g_j)å¯¹
                - å°†e_iæ”¾ç½®åœ¨g_jä½ç½®ï¼Œæ›´æ–°å¸ƒå±€L
                - ä»å€™é€‰é›†ä¸­ç§»é™¤e_i
                - é‡å¤ç›´åˆ°æ— æ³•æ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„åŒ¹é…
             d) **çº¦æŸ**: å°å…ƒç´ æ•°é‡â‰¤Mini_num=5ï¼ˆé¿å…è¿‡å¤šå°å…ƒç´ é™ä½ç¾å­¦ï¼‰
           - **ä¼˜åŠ¿**: å¹³è¡¡å¸ƒå±€å¤šæ ·æ€§ï¼ˆéšæœºæ€§ï¼‰å’Œç¾å­¦ï¼ˆå¡«å……ç‡å’Œå¯¹é½ï¼‰
        3. **å›¾åƒæ¸²æŸ“ä¸åå¤„ç†ï¼ˆRenderingï¼‰**:
           - **æ¸²æŸ“**: å°†å¸ƒå±€Lå’Œå…ƒç´ æ¸²æŸ“ä¸ºå®Œæ•´æ–‡æ¡£å›¾åƒ
           - **åå¤„ç†**:
             - åº”ç”¨æ ·å¼è¿ç§»ã€LLMé‡å†™ã€èƒŒæ™¯æ›¿æ¢ç­‰å¢å¼ºæŠ€æœ¯
             - æ·»åŠ å¼¹æ€§å˜æ¢å’Œé«˜æ–¯å™ªå£°æ¨¡æ‹ŸçœŸå®åœºæ™¯
           - **è¾“å‡º**: æœ€ç»ˆçš„æ–‡æ¡£å›¾åƒåŠå¯¹åº”çš„å¸ƒå±€æ ‡æ³¨
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç¾å­¦ä¿è¯**: é€šè¿‡å¡«å……ç‡å’Œå¯¹é½ä¼˜åŒ–ï¼Œç”Ÿæˆå¸ƒå±€ç¬¦åˆäººç±»è®¾è®¡åŸåˆ™
          - **å¯¹é½åº¦è¯„åˆ†**: Î”x* = min|x*_i - x*_j|ï¼ˆè¶Šå°è¶Šå¯¹é½ï¼‰ï¼Œå®éªŒæ˜¾ç¤ºMesh-BFä¸º0.0009 vs Random 0.0171 vs Diffusion 0.0032
          - **å¯†åº¦è¯„åˆ†**: L_dst = Î£|e_i| / |L|ï¼ˆè¶Šå¤§è¶Šç´§å‡‘ï¼‰ï¼Œå®éªŒæ˜¾ç¤ºMesh-BFä¸º0.645 vs Random 0.259 vs Diffusion 0.476
        - **å¸ƒå±€å¤šæ ·æ€§**: ç”Ÿæˆä»å¯†é›†ï¼ˆå¤šå°å…ƒç´ ï¼‰åˆ°ç¨€ç–ï¼ˆå°‘å¤§å…ƒç´ ï¼‰çš„å„ç§å¸ƒå±€
        - **å…ƒç´ å¤šæ ·æ€§**: 74ç§ç»†ç²’åº¦ç±»åˆ«ï¼Œè¿œè¶…PubLayNetï¼ˆ6ç±»ï¼‰ã€DocBankï¼ˆ13ç±»ï¼‰
        - **å¯æ‰©å±•æ€§**: å¯åŸºäºä»»ä½•æ–‡æ¡£å…ƒç´ æ± ç”Ÿæˆä»»æ„è§„æ¨¡æ•°æ®é›†
  - **DocSynth-300Kæ•°æ®é›†**:
      - **åŸå§‹ç”Ÿæˆ**: 594Kæ–‡æ¡£å›¾åƒ
      - **è¿‡æ»¤åè§„æ¨¡**: 300Ké«˜è´¨é‡æ–‡æ¡£ï¼ˆä¸¢å¼ƒåº•éƒ¨è¿‡æ»¤æ ·æœ¬ï¼‰
      - **å…ƒç´ è¦†ç›–**: 74ç§ç»†ç²’åº¦å…ƒç´ ç±»åˆ«
      - **å¸ƒå±€å¤šæ ·æ€§**: æ¶µç›–å­¦æœ¯è®ºæ–‡ã€æ•™ç§‘ä¹¦ã€å¸‚åœºåˆ†ææŠ¥å‘Šã€è´¢åŠ¡æ–‡æ¡£ç­‰å¤šç§ç±»å‹
      - **æ ‡æ³¨**: æ¯ä¸ªå…ƒç´ çš„ç±»åˆ«ã€ä½ç½®ï¼ˆbounding boxï¼‰
      - **ç‰¹ç‚¹**:
        - è¿œè¶…ç°æœ‰æ•°æ®é›†çš„å¤šæ ·æ€§ï¼ˆPubLayNet 360Kä½†ä»…å­¦æœ¯è®ºæ–‡ï¼ŒDocBank 500Kä½†å¼±ç›‘ç£è´¨é‡è¾ƒä½ï¼‰
        - ç¾å­¦è¯„åˆ†æ˜¾è‘—ä¼˜äºRandomå’ŒDiffusionæ–¹æ³•
  - **DocStructBenchè¯„ä¼°åŸºå‡†**:
      - **ç›®æ ‡**: å®šé‡è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ–‡æ¡£ç±»å‹ä¸Šçš„æ€§èƒ½
      - **è§„æ¨¡**: 9,955å¼ å›¾åƒï¼ˆ7,310è®­ç»ƒ + 2,645æµ‹è¯•ï¼‰
      - **å››ä¸ªå­é›†**:
        - **Academic**: å­¦æœ¯è®ºæ–‡ï¼ˆ1,605è®­ç»ƒ + 402æµ‹è¯•ï¼‰
        - **Textbook**: æ•™ç§‘ä¹¦å’Œè¯•å·ï¼ˆ2,345è®­ç»ƒ + 587æµ‹è¯•ï¼‰
        - **Market Analysis**: è¡Œä¸šå’Œå¸‚åœºåˆ†ææŠ¥å‘Šï¼ˆ2,660è®­ç»ƒ + 651æµ‹è¯•ï¼‰
        - **Financial**: è´¢åŠ¡ä¸šåŠ¡æ–‡æ¡£ï¼ˆ2,472è®­ç»ƒ + 592æµ‹è¯•ï¼‰
      - **10ä¸ªå…ƒç´ ç±»åˆ«**: Title, Plain Text, Abandoned Text, Figure, Figure Caption, Table, Table Caption, Table Footnote, Isolated Formula, Formula Caption
      - **æ¥æºå¤šæ ·åŒ–**: æ¥è‡ªä¸åŒæœºæ„ã€å‡ºç‰ˆç¤¾ã€ç½‘ç«™çš„å¹¿æ³›é¢†åŸŸæ–‡æ¡£
      - **äººå·¥æ ‡æ³¨**: æ¯å¼ å›¾åƒç»äººå·¥ç²¾ç¡®æ ‡æ³¨
  - **Global-to-Local Controllable Receptive Module (GL-CRM)**:
      - **é—®é¢˜**: æ–‡æ¡£å…ƒç´ å°ºåº¦å˜åŒ–å¤§ï¼ˆå•è¡Œæ ‡é¢˜ vs æ•´é¡µè¡¨æ ¼ï¼‰
      - **è§£å†³æ–¹æ¡ˆ**: åˆ†å±‚æ¶æ„ä»å…¨å±€åˆ°å±€éƒ¨æ„ŸçŸ¥
      - **Controllable Receptive Module (CRM)**:
        - **è¾“å…¥**: ç‰¹å¾å›¾X
        - **å¤šç²’åº¦ç‰¹å¾æå–**: ä½¿ç”¨æƒé‡å…±äº«å·ç§¯wï¼ˆkernel size kï¼‰å’Œä¸åŒè†¨èƒ€ç‡d=[d_1, d_2, ..., d_n]
        - **å…¬å¼**: F_i = GELU(BN(Conv(X, w, d_i)))
        - **ç‰¹å¾èåˆ**: FË† = Concat(F_1, ..., F_n) â†’ Conv â†’ SigmoidåŠ æƒ
        - **è‡ªé€‚åº”èåˆ**: ç½‘ç»œå­¦ä¹ è‡ªåŠ¨èåˆä¸åŒç²’åº¦ç‰¹å¾
      - **Global-to-Localè®¾è®¡ï¼ˆä¸‰å±‚æ¬¡ï¼‰**:
        a) **Global-levelï¼ˆæµ…å±‚ï¼‰**: CRM with k=7, d=[1,3,5,7] - æ„ŸçŸ¥æ•´é¡µå°ºåº¦å…ƒç´ 
        b) **Block-levelï¼ˆä¸­å±‚ï¼‰**: CRM with k=3, d=[1,2,3] - æ„ŸçŸ¥æ–‡æ¡£å­å—ï¼ˆä¸­ç­‰å°ºåº¦ï¼‰
        c) **Local-levelï¼ˆæ·±å±‚ï¼‰**: Basic bottleneck - èšç„¦å±€éƒ¨è¯­ä¹‰ä¿¡æ¯ï¼ˆå°å°ºåº¦ï¼‰
      - **ä¼˜åŠ¿**: é€‚åº”æ–‡æ¡£å…ƒç´ çš„å¤šå°ºåº¦ç‰¹æ€§ï¼Œæ˜¾è‘—æå‡æ£€æµ‹ç²¾åº¦
  - **å®éªŒç»“æœ** - **é€Ÿåº¦å’Œå‡†ç¡®ç‡åŒæå‡**:
      - **D4LAæ•°æ®é›†**ï¼ˆ11,092å¼ å¤æ‚æ–‡æ¡£ï¼Œ27ç±»ï¼Œ12ç§æ–‡æ¡£ç±»å‹ï¼‰:
        - DocLayout-YOLO: mAP **70.3%**, AP50 82.4%, FPS **144.9**
        - YOLO-v10 (Baseline): mAP 68.6%, AP50 80.7%, FPS 144.9%
        - DINO-4scale: mAP 64.7%, AP50 76.9%, FPS 26.7
        - DiT-Cascade-L: mAP 68.2%, AP50 80.1%, FPS 6.0
        - LayoutLMv3-B: mAP 60.0%, AP50 72.6%, FPS 9.0
        - **ç»“è®º**: è¶…è¶Šæ‰€æœ‰å•æ¨¡æ€å’Œå¤šæ¨¡æ€æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒæœ€å¿«é€Ÿåº¦
      - **DocLayNetæ•°æ®é›†**ï¼ˆ80,863é¡µï¼Œ11ç±»ï¼Œ7ç§æ–‡æ¡£ç±»å‹ï¼‰:
        - DocLayout-YOLO: mAP **79.7%**, AP50 93.4%
        - YOLO-v10 (Baseline): mAP 76.2%, AP50 93.0%
        - DINO-4scale: mAP 77.7%, AP50 93.5%
        - DiT-Cascade-B/L: mAP 73.2%/72.6%
        - LayoutLMv3-B: mAP 75.4%, AP50 92.1%
        - **ç»“è®º**: æ˜¾è‘—è¶…è¶Šæ‰€æœ‰æ–¹æ³•ï¼ˆ+2.0% vs DINOï¼Œ+7.1% vs DiT-Lï¼‰
      - **DocStructBenchå››å­é›†æ€§èƒ½**:
        - **Academic**: 81.8% (vs YOLO-v10 80.5%, DiT-L 81.0%)
        - **Textbook**: 73.7% (vs YOLO-v10 70.2%, DiT-L 70.8%)
        - **Market Analysis**: 69.4% (vs YOLO-v10 68.9%, DiT-L 70.8%)
        - **Financial**: 90.1% (vs YOLO-v10 89.9%, DiT-L 89.3%)
        - **ç»“è®º**: åœ¨æ‰€æœ‰æ–‡æ¡£ç±»å‹ä¸Šå‡è¾¾åˆ°æˆ–æ¥è¿‘æœ€ä½³æ€§èƒ½
      - **é€Ÿåº¦å¯¹æ¯”**ï¼ˆå•å¼ A100 GPUï¼‰:
        - DocLayout-YOLO: **85.5 FPS**
        - YOLO-v10: 144.9 FPSï¼ˆç•¥å¿«ä½†ç²¾åº¦è¾ƒä½ï¼‰
        - DINO-4scale: 26.7 FPS
        - DiT-Cascade-L: 6.0 FPS
        - LayoutLMv3: 9.0 FPS
        - **ç»“è®º**: åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶ï¼Œé€Ÿåº¦æ˜¾è‘—å¿«äºå¤šæ¨¡æ€æ–¹æ³•ï¼ˆ9-14å€ï¼‰
  - **é¢„è®­ç»ƒæ•°æ®é›†å¯¹æ¯”å®éªŒ**ï¼ˆ100Kæ ·æœ¬ï¼Œåœ¨DocStructBenchä¸Šå¾®è°ƒï¼‰:
      - **DocSynth-300K**: Academic 82.1%, Textbook 71.5%, Market 69.3%, Financial 90.3%
      - **PubLayNet (300K)**: Academic 81.0%, Textbook 71.5%, Market 69.1%, Financial 89.7%
      - **DocBank (400K)**: Academic 81.6%, Textbook 70.9%, Market 69.1%, Financial 90.1%
      - **Diffusion (300K)**: Academic 80.7%, Textbook 71.9%, Market 68.9%, Financial 89.3%
      - **Random (300K)**: Academic 80.5%, Textbook 71.2%, Market 68.1%, Financial 89.6%
      - **M6Doc (2K)**: Academic 80.4%, Textbook 70.0%, Market 68.9%, Financial 89.7%
      - **ç»“è®º**: DocSynth-300Kåœ¨æ‰€æœ‰æ–‡æ¡£ç±»å‹ä¸Šéƒ½å®ç°æœ€ä½³æˆ–æ¥è¿‘æœ€ä½³æ€§èƒ½ï¼Œå±•ç°å“è¶Šæ³›åŒ–èƒ½åŠ›
  - **æ¶ˆèå®éªŒå…³é”®å‘ç°**:
      - **GL-CRMç»„ä»¶æ•ˆæœ**:
        - **Global-level CRM**: å•ç‹¬ä½¿ç”¨æå‡0.5% mAP
        - **Block-level CRM**: å•ç‹¬ä½¿ç”¨æå‡0.7% mAP
        - **ä¸¤è€…ç»“åˆ**: æå‡1.2% mAPï¼ˆD4LA: 68.6%â†’69.8%ï¼‰
        - **ç»“è®º**: åˆ†å±‚è®¾è®¡æœ‰æ•ˆé€‚åº”æ–‡æ¡£å…ƒç´ å¤šå°ºåº¦ç‰¹æ€§
      - **DocSynth-300Ké¢„è®­ç»ƒæ•ˆæœ**:
        - **æ— é¢„è®­ç»ƒ**: D4LA 68.6%, DocLayNet 76.2%
        - **+DocSynth-300Ké¢„è®­ç»ƒ**: D4LA 69.8% (+1.2%), DocLayNet 79.3% (+3.1%)
        - **ç»“è®º**: é¢„è®­ç»ƒæ˜¾è‘—æå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚æ•°æ®é›†ä¸Š
      - **æ•°æ®è¿‡æ»¤å¿…è¦æ€§**: è¿‡æ»¤ä½è´¨é‡æ ·æœ¬åæ€§èƒ½è¿›ä¸€æ­¥æå‡
      - **é¢„è®­ç»ƒæ•°æ®è§„æ¨¡**: æ€§èƒ½éšæ•°æ®é‡å¢åŠ ï¼ˆ0â†’30Kâ†’50Kâ†’100Kâ†’200Kâ†’300Kï¼‰æŒç»­æå‡
  - **ç”Ÿæˆæ•°æ®å¯è§†åŒ–åˆ†æ**:
      - DocSynth-300Kç”Ÿæˆçš„æ–‡æ¡£å±•ç°é«˜åº¦å¤šæ ·æ€§ï¼š
        - å¯†é›†å¸ƒå±€ï¼ˆå¤šå°å…ƒç´ ï¼‰vs ç¨€ç–å¸ƒå±€ï¼ˆå°‘å¤§å…ƒç´ ï¼‰
        - ä¸åŒå…ƒç´ ç»„åˆï¼ˆS/M/L = Small/Medium/Largeä¸»å¯¼ï¼‰
        - é«˜ç¾å­¦è´¨é‡ï¼ˆå¯¹é½ã€å¯†åº¦å‡ä¼˜äºRandomå’ŒDiffusionï¼‰
      - ä¸Diffusionã€Randomæ–¹æ³•å¯¹æ¯”ï¼ŒDocSynthå¸ƒå±€æ›´åˆç†ã€æ›´ç¾è§‚
  - **æœºæ„**: ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤
  - **ä½œè€…**: Zhiyuan Zhao, Hengrui Kang, Bin Wang, Conghui He
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´10æœˆï¼ˆv1ï¼‰
  - **å¼€æº**: âœ… [ä»£ç ã€æ•°æ®å’Œæ¨¡å‹](https://github.com/opendatalab/DocLayout-YOLO)
  - **æ„ä¹‰**:
      - **é€Ÿåº¦-ç²¾åº¦æƒè¡¡çªç ´**: é¦–æ¬¡å®ç°å•æ¨¡æ€æ–¹æ³•åœ¨ç²¾åº¦ä¸Šè¶…è¶Šå¤šæ¨¡æ€æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒé€Ÿåº¦ä¼˜åŠ¿ï¼ˆå¿«9-14å€ï¼‰
      - **æ•°æ®é›†è´¡çŒ®**:
        - DocSynth-300Kæä¾›é¦–ä¸ªå¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€é«˜ç¾å­¦è´¨é‡çš„æ–‡æ¡£åˆæˆæ•°æ®é›†
        - DocStructBenchæä¾›å…¨é¢çš„å¤šæ–‡æ¡£ç±»å‹è¯„ä¼°åŸºå‡†
      - **æ–¹æ³•åˆ›æ–°**:
        - Mesh-candidate BestFitç®—æ³•é¦–æ¬¡å°†æ–‡æ¡£åˆæˆè§†ä¸ºè£…ç®±é—®é¢˜ï¼Œç”Ÿæˆç¾è§‚å¤šæ ·çš„å¸ƒå±€
        - GL-CRMæ¨¡å—æœ‰æ•ˆå¤„ç†æ–‡æ¡£å…ƒç´ çš„æç«¯å°ºåº¦å˜åŒ–
      - **æ³›åŒ–èƒ½åŠ›**: è¯æ˜åœ¨å¤šæ ·åŒ–åˆæˆæ•°æ®ä¸Šé¢„è®­ç»ƒå¯æ˜¾è‘—æå‡æ¨¡å‹åœ¨å„ç±»çœŸå®æ–‡æ¡£ä¸Šçš„æ³›åŒ–æ€§èƒ½
      - **å®ç”¨ä»·å€¼**: ä¸ºæ–‡æ¡£è§£æç³»ç»Ÿæä¾›å¿«é€Ÿå‡†ç¡®çš„å¸ƒå±€åˆ†æè§£å†³æ–¹æ¡ˆï¼Œå¯ç›´æ¥åº”ç”¨äºRAGç³»ç»Ÿã€æ–‡æ¡£OCRç­‰å®é™…åœºæ™¯
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2407.07053">ğŸ“„ Multimodal Self-Instruct</a></b><br>
<code>arXiv 2407.07053</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ä½¿ç”¨è¯­è¨€æ¨¡å‹åˆæˆæŠ½è±¡å›¾åƒå’Œè§†è§‰æ¨ç†æŒ‡ä»¤** - åˆ©ç”¨LLMåŠå…¶ä»£ç èƒ½åŠ›åˆæˆå¤§é‡æŠ½è±¡å›¾åƒï¼ˆå›¾è¡¨ã€åœ°å›¾ã€ä»ªè¡¨ç›˜ç­‰ï¼‰å’Œè§†è§‰æ¨ç†æŒ‡ä»¤ï¼Œæ— éœ€ä¾èµ–GPT-4V
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä»£ç é©±åŠ¨çš„å¤šæ¨¡æ€è‡ªæŒ‡å¯¼Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»Ÿæ€§æ¢ç´¢ä½¿ç”¨LLMå’Œä»£ç åˆæˆæŠ½è±¡å›¾åƒï¼ˆéè‡ªç„¶å›¾åƒï¼‰çš„æ–¹æ³•ï¼Œè¯æ˜ä»£ç ç”Ÿæˆå¯ä»¥ç²¾ç¡®æ§åˆ¶æŠ½è±¡å›¾åƒçš„ç»†èŠ‚
      - **å¤šæ¨¡æ€è‡ªæŒ‡å¯¼ç­–ç•¥ï¼ˆä¸‰ä¸ªå…³é”®æ­¥éª¤ï¼‰**:
        1. **è§†è§‰æƒ³æ³•ææ¡ˆé˜¶æ®µ**:
           - **ä»»åŠ¡**: LLMè‡ªä¸»æå‡ºåˆ›æ„è§†è§‰æƒ³æ³•ï¼Œæè¿°æ—¥å¸¸åœºæ™¯ï¼ˆå¦‚åŸå¸‚åœ°å›¾ã€æµç¨‹å›¾ã€ç»Ÿè®¡å›¾è¡¨ï¼‰
           - **å…«ç§æŠ½è±¡å›¾åƒç±»å‹**: å›¾è¡¨ï¼ˆChartï¼‰ã€è¡¨æ ¼ï¼ˆTableï¼‰ã€æ¨¡æ‹Ÿåœ°å›¾ï¼ˆRoad Mapï¼‰ã€ä»ªè¡¨ç›˜ï¼ˆDashboardï¼‰ã€æµç¨‹å›¾ï¼ˆFlowchartï¼‰ã€å…³ç³»å›¾ï¼ˆRelation Graphï¼‰ã€2Då¹³é¢å¸ƒå±€ï¼ˆ2D Planar Layoutï¼‰ã€è§†è§‰è°œé¢˜ï¼ˆVisual Puzzleï¼‰
           - **è¯¦ç»†å‚æ•°æ§åˆ¶**: é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°æ§åˆ¶å›¾åƒåˆæˆçš„å…·ä½“ç»†èŠ‚ï¼ˆé¢œè‰²ã€å­—ä½“ã€å¸ƒå±€ç­‰ï¼‰
        2. **å›¾åƒåˆæˆé˜¶æ®µ**:
           - **æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆ**: LLMä¸ºæå‡ºçš„è§†è§‰æƒ³æ³•ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼ˆå¦‚é¥¼å›¾ç™¾åˆ†æ¯”ã€åœ°å›¾è·¯å¾„ç‚¹ï¼‰
           - **ä»£ç ç”Ÿæˆ**: LLMä½¿ç”¨Matplotlibæˆ–EChartsç­‰å¯è§†åŒ–åº“ç”ŸæˆPythonä»£ç 
           - **æ˜¾å¼å‚æ•°å®šä¹‰**: ä»£ç ä¸­æ˜ç¡®å®šä¹‰æ‰€æœ‰å‚æ•°ï¼ˆå›¾åƒæ ·å¼ã€é¢œè‰²ã€å­—ä½“å¤§å°ã€å›¾ä¾‹ä½ç½®ç­‰ï¼‰
           - **å›¾åƒæ¸²æŸ“**: æ‰§è¡Œä»£ç ç”ŸæˆæœŸæœ›çš„æŠ½è±¡å›¾åƒ
        3. **è§†è§‰æŒ‡ä»¤æ„å»ºé˜¶æ®µ**:
           - **é—®é¢˜-ç­”æ¡ˆå¯¹ç”Ÿæˆ**: LLMåŸºäºè§†è§‰æƒ³æ³•ã€æ¨¡æ‹Ÿæ•°æ®å’Œç”Ÿæˆä»£ç è®¾è®¡å¤šä¸ªé—®é¢˜-ç­”æ¡ˆå¯¹
           - **é—®é¢˜ç±»å‹å¤šæ ·æ€§**:
             - **å›¾è¡¨ä»»åŠ¡**: OCRã€Captionã€è¯¦ç»†æ„ŸçŸ¥ï¼ˆä½ç½®/æ•°é‡/å¸ƒå±€ï¼‰ã€æ•°æ®æå–ã€æ•°å­¦æ¨ç†
             - **åœ°å›¾ä»»åŠ¡**: è·¯å¾„è§„åˆ’ã€ç©ºé—´å…³ç³»æ¨ç†
             - **æµç¨‹å›¾ä»»åŠ¡**: ç»“æ„é—®é¢˜ï¼ˆæ­¥éª¤æ•°ã€ç¬¦å·ç±»å‹ï¼‰ã€æ¨ç†é—®é¢˜ï¼ˆä¸‹ä¸€æ­¥æ“ä½œï¼‰
             - **å…³ç³»å›¾ä»»åŠ¡**: æ ‘å½¢ç»“æ„é—®é¢˜ã€æ•°å­¦æ¨ç†é—®é¢˜
           - **ç­”æ¡ˆæ ‡æ³¨ä¸ç†ç”±**: ä¸ºæ¯ä¸ªé—®é¢˜æä¾›è¯¦ç»†ç†ç”±ï¼ˆç±»ä¼¼æ€ç»´é“¾ï¼‰ï¼Œå¢å¼ºè®­ç»ƒæ•ˆæœ
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ä»£ç ç²¾ç¡®æ§åˆ¶**: é€šè¿‡ä»£ç ç²¾ç¡®æ§åˆ¶æŠ½è±¡å›¾åƒçš„å‡ ä½•ç‰¹å¾å’Œæ–‡æœ¬å†…å®¹ï¼Œé¿å…æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„ç»†èŠ‚æ§åˆ¶å¤±è´¥
        - **æ— å¹»è§‰ä¿è¯**: åŸºäºä»£ç å’Œæ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆï¼Œç¡®ä¿ç­”æ¡ˆå‡†ç¡®æ€§ï¼ˆåªè¦åœºæ™¯å›¾å‡†ç¡®ï¼‰
        - **å¯è§£é‡Šæ€§**: ä»£ç ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œä½¿æ•°æ®ç”Ÿæˆè¿‡ç¨‹å®Œå…¨å¯è§£é‡Šå’Œå¯æ§åˆ¶
        - **æˆæœ¬æ•ˆç›Š**: ä½¿ç”¨GPT-4-turboè€ŒéGPT-4Vï¼Œæ˜¾è‘—é™ä½æˆæœ¬
        - **å¯æ‰©å±•æ€§**: é€šè¿‡æ·»åŠ æ–°æ¨¡æ¿æˆ–è‡ªå®šä¹‰ç°æœ‰æ¨¡æ¿ï¼Œè½»æ¾æ‰©å±•æŒ‡ä»¤æ•°æ®ç±»å‹
      - **æ•°æ®é›†ç»Ÿè®¡**:
        - **åŸºå‡†æ•°æ®é›†**: 3,658å¼ å›¾åƒï¼Œ11,193æ¡æŒ‡ä»¤ï¼ˆ8ç§åœºæ™¯ï¼‰
          - Dashboard: 73å¼ ï¼Œ1,013æ¡æŒ‡ä»¤
          - RelationGraph: 66å¼ ï¼Œ822æ¡æŒ‡ä»¤
          - Flowchart: 98å¼ ï¼Œ1,451æ¡æŒ‡ä»¤
          - VisualPuzzle: 189å¼ ï¼Œ529æ¡æŒ‡ä»¤
          - 2DPlanarLayout: 25å¼ ï¼Œ252æ¡æŒ‡ä»¤
        - **è®­ç»ƒæ•°æ®é›†**: 19,338å¼ å›¾åƒï¼Œ62,476æ¡æŒ‡ä»¤ï¼ˆ3ç§åœºæ™¯ï¼‰
          - Chart: 1,768å¼ ï¼Œ34,590æ¡æŒ‡ä»¤
          - Table: 570å¼ ï¼Œ10,886æ¡æŒ‡ä»¤
          - Roadmap: 17,000å¼ ï¼Œ17,000æ¡æŒ‡ä»¤
        - **æ•°æ®è´¨é‡ä¿è¯**:
          - **ä»£ç å¯è¡Œæ€§è¿‡æ»¤**: å¦‚æœç”Ÿæˆçš„ä»£ç æ— æ³•è¿è¡Œï¼Œæç¤ºLLMåŸºäºç¼–è¯‘å™¨é”™è¯¯åé¦ˆè¿›è¡Œè‡ªæˆ‘åæ€ï¼Œæœ€å¤šé‡è¯•3æ¬¡
          - **å›¾åƒç¾å­¦æ£€æŸ¥**: ä½¿ç”¨LLaVA-1.5æ£€æŸ¥å›¾åƒç¾å­¦ï¼ˆè§†è§‰å…ƒç´ å¹²æ‰°ã€å¸ƒå±€åˆç†æ€§ã€æ–‡æœ¬å¯è¯»æ€§ï¼‰
          - **ç­”æ¡ˆå‡†ç¡®æ€§éªŒè¯**: é‡‡ç”¨è‡ªä¸€è‡´æ€§æ–¹æ³•ï¼Œè®©LLMåŸºäºæƒ³æ³•ã€ä»£ç å’Œé—®é¢˜ç”Ÿæˆå¤šä¸ªå“åº”ï¼Œé€šè¿‡æŠ•ç¥¨é€‰æ‹©æœ€ç»ˆç­”æ¡ˆ
          - **äººå·¥è¯„ä¼°**: éšæœºé‡‡æ ·10%çš„<é—®é¢˜ï¼Œç­”æ¡ˆ>å¯¹ï¼Œ4åè®¡ç®—æœºç§‘å­¦ç ”ç©¶ç”Ÿä»å››ä¸ªç»´åº¦è¯„ä¼°ï¼ˆå›¾åƒç¾å­¦ã€é—®é¢˜åˆç†æ€§ã€ç­”æ¡ˆå‡†ç¡®æ€§ã€å›¾åƒ-æŒ‡ä»¤ç›¸å…³æ€§ï¼‰
      - **å®éªŒç»“æœ**:
        - **åŸºå‡†è¯„ä¼°**ï¼ˆ8ç§æŠ½è±¡å›¾åƒä»»åŠ¡ï¼‰:
          - **äººç±»æ°´å¹³**: å¹³å‡å‡†ç¡®ç‡82.1%
          - **æœ€ä½³LMMæ€§èƒ½**: Claude-3.5-Sonnet 64.74%ï¼ŒGPT-4o 59.99%
          - **æ˜¾è‘—å·®è·**: å³ä½¿æœ€å…ˆè¿›çš„LMMï¼ˆGPT-4oï¼‰åœ¨Dashboardä»»åŠ¡ä¸Šä»…è¾¾åˆ°54.79%ï¼Œè¿œä½äºäººç±»æ°´å¹³ï¼ˆ85.3%ï¼‰
          - **å¼€æºvsé—­æºå·®è·**: å¼€æºæ¨¡å‹ï¼ˆå¦‚Vanilla Llava-1.5-7Bï¼‰å¹³å‡å‡†ç¡®ç‡ä»…15.4%ï¼Œä¸é—­æºæ¨¡å‹å­˜åœ¨å·¨å¤§å·®è·
        - **å¾®è°ƒæ•ˆæœ**ï¼ˆLlava-our-62kï¼‰:
          - **å›¾è¡¨ç†è§£**: 10.5% â†’ 30.3% (+19.8%)
          - **è¡¨æ ¼ç†è§£**: 15.8% â†’ 51.8% (+36.0%)
          - **åœ°å›¾å¯¼èˆª**: 0.3% â†’ 67.7% (+67.4%)ï¼Œè¶…è¶ŠGPT-4oï¼ˆ23.3%ï¼‰å’ŒClaude-3ï¼ˆ38.3%ï¼‰
          - **ä»…ä½¿ç”¨68Kåˆæˆæ•°æ®å’Œ4å°æ—¶LoRAå¾®è°ƒ**ï¼Œå°†Llava-1.5-7Bçš„å›¾è¡¨ç†è§£èƒ½åŠ›æå‡è‡³Qwen-VL-Plusæ°´å¹³
        - **ä»»åŠ¡ååŒæ•ˆåº”**:
          - **å›¾è¡¨+è¡¨æ ¼è®­ç»ƒ**: å¯¹åœ°å›¾å¯¼èˆªä»»åŠ¡æœ‰æ­£å‘å½±å“ï¼ˆ+5%æ€§èƒ½æå‡ï¼‰
          - **åœ°å›¾è®­ç»ƒ**: å¯¹å›¾è¡¨å’Œè¡¨æ ¼ä»»åŠ¡å½±å“è¾ƒå°
          - **æ¨æµ‹åŸå› **: ä¸åŒä»»åŠ¡æ‰€éœ€èƒ½åŠ›ä¸åŒ
        - **æ•°æ®è§„æ¨¡å½±å“**:
          - éšç€åˆæˆæ•°æ®é‡å¢åŠ ï¼ˆ35k â†’ 47k â†’ 62kï¼‰ï¼Œæ¨¡å‹æ€§èƒ½æŒç»­æå‡ï¼Œæœªè¾¾åˆ°å¹³å°æœŸ
          - æ•°å­¦æ¨ç†å­ä»»åŠ¡æå‡æœ€æ˜æ˜¾
        - **æ³›åŒ–èƒ½åŠ›**ï¼ˆå¼±ç›¸å…³ä»»åŠ¡ï¼‰:
          - **ChartQA**: 19.9% â†’ 23.9% (+4.0%)
          - **MathVista**: 25.1% â†’ 25.9% (+0.8%)
          - **æœªè®­ç»ƒä»»åŠ¡**: Dashboard +0.0%ï¼ŒRelationGraph +0.5%ï¼ŒFlowchart +2.7%ï¼ŒVisualPuzzle +0.2%ï¼ŒPlanarLayout +6.4%
          - **ç»“è®º**: ä»…è®­ç»ƒå›¾è¡¨ã€è¡¨æ ¼å’Œåœ°å›¾æ•°æ®ï¼Œä¹Ÿèƒ½æå‡å…¶ä»–æŠ½è±¡å›¾åƒæ¨ç†ä»»åŠ¡
      - **å…³é”®å‘ç°**:
        - **æŠ½è±¡å›¾åƒç†è§£æŒ‘æˆ˜**: å½“å‰LMMåœ¨ç†è§£æŠ½è±¡å›¾åƒæ–¹é¢å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå³ä½¿ç®€å•æ—¥å¸¸ä»»åŠ¡ï¼ˆå¦‚ä»æ—¶é’Ÿè¯»å–æ—¶é—´ã€ä½¿ç”¨åœ°å›¾è§„åˆ’è·¯çº¿ï¼‰ä¹Ÿç»å¸¸å¤±è´¥
        - **ä»£ç ç”Ÿæˆä¼˜åŠ¿**: ä½¿ç”¨ä»£ç åˆæˆæŠ½è±¡å›¾åƒå¯ä»¥ç²¾ç¡®æ§åˆ¶ç»†èŠ‚ï¼Œé¿å…æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„ç»†èŠ‚æ§åˆ¶å¤±è´¥
        - **æ•°æ®è´¨é‡é‡è¦æ€§**: é€šè¿‡ä¸‰å±‚è¿‡æ»¤ï¼ˆä»£ç å¯è¡Œæ€§ã€å›¾åƒç¾å­¦ã€ç­”æ¡ˆå‡†ç¡®æ€§ï¼‰ç¡®ä¿åˆæˆæ•°æ®è´¨é‡
        - **å¯æ‰©å±•æ€§**: æ–¹æ³•å¯è½»æ¾æ‰©å±•åˆ°æ›´å¤šåœºæ™¯å’Œä»»åŠ¡ç±»å‹
      - **æœºæ„**: æµ™æ±Ÿå¤§å­¦ã€ä¸­ç§‘é™¢è½¯ä»¶æ‰€ã€ä¸Šæµ·ç†å·¥å¤§å­¦
      - **ä½œè€…**: Wenqi Zhang, Zhenglin Cheng, Yuanyu He, Mengna Wang, Yongliang Shen, Zeqi Tan, Guiyang Hou, Mingqian He, Yanna Ma, Weiming Lu, Yueting Zhuang
      - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´7æœˆï¼ˆv5ï¼‰
      - **å¼€æº**: âœ… [ä»£ç ](https://github.com/zwq2018/Multi-modal-Self-instruct) | [é¡¹ç›®é¡µé¢](https://multi-modal-self-instruct.github.io)
      - **æ„ä¹‰**:
        - **é—®é¢˜è¯†åˆ«**: é¦–æ¬¡ç³»ç»Ÿæ€§è¯†åˆ«å½“å‰LMMåœ¨æŠ½è±¡å›¾åƒç†è§£æ–¹é¢çš„æ˜¾è‘—ç¼ºé™·
        - **æ–¹æ³•åˆ›æ–°**: æå‡ºä»£ç é©±åŠ¨çš„æŠ½è±¡å›¾åƒåˆæˆæ–¹æ³•ï¼Œä¸ºLMMè®­ç»ƒæä¾›é«˜è´¨é‡æŠ½è±¡å›¾åƒæ•°æ®
        - **åŸºå‡†è´¡çŒ®**: æ„å»ºåŒ…å«8ç§åœºæ™¯çš„æŠ½è±¡å›¾åƒç†è§£åŸºå‡†ï¼Œæ­ç¤ºLMMä¸äººç±»æ°´å¹³çš„å·¨å¤§å·®è·
        - **å®ç”¨ä»·å€¼**: æä¾›å¯æ‰©å±•çš„æ•°æ®åˆæˆæ¡†æ¶ï¼Œæ”¯æŒå®šåˆ¶åŒ–æŠ½è±¡å›¾åƒæ•°æ®ç”Ÿæˆ
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.14846">ğŸ“„ CoSyn</a></b><br>
<code>arXiv 2502.14846</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ä»£ç å¼•å¯¼çš„åˆæˆæ–‡æœ¬å¯†é›†å‹å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆ** - åˆ©ç”¨æ–‡æœ¬LLMçš„ç¼–ç¨‹èƒ½åŠ›è‡ªåŠ¨åˆ›å»ºå¤šæ ·åŒ–æ–‡æœ¬å¯†é›†å‹å›¾åƒæ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä»£ç é©±åŠ¨çš„å›¾åƒæ¸²æŸ“ + æ–‡æœ¬æ ‡æ³¨ç”Ÿæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: å°†ä»£ç ä½œä¸ºä¸­é—´è¡¨å¾æ¡¥æ¥å›¾åƒä¸æ–‡æœ¬ï¼Œå……åˆ†åˆ©ç”¨æ–‡æœ¬LLMçš„å¼ºå¤§ç¼–ç¨‹èƒ½åŠ›
      - **ä¸‰å¤§ç”Ÿæˆé˜¶æ®µ**:
        1. **ä»£ç ç”Ÿæˆé˜¶æ®µ** (P_LLM(C|q)):
           - è¾“å…¥ï¼šç”¨æˆ·æŸ¥è¯¢qï¼ˆå¦‚"ç”Ÿæˆè¥å…»æ ‡ç­¾æ•°æ®é›†"ï¼‰
           - è¾“å‡ºï¼šå¯æ‰§è¡Œä»£ç C
           - LLMï¼šClaude-3.5-Sonnetï¼ˆç¼–ç èƒ½åŠ›å¼ºï¼‰
           - **æ”¯æŒ11ç§æ¸²æŸ“å·¥å…·**ï¼šMatplotlibã€Plotlyã€VegaLiteã€LaTeXã€HTMLã€Mermaidã€Graphvizã€SVGã€Asymptoteã€Lilypondã€RDKit
        2. **å›¾åƒæ¸²æŸ“é˜¶æ®µ** (P(I|C)):
           - æ‰§è¡Œç”Ÿæˆçš„ä»£ç Cæ¸²æŸ“å›¾åƒI
           - ç²¾ç¡®æ§åˆ¶å›¾åƒå†…å®¹ï¼ˆæ–‡æœ¬ã€å¸ƒå±€ã€æ ·å¼ï¼‰
           - ä¿è¯å¯å¤ç°æ€§ï¼ˆä»£ç å¯è¿½æº¯ï¼‰
        3. **æŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ** (P_LLM(T|C)):
           - åŸºäºä»£ç Cï¼ˆæ— éœ€å›¾åƒï¼‰ç”Ÿæˆæ–‡æœ¬æŒ‡ä»¤T
           - LLMï¼šGPT-4o-miniï¼ˆæˆæœ¬æ•ˆç›Šé«˜ï¼‰
           - ç”Ÿæˆé—®ç­”å¯¹ã€è§£é‡Šæ–‡æœ¬ï¼ˆæ”¯æŒCoTæ¨ç†ï¼‰
      - **20æ¡ç”Ÿæˆç®¡é“** - åŸºäº11ç§æ¸²æŸ“å·¥å…·æ„å»º:
        - **å›¾è¡¨**: Matplotlibã€VegaLiteã€Plotlyã€LaTeXã€HTML
        - **æ–‡æ¡£**: LaTeXã€HTML
        - **è¡¨æ ¼**: LaTeXã€Matplotlibã€Plotlyã€HTML
        - **å›¾ç¤º**: Graphvizã€LaTeXã€Mermaid
        - **æ•°å­¦é—®é¢˜**: LaTeX
        - **çŸ¢é‡å›¾å½¢**: SVGã€Asymptote
        - **ä¹è°±**: LilyPond
        - **ç”µè·¯**: LaTeX
        - **åŒ–å­¦ç»“æ„**: RDKit
      - **å¤šæ ·æ€§å¢å¼ºç­–ç•¥ - Personaé©±åŠ¨**:
        - **é—®é¢˜**: LLMé‡‡æ ·å‚æ•°éš¾ä»¥ç”Ÿæˆå¤šæ ·åŒ–æ•°æ®
        - **è§£å†³**: åœ¨ä¸»é¢˜ç”Ÿæˆé˜¶æ®µå¼•å…¥**200K personas**ï¼ˆæ€§æ ¼/èº«ä»½æè¿°ï¼‰
        - **æ•ˆæœ**: ä»ä¸åŒè§†è§’ç”Ÿæˆä¸»é¢˜ï¼Œæ˜¾è‘—æå‡å†…å®¹å¤šæ ·æ€§
        - **ç¤ºä¾‹**: Persona "ç§‘å¹»å°è¯´å®¶å–œæ¬¢å¤–æ˜Ÿä¸–ç•Œ" â†’ ä¸»é¢˜ "å¤–æ˜Ÿæ¤ç‰©ä¸åŠ¨ç‰©å›¾è§£æŒ‡å—"
      - **å››é˜¶æ®µPipelineç¤ºä¾‹**ï¼ˆä»¥HTMLæ–‡æ¡£ä¸ºä¾‹ï¼‰:
        1. **ä¸»é¢˜ç”Ÿæˆ**: æ ¹æ®æŸ¥è¯¢+personaç”Ÿæˆæ–‡æ¡£ä¸»é¢˜ï¼ˆå¦‚"1æœˆæ°´ç”µè´¦å•"ï¼‰
        2. **æ•°æ®ç”Ÿæˆ**: å¡«å……è¯¦ç»†å†…å®¹ï¼ˆè´¹ç”¨æ˜ç»†ã€æ—¥æœŸã€ç”¨æˆ·ä¿¡æ¯ï¼‰
        3. **ä»£ç ç”Ÿæˆ**: å°†æ•°æ®è½¬æ¢ä¸ºå¯æ‰§è¡Œä»£ç ï¼ˆHTML+CSSï¼‰
        4. **æŒ‡ä»¤ç”Ÿæˆ**: åŸºäºä»£ç ç”Ÿæˆé—®ç­”å¯¹ï¼ˆé—®é¢˜+è§£é‡Š+ç®€æ´ç­”æ¡ˆï¼‰
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **é«˜ä¿çœŸåº¦**: ä»£ç æ¸²æŸ“ç¡®ä¿æ–‡æœ¬å‡†ç¡®æ€§ï¼ˆæ— å¹»è§‰ï¼‰
        - **å¯æ§æ€§å¼º**: é€šè¿‡ä»£ç ç²¾ç¡®æ§åˆ¶å›¾åƒç»“æ„å’Œå†…å®¹
        - **å¤šæ ·æ€§é«˜**: æ”¯æŒ11ç§å·¥å…·ã€9å¤§ç±»åˆ«ã€100+ç»†åˆ†æŸ¥è¯¢
        - **å¯æ‰©å±•**: è¯­è¨€åŒ–æŸ¥è¯¢æ§åˆ¶ï¼Œæ˜“äºå®šåˆ¶æ–°é¢†åŸŸ
        - **æˆæœ¬æ•ˆç›Š**: çº¯æ–‡æœ¬LLMæˆæœ¬è¿œä½äºå¤šæ¨¡æ€æ¨¡å‹
  - **æ•°æ®è§„æ¨¡**:
      - **CoSyn-400K**: 40ä¸‡åˆæˆå›¾åƒï¼Œ270ä¸‡æŒ‡ä»¤è°ƒä¼˜æ•°æ®
      - **9å¤§ç±»åˆ«åˆ†å¸ƒ**:
        - å›¾è¡¨: 11.8ä¸‡ | æ–‡æ¡£: 7.3ä¸‡ | æ•°å­¦: 6.8ä¸‡
        - è¡¨æ ¼: 4.8ä¸‡ | å›¾ç¤º: 3.6ä¸‡ | çŸ¢é‡å›¾å½¢: 2.8ä¸‡
        - ä¹è°±: 1.2ä¸‡ | ç”µè·¯: 1.0ä¸‡ | åŒ–å­¦ç»“æ„: 0.9ä¸‡
      - **æŸ¥è¯¢å¤šæ ·æ€§**:
        - å›¾è¡¨: 51ç§ç±»å‹ | æ–‡æ¡£: 107ç§ç±»å‹ | æ•°å­¦: 110ç§ç±»å‹
        - è¡¨æ ¼: 35ç§ç±»å‹ | å›¾ç¤º: 34ç§ç±»å‹ | çŸ¢é‡å›¾å½¢: 36ç§ç±»å‹
      - **æ‰©å±•åº”ç”¨ - åˆæˆPointingæ•°æ®**: 6.5ä¸‡å›¾åƒçš„ç‚¹å‡»åæ ‡æ ‡æ³¨
  - **æ¨¡å‹**: åŸºäº**Molmoæ¶æ„**ï¼ˆCLIP-ViT-L + Mistral-7Bï¼‰
      - è§†è§‰ç¼–ç å™¨ï¼šOpenAI CLIP (ViT-L/14 336px)
      - è¯­è¨€æ¨¡å‹ï¼šMistral-7B
      - è¿æ¥æ–¹å¼ï¼šMLPæŠ•å½±å±‚
  - **å®éªŒç»“æœ** - **7ä¸ªæ–‡æœ¬å¯†é›†å‹åŸºå‡†ä¸Šçš„SOTA**:
      - **å¼€æºæ¨¡å‹ä¸­æœ€ä½³**: å¹³å‡80.9%ï¼ˆè¶…è¶Šç¬¬äºŒåLlama 3.2 11Bçš„77.0%ï¼Œ+3.9%ï¼‰
      - **è¶…è¶Šé—­æºæ¨¡å‹**: GPT-4V (72.8%), Gemini 1.5 Flash (76.2%)
      - **åˆ†é¡¹æˆç»©**:
        - ChartQA: **86.3%** (vs GPT-4V 78.1%, +8.2%)
        - DocVQA: **90.0%** (vs GPT-4V 87.2%, +2.8%)
        - InfoVQA: **70.5%** (vs GPT-4V 75.1%, -4.6%)
        - TableVQA: **65.8%** (vs GPT-4V 60.5%, +5.3%)
        - AI2D: **91.9%** (vs GPT-4V 89.4%, +2.5%)
        - TextVQA: **82.0%** (vs GPT-4V 78.0%, +4.0%)
        - ScreenQA: **80.1%** (vs GPT-4V 41.6%, +38.5%)
      - **é›¶æ ·æœ¬æ€§èƒ½**ï¼ˆä»…ç”¨è¾…åŠ©+åˆæˆæ•°æ®ï¼Œæ— è¯„ä¼°é›†è®­ç»ƒï¼‰:
        - å¹³å‡**74.7%**ï¼Œè¶…è¶ŠGPT-4Vï¼ˆ72.8%ï¼‰
        - è¶…è¶Šå¤§å¤šæ•°å¼€æºå’Œé—­æºæ¨¡å‹ï¼ˆæ— çœŸå®è®­ç»ƒæ•°æ®ï¼‰
  - **æ–°é¢†åŸŸé€‚åº”èƒ½åŠ›** - **NutritionQAåŸºå‡†**:
      - **é—®é¢˜**: å¼€æºVLMåœ¨æ–°ä»»åŠ¡ï¼ˆè¥å…»æ ‡ç­¾é—®ç­”ï¼‰ä¸Šè¡¨ç°å·®
      - **é›¶æ ·æœ¬é€‚åº”**: ä»…ç”¨CoSyn-400Kè®­ç»ƒ â†’ åŒ¹é…GPT-4Væ€§èƒ½
      - **ç›®æ ‡åŸŸå¾®è°ƒ**: ä»…ç”¨**7Kåˆæˆè¥å…»æ ‡ç­¾æ•°æ®**å¾®è°ƒ â†’ è¶…è¶Šå¤§å¤šæ•°ç™¾ä¸‡çº§è®­ç»ƒçš„å¼€æºVLM
      - **æ•°æ®æ•ˆç‡**: è¯æ˜é’ˆå¯¹æ€§åˆæˆæ•°æ®çš„æé«˜æ ·æœ¬æ•ˆç‡
  - **åˆæˆæ•°æ®ä¼˜åŠ¿åˆ†æ**:
      - **æ¶ˆèç ”ç©¶**ï¼ˆè§Figure 4ï¼‰:
        - ä»…è¾…åŠ©æ•°æ®ï¼ˆ1Må›¾åƒï¼‰: 58.7%
        - ä»…åˆæˆæ•°æ®ï¼ˆ400Kå›¾åƒï¼‰: **70.5%**ï¼ˆåŒ¹é…GPT-4Vï¼‰
        - è¾…åŠ©+åˆæˆï¼ˆé›¶æ ·æœ¬ï¼‰: **74.7%**ï¼ˆè¶…è¶ŠGPT-4Vï¼‰
        - è¯„ä¼°+è¾…åŠ©+åˆæˆï¼ˆç›‘ç£ï¼‰: **80.9%**ï¼ˆSOTAï¼‰
        - **ç»“è®º**: 40ä¸‡åˆæˆæ•°æ®è´¡çŒ®è¶…è¿‡100ä¸‡çœŸå®è¾…åŠ©æ•°æ®
      - **CoTæ¨ç†å¢å¼º**:
        - åˆæˆæ•°æ®åŒ…å«ï¼ˆé—®é¢˜ã€è§£é‡Šã€ç®€ç­”ï¼‰ä¸‰å…ƒç»„
        - ChartQA: +3.2% | TableVQA: +1.5% | NutritionQA: +14.0%
        - å¯¹éœ€è¦å¤šæ­¥æ¨ç†çš„ä»»åŠ¡æå‡æ˜¾è‘—
      - **ç¼“è§£æ•°æ®åå·®**ï¼ˆChartQAæ¡ˆä¾‹ï¼‰:
        - **é—®é¢˜**: ChartQAè®­ç»ƒé›†73.9%ä¸ºT5æœºå™¨ç”Ÿæˆï¼Œæµ‹è¯•é›†50%äººå·¥æ ‡æ³¨
        - **è¿‡æ‹Ÿåˆ**: PaliGemmaåœ¨æœºå™¨é—®é¢˜ä¸Š88.5%ï¼Œäººå·¥é—®é¢˜ä¸Šä»…54.2%ï¼ˆå·®è·34.3%ï¼‰
        - **CoSynè®­ç»ƒ**: æœºå™¨é—®é¢˜93.4%ï¼Œäººå·¥é—®é¢˜79.1%ï¼ˆå·®è·**14.2%**ï¼Œå‡å°‘20.1%ï¼‰
        - **ç»“è®º**: åˆæˆæ•°æ®ç¼“è§£å¯¹benchmarkåå·®çš„è¿‡æ‹Ÿåˆ
      - **æ•°æ®å¤šæ ·æ€§é‡åŒ–**ï¼ˆä¸ç°æœ‰å›¾è¡¨æ•°æ®é›†å¯¹æ¯”ï¼‰:
        - **å›¾åƒå¤šæ ·æ€§**: CoSyn 0.596 vs ChartQA 0.340 (+75.3%)
        - **æ–‡æœ¬å¤šæ ·æ€§**: CoSyn 0.823 vs ChartQA 0.742 (+10.9%)
        - **å·¥å…·å¤šæ ·æ€§**: ä½¿ç”¨5ç§å·¥å…· vs ä»…Matplotlib â†’ +1.3% ChartQAå‡†ç¡®ç‡
      - **æ‰©å±•æ€§åˆ†æ**:
        - åˆæˆå›¾è¡¨æ•°é‡ä»5K â†’ 116Kï¼ŒChartQAé›¶æ ·æœ¬æ€§èƒ½ä»64.2% â†’ 78.2%
        - æ€§èƒ½æŒç»­æå‡ï¼Œæœªè¾¾é¥±å’Œç‚¹ï¼ˆå»ºè®®æœªæ¥æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡ï¼‰
  - **åˆæˆPointingæ•°æ®** - **SOTAç‚¹å‡»é¢„æµ‹**:
      - **æ–¹æ³•**: LLMç¼–è¾‘ä»£ç åœ¨å›¾åƒä¸Šæ˜¾å¼ç»˜åˆ¶ç‚¹ â†’ æå–åæ ‡
      - **æ•°æ®é‡**: 6.5ä¸‡å›¾åƒçš„pointingæ ‡æ³¨
      - **ScreenSpotåŸºå‡†**:
        - ä»…åˆæˆæ•°æ®: å¹³å‡68.0%
        - ä»…äººå·¥æ•°æ®(PixMo-point 155K): 68.5%
        - åˆæˆ+äººå·¥: **74.9%**ï¼ˆSOTAï¼Œè¶…è¶ŠUGround 1.3Mè®­ç»ƒçš„73.3%ï¼‰
      - **æ•°æ®æ•ˆç‡**: 6.5ä¸‡åˆæˆæ•°æ®åŒ¹é…15.5ä¸‡äººå·¥æ ‡æ³¨æ€§èƒ½
  - **å®ç°ç»†èŠ‚**:
      - **åŸºç¡€è®¾æ–½**: DataDreameråº“ï¼ˆæ”¯æŒå¹¶è¡Œç”Ÿæˆã€å“åº”ç¼“å­˜ã€å®Œæ•´æ—¥å¿—ï¼‰
      - **LLMé€‰æ‹©**: Claude-3.5-Sonnetï¼ˆä»£ç ç”Ÿæˆå¼ºï¼‰vs GPT-4oï¼ˆå¤±è´¥ç‡é«˜ï¼‰
      - **æˆæœ¬**: CoSyn-400Kæ•°æ®é›†æˆæœ¬çº¦**$8,000**
      - **è®­ç»ƒ**: TPU v3-128ï¼Œbatch size 32ï¼Œ60Kæ­¥ï¼ˆçº¦30å°æ—¶ï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´2æœˆ
  - **æœºæ„**: å®¾å¤•æ³•å°¼äºšå¤§å­¦ã€è‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€ï¼ˆAi2ï¼‰
  - **ä½œè€…**: Yue Yang, Ajay Patel, Matt Deitke, Tanmay Guptaç­‰
  - **å¼€æº**: âœ… **å®Œå…¨å¼€æº** - CoSyn-400Kæ•°æ®é›†ã€ä»£ç ã€æ¨¡å‹
  - **é¡¹ç›®é¡µé¢**: [yueyang1996.github.io/cosyn](https://yueyang1996.github.io/cosyn)
  - **é‡è¦æ„ä¹‰**:
      - **æ–‡æœ¬LLMé©±åŠ¨å¤šæ¨¡æ€**: é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†æ–‡æœ¬LLMç¼–ç¨‹èƒ½åŠ›ç”¨äºå¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®åˆæˆ
      - **ä»£ç ä½œä¸ºä¸­é—´è¡¨å¾**: åˆ›æ–°æ€§åœ°å°†ä»£ç ä½œä¸ºå›¾åƒ-æ–‡æœ¬æ¡¥æ¢ï¼Œç¡®ä¿å‡†ç¡®æ€§å’Œå¯æ§æ€§
      - **è¶…è¶Šæ¸²æŸ“å±€é™**: çªç ´ä¼ ç»Ÿæ¨¡æ¿åŒ–æ¸²æŸ“æ–¹æ³•çš„å¤šæ ·æ€§ç“¶é¢ˆ
      - **å¹¿æ³›é€‚ç”¨æ€§**: 9å¤§ç±»åˆ«ã€20æ¡pipelineè¯æ˜æ¡†æ¶çš„é€šç”¨æ€§
      - **å®ç”¨å½±å“**: è¯æ˜åˆæˆæ•°æ®åœ¨æ–‡æœ¬å¯†é›†å‹ç†è§£ä»»åŠ¡ä¸Šçš„å¼ºå¤§æ½œåŠ›ï¼Œä¸ºVLMè®­ç»ƒæä¾›æ–°èŒƒå¼
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2412.01137">ğŸ“„ TextSSR</a></b><br>
<code>arXiv 2412.01137</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ICCV_2025-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **åŸºäºæ‰©æ•£çš„åœºæ™¯æ–‡æœ¬è¯†åˆ«æ•°æ®åˆæˆ** - ä¸ºæ–‡æœ¬in-the-wildè¯†åˆ«ç”Ÿæˆè®­ç»ƒæ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸‰å¤§æ”¯æŸ±æ‰©æ•£Pipelineï¼šå‡†ç¡®æ€§ã€çœŸå®æ€§ã€å¯æ‰©å±•æ€§**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç«¯åˆ°ç«¯æ‰©æ•£å¼åˆæˆï¼Œè§£å†³æ¸²æŸ“æ–¹æ³•ï¼ˆç¼ºä¹çœŸå®æ„Ÿï¼‰å’Œçº¯ç”Ÿæˆæ–¹æ³•ï¼ˆç¼ºä¹æ§åˆ¶ï¼‰çš„å±€é™
      - **æ”¯æŸ±1ï¼šå‡†ç¡®æ€§ - åŒºåŸŸä¸­å¿ƒæ–‡æœ¬ç”Ÿæˆ + ä½ç½®-å­—å½¢å¢å¼º**:
        1. **åŒºåŸŸä¸­å¿ƒç”Ÿæˆ**:
           - ä¸å›¾åƒçº§æ–‡æœ¬ç”Ÿæˆï¼ˆæ˜“äº§ç”Ÿå¹»è§‰ï¼‰ä¸åŒï¼Œåœ¨**æŒ‡å®šè¾¹ç•Œæ¡†å†…**ç”Ÿæˆæ–‡æœ¬
           - ä½¿ç”¨**åŒºåŸŸæ¡ä»¶æ‰©æ•£**ï¼ˆå—layout-to-imageæ–¹æ³•å¯å‘ï¼‰
           - ç¡®ä¿å¯¹æ–‡æœ¬ä½ç½®çš„ç²¾ç¡®æ§åˆ¶ï¼Œé˜²æ­¢å…¶ä»–åœ°æ–¹å‡ºç°éé¢„æœŸæ–‡æœ¬
        2. **ä½ç½®-å­—å½¢å¢å¼º (PGE)**:
           - **é—®é¢˜**: æ‰©æ•£æ¨¡å‹åœ¨å‡†ç¡®å­—ç¬¦ç”Ÿæˆå’Œåºåˆ—é¡ºåºæ–¹é¢å­˜åœ¨å›°éš¾
           - **è§£å†³æ–¹æ¡ˆ**: åŒæµæ¡ä»¶åŒ–
             - **å­—å½¢æµ**: å°†ç›®æ ‡æ–‡æœ¬æ¸²æŸ“ä¸ºå¹²å‡€çš„å­—å½¢å›¾åƒï¼ˆå­—ç¬¦å½¢çŠ¶ï¼‰
             - **ä½ç½®æµ**: ç¼–ç è¾¹ç•Œæ¡†å†…çš„å­—ç¬¦ä½ç½®
           - **èåˆ**: é€šè¿‡äº¤å‰æ³¨æ„åŠ›å°†å­—å½¢+ä½ç½®ä¿¡æ¯æ³¨å…¥æ‰©æ•£UNet
           - **ç»“æœ**: ä¿æŒè‡ªç„¶å¤–è§‚çš„åŒæ—¶å®ç°å­—ç¬¦çº§å‡†ç¡®æ€§
      - **æ”¯æŸ±2ï¼šçœŸå®æ€§ - ä¸Šä¸‹æ–‡æç¤ºå®ç°è‡ªç„¶é£æ ¼åŒ–**:
        - **æŒ‘æˆ˜**: çº¯æ–‡æœ¬æ§åˆ¶ç”Ÿæˆäº§ç”Ÿé€šç”¨é£æ ¼ï¼›ä»çœŸå®å›¾åƒç›´æ¥é£æ ¼è¿ç§»å¯¼è‡´è¿‡æ‹Ÿåˆ
        - **æ–¹æ³• - ä¸Šä¸‹æ–‡æç¤ºæœºåˆ¶**:
          1. **çœŸå®åœºæ™¯é‡‡æ ·**: ä»STRæ•°æ®é›†ï¼ˆå¦‚COCO-Textã€MLTï¼‰é€‰æ‹©çœŸå®åœºæ™¯æ–‡æœ¬å›¾åƒ
          2. **æ–‡æœ¬ä¿®å¤**: ä½¿ç”¨ä¿®å¤æ¨¡å‹ä»é€‰å®šå›¾åƒä¸­ç§»é™¤åŸå§‹æ–‡æœ¬
          3. **æç¤ºæå–**: ä»åŸå§‹æ–‡æœ¬åŒºåŸŸæå–**ä½åˆ†è¾¨ç‡ä¸Šä¸‹æ–‡æç¤º**ï¼ˆé¢œè‰²ã€çº¹ç†ã€æ–¹å‘ã€é€€åŒ–æ¨¡å¼ï¼‰
          4. **æ¡ä»¶ç”Ÿæˆ**: æ¡ä»¶æ‰©æ•£æ¨¡å‹åŸºäº:
             - ç›®æ ‡æ–‡æœ¬å†…å®¹ï¼ˆé€šè¿‡PGEï¼‰
             - è¾¹ç•Œæ¡†ä½ç½®
             - **ä¸Šä¸‹æ–‡æç¤º**ï¼ˆä½åˆ†è¾¨ç‡çº¹ç†/é¢œè‰²å¼•å¯¼ï¼‰
          5. **ç»“æœ**: ç”Ÿæˆçš„æ–‡æœ¬ç»§æ‰¿çœŸå®é£æ ¼ï¼ˆå¤±çœŸã€æ¨¡ç³Šã€å…‰ç…§ã€é€è§†ï¼‰è€Œä¸è®°å¿†ç‰¹å®šå®ä¾‹
      - **æ”¯æŸ±3ï¼šå¯æ‰©å±•æ€§ - ç»„åˆæ–‡æœ¬æ’åˆ—**:
        - **ç­–ç•¥**: ç³»ç»Ÿæ€§åœ°ä»è¯æ±‡è¡¨é‡‡æ ·åˆ›å»ºå¤šæ ·åŒ–æ–‡æœ¬ç»„åˆ
        - **è¯­æ–™æ¥æº**:
          - **å•è¯**: é¢‘ç‡åˆ—è¡¨ä¸­çš„å¸¸è§è‹±æ–‡/ä¸­æ–‡å•è¯
          - **å‘½åå®ä½“**: äººåã€å“ç‰Œã€åœ°ç‚¹
          - **æ•°å­—åºåˆ—**: ç”µè¯å·ç ã€æ—¥æœŸã€ä»·æ ¼
        - **æ’åˆ—**: ç”ŸæˆæŒ‡å®šé•¿åº¦å†…æ‰€æœ‰å¯è¡Œçš„n-gramå’ŒçŸ­è¯­
        - **è§„æ¨¡**: ä»æœ‰é™è¯æ±‡è¡¨ç”Ÿæˆ**æ•°ç™¾ä¸‡ç‹¬ç‰¹æ–‡æœ¬å®ä¾‹**
      - **è´¨é‡ç­›é€‰**:
        - **ååˆæˆè¿‡æ»¤**: ä½¿ç”¨é¢„è®­ç»ƒSTRæ¨¡å‹éªŒè¯ç”Ÿæˆæ–‡æœ¬ä¸ç›®æ ‡æ ‡ç­¾åŒ¹é…
        - **å¤šæ¨¡å‹å…±è¯†**: è¦æ±‚å¤šä¸ªSTRæ¨¡å‹ï¼ˆCRNNã€ASTERã€ABINetï¼‰è¾¾æˆä¸€è‡´
        - **æ¥å—ç‡**: ~60-70%çš„ç”Ÿæˆå›¾åƒé€šè¿‡è´¨é‡ç­›é€‰
  - **æ•°æ®è§„æ¨¡**:
      - **TextSSR-Fï¼ˆè¿‡æ»¤æ•°æ®é›†ï¼‰**: 355ä¸‡è´¨é‡ç­›é€‰çš„åˆæˆåœºæ™¯æ–‡æœ¬å›¾åƒ
      - **æ–‡æœ¬é•¿åº¦**: 1-25å­—ç¬¦ï¼Œå¤šæ ·åŒ–åˆ†å¸ƒ
      - **é£æ ¼**: 50+åœºæ™¯ç±»å‹ï¼ˆè¡—é“æ ‡è¯†ã€åº—é¢ã€æ–‡æ¡£ã€äº§å“åŒ…è£…ç­‰ï¼‰
      - **è¯­è¨€**: ä¸»è¦è‹±æ–‡ + å¤šè¯­è¨€å­é›†
  - **è®­ç»ƒPipeline**:
      - **é˜¶æ®µ1**: åœ¨çœŸå®STRæ•°æ®é›†ä¸Šé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å­¦ä¹ åœºæ™¯æ–‡æœ¬åˆ†å¸ƒ
      - **é˜¶æ®µ2**: ä½¿ç”¨PGE + ä¸Šä¸‹æ–‡æç¤ºå¾®è°ƒå®ç°å‡†ç¡®å¯æ§ç”Ÿæˆ
      - **é˜¶æ®µ3**: ä½¿ç”¨æ–‡æœ¬æ’åˆ—è¿›è¡Œå¤§è§„æ¨¡åˆæˆ
      - **é˜¶æ®µ4**: è´¨é‡è¿‡æ»¤äº§ç”ŸTextSSR-F
  - **å®éªŒç»“æœ**:
      - **STRåŸºå‡†**: åœ¨TextSSR-Fä¸Šè®­ç»ƒè¾¾åˆ°**ä¸çœŸå®æ•°æ®è®­ç»ƒç›¸å½“æˆ–æ›´ä¼˜**çš„æ€§èƒ½
        - **IIIT5K**: 95.3%å‡†ç¡®ç‡ï¼ˆä¸çœŸå®æ•°æ®æŒå¹³ï¼‰
        - **SVT**: 93.1% (+1.8% è¶…è¶ŠåˆæˆåŸºçº¿)
        - **ICDARæ•°æ®é›†**: æŒç»­ä¼˜äºåŸºäºæ¸²æŸ“çš„åˆæˆæ•°æ®
      - **çœŸå®+åˆæˆæ··åˆ**: é€šè¿‡ç»“åˆTextSSR-Fä¸çœŸå®æ•°æ®è¾¾åˆ°æœ€ä½³ç»“æœï¼ˆå¹³å‡+2.1%å¢ç›Šï¼‰
      - **é›¶æ ·æœ¬è¿ç§»**: å¯¹æœªè§å­—ä½“ã€è¯­è¨€ã€å¤±çœŸçš„å¼ºæ³›åŒ–èƒ½åŠ›
  - **æ¶ˆèç ”ç©¶**:
      - **PGEè´¡çŒ®**: +8.3%å‡†ç¡®ç‡ è¶…è¶ŠåŸºçº¿æ‰©æ•£
      - **ä¸Šä¸‹æ–‡æç¤º**: +5.7% è¶…è¶Šä»…å­—å½¢æ¡ä»¶åŒ–
      - **è´¨é‡è¿‡æ»¤**: æå‡ä¸‹æ¸¸STRå‡†ç¡®ç‡4.2%
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´7æœˆ | ACM MM 2025
  - **æœºæ„**: *å­¦æœ¯ç ”ç©¶ï¼ˆè§è®ºæ–‡ä½œè€…ä¿¡æ¯ï¼‰*
  - **å¼€æº**: ğŸ”„ **é¢„è®¡å¼€æº** - Code + SynthVLM-100Kæ•°æ®é›†ï¼ˆè®ºæ–‡æ‰¿è¯ºï¼‰
  - **é‡è¦æ„ä¹‰**:
      - **èŒƒå¼è½¬æ¢**: é¦–æ¬¡å°†"Captionâ†’Image"ä½œä¸ºVLMè®­ç»ƒä¸»æµç¨‹ï¼Œé¢ è¦†ä¼ ç»Ÿ"å›¾åƒâ†’caption"ä¾èµ–
      - **è´¨é‡çªç ´**: ç³»ç»Ÿæ€§è§£å†³Webæ•°æ®ä¸‰å¤§è´¨é‡ç—›ç‚¹ï¼Œå»ºç«‹é«˜è´¨é‡åˆæˆæ•°æ®æ ‡å‡†
      - **æ•ˆç‡è¯æ˜**: å°æ•°æ®é›†å¤§æ¨¡å‹æ•ˆæœï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒæä¾›å¯è¡Œè·¯å¾„
  
      - **æ ¸å¿ƒæŠ€æœ¯è¦ç‚¹**:
        - **åœºæ™¯å‡ ä½•ç†è§£**: ä½¿ç”¨CNNé¢„æµ‹dense depth mapï¼Œä¼°è®¡å±€éƒ¨è¡¨é¢æ³•çº¿
        - **æ–‡æœ¬å¯¹é½**: æ ¹æ®ä¼°è®¡çš„å¹³é¢æ–¹å‘è¿›è¡Œé€è§†å˜æ¢ï¼Œä½¿æ–‡æœ¬ä¸è¡¨é¢å¯¹é½
        - **åŒºåŸŸçº¦æŸ**: ä½¿ç”¨gPb-UCMåˆ†å‰²ï¼Œç¡®ä¿æ–‡æœ¬é™åˆ¶åœ¨å…·æœ‰ç»Ÿä¸€é¢œè‰²å’Œçº¹ç†çš„åŒºåŸŸå†…
        - **é¢œè‰²è‡ªé€‚åº”**: ä»IIIT5Kæ•°æ®é›†å­¦ä¹ æ–‡æœ¬-èƒŒæ™¯é¢œè‰²å¯¹ï¼Œè‡ªé€‚åº”åŒ¹é…ç›®æ ‡åŒºåŸŸ
        - **æ³Šæ¾èåˆ**: ä½¿ç”¨Poisson image editingè‡ªç„¶èåˆæ–‡æœ¬ï¼Œä¿ç•™å…‰ç…§æ¢¯åº¦
      - **ä¸‰é˜¶æ®µPipeline**:
        1. **åœºæ™¯åˆ†æ**:
           - è¾“å…¥èƒŒæ™¯å›¾åƒï¼ˆéœ€æ— æ–‡æœ¬ï¼Œé€šè¿‡å…³é”®è¯è¿‡æ»¤+äººå·¥æ£€æŸ¥ï¼‰
           - CNNé¢„æµ‹dense depth mapï¼ˆä½¿ç”¨Liuç­‰äºº[30]çš„æ–¹æ³•ï¼‰
           - gPb-UCMåˆ†å‰²ç”Ÿæˆå±€éƒ¨é¢œè‰²/çº¹ç†ä¸€è‡´çš„åŒºåŸŸ
           - åŒºåŸŸè¿‡æ»¤ï¼šæ’é™¤è¿‡å°ã€æç«¯é•¿å®½æ¯”ã€è¡¨é¢æ³•çº¿å‚ç›´è§†è§’ã€é«˜çº¹ç†çš„åŒºåŸŸ
        2. **æ–‡æœ¬æ¸²æŸ“ä¸å˜æ¢**:
           - ä»Newsgroup20æ•°æ®é›†é‡‡æ ·æ–‡æœ¬ï¼ˆå•è¯ã€è¡Œã€æ®µè½ï¼‰
           - éšæœºé€‰æ‹©å­—ä½“
           - **å…³é”®æ­¥éª¤**ï¼šé€è§†å˜æ¢ä»¥åŒ¹é…å±€éƒ¨è¡¨é¢æ–¹å‘
           - é¢œè‰²é€‰æ‹©ï¼šä»å­¦ä¹ çš„é¢œè‰²å¯¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„å‰æ™¯-èƒŒæ™¯é¢œè‰²å¯¹
           - 20%çš„æ–‡æœ¬å®ä¾‹éšæœºæ·»åŠ è¾¹æ¡†
        3. **æ³Šæ¾å›¾åƒç¼–è¾‘èåˆ**:
           - ä½¿ç”¨æ³Šæ¾ç¼–è¾‘å°†æ–‡æœ¬ä¸èƒŒæ™¯å›¾åƒèåˆ
           - ä¿ç•™åœºæ™¯ä¸­çš„å…‰ç…§æ¢¯åº¦
           - åˆ›å»ºè‡ªç„¶å¤–è§‚çš„åˆæˆåœºæ™¯æ–‡æœ¬å›¾åƒ
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å‡ ä½•å‡†ç¡®æ€§**: æ–‡æœ¬éµå¾ªçœŸå®è¡¨é¢æ–¹å‘ï¼Œé¿å…ä¸è‡ªç„¶çš„å¹³å¦å åŠ 
        - **è¾¹ç•Œå°Šé‡**: æ–‡æœ¬ä¸è·¨è¶Šå¼ºçƒˆçš„å›¾åƒä¸è¿ç»­æ€§ï¼ˆå¦‚ç‰©ä½“è¾¹ç¼˜ï¼‰
        - **å…‰ç…§ä¸€è‡´æ€§**: æ³Šæ¾èåˆä¿æŒåœºæ™¯å…‰ç…§ç‰¹æ€§
        - **å¯æ‰©å±•æ€§**: å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œå¯ç”Ÿæˆæ— é™æ•°æ®
  - **æ•°æ®è§„æ¨¡**:
      - **SynthText in the Wild**: 800,000å¼ åˆæˆåœºæ™¯æ–‡æœ¬å›¾åƒ
      - **èƒŒæ™¯æ¥æº**: 8,000å¼ é€šè¿‡Google Image Searchæ”¶é›†çš„æ— æ–‡æœ¬å›¾åƒ
      - **æ–‡æœ¬æ¥æº**: Newsgroup20æ•°æ®é›†
      - **æ ‡æ³¨**: æ¯å¼ å›¾åƒé…word-levelçš„axis-aligned bounding boxes
  - **é…å¥—æ–‡æœ¬æ£€æµ‹å™¨** - **FCRN (Fully-Convolutional Regression Network)**:
      - **æ¶æ„**: å—FCNå’ŒYOLOå¯å‘çš„å¯†é›†é¢„æµ‹ç½‘ç»œ
      - **åˆ›æ–°**: æ¯ä¸ªä½ç½®(u,v)é¢„æµ‹æ–‡æœ¬å­˜åœ¨ + bounding boxå‚æ•°(x,y,w,h,cosÎ¸)
      - **ä¼˜åŠ¿**: 30Ã— lesså‚æ•° than YOLOï¼Œæ— éœ€é‡è®­ç»ƒå³å¯å¤„ç†å¤šå°ºåº¦
      - **é€Ÿåº¦**: 15 images/sec on GPUï¼Œ**45Ã—å¿«äºå½“æ—¶SOTA**
  - **å®éªŒç»“æœ** - **SOTAæ–‡æœ¬æ£€æµ‹æ€§èƒ½**:
      - **è®­ç»ƒç­–ç•¥**: åœ¨SynthTextä¸Šé¢„è®­ç»ƒ â†’ åœ¨å°è§„æ¨¡çœŸå®æ•°æ®é›†ä¸Šfine-tune
      - **ICDAR 2013ç»“æœ**:
        - ä»…åˆæˆæ•°æ®é¢„è®­ç»ƒæ˜¾è‘—æå‡æ€§èƒ½
        - åŠ ä¸Šfine-tuning: è¾¾åˆ°F-measure **84.2%**ï¼Œç«äº‰åŠ›SOTAæ°´å¹³
      - **Multi-Oriented Text (MSRA-TD500)**: åœ¨å¤æ‚å¤šæ–¹å‘æ–‡æœ¬åœºæ™¯ä¸­è¡¨ç°æœ‰æ•ˆ
      - **å…³é”®å‘ç°**: å‡ ä½•å»ºæ¨¡çš„åˆæˆæ•°æ®æœ‰æ•ˆè¿ç§»åˆ°çœŸå®åœºæ™¯æ–‡æœ¬æ£€æµ‹
  - **æ¶ˆèç ”ç©¶**:
      - **å‡ ä½•æ„ŸçŸ¥**: ä½¿ç”¨å‡ ä½•æ„ŸçŸ¥åˆæˆçš„æ¨¡å‹ä¼˜äºå¹³é¢æ–‡æœ¬å åŠ 
      - **é¢œè‰²è‡ªé€‚åº”**: è‡ªé€‚åº”é¢œè‰²é€‰æ‹©ä¼˜äºéšæœºé¢œè‰²
      - **Poissonèåˆ**: æ— ç¼èåˆå¯¹é€¼çœŸå¤–è§‚è‡³å…³é‡è¦
  - **å‘å¸ƒæ—¶é—´**: arXiv 2016å¹´4æœˆ
  - **æœºæ„**: University of Oxford, Dept. of Engineering Science
  - **ä½œè€…**: Ankush Gupta, Andrea Vedaldi, Andrew Zisserman
  - **å¼€æº**: âœ… æ•°æ®é›†ï¼ˆSynthText in the Wildï¼Œ800Kå›¾åƒï¼‰ - å®˜ç½‘: [robots.ox.ac.uk/~vgg/data/scenetext](http://www.robots.ox.ac.uk/~vgg/data/scenetext)
  - **é‡è¦æ„ä¹‰**:
      - **é¦–åˆ›å‡ ä½•æ„ŸçŸ¥åˆæˆ**: é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†3Dåœºæ™¯ç†è§£å¼•å…¥æ–‡æœ¬åˆæˆ
      - **è§£å†³æ•°æ®ç“¶é¢ˆ**: è§£å†³äº†åœºæ™¯æ–‡æœ¬æ£€æµ‹æ ‡æ³¨æ˜‚è´µçš„é—®é¢˜
      - **å¥ å®šèŒƒå¼**: å½±å“äº†åç»­å¤§é‡åœºæ™¯æ–‡æœ¬åˆæˆå·¥ä½œ
      - **å®ç”¨ä»·å€¼**: åˆæˆæ•°æ®è®­ç»ƒçš„æ¨¡å‹è¾¾åˆ°å½“æ—¶SOTAï¼Œè¯æ˜åˆæˆæ•°æ®çš„æœ‰æ•ˆæ€§
      - **å¼€åˆ›æ€§å·¥ä½œ**: åœ¨æ·±åº¦å­¦ä¹ æ–‡æœ¬æ£€æµ‹é¢†åŸŸå…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/1604.06646">ğŸ“„ åˆæˆæ–‡æœ¬å®šä½ (Synthetic Text Localisation)</a></b><br>
<code>arXiv 1604.06646</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **åœºæ™¯æ–‡æœ¬æ£€æµ‹çš„åˆæˆæ•°æ®** - ç”Ÿæˆé«˜è´¨é‡åœºæ™¯æ–‡æœ¬å›¾åƒç”¨äºè®­ç»ƒæ–‡æœ¬æ£€æµ‹æ¨¡å‹
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å‡ ä½•æ„ŸçŸ¥åœºæ™¯æ–‡æœ¬å åŠ Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: è‡ªç„¶åœ°å°†åˆæˆæ–‡æœ¬å åŠ åˆ°çœŸå®åœºæ™¯ä¸Šï¼Œ**è€ƒè™‘å±€éƒ¨3Dåœºæ™¯å‡ ä½•**è€Œéç®€å•çš„2Då åŠ 
      - **å…³é”®æŠ€æœ¯ç»„ä»¶**:
        - **åœºæ™¯å‡ ä½•ç†è§£**: ä½¿ç”¨CNNé¢„æµ‹å¯†é›†æ·±åº¦å›¾ï¼Œä¼°è®¡å±€éƒ¨è¡¨é¢æ³•çº¿
        - **æ–‡æœ¬å¯¹é½**: åŸºäºä¼°è®¡çš„å¹³é¢æ–¹å‘æ‰§è¡Œé€è§†å˜æ¢ï¼Œä½¿æ–‡æœ¬ä¸è¡¨é¢å¯¹é½
        - **åŒºåŸŸçº¦æŸ**: ä½¿ç”¨gPb-UCMåˆ†å‰²ç¡®ä¿æ–‡æœ¬è¢«é™åˆ¶åœ¨é¢œè‰²å’Œçº¹ç†å‡åŒ€çš„åŒºåŸŸå†…
        - **é¢œè‰²é€‚é…**: ä»IIIT5Kæ•°æ®é›†å­¦ä¹ æ–‡æœ¬-èƒŒæ™¯é¢œè‰²å¯¹ï¼Œè‡ªé€‚åº”åŒ¹é…ç›®æ ‡åŒºåŸŸ
        - **æ³Šæ¾èåˆ**: ä½¿ç”¨æ³Šæ¾å›¾åƒç¼–è¾‘å®ç°æ–‡æœ¬-èƒŒæ™¯æ— ç¼é›†æˆï¼Œæ˜¾å¾—è‡ªç„¶åµŒå…¥
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **3Då‡ ä½•æ„ŸçŸ¥**: æ–‡æœ¬é€è§†è‡ªç„¶åŒ¹é…è¡¨é¢æ–¹å‘ï¼Œè€Œéå¹³é¢å åŠ 
        - **åŒºåŸŸçº¦æŸ**: é¿å…åœ¨å¼‚è´¨åŒºåŸŸä¸çœŸå®çš„æ”¾ç½®
        - **è‡ªé€‚åº”ç€è‰²**: æ–‡æœ¬é¢œè‰²ä¸èƒŒæ™¯è‡ªç„¶åè°ƒ
        - **æ— ç¼èåˆ**: æ³Šæ¾æ··åˆæ¶ˆé™¤åˆæˆä¼ªå½±
      - **åˆæˆPipeline**:
        1. **è¾“å…¥**: è‡ªç„¶åœºæ™¯å›¾åƒï¼ˆé€šè¿‡Googleå›¾ç‰‡æœç´¢æ”¶é›†çš„8,000å¼ èƒŒæ™¯å›¾åƒï¼‰
        2. **æ·±åº¦ä¼°è®¡**: CNNé¢„æµ‹å¯†é›†æ·±åº¦å›¾
        3. **è¡¨é¢æ³•çº¿ä¼°è®¡**: ä»æ·±åº¦è®¡ç®—å±€éƒ¨è¡¨é¢æ–¹å‘
        4. **åˆ†å‰²**: gPb-UCMç”Ÿæˆå€™é€‰åŒºåŸŸ
        5. **åŒºåŸŸé€‰æ‹©**: æŒ‰å¤§å°ã€çºµæ¨ªæ¯”ã€å‡åŒ€æ€§è¿‡æ»¤åŒºåŸŸ
        6. **é¢œè‰²é‡‡æ ·**: é€‰æ‹©ä¸åŒºåŸŸåŒ¹é…çš„æ–‡æœ¬-èƒŒæ™¯é¢œè‰²å¯¹
        7. **æ–‡æœ¬æ¸²æŸ“**: ç”¨é€‰å®šé¢œè‰²æ¸²æŸ“å•è¯ï¼ˆæ–‡æœ¬ä»Newsgroup20æ•°æ®é›†é‡‡æ ·ï¼‰
        8. **é€è§†å˜æ¢**: åŸºäºè¡¨é¢æ³•çº¿åº”ç”¨é€è§†æ‰­æ›²
        9. **æ³Šæ¾æ··åˆ**: æ— ç¼å°†æ–‡æœ¬é›†æˆåˆ°åœºæ™¯ä¸­
        10. **è¾“å‡º**: åˆæˆåœºæ™¯æ–‡æœ¬å›¾åƒ + è¾¹ç•Œæ¡†æ ‡æ³¨
  - **æ•°æ®è§„æ¨¡**:
      - **SynthTextæ•°æ®é›†**: 800Kåˆæˆåœºæ™¯æ–‡æœ¬å›¾åƒ
      - **æ ‡æ³¨**: å•è¯çº§å’Œå­—ç¬¦çº§è¾¹ç•Œæ¡†
      - **èƒŒæ™¯å›¾åƒ**: 8,000å¼ é€šè¿‡Googleå›¾ç‰‡æœç´¢æ”¶é›†çš„å›¾åƒï¼ˆè¿‡æ»¤ç¡®ä¿æ— æ–‡æœ¬ï¼‰
      - **æ–‡æœ¬æ¥æº**: Newsgroup20æ•°æ®é›†ï¼ˆå•è¯ã€å¥å­ã€æ®µè½ï¼‰
  - **å®éªŒç»“æœ** - **æœ€å…ˆè¿›çš„æ–‡æœ¬æ£€æµ‹**:
      - **è®­ç»ƒç­–ç•¥**: åœ¨SynthTextä¸Šé¢„è®­ç»ƒ â†’ åœ¨å°å‹çœŸå®æ•°æ®é›†ä¸Šå¾®è°ƒ
      - **ICDAR 2013ç»“æœ**:
        - çº¯åˆæˆé¢„è®­ç»ƒæ˜¾è‘—æå‡æ€§èƒ½
        - å¾®è°ƒå: è¾¾åˆ°**Få€¼84.2%**ï¼Œå…·æœ‰ç«äº‰åŠ›çš„SOTAæ°´å¹³
      - **å¤šæ–¹å‘æ–‡æœ¬ç»“æœï¼ˆMSRA-TD500ï¼‰**:
        - åœ¨å¤æ‚å¤šæ–¹å‘æ–‡æœ¬åœºæ™¯ä¸Šå±•ç¤ºæœ‰æ•ˆæ€§
      - **å…³é”®å‘ç°**: å…·æœ‰é€‚å½“å‡ ä½•å»ºæ¨¡çš„åˆæˆæ•°æ®æœ‰æ•ˆè¿ç§»åˆ°çœŸå®ä¸–ç•Œæ–‡æœ¬æ£€æµ‹
  - **æ¶ˆèç ”ç©¶**:
      - **å‡ ä½•æ„ŸçŸ¥**: ä½¿ç”¨å‡ ä½•æ„ŸçŸ¥åˆæˆçš„æ¨¡å‹ä¼˜äºå¹³é¢æ–‡æœ¬å åŠ 
      - **é¢œè‰²é€‚é…**: è‡ªé€‚åº”ç€è‰²æ¯”éšæœºé¢œè‰²æé«˜æ£€æµ‹æ€§èƒ½
      - **æ³Šæ¾èåˆ**: æ— ç¼æ··åˆå¯¹äºçœŸå®å¤–è§‚è‡³å…³é‡è¦
  - **å‘å¸ƒæ—¶é—´**: CVPR 2016 | arXiv 2016å¹´4æœˆ
  - **æœºæ„**: ç‰›æ´¥å¤§å­¦
  - **ä½œè€…**: Ankush Gupta, Andrea Vedaldi, Andrew Zisserman
  - **å¼€æº**: âœ… [ä»£ç ](https://github.com/ankush-me/SynthText) å’Œ [æ•°æ®é›†](https://www.robots.ox.ac.uk/~vgg/data/scenetext/)
  - **é‡è¦æ„ä¹‰**:
      - **å¼€åˆ›æ€§å·¥ä½œ**: é¦–æ‰¹ç³»ç»Ÿæ€§å¤„ç†åœºæ™¯æ–‡æœ¬æ£€æµ‹åˆæˆæ•°æ®å¹¶å…·æœ‰å‡ ä½•æ„ŸçŸ¥çš„å·¥ä½œä¹‹ä¸€
      - **å‡ ä½•æ„ŸçŸ¥åˆæˆ**: å°†3Då‡ ä½•è€ƒè™‘å¼•å…¥æ–‡æœ¬åˆæˆï¼Œæ˜¾è‘—æé«˜çœŸå®æ€§
      - **å½±å“åŠ›**: SynthTextæ•°æ®é›†åœ¨æ–‡æœ¬æ£€æµ‹ç ”ç©¶ä¸­è¢«å¹¿æ³›ç”¨ä½œé¢„è®­ç»ƒæ•°æ®
      - **è¿ç§»å­¦ä¹ **: å±•ç¤ºäº†æ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸­åˆæˆåˆ°çœŸå®çš„æœ‰æ•ˆè¿ç§»
  
  #### ğŸ  3Dåœºæ™¯åˆæˆ
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2407.06084">ğŸ“„ SynVL3D</a></b><br>
<code>arXiv 2407.06084</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2024å¹´7æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡åˆæˆæ•°æ®çš„3Dè§†è§‰è¯­è¨€é¢„è®­ç»ƒ** - æ„å»ºå¤§è§„æ¨¡åˆæˆ3Dåœºæ™¯æ–‡æœ¬è¯­æ–™åº“ï¼Œè§£å†³3D-VLPæ•°æ®é›†åœºæ™¯å¤šæ ·æ€§æœ‰é™å’Œç»†ç²’åº¦æ ‡æ³¨ä¸è¶³çš„é—®é¢˜
  - **æ•°æ®åˆæˆæ–¹æ³•** - **3Dæ¨¡æ‹Ÿå™¨é©±åŠ¨çš„åœºæ™¯ç”Ÿæˆ + å¤šç²’åº¦æ–‡æœ¬æè¿°åˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: åˆ©ç”¨å…è´¹3Dæ¨¡æ‹Ÿå™¨æ„å»ºå¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„åˆæˆ3Dåœºæ™¯æ•°æ®é›†ï¼ŒåŒ…å«å¯¹è±¡ã€è§†å›¾ã€æˆ¿é—´ä¸‰ä¸ªå±‚æ¬¡çš„1Mæè¿°
      - **é—®é¢˜è¯†åˆ«**: ç°æœ‰3D-VLPæ•°æ®é›†è§„æ¨¡å°ä¸”æ ‡æ³¨æœ‰é™
        - **æ•°æ®ç¨€ç¼º**: ScanScribeä»…1.2Kåœºæ™¯å’Œ280Kæ–‡æœ¬æ ‡æ³¨
        - **å¤šæ ·æ€§ä¸è¶³**: åœºæ™¯ç±»å‹å’Œå¯¹è±¡ç±»åˆ«æœ‰é™
        - **æ ‡æ³¨æˆæœ¬é«˜**: 3Dåœºæ™¯æ•°æ®æ”¶é›†å’Œæ ‡æ³¨æå…¶æ˜‚è´µ
        - **ç»†ç²’åº¦ç¼ºå¤±**: ç¼ºä¹å¯¹è±¡çº§ã€è§†å›¾çº§ã€æˆ¿é—´çº§çš„å¤šå±‚æ¬¡å…³è”
      - **3Dåœºæ™¯ç”Ÿæˆ**:
        - **æ¨¡æ‹Ÿå™¨å¹³å°**: åŸºäºAI2-THOR 3Dæ¨¡æ‹Ÿå™¨ç¯å¢ƒ
        - **åœºæ™¯è§„æ¨¡**: 10,000ä¸ªå®¤å†…3Dåœºæ™¯ï¼Œ108ä¸ªå¯¹è±¡ç±»åˆ«
        - **åœºæ™¯å›¾æ„å»º**:
          - ä¸ºæ¯ä¸ªæˆ¿å±‹(åœºæ™¯)æ„å»ºåœºæ™¯å›¾ï¼Œæè¿°å¯¹è±¡é—´çš„ç©ºé—´å…³ç³»
          - åŸºäºå¯¹è±¡çš„ç©ºé—´ä½ç½®ã€å°ºå¯¸å’Œå½¢çŠ¶å®šä¹‰å…³ç³»
          - ä¸‰å¤§å…³ç³»ç±»å‹:
            1. **æ”¯æ’‘å…³ç³»** (e.g., on, in): åŸºäºç‰©ç†æ¥è§¦å’ŒåŒ…å«
            2. **ç©ºé—´å…³ç³»** (e.g., next to, in front of): åŸºäºç›¸å¯¹ä½ç½®
            3. **æ¯”è¾ƒå…³ç³»** (e.g., bigger than, same shape as): åŸºäºå°ºå¯¸å’Œå½¢çŠ¶
        - **ç²¾ç¡®æ ‡æ³¨**: æä¾›è¯­ä¹‰(ç±»åˆ«)ã€è§†è§‰(é«˜è´¨é‡mesh)ã€ç»†ç²’åº¦è§†è§‰æ ‡æ³¨(æ— è¯¯å·®ä½ç½®ã€æ–¹å‘ã€åˆ†å‰²mask)
      - **å¤šç²’åº¦æ–‡æœ¬æè¿°åˆæˆ**:
        - **æ€»è®¡**: è¶…è¿‡1Mä¸ªæ¨¡æ¿åŒ–å’Œè‡ªç”±å½¢å¼æè¿°
        - **ä¸‰ç§æè¿°ç±»å‹**:
          1. **æ¨¡æ¿åŒ–æè¿°**:
             - **å¯¹è±¡å¤–è§‚**: ä½¿ç”¨ç°æˆå›¾åƒæ ‡æ³¨å™¨ä¸ºæ¯ä¸ªå¯¹è±¡æ­£é¢è§†å›¾ç”Ÿæˆæ ‡æ³¨
             - **å…³ç³»ä¸‰å…ƒç»„**: <object1, relation, object2>å½¢å¼ï¼Œä½¿ç”¨æ¨¡æ¿"the object1 is relation to object2"
             - **å®ä¾‹æè¿°**: å°†å¤–è§‚æè¿°ä¸é‚»è¿‘å¯¹è±¡å…³ç³»æè¿°åˆæˆæ®µè½
          2. **è‡ªç”±å½¢å¼æè¿°**: ä½¿ç”¨GPT-3é‡æ–°è¡¨è¿°æ¨¡æ¿åŒ–æè¿°ä»¥å¢å¼ºè‡ªç„¶æ€§
          3. **å¤šè§†è§’æè¿°**: ä¸ºä¸åŒè§†è§’å’Œæˆ¿é—´å±‚æ¬¡ç”Ÿæˆæè¿°
        - **çŸ­è¯­-åŒºåŸŸå…³è”**: ä¸ºæ¯ä¸ªåè¯çŸ­è¯­è®­ç»ƒç‹¬ç‰¹æ ‡è¯†ç¬¦ï¼Œå»ºç«‹çŸ­è¯­ä¸ç©ºé—´åŒºåŸŸçš„è¿æ¥
      - **å¤šå±‚æ¬¡å…³è”å»ºç«‹**:
        - **å¯¹è±¡çº§å…³è”**: çŸ­è¯­æ ‡è¯†ç¬¦ä¸3Då¯¹è±¡è¾¹ç•Œæ¡†ç²¾ç¡®å¯¹åº”
        - **è§†å›¾çº§å…³è”**: å¤šè§†è§’ä¸‹çš„å¯¹è±¡-æ–‡æœ¬å¯¹é½
        - **æˆ¿é—´çº§å…³è”**: åœºæ™¯æ•´ä½“æè¿°ä¸3Dåœºæ™¯çš„å…³è”
  - **SynFormer3Dé¢„è®­ç»ƒæ¡†æ¶**:
      - **ç»Ÿä¸€Transformeræ¶æ„**: å¯¹é½3Dåœºæ™¯å’Œè¯­è¨€çš„ç®€å•ç»Ÿä¸€æ¨¡å‹
      - **ä¸‰å¤§ç»„ä»¶**:
        1. **3Då¯¹è±¡ç¼–ç å™¨**: å¤„ç†ç‚¹äº‘ç‰¹å¾
        2. **æ–‡æœ¬ç¼–ç å™¨**: å¤„ç†è‡ªç„¶è¯­è¨€æè¿°
        3. **è·¨æ¨¡æ€èåˆæ¨¡å—**: å®ç°3D-æ–‡æœ¬å¯¹é½
      - **ç»†ç²’åº¦é¢„è®­ç»ƒä»»åŠ¡**:
        1. **å¯¹è±¡å…³ç³»é¢„æµ‹ (ORP)**: é¢„æµ‹3Då¯¹è±¡é—´çš„ç©ºé—´å…³ç³»
        2. **å¤šå±‚æ¬¡åŒºåŸŸ-è¯å¯¹é½ (MRWA)**: å¯¹è±¡ã€æˆ¿é—´ã€åœºæ™¯ä¸‰ä¸ªå±‚æ¬¡çš„å¯¹é½
        3. **è§†å›¾èšåˆåŒºåŸŸ-è¯å¯¹é½ (VRWA)**: å¤šè§†è§’ä¿¡æ¯èšåˆå¯¹é½
      - **åˆæˆåˆ°çœŸå®åŸŸé€‚åº”**:
        - **ä¸‰é‡åŸŸåˆ¤åˆ«å™¨**: è§†è§‰åŸŸã€è¯­è¨€åŸŸã€è§†è§‰-è¯­è¨€è”åˆåŸŸ
        - **æ¢¯åº¦åè½¬å±‚**: æœ€å°-æœ€å¤§ä¼˜åŒ–è§£å†³åŸŸåç§»
        - **è”åˆé€‚åº”**: åŒæ—¶å¤„ç†å•æ¨¡æ€å’Œè·¨æ¨¡æ€åŸŸåç§»
  - **æ•°æ®è§„æ¨¡**:
      - **SynVL3Dæ•°æ®é›†**: 10,000ä¸ªå®¤å†…åœºæ™¯ï¼Œ1M+æ–‡æœ¬æè¿°
      - **å¯¹è±¡è¦†ç›–**: 108ä¸ªå¯¹è±¡ç±»åˆ«
      - **å…³ç³»ç±»å‹**: æ”¯æ’‘ã€ç©ºé—´ã€æ¯”è¾ƒä¸‰å¤§ç±»å…³ç³»
      - **å¤šç²’åº¦æ ‡æ³¨**: å¯¹è±¡çº§ã€è§†å›¾çº§ã€æˆ¿é—´çº§ä¸‰å±‚æ¬¡å…³è”
  - **å®éªŒç»“æœ** - **3D-VLä»»åŠ¡ä¸Šçš„SOTAæ€§èƒ½**:
      - **3Dè§†è§‰å®šä½ (3D Visual Grounding)**:
        - Nr3D: 65.5% accuracy (vs 3D-VISTA 64.2%, +1.3%)
        - Sr3D: 77.9% accuracy (vs 3D-VISTA 76.4%, +1.5%)
        - ScanRefer: 52.3%@0.25IoU, 46.2%@0.5IoU
      - **3Då¯†é›†æ ‡æ³¨ (3D Dense Captioning)**:
        - Scan2Cap: CIDEr score 72.1@0.25IoU (vs 3D-VISTA 71.0, +1.1%)
        - BLEU-4ã€METEORã€ROUGEç­‰æŒ‡æ ‡å…¨é¢é¢†å…ˆ
      - **3Dé—®ç­” (3D Question Answering)**:
        - ScanQA: EM@1è¾¾27.6% (vs 3D-VISTA 26.5%, +1.1%)
        - åœ¨BLEU-4ã€ROUGEã€METEORç­‰è¯­è¨€ç”ŸæˆæŒ‡æ ‡ä¸Šæå‡
  - **æ¶ˆèç ”ç©¶å‘ç°**:
      - **ç»†ç²’åº¦é¢„è®­ç»ƒä»»åŠ¡è´¡çŒ®**:
        - å¯¹è±¡å…³ç³»é¢„æµ‹ (+6.2% VG, +6.8% Cap, +2.0% QA)
        - å¤šå±‚æ¬¡åŒºåŸŸ-è¯å¯¹é½ (+5.8% VG, +6.4% Cap, +2.2% QA)
        - è§†å›¾èšåˆå¯¹é½ (+1.6% VG, +1.2% Cap, +0.3% QA)
      - **åˆæˆåˆ°çœŸå®é€‚åº”**: ä¸‰é‡åŸŸé€‚åº”æ˜¾è‘—æå‡æ€§èƒ½ (+14.4% VG, +13.4% Cap, +3.9% QA)
      - **å¤šå±‚æ¬¡å¯¹é½**: å¯¹è±¡ã€æˆ¿é—´ã€åœºæ™¯å±‚æ¬¡å¯¹é½å‡æœ‰è´¡çŒ®ï¼Œç»„åˆæ•ˆæœæœ€ä½³
  - **å…³é”®å‘ç°**:
      - **åˆæˆæ•°æ®æœ‰æ•ˆæ€§**: çº¯åˆæˆæ•°æ®é¢„è®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®3Dåœºæ™¯ä¸Šè¡¨ç°ä¼˜å¼‚
      - **å¤šç²’åº¦å…³è”ä»·å€¼**: å¯¹è±¡-è§†å›¾-æˆ¿é—´ä¸‰å±‚æ¬¡å…³è”å¯¹æ€§èƒ½æå‡å…³é”®
      - **åŸŸé€‚åº”é‡è¦æ€§**: åˆæˆåˆ°çœŸå®çš„åŸŸé€‚åº”å¯¹æ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦
      - **å¯æ‰©å±•æ€§**: ç›¸æ¯”çœŸå®æ•°æ®æ”¶é›†ï¼Œåˆæˆæ–¹æ³•æˆæœ¬ä½ã€å¯æ‰©å±•æ€§å¼º
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´7æœˆ | åŒ—äº¬å¤§å­¦
  - **å¼€æº**: âœ… SynVL3Dæ•°æ®é›†(10Kåœºæ™¯+1Mæè¿°) + SynFormer3Dæ¨¡å‹ + è®­ç»ƒä»£ç 
  - **é‡è¦æ„ä¹‰**:
      - **3D-VLPæ•°æ®çªç ´**: é¦–æ¬¡æ„å»ºå¤§è§„æ¨¡ã€å¤šå±‚æ¬¡çš„åˆæˆ3Dè§†è§‰è¯­è¨€æ•°æ®é›†
      - **æˆæœ¬æ•ˆç›Šæ–¹æ¡ˆ**: ä¸º3Dåœºæ™¯ç†è§£æä¾›ä½æˆæœ¬ã€é«˜è´¨é‡çš„æ•°æ®è·å–æ–¹æ¡ˆ
      - **å¤šç²’åº¦æ¡†æ¶**: å»ºç«‹äº†å¯¹è±¡-è§†å›¾-æˆ¿é—´ä¸‰å±‚æ¬¡çš„3D-æ–‡æœ¬å…³è”æ¡†æ¶
      - **åŸŸé€‚åº”åˆ›æ–°**: æå‡ºäº†é’ˆå¯¹3Dè§†è§‰è¯­è¨€ä»»åŠ¡çš„æœ‰æ•ˆåŸŸé€‚åº”æ–¹æ³•
  

</details>
---

#### ğŸ”„ å¯¹æ¯”å­¦ä¹ ä¸å›¾åƒå·®å¼‚

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Img-Diff%20CVPR%202025">ğŸ“„ Img-Diff</a></b><br>
<code>CVPR 2025</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **Focus**: **Contrastive Data Synthesis for MLLMs** - Enhances fine-grained image recognition through object differences in similar image pairs
  - **Data Synthesis Method** - **Three-Stage Contrastive Data Pipeline: Image Pair Generation + Difference Area Localization + Difference Caption Generation**:
      - **Core Innovation**: Draws from contrastive learning principles to generate similar image pairs with fine-grained difference annotations, training models to identify subtle differences in similar images
      - **Stage 1: Image Pair Generation - Object Replacement Paradigm**:
        - **Generation Tools**: Stable-Diffusion-XL + Prompt-to-Prompt image editing technique
        - **Pipeline**:
          1. Obtain image captions from caption databases (MS-COCO, LLaVA pre-training data)
          2. Use LLM to perform object replacement in captions (prompt: "Only replace one object in this sentence")
          3. Based on caption pairs, use SDXL + Prompt-to-Prompt to generate similar image pairs
        - **Result**: Highly similar image pairs with different objects
      - **Stage 2: Difference Area Generator**:
        - **Goal**: Locate precise bounding boxes of object differences in image pairs
        - **Three Components**:
          1. **Image Similarity Filter** (used twice):
             - **First use** (on generated pairs): Extract features via CLIP, compute cosine similarity, keep highly similar but not identical pairs
             - **Second use** (on cropped sub-images): Filter out bbox regions with actual differences
          2. **Image-Text Matching Filter**:
             - Extract image features using BLIP, compare with object name text features
             - Determine whether cropped sub-images contain valid objects (replaced or replacing objects)
          3. **Difference Detector**:
             - Based on given bbox, crop two sub-images from image A and B
             - Use image similarity filter to determine if differences are significant
             - Apply IoU filtering to remove overlapping bboxes, keep only bboxes with higher difference degree
        - **Flow**: FastSAM segmentation â†’ crop based on bbox â†’ image-text matching filter â†’ difference detection + IoU filter
        - **Output**: Maximum 5 valid difference bboxes per image pair
      - **Stage 3: Difference Captions Generator**:
        - **Feature**: Generates difference captions for **specific regions** (not whole image), ensuring accuracy
        - **Two-Stage Process**:
          - **Stage 1 - Object Labeling & Filtering**:
            1. Select N (default 5) bboxes with lowest similarity as candidates
            2. Use MLLM (LLaVA-NEXT) to describe each bbox region content
            3. **Image-Text Matching Filter**: Check if region content matches captions
            4. **Caption Similarity Filter**: Use CLIP text features to assess whether two captions differ
          - **Stage 2 - Difference Caption Generation**:
            1. Mark difference areas with red boxes on images for enhanced localization
            2. Provide LLaVA-NEXT with bbox content captions and marked images
            3. MLLM generates targeted difference descriptions based on this information
        - **Advantage**: Region-focused strategy avoids inaccuracy when single description can't capture all image differences
      - **Key Technical Advantages**:
        - **Fine-Grained Localization**: Bboxes precisely locate difference areas
        - **Contrastive Learning Principles**: Simulates positive-negative sample comparison mechanism of contrastive learning
        - **High-Quality Filtering**: Multiple filtering ensures data quality (image similarity, image-text matching, caption difference)
        - **Automated Scalability**: Fully automated pipeline, expandable as needed
  - **Data Scale**:
      - **Img-Diff (Main Evaluation Version)**: 12,688 high-quality "object replacement" samples
        - Source captions: MS-COCO (generated 118K image pairs â†’ filtered to 38,533 pairs â†’ 117,779 valid bboxes â†’ 12,688 final samples)
      - **Extended Version**: 34,538 "object replacement" samples (based on LLaVA pre-training dataset)
      - **Object Diversity**:
        - Covers 1,203 object categories
        - 3,680 unique "object replacement pairs"
        - Object365 dataset objects appear 13,164 times in this dataset (52.06% of total occurrences)
  - **Models**: Fine-tuned based on SOTA MLLMs
      - Main evaluation: LLaVA-1.5-7B, MGM-7B, InternVL2-8B
      - Supplementary evaluation: InternVL2-1B, LLaVA-1.5-13B
  - **Experimental Results** - **Significant Improvements on Image Difference Benchmarks**:
      - **MMVP Benchmark** (evaluating MLLM visual capabilities):
        - LLaVA-1.5-7B + Img-Diff: 27.3% (original 24.0%, +3.3%, surpasses LLaVA-1.5-13B 24.7%)
        - MGM-7B + Img-Diff: **50.7%** (original 40.0%, +10.7%, **surpasses GPT-4V 38.7% and Gemini 40.7%**)
        - InternVL2-8B + Img-Diff: 43.3% (original 38.7%, +4.6%)
      - **Spot-the-Diff Benchmark** (street scene difference detection):
        - LLaVA-1.5-7B + Img-Diff: CIDEr-D **43.2** (original 38.3, +4.9)
        - MGM-7B + Img-Diff: CIDEr-D **53.5** (original 46.3, +7.2, **surpasses previous specialized model VACC 41.5**)
        - InternVL2-8B + Img-Diff: CIDEr-D **32.2** (original 26.5, +5.7)
      - **Image-Edit-Request Benchmark** (image editing differences):
        - LLaVA-1.5-7B + Img-Diff: CIDEr-D **60.9** (original 60.6, further improves SOTA)
        - MGM-7B + Img-Diff: CIDEr-D **68.1** (original 66.8, new SOTA)
        - InternVL2-8B + Img-Diff: CIDEr-D **56.0** (original 51.5, +4.5)
  - **General MLLM Benchmark Improvements** (average across 8 benchmarks):
      - **LLaVA-1.5-7B**: Average improvement **+3.06%** (comprehensive improvements)
      - **MGM-7B**: Average improvement **+1.28%**
      - **InternVL2-8B**: Average improvement **+1.01%**
      - **Key Improvements**: VQAv2, GQA, POPE (localization), MMBench, MM-Vet, ScienceQA, SEED-Bench
  - **Data Quality Assessment** (1000 samples human annotation):
      - **Bounding Box Difference**: 78.9% high (different objects), 16.6% medium (different features), 4.5% low
      - **Content Caption Accuracy**: 80.1% high (completely correct), 14.1% medium, 5.8% low
      - **Difference Caption Accuracy**: 70.4% high (completely accurate), 21.8% medium (correct objects but wrong features), 7.8% low
  - **Extended Exploration** - **Object Removal Data** (supplementary materials):
      - Generated "object removal" dataset (prompts models to analyze which image contains specific object)
      - Further improves fine-tuned MLLM performance
  - **Publication**: CVPR 2025
  - **Institution**: Sun Yat-sen University, Alibaba Group
  - **Authors**: Qirui Jiao, Daoyuan Chen, Yilun Huang, Bolin Ding, Yaliang Li, Ying Shen
  - **Open Source**: âœ… **Fully Open-Source** - Code, dataset
  - **Code Repository**: [github.com/modelscope/data-juicer/tree/ImgDiff](https://github.com/modelscope/data-juicer/tree/ImgDiff)
  - **Significance**:
      - **Contrastive Learning Dataification**: First systematic application of contrastive learning principles to MLLM data synthesis
      - **Fine-Grained Difference Recognition**: Significantly improves MLLM's ability to identify subtle differences in similar images
      - **Region-Focused Strategy**: Innovative region-level difference annotation avoids inaccuracy of whole-image descriptions
      - **Surpasses Closed-Source Models**: Fine-tuned open 7B models surpass GPT-4V and Gemini on MMVP
      - **General Capability Enhancement**: Not only enhances difference recognition but also comprehensively improves VQA and localization capabilities
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.19492">ğŸ“„ ChartGen</a></b><br>
<code>arXiv 2507.19492</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**ä»£ç å¼•å¯¼çš„åˆæˆå›¾è¡¨æ•°æ®ä¸"å›¾è¡¨â†’ä»£ç "è¯„æµ‹** â€”â€” ä¸¤é˜¶æ®µè‡ªåŠ¨åŒ–æµæ°´çº¿ï¼šå…ˆç”¨ VLM å°†çœŸå®å›¾è¡¨"é‡ç»˜"ä¸º Python ç»˜å›¾ä»£ç ï¼Œå†ç”¨ä»£ç å‘ LLM è¿­ä»£å¢å¹¿ç”Ÿæˆå¤šæ ·å›¾è¡¨ï¼Œæ„å»ºå¤§è§„æ¨¡å¤šæ¨¡æ€å›¾è¡¨è¯­æ–™å¹¶æå‡ºé‡ç»˜è¯„æµ‹åè®®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **VLM é‡ç»˜ â†’ ä»£ç  LLM è¿­ä»£å¢å¹¿**ï¼š
      1) **VLM å›¾è¡¨é‡ç»˜**ï¼šä»¥ç§å­å›¾è¡¨ï¼ˆChartQA 13Kï¼‰ä¸ºè¾“å…¥ï¼Œphiâ€‘3.5â€‘vision-instruct ç”Ÿæˆå¯æ‰§è¡Œç»˜å›¾è„šæœ¬ï¼Œè·å–ç»“æ„åŒ–è¡¨ç¤º
      2) **LLM ä»£ç å¢å¹¿**ï¼šCodestralâ€‘22B å¯¹åˆå§‹è„šæœ¬è¿›è¡Œ ~20 è½®é£æ ¼/ç±»å‹/åº“/ä¸»é¢˜å¢å¹¿ï¼Œæ‰§è¡Œå¾—åˆ°æ–°å›¾è¡¨ï¼›æ˜¾è‘—æ‰©å¤§è§„æ¨¡ä¸å¤šæ ·æ€§ï¼ˆä¸ç›´æ¥æ”¹å›¾ï¼Œè€Œæ˜¯æ”¹ä»£ç ï¼‰
  - **æ•°æ®ä¸èµ„æº**ï¼š
      - **ChartGenâ€‘200K**ï¼š222.5K å›¾åƒâ€‘ä»£ç å¯¹ï¼Œè¦†ç›– 27 å›¾è¡¨ç±»å‹ã€11 ä¸ªç»˜å›¾åº“ï¼›å¹¶æä¾› CSV æ•°æ®ã€DocTagsã€æ–‡æœ¬æ‘˜è¦ä¸ QA å¯¹ï¼›Heldâ€‘out 4.3K ç”¨äºé‡ç»˜è¯„æµ‹
      - **è¯„æµ‹åè®®**ï¼šä»¥ GPTâ€‘4o ä¸ºè£åˆ¤ï¼Œåˆ†åˆ«æ¯”è¾ƒ"ä»£ç å±‚"ï¼ˆæ•°æ®å¿ å®åº¦0â€“1ï¼›è¯­ä¹‰/é£æ ¼0â€“10ï¼‰ä¸"æ¸²æŸ“å›¾åƒå±‚"ï¼ˆ0â€“10ï¼‰ï¼Œæ›´å…¨é¢åˆ»ç”»"å›¾è¡¨â†’ä»£ç "èƒ½åŠ›
  - **å®éªŒç»“è®º**ï¼š
      - 6 ä¸ªå¼€æºæƒé‡ VLMï¼ˆ3Bâ€“26Bï¼‰åœ¨æ•°æ®å¿ å®åº¦ï¼ˆâ‰¤0.58/1ï¼‰ä¸å›¾åƒç›¸ä¼¼åº¦ï¼ˆâ‰¤7.48/10ï¼‰ä¸Šä»æœ‰æ˜æ˜¾å·®è·ï¼Œ"å›¾è¡¨â†’ä»£ç "ä»å…·æŒ‘æˆ˜
      - ç›¸è¾ƒç°æœ‰å›¾è¡¨â€‘ä»£ç èµ„æºï¼ˆPlot2Codeã€ChartMimicã€ChartXã€ChartCoderï¼‰ï¼Œæœ¬å·¥ä½œåœ¨è§„æ¨¡ã€åº“è¦†ç›–ä¸å¤šæ¨¡æ€é…å¥—ä¸Šæ›´å…¨é¢
  - **æ„ä¹‰**ï¼š
      - **ä»¥"ä»£ç "ä¸ºå›¾è¡¨çš„è§„èŒƒè¡¨ç¤º**ï¼šä¾¿äºè¡ç”Ÿæ–‡æœ¬æ‘˜è¦/QA/CSV ç­‰å¤šæ¨¡æ€ç›‘ç£ï¼Œæå‡è®­ç»ƒä¸è¯„æµ‹çš„å¯æ‰©å±•æ€§ä¸å¯å¤ç°æ€§
      - **æ¨åŠ¨ä»"é—®ç­”/æ‘˜è¦"åˆ°"é‡ç»˜/ä»£ç ç”Ÿæˆ"çš„èƒ½åŠ›è¯„æµ‹**ï¼šæ›´ç»†ç²’åº¦æ£€éªŒå›¾è¡¨ç†è§£ä¸è§†è§‰æ¡ä»¶ä»£ç ç”Ÿæˆ
  - **å¼€æº**ï¼šä»£ç ã€æ•°æ®ä¸åŸºå‡†å‡ä»¥ CCâ€‘BYâ€‘4.0 å‘å¸ƒï¼š`https://github.com/SD122025/ChartGen/`
  
  
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2508.06492">ğŸ“„ Effective Chart Dataset (ECD)</a></b><br>
<code>arXiv 2508.06492</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**é¢å‘å›¾è¡¨ç†è§£çš„é«˜è´¨é‡åˆæˆè®­ç»ƒæ•°æ®** â€”â€” æå‡ºäº”é˜¶æ®µå›¾è¡¨æ•°æ®åˆæˆpipelineï¼Œæ„å»ºECDè®­ç»ƒé›†ä¸ECDBenchè¯„æµ‹é›†ï¼Œæ˜¾è‘—æå‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰çš„å›¾è¡¨ç†è§£èƒ½åŠ›
  - **æ•°æ®åˆæˆæ–¹æ³•** - **äº”é˜¶æ®µæ¨¡å—åŒ–åˆæˆä¸è´¨é‡è¿‡æ»¤**ï¼š
      1) **å•å›¾ç”Ÿæˆï¼ˆä»£ç å‡½æ•°+æ•°æ®åˆ†ç¦»ï¼‰**ï¼šé¢„å®šä¹‰29ç±»å›¾è¡¨å‡½æ•°ï¼ŒGPT-4oæ ¹æ®ä¸»é¢˜ä¸å‡½æ•°æ¥å£ç”Ÿæˆæ•°æ®ä¸å‚æ•°ï¼Œæ¸²æŸ“å•å›¾ï¼ˆ10,875å¼ ï¼‰
      2) **æ¡ä»¶å¼å¤šå­å›¾ç»„åˆ**ï¼šåŸºäºå·²æœ‰å­å›¾é€æ­¥æ¡ä»¶ç”Ÿæˆï¼Œä¿è¯å¤šå­å›¾é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆ6,006å¼ ï¼Œå¤šå­å›¾å¹³å‡4ä¸ªï¼‰
      3) **å›¾åƒå¤šæ ·åŒ–**ï¼šè‡ªåŠ¨æ·»åŠ æ³¨é‡Šã€åŒºåŸŸç€è‰²ã€ç¼©ç•¥çª—ã€å­—ä½“/è¾¹æ¡†/é…è‰²ç­‰é£æ ¼å˜åŒ–ï¼ŒåŒ…å«å¸ƒå±€ä¸æ ·å¼å¤šç»´æ‰°åŠ¨
      4) **å›¾åƒè´¨é‡è¿‡æ»¤**ï¼šä»¥"å¯è¯»æ€§ï¼ˆvisual clarityï¼‰+ è¯­ä¹‰è¿è´¯ï¼ˆsemantic coherenceï¼‰"åŒæŒ‡æ ‡å¯¹å›¾åƒæ‰“åˆ†ï¼Œè¿‡æ»¤ä½è´¨é‡æ ·æœ¬ï¼ˆä»16,829å¼ ä¿ç•™è‡³10,535å¼ ï¼‰
      5) **QAå¯¹ç”Ÿæˆä¸è¿‡æ»¤**ï¼šå¯¹æ¯å¼ å›¾ç”Ÿæˆæè¿°å‹ä¸æ¨ç†å‹QAå¯¹ï¼Œå¹¶ä¿ç•™é«˜ç½®ä¿¡ç»“æœï¼ˆæœ€ç»ˆ321,544é«˜è´¨é‡QAï¼‰
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **ECDè®­ç»ƒé›†**ï¼š10,535å¼ å›¾ + 321,544ä¸ªQAï¼ˆè¦†ç›–25ä¸»é¢˜ã€29å›¾è¡¨ç±»å‹ã€252ç§å­å›¾ç»„åˆï¼‰
      - **ECDBenchæµ‹è¯•é›†**ï¼š1,224å¼ å›¾ï¼ˆ364å•å›¾ã€860å¤šå­å›¾ï¼‰+ 2,448 QAï¼ˆæ¯å›¾1ä¸ªæè¿°å‹+1ä¸ªæ¨ç†å‹ï¼‰
  - **å®éªŒç»“æœï¼ˆå¤šæ¨¡å‹ä¸€è‡´å¢ç›Šï¼‰**ï¼š
      - åœ¨CharXivã€ChartQAã€ReachQAã€ChartBenchã€ChartXã€ECDBenchå…­é¡¹è¯„æµ‹ä¸Šï¼ŒLLaVA-Next-Llama3-8Bã€MiniCPM-V2.6ã€Phi-3-Visionã€Qwen2.5-VL-7Bå‡æœ‰æ•´ä½“æå‡
      - ä¾‹å¦‚ï¼šQwen2.5-VL-7Båœ¨CharXivå¹³å‡ç”±61.36%â†’67.40%ï¼Œåœ¨ECDBenchç”±38.19%â†’50.86%ï¼ˆæŠ¥å‘Šè¡¨2ä¸è¡¨3ï¼‰
  - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**ï¼š
      - **ä»£ç -æ•°æ®è§£è€¦ä¸æ¡ä»¶å¼å­å›¾ç”Ÿæˆ**ï¼šæå‡æ ·å¼ä¸è¯­ä¹‰å¤šæ ·æ€§å¹¶ä¿è¯å¤šå­å›¾ä¸€è‡´æ€§
      - **è´¨é‡åŒæŒ‡æ ‡è¿‡æ»¤**ï¼šæ˜¾è‘—é™ä½ä½è´¨é‡æ¸²æŸ“å’Œè¯­ä¹‰ä¸è¿è´¯æ ·æœ¬ï¼ˆFIDé™ä½ã€åƒç´ ç†µæå‡ï¼‰
      - **æ¨ç†å‹QAä¿ç•™rationale**ï¼šä¸ºè®­ç»ƒæ¨ç†èƒ½åŠ›æä¾›å¯è§£é‡Šç›‘ç£
  - **èµ„æºä¸å¯å¤ç°æ€§**ï¼š
      - è®ºæ–‡æä¾›å®Œæ•´pipelineæè¿°ä¸æ¶ˆèåˆ†æï¼Œå¹¶ç»™å‡ºGitHubé“¾æ¥ï¼ˆæ•°æ®ä¸ä»£ç è®¡åˆ’å¼€æ”¾ï¼‰
      - ä»£ç /æ•°æ®ï¼š`https://github.com/yuweiyang-anu/ECD`ï¼ˆä»¥è®ºæ–‡è¯´æ˜ä¸ºå‡†ï¼‰
  - **é‡è¦æ„ä¹‰**ï¼š
      - **çœŸå®åº¦ä¸å¤æ‚åº¦**ï¼šä¸CharXivåˆ†å¸ƒå¯¹é½çš„é£æ ¼è¦†ç›–ä¸å¤æ‚åº¦ï¼ˆæ›´ä½FIDã€æ›´é«˜ç†µï¼‰
      - **é€šç”¨å¯æ‰©å±•**ï¼šå¯æ‰©å±•åˆ°æ›´å¤šå­å›¾ç»„åˆã€ä¸»é¢˜ä¸å¸ƒå±€ï¼›èƒ½ä½œä¸ºé€šç”¨çš„å›¾è¡¨åˆæˆè®­ç»ƒåŸºåº§
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2403.07750">ğŸ“„ SynthÂ²</a></b><br>
<code>arXiv 2403.07750</code>
</summary>

  - **æ•°æ®åˆæˆæ–¹æ³•** - **LLMæ ‡é¢˜ + æ–‡æœ¬åˆ°å›¾åƒåµŒå…¥ç”Ÿæˆ**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–ä¸ªå®Œå…¨åˆæˆçš„VLMè®­ç»ƒæ–¹æ³•ï¼ŒåŒæ—¶åˆæˆæ ‡é¢˜å’Œå›¾åƒåµŒå…¥ï¼Œåœ¨åµŒå…¥ç©ºé—´æ“ä½œä»¥ç»•è¿‡åƒç´ çº§å¤„ç†
      - **ä¸¤é˜¶æ®µæµæ°´çº¿**ï¼š
        - **é˜¶æ®µ1**ï¼šLLMç”Ÿæˆå¤šæ ·åŒ–ã€ä¿¡æ¯ä¸°å¯Œçš„æ ‡é¢˜ï¼ˆä½¿ç”¨å¤–éƒ¨æ–‡æœ¬è¯­æ–™åº“æç¤ºï¼‰
        - **é˜¶æ®µ2**ï¼šæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å°†æ ‡é¢˜è½¬æ¢ä¸ºå¯¹åº”çš„å›¾åƒåµŒå…¥ï¼ˆç»•è¿‡åƒç´ ç”Ÿæˆï¼‰
      - **åµŒå…¥ç©ºé—´ä¼˜åŠ¿**ï¼š
        - **æ•ˆç‡æå‡**ï¼š2.08 vs 1.66 æ­¥/ç§’ï¼ˆåµŒå…¥ vs åƒç´ ï¼‰ï¼Œ25%è®­ç»ƒåŠ é€Ÿ
        - **è´¨é‡ä¿æŒ**ï¼šåµŒå…¥çº§ç”Ÿæˆä¿æŒæ€§èƒ½ï¼ŒåŒæ—¶å¤§å¹…æé«˜è®¡ç®—æ•ˆç‡
        - **å†…å­˜ä¼˜åŒ–**ï¼šæ¶ˆé™¤è®­ç»ƒæœŸé—´æ˜‚è´µçš„åƒç´ ç¼–ç /è§£ç 
  - **æ•°æ®è§„æ¨¡ä¸æ„æˆ**ï¼š
      - **æ¨¡å‹å‚æ•°**ï¼š632Mï¼ˆvs ç«äº‰å¯¹æ‰‹1.4-1.7Bï¼‰
      - **æ•°æ®é…æ¯”**ï¼š10.1MçœŸå®æ•°æ® + 711Måˆæˆæ•°æ®
      - **å¯¹æ¯”**ï¼šå¯æ¯”æ€§èƒ½ä½†ä»…éœ€ä¼ ç»Ÿæ–¹æ³•1/40çš„é…å¯¹æ•°æ®ï¼ˆvs DC-BLIP 5.5BçœŸå®æ•°æ®ï¼‰
  - **å®éªŒç»“æœ**ï¼š
      - **å›¾åƒæ ‡é¢˜ç”Ÿæˆ**ï¼šCIDEråˆ†æ•°131.3ï¼ˆå¾®è°ƒï¼‰ï¼Œ35.4ï¼ˆé›¶æ ·æœ¬ï¼‰
      - **åœºæ™¯ç†è§£é—®ç­”**ï¼šVQAv2 29.1â†’35.3 (+21%)
      - **å¤–éƒ¨çŸ¥è¯†é—®ç­”**ï¼šOKVQA 32.4â†’36.1 (+11%)
      - **æ•ˆç‡æ”¶ç›Š**ï¼šç”¨çº¦1/3çš„è®­ç»ƒæ­¥éª¤è¾¾åˆ°åŸºçº¿æ€§èƒ½ï¼Œ2.08 vs 1.66 æ­¥/ç§’ï¼ˆåµŒå…¥ vs åƒç´ ï¼‰
      - **æ•°æ®æ•ˆç‡**ï¼šä¸ä½¿ç”¨40å€é…å¯¹æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ç›¸å½“ï¼ˆvs. DC-BLIP 5.5BçœŸå®æ•°æ®ï¼‰
  - **æ¯”è¾ƒåˆ†æ**ï¼š
      - **vs. ITIT**ï¼š35.4 vs 32.1 CIDEré›¶æ ·æœ¬ï¼ˆå‚æ•°å’Œæ•°æ®ä½¿ç”¨é‡ç›¸ä¼¼ï¼‰
      - **vs. DC & SimVLM**ï¼š632Må‚æ•°ä¸1.4-1.7Bå‚æ•°ç«äº‰ç»“æœ
      - **è¯­ä¹‰é›†ä¸­åº¦**ï¼šGenPairæ˜¾ç¤ºæœ€é«˜ç†µï¼ˆ3.81ï¼‰å’Œæœ€ä½é›†ä¸­åº¦ï¼Œè¡¨æ˜å“è¶Šçš„å¤šæ ·æ€§
  - **æˆæœ¬æ•ˆç‡**ï¼š
      - **è®­ç»ƒé€Ÿåº¦**ï¼šæ¯”åƒç´ ç©ºé—´è®­ç»ƒå¿«25%ï¼Œæ— æ€§èƒ½ä¸‹é™
      - **å†…å­˜æ•ˆç‡**ï¼šæ¶ˆé™¤åˆæˆæ•°æ®è®­ç»ƒæœŸé—´æ˜‚è´µçš„åƒç´ ç¼–ç /è§£ç 
      - **æ•°æ®éœ€æ±‚**ï¼š10.1MçœŸå® + 711Måˆæˆ vs ä¼ ç»Ÿæ–¹æ³•éœ€è¦æ•°åäº¿çœŸå®é…å¯¹
  - **æœºæ„**ï¼šGoogle DeepMind
  - **ä½œè€…**ï¼šSahand Sharifzadeh, Christos Kaplanis, Shreya Pathak, Dharshan Kumaranç­‰
  - **å¼€æº**ï¼šâš ï¸ è®ºæ–‡ä¸­æœªæŒ‡å®šä»£ç /æ•°æ®å¯ç”¨æ€§
  - **æ„ä¹‰**ï¼š
      - **èŒƒå¼åˆ›æ–°**ï¼šé¦–æ¬¡å±•ç¤ºäº†VLMçš„å®Œå…¨åˆæˆå›¾åƒ-æ–‡æœ¬å¯¹è®­ç»ƒï¼Œæ— éœ€ä¾èµ–å¤§è§„æ¨¡çœŸå®æ•°æ®é›†
      - **åµŒå…¥ç©ºé—´æ•ˆç‡**ï¼šè¯æ˜åµŒå…¥çº§ç”Ÿæˆåœ¨ä¿æŒè´¨é‡çš„åŒæ—¶æ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡
      - **å—æ§æ–¹æ³•è®º**ï¼šå»ºç«‹äº†ç”¨äºåˆ†ç¦»åˆæˆæ•°æ®è´¡çŒ®çš„ä¸¥æ ¼å®éªŒæ¡†æ¶
      - **å®é™…éƒ¨ç½²**ï¼šä¸ºä¸“é—¨é¢†åŸŸå¯ç”¨å®šåˆ¶æ•°æ®é›†åˆ›å»ºå’Œèµ„æºé«˜æ•ˆçš„VLMè®­ç»ƒ
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.02948">ğŸ“„ DriveMRP</a></b><br>
<code>arXiv 2507.02948</code>
</summary>

  - **æ•°æ®åˆæˆæ–¹æ³•** - **åŸºäºBEVçš„è‡ªåŠ¨é©¾é©¶é«˜é£é™©è¿åŠ¨ä»¿çœŸ**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–ä¸ªåŸºäºVLMçš„è¿åŠ¨é£é™©é¢„æµ‹å¯æ‰©å±•åˆæˆæ•°æ®é›†ï¼Œè§£å†³é•¿å°¾é«˜é£é™©åœºæ™¯ç¨€ç¼ºé—®é¢˜
      - **ä¸‰ç»´é£é™©å»ºæ¨¡**ï¼šç³»ç»Ÿæ€§åœ°ä»è‡ªè½¦è¡Œä¸ºã€å…¶ä»–è½¦è¾†äº¤äº’å’Œç¯å¢ƒçº¦æŸä¸‰ä¸ªç»´åº¦åˆæˆé£é™©
      - **BEVå¤šé¡¹å¼ä»¿çœŸ**ï¼šä½¿ç”¨å¸¦è½¦è¾†åŠ¨åŠ›å­¦çº¦æŸçš„å¤šé¡¹å¼è½¨è¿¹ç”Ÿæˆï¼Œåˆ›å»ºç‰©ç†ä¸Šåˆç†çš„é«˜é£é™©è¿åŠ¨
      - **æ•°æ®è§„æ¨¡**ï¼šDriveMRP-10Kæ•°æ®é›†ï¼ŒåŒ…å«10,000ä¸ªé«˜è´¨é‡è¿åŠ¨é£é™©åœºæ™¯ï¼Œæ¶µç›–ç¢°æ’ã€æ€¥åˆ¹è½¦ã€å¼‚å¸¸åŠ é€Ÿã€è½¦é“è¿è§„
  - **å…³é”®æŠ€æœ¯ç»„ä»¶**ï¼š
      - **é«˜é£é™©åœºæ™¯é€‰æ‹©**ï¼šåŸºäºçœŸå®ä¸–ç•Œäº¤é€šäº‹æ•…åˆ†æçš„ç¢°æ’äº‹ä»¶ã€æ€¥åˆ¹è½¦/åŠ é€Ÿã€è½¦é“è¿è§„/åç¦»é“è·¯
      - **åŸºäºè§„åˆ™çš„å®šä¹‰**ï¼šå®‰å…¨è·ç¦»ï¼ˆç¢°æ’ï¼‰ã€åŠ é€Ÿåº¦å¹…å€¼/æŒç»­æ—¶é—´ï¼ˆæ€¥åˆ¹è½¦ï¼‰ã€å‡ ä½•å…³ç³»ï¼ˆè½¦é“è¿è§„ï¼‰çš„ç²¾ç¡®é˜ˆå€¼
      - **è¿åŠ¨æŠ•å½±è§†è§‰æç¤º**ï¼šå°†BEVè½¨è¿¹æŠ•å½±åˆ°è‡ªè½¦å‰è§†æ‘„åƒå¤´ï¼Œå¼¥åˆåæ ‡å’Œè§†è§‰ä¹‹é—´çš„æ¨¡æ€å·®è·
      - **äººæœºå›è·¯è´¨é‡æ§åˆ¶**ï¼šäººå·¥ç­›é€‰è¿‡æ»¤ç‰©ç†ä¸Šä¸åˆç†çš„è½¨è¿¹ï¼Œç¡®ä¿æ¸…æ™°çš„æ‘„åƒå¤´æŠ•å½±å¯è§æ€§
  - **DriveMRP-Agentæ¡†æ¶**ï¼š
      - **VLMä¸å¯çŸ¥æ¶æ„**ï¼šä½¿ç”¨LoRAå¾®è°ƒä¸å¤šä¸ªVLMï¼ˆQwen2.5-VL-7Bã€InternVLã€LLaVAï¼‰é…åˆå·¥ä½œ
      - **æ€ç»´é“¾æ¨ç†**ï¼š"åœºæ™¯ç†è§£ â†’ è¿åŠ¨åˆ†æ â†’ é£é™©é¢„æµ‹"è®¤çŸ¥è·¯å¾„ï¼Œç”¨äºå¯è§£é‡Šçš„é£é™©è¯„ä¼°
      - **å¤šæ¨¡æ€è¾“å…¥é›†æˆ**ï¼šç»“åˆBEVå¸ƒå±€ã€å‰è§†åœºæ™¯å›¾åƒå’ŒæŠ•å½±è¿åŠ¨èˆªç‚¹
      - **GPT-4oæ ‡é¢˜ç”Ÿæˆ**ï¼šæ¶µç›–åœºæ™¯åˆ†æã€è¿åŠ¨è¡Œä¸ºè§£é‡Šå’Œé£é™©åˆ†ç±»çš„ç»“æ„åŒ–è‡ªç„¶è¯­è¨€æè¿°
  - **å®éªŒç»“æœ**ï¼š
      - **åˆæˆæ•°æ®æ€§èƒ½**ï¼šäº‹æ•…è¯†åˆ«å‡†ç¡®ç‡27.13% â†’ 88.03% (+60.9%)ï¼Œåœ¨DriveMRP-10Kæµ‹è¯•é›†ä¸Š
      - **é›¶æ ·æœ¬æ³›åŒ–**ï¼šçœŸå®ä¸–ç•Œé«˜é£é™©æ•°æ®é›†å‡†ç¡®ç‡29.42% â†’ 68.50% (+39.1%)ï¼Œæ— çœŸå®ä¸–ç•Œè®­ç»ƒæš´éœ²
      - **è·¨æ¨¡å‹å¢å¼º**ï¼šåœ¨LLaVA-1.5-7Bã€Llama3.2-vision-11Bã€Qwen2.5-VL-7BåŸºçº¿ä¸Šä¸€è‡´æ”¹è¿›
      - **åœºæ™¯ç†è§£æŒ‡æ ‡**ï¼šROUGE-1-F1 48.54â†’69.08ï¼ŒBERTScore 68.83â†’81.25ï¼Œå±•ç¤ºç»¼åˆç¯å¢ƒç†è§£
  - **æ¶ˆèç ”ç©¶**ï¼š
      - **BEVä¿¡æ¯**ï¼šå¯¹å…¨å±€ä¸Šä¸‹æ–‡ç†è§£å’Œç©ºé—´å…³ç³»æ¨ç†è‡³å…³é‡è¦
      - **è§†è§‰è½¨è¿¹æŠ•å½±**ï¼šæ˜¾è‘—ä¼˜äºåŸå§‹åæ ‡åºåˆ—ï¼Œå¼¥åˆè§†è§‰-è¯­è¨€æ¨¡æ€å·®è·
      - **å¤šè¾“å…¥èåˆ**ï¼šBEV + å‰è§† + æŠ•å½±è½¨è¿¹ç»„åˆè¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼ˆ88.03%å‡†ç¡®ç‡ï¼‰
  - **æˆæœ¬ä¸æ³›åŒ–**ï¼š
      - **è®­ç»ƒæ•ˆç‡**ï¼šåœ¨8ä¸ªNVIDIA H100 GPUä¸Šä½¿ç”¨Flash AttentionåŠ é€Ÿè¿›è¡ŒLoRAå¾®è°ƒ
      - **çœŸå®ä¸–ç•Œè¿ç§»**ï¼šåœ¨ä¸“æœ‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å¼ºé›¶æ ·æœ¬æ€§èƒ½éªŒè¯åˆæˆåˆ°çœŸå®çš„æ³›åŒ–
      - **å³æ’å³ç”¨**ï¼šæ•°æ®é›†å¢å¼ºå¤šä¸ªé€šç”¨VLMçš„é©¾é©¶å®‰å…¨åº”ç”¨
  - **æœºæ„**ï¼šè¥¿æ¹–å¤§å­¦ã€å°ç±³æ±½è½¦ã€æµ™æ±Ÿå¤§å­¦
  - **ä½œè€…**ï¼šä¾¯å¿—æ¯…ã€é©¬æ©æ…§ã€æèŠ³ã€èµ–å¿—æ¯…ã€ä½•å®¶ä¹ç­‰
  - **å¼€æº**ï¼šâœ… [ä»£ç ä¸æ•°æ®é›†](https://github.com/xiaomi-ev/DriveMRP)ï¼ˆå¦‚æ‰€ç¤ºï¼‰
  - **æ„ä¹‰**ï¼š
      - **è‡ªåŠ¨é©¾é©¶å®‰å…¨**ï¼šè§£å†³é«˜é£é™©åœºæ™¯è¦†ç›–çš„å…³é”®å·®è·ï¼Œå®ç°æ›´å®‰å…¨çš„è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ
      - **åˆæˆæ•°æ®èŒƒå¼**ï¼šå±•ç¤ºäº†éš¾ä»¥å¤§è§„æ¨¡æ”¶é›†çš„ç½•è§ä½†å…³é”®é©¾é©¶äº‹ä»¶çš„æœ‰æ•ˆåˆæˆ
      - **å¯è§£é‡ŠAI**ï¼šæä¾›å¯è§£é‡Šçš„é£é™©é¢„æµ‹å’Œå› æœåˆ†æï¼Œç”¨äºæŒç»­ç®—æ³•æ”¹è¿›
      - **è¡Œä¸šå½±å“**ï¼šä¸ºå¤æ‚ã€éç»“æ„åŒ–é©¾é©¶ç¯å¢ƒä¸­çš„é²æ£’è¿åŠ¨è§„åˆ’ç®—æ³•å¼€å‘å¥ å®šåŸºç¡€
  

</details>
---

### ğŸ’­ å›¾åƒä»‹å…¥æ¨ç†

This emerging category constructs **image-text interleaved reasoning traces** where images are actively **edited and manipulated** during the reasoning process. Unlike traditional text-only approaches, these methods treat text and images as **complementary modalities** that jointly advance problem-solving through progressive visual modifications (e.g., highlighting, overlaying, zooming, inpainting).

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=ThinkMorph">ğŸ“„ ThinkMorph</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Multimodal Interleaved Chain-of-Thought Reasoning**:
      - **Core Innovation**: Constructs **image-text interleaved reasoning traces** where text and images function as **complementary modalities** that mutually advance reasoning
      - **Data Scale**: ~24K high-quality interleaved reasoning traces across 4 tasks
      - **Task Coverage** (varying visual engagement levels):
        - **Jigsaw Assembly** (6K): Visualizing re-arranged pieces â†’ holistic spatial context
        - **Spatial Navigation** (6K): Overlaying mazes with paths highlighted via red lines/arrows
        - **Visual Search** (6,990): Drawing bounding boxes around target objects
        - **Chart Refocus** (6K): Highlighting regions with red bounding boxes or overlays
      - **Data Synthesis Pipeline**:
        - **Design Principle**: Progressive textâ†’imageâ†’text sequences
        - **Generation Strategy**:
          - Jigsaw & Spatial: Custom synthesis pipeline (newly generated)
          - Visual Search & Chart: Human-in-the-loop MLLM filtering from existing datasets
        - **Quality Control**: Strict filtering (e.g., target object must occupy 1-30% of image area for Visual Search, reducing 144Kâ†’6,990 high-quality samples)
      - **Reasoning Pattern**: Initial text establishes context â†’ Visual tokens manipulate/visualize â†’ Final text verifies solution
      - **Key Findings**: Interleaved reasoning outperforms text-only and vision-only by 5.33% average on vision-centric tasks; exhibits emergent properties including unseen visual manipulations (zoom-in, inpainting, multi-box generation)
  - **Publication**: arXiv October 2025
  - **Institution**: National University of Singapore, Zhejiang University, University of Washington, Stanford, CUHK
  - **Open Source**: âœ… [Code & Models](https://github.com/ThinkMorph/ThinkMorph) | [Dataset](https://huggingface.co/ThinkMorph)
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2510.01582">ğŸ“„ ImageNet-Think-250K</a></b><br>
<code>arXiv 2510.01582</code>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Scale-250K-orange?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2024å¹´10æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨ç†åˆæˆæ•°æ®é›†** - æ„å»ºåŒ…å«æ˜¾å¼æ€ç»´è¿‡ç¨‹çš„å¤šæ¨¡æ€æ¨ç†æ•°æ®é›†ï¼ŒåŠ©åŠ›è§†è§‰è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›å¼€å‘
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å¤šæ¨¡æ€å¤§æ¨¡å‹é©±åŠ¨çš„æ€ç»´è½¨è¿¹åˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: åˆ©ç”¨SOTAè§†è§‰è¯­è¨€æ¨¡å‹ç”ŸæˆåŒ…å«æ˜¾å¼æ¨ç†æ­¥éª¤çš„å¤§è§„æ¨¡åˆæˆæ•°æ®é›†ï¼Œæ•è·VLMçš„é€æ­¥æ€ç»´è¿‡ç¨‹å’Œæœ€ç»ˆæè¿°æ€§ç­”æ¡ˆ
      - **é—®é¢˜è¯†åˆ«**: ç°æœ‰å¤šæ¨¡æ€æ•°æ®é›†å±€é™æ€§
        - **ç¼ºä¹æ¨ç†é€æ˜æ€§**: å¤§å¤šæ•°æ•°æ®é›†åªå…³æ³¨è¾“å…¥-è¾“å‡ºæ˜ å°„ï¼Œä¸æ•è·ä¸­é—´æ¨ç†æ­¥éª¤
        - **æ¨ç†è¯Šæ–­å›°éš¾**: æ— æ³•ç†è§£æ¨¡å‹å†³ç­–è¿‡ç¨‹æˆ–è¯Šæ–­æ¨¡å‹å¤±è¯¯
        - **é¢†åŸŸå±€é™æ€§**: ç°æœ‰æ¨ç†æ•°æ®é›†é€šå¸¸é¢†åŸŸç‰¹å®šæˆ–è§„æ¨¡æœ‰é™
        - **ä¸“æœ‰æ•°æ®å£å’**: è®­ç»ƒæ•°æ®é€šå¸¸ä¸“æœ‰æˆ–èŒƒå›´å—é™ï¼Œé˜»ç¢å¹¿æ³›ç ”ç©¶
      - **æ•°æ®ç”Ÿæˆpipeline**:
        - **æ•°æ®æº**: 250,000å¼ å›¾åƒï¼Œæ¥è‡ªImageNet-21kæ•°æ®é›†ç²¾é€‰æ ·æœ¬
        - **å›¾åƒç­›é€‰æ ‡å‡†**:
          1. **è§†è§‰è´¨é‡**: é«˜åˆ†è¾¨ç‡ã€æ¸…æ™°åº¦è‰¯å¥½
          2. **å†…å®¹å®Œæ•´æ€§**: æ— æ˜¾è‘—é®æŒ¡æˆ–æŸå
          3. **è¯­ä¹‰å¤šæ ·æ€§**: ä¿ƒè¿›æ³›åŒ–çš„å¤šæ ·è¯­ä¹‰ç±»åˆ«
          4. **å¤æ‚åº¦å¹³è¡¡**: è·¨ä¸åŒè§†è§‰å¤æ‚åº¦çº§åˆ«çš„å¹³è¡¡è¡¨ç¤º
        - **åŒæ¨¡å‹ç”Ÿæˆç­–ç•¥**:
          - **GLM-4.1V-9B-Thinking**: ç”Ÿæˆæ€ç»´è½¨è¿¹1
          - **Kimi-VL-A3B-Thinking-2506**: ç”Ÿæˆæ€ç»´è½¨è¿¹2
          - æ¯ä¸ªå›¾åƒé…å¯¹ä¸¤ç»„thinking-answeråºåˆ—ï¼Œæä¾›æ¨ç†å¤šæ ·æ€§
      - **ç»Ÿä¸€æç¤ºè®¾è®¡**:
        - **æç¤ºæ¨¡æ¿**: "Please analyze this image step by step. Explain your reasoning process. Describe this image and give as much information as possible"
        - **å¼•å¯¼ç›®æ ‡**:
          1. é¦–å…ˆæè¿°è§‚å¯Ÿåˆ°çš„å†…å®¹
          2. è§£é‡Šæ¨ç†è¿‡ç¨‹
          3. ç»™å‡ºæœ€ç»ˆè¯¦ç»†ç­”æ¡ˆ
        - **æ ‡å‡†åŒ–æµç¨‹**: ç¡®ä¿æ€ç»´é“¾ç”Ÿæˆçš„ä¸€è‡´æ€§å’Œè´¨é‡
      - **æ€ç»´-ç­”æ¡ˆåˆ†ç¦»**:
        - **æ€ç»´tokens (Think)**: æè¿°å¯¹è±¡ã€ä¸Šä¸‹æ–‡ã€å…³ç³»çš„ä¸­é—´æ¨ç†æ­¥éª¤
        - **ç­”æ¡ˆtokens (Answer)**: æç‚¼æˆ–å®Œå–„å›¾åƒè§£è¯»çš„æœ€ç»ˆæè¿°æ€§ç­”æ¡ˆ
        - **é…å¯¹ç»“æ„**: æ¯ä¸ªå›¾åƒâ†’2Ã—(thinking, answer)å¯¹ï¼Œæ”¯æŒæ¨ç†è´¨é‡å’Œç»“æœå‡†ç¡®æ€§è¯„ä¼°
  - **æ•°æ®è§„æ¨¡ä¸ç»Ÿè®¡**:
      - **æ€»æ•°æ®é‡**: 250,000å›¾åƒï¼Œ500,000ä¸ªthinking-answeré…å¯¹
      - **ç±»åˆ«è¦†ç›–**: 15,234ä¸ªç‹¬ç‰¹ImageNet-21kç±»åˆ«
      - **å¹³å‡åˆ†å¸ƒ**: æ¯ç±»16.4å¼ å›¾åƒï¼Œæ ‡å‡†å·®12.8
      - **Tokenç»Ÿè®¡**:
        - **æœ€å°tokens**: 521ä¸ªtokens/æ ·æœ¬
        - **æœ€å¤§tokens**: 196,388ä¸ªtokens/æ ·æœ¬
        - **å¹³å‡tokens**: 1,542ä¸ªtokens/æ ·æœ¬
        - **æ€»tokenæ•°**: 3äº¿tokens
      - **å¤šæ ·æ€§æŒ‡æ ‡**: è·¨ç§‘å­¦ã€è‡ªç„¶ã€ç¤¾ä¼šç§‘å­¦ç­‰å¹¿æ³›è¯­ä¹‰ç±»åˆ«
  - **åˆæˆè´¨é‡æ§åˆ¶**:
      - **ä¸€è‡´æ€§æ£€éªŒ**: ç¡®ä¿ç”Ÿæˆçš„thinkingå’Œansweré€»è¾‘ä¸€è‡´
      - **å¤šæ¨¡å‹éªŒè¯**: ä¸¤ä¸ªSOTA VLMçš„äº¤å‰éªŒè¯æé«˜å¯é æ€§
      - **é•¿åº¦è¿‡æ»¤**: ç§»é™¤è¿‡çŸ­æˆ–å¼‚å¸¸é•¿çš„å“åº”
      - **å†…å®¹è´¨é‡**: é€šè¿‡LLMè¯„ä¼°å“åº”è´¨é‡å’Œç›¸å…³æ€§
  - **åŸºå‡†è¯„ä¼°æ¡†æ¶**:
      - **æ¨ç†è´¨é‡æŒ‡æ ‡**:
        - **è¯­ä¹‰ç›¸ä¼¼åº¦**: BERTScoreã€Sentence-BERTä½™å¼¦ç›¸ä¼¼åº¦
        - **è¯æ±‡é‡å **: ROUGE-1ã€ROUGE-Lã€JaccardæŒ‡æ•°ã€é‡å ç³»æ•°
        - **å‘é‡ç©ºé—´**: TF-IDFä½™å¼¦ç›¸ä¼¼åº¦
      - **æ¨¡å‹æ¯”è¾ƒ**: 5ä¸ªSOTA VLMåœ¨ImageNet-Thinkä¸Šçš„æ€§èƒ½è¯„ä¼°
        - InternVL-3.5-8Bã€VL-Rethinker-7Bã€VisionThink-Efficient
        - OpenVLThinker-7Bã€R1-OneVision-7B
      - **æ€ç»´vsç­”æ¡ˆåˆ†æ**: æ€ç»´tokensåœ¨è¯­ä¹‰å¯¹é½ä¸Šä¼˜äºç­”æ¡ˆtokensï¼Œç­”æ¡ˆtokensåœ¨è¯æ±‡é‡å ä¸Šè¡¨ç°æ›´å¥½
  - **å®éªŒå‘ç°**:
      - **æ¨ç†ä¸°å¯Œæ€§**: æ€ç»´è½¨è¿¹æä¾›äº†ä¸°å¯Œçš„ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œæœ‰åŠ©äºç†è§£VLMå†³ç­–è¿‡ç¨‹
      - **æ¨¡å‹å·®å¼‚æ€§**: ä¸åŒVLMåœ¨æ¨ç†é£æ ¼å’Œè´¨é‡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—å·®å¼‚
      - **è¯„ä¼°ç»´åº¦**: å¤šç»´åº¦è¯„ä¼°æ­ç¤ºäº†è¯­ä¹‰ç†è§£å’Œè¯æ±‡è¡¨è¾¾çš„ä¸åŒæ¨¡å¼
      - **å¯æ‰©å±•æ€§**: åˆæˆæ–¹æ³•å¯æ‰©å±•åˆ°æ›´å¤§è§„æ¨¡å’Œæ›´å¤šè§†è§‰é¢†åŸŸ
  - **å…³é”®è´¡çŒ®**:
      - **é¦–ä¸ªå¤§è§„æ¨¡æ¨ç†æ•°æ®é›†**: ImageNet-Thinkæä¾›æœ€å¤§è§„æ¨¡çš„å¤šæ¨¡æ€æ¨ç†æ•°æ®é›†
      - **æ˜¾å¼æ€ç»´æ•è·**: ç³»ç»Ÿæ€§æ•è·VLMçš„é€æ­¥æ¨ç†è¿‡ç¨‹
      - **å¤šæ¨¡å‹è§†è§’**: åˆ©ç”¨å¤šä¸ªSOTA VLMæä¾›æ¨ç†å¤šæ ·æ€§
      - **æ ‡å‡†åŒ–è¯„ä¼°**: å»ºç«‹å¤šç»´åº¦æ¨ç†è´¨é‡è¯„ä¼°æ¡†æ¶
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´10æœˆ | Argonne National Laboratory
  - **å¼€æº**: âœ… ImageNet-Think-250Kæ•°æ®é›† + è¯„ä¼°åŸºå‡† + æ•°æ®ç”Ÿæˆä»£ç  - å…¬å¼€å¯ç”¨ä»¥æ”¯æŒç ”ç©¶
  - **é‡è¦æ„ä¹‰**:
      - **æ¨ç†é€æ˜åŒ–**: ä¸ºå¤šæ¨¡æ€æ¨ç†ç ”ç©¶æä¾›é€æ˜çš„æ€ç»´è¿‡ç¨‹æ•°æ®
      - **æ¨¡å‹è¯Šæ–­å·¥å…·**: å¸®åŠ©ç ”ç©¶è€…ç†è§£å’Œæ”¹è¿›VLMæ¨ç†èƒ½åŠ›
      - **æ ‡å‡†åŒ–åŸºå‡†**: ä¸ºå¤šæ¨¡æ€æ¨ç†æ¨¡å‹è¯„ä¼°å»ºç«‹æ ‡å‡†
      - **ç ”ç©¶åŠ é€Ÿ**: é™ä½æ¨ç†æ•°æ®è·å–é—¨æ§›ï¼Œä¿ƒè¿›å¹¿æ³›ç ”ç©¶
  
  #### ğŸ¤– æœºå™¨äººåŠ¨ä½œåˆæˆ
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2505.03233">ğŸ“„ GraspVLA</a></b><br>
<code>arXiv 2505.03233</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **åŸºäºåäº¿çº§åˆæˆåŠ¨ä½œæ•°æ®é¢„è®­ç»ƒçš„æŠ“å–åŸºç¡€æ¨¡å‹** - é¦–ä¸ªå®Œå…¨åŸºäºå¤§è§„æ¨¡åˆæˆåŠ¨ä½œæ•°æ®è®­ç»ƒçš„VLAæ¨¡å‹ï¼Œå…·å¤‡ç›´æ¥sim-to-realè¿ç§»èƒ½åŠ›
  - **æ•°æ®åˆæˆæ–¹æ³•** - **åäº¿çº§ç…§ç‰‡çº§çœŸå®æœºå™¨äººåŠ¨ä½œç”Ÿæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»Ÿæ€§æ–¹æ³•ï¼Œå®Œå…¨åŸºäºå¤§è§„æ¨¡åˆæˆåŠ¨ä½œæ•°æ®è®­ç»ƒè§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹ï¼Œè¯æ˜åˆæˆæ•°æ®å¯ä»¥æ›¿ä»£çœŸå®ä¸–ç•Œé¥æ“ä½œæ•°æ®è¿›è¡Œæœºå™¨äººå­¦ä¹ 
      - **SynGrasp-1Bæ•°æ®é›†ç”Ÿæˆ**:
        - **å¤§è§„æ¨¡**: **10äº¿å¸§**æœºå™¨äººæŠ“å–æ•°æ®ï¼ˆ1000ä¸‡è½¨è¿¹ Ã— ~100å¸§æ¯ä¸ªï¼‰
        - **å¯¹è±¡å¤šæ ·æ€§**: æ¥è‡ªObjaverseçš„240ä¸ªç±»åˆ«ä¸­çš„10,680ä¸ªç‹¬ç‰¹å¯¹è±¡
        - **åœºæ™¯å¤šæ ·æ€§**: 100ä¸‡ä¸ªç‹¬ç‰¹åœºæ™¯ï¼Œå¹¿æ³›çš„åŸŸéšæœºåŒ–
        - **ç…§ç‰‡çº§æ¸²æŸ“**: ä½¿ç”¨NVIDIA IsaacSimçš„å…ˆè¿›å…‰çº¿è¿½è¸ªæ¸²æŸ“ï¼Œå®ç°é«˜ä¿çœŸè§†è§‰åˆæˆ
      - **å…¨é¢åŸŸéšæœºåŒ–**:
        - **è§†è§‰éšæœºåŒ–**: æè´¨ï¼ˆæ¡Œå­/æœºå™¨äººï¼‰ã€å…‰ç…§ï¼ˆç‚¹å…‰æº/å®šå‘å…‰/åœ†é¡¶å…‰ï¼‰ã€ç›¸æœºè§†è§’ã€èƒŒæ™¯
        - **ç‰©ç†éšæœºåŒ–**: å¯¹è±¡å¸ƒå±€ã€æŠ“å–å§¿æ€ã€æœºå™¨äººè½¨è¿¹ã€æ¡Œå­é«˜åº¦ï¼ˆ-0.1måˆ°0.2mï¼‰
        - **æ—¶é—´éšæœºåŒ–**: ä½¿ç”¨CuRoboè¿åŠ¨è§„åˆ’çš„è½¨è¿¹å˜åŒ–
        - **æŒ‡ä»¤éšæœºåŒ–**: å¯¹è±¡æ“ä½œçš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¨¡æ¿
      - **æ¸è¿›å¼åŠ¨ä½œç”Ÿæˆ(PAG)**:
        - **æ€ç»´é“¾æ¶æ„**: é›†æˆè‡ªå›å½’æ„ŸçŸ¥(VLM) + æµåŒ¹é…åŠ¨ä½œç”Ÿæˆ
        - **å¤šæ¨¡æ€è®­ç»ƒ**: åˆæˆåŠ¨ä½œæ•°æ® + äº’è”ç½‘æ¥åœ°æ•°æ®(GRIT)çš„è”åˆè®­ç»ƒ
        - **å±‚æ¬¡é¢„æµ‹**: è¾¹ç•Œæ¡† â†’ æŠ“å–å§¿æ€ â†’ åŠ¨ä½œå—ç”Ÿæˆ
        - **è·¨æ¨¡æ€å¯¹é½**: é€šè¿‡äº’è”ç½‘æ•°æ®ååŒè®­ç»ƒå¼¥åˆsim-to-realå·®è·
      - **é«˜æ•ˆæ•°æ®ç”ŸæˆPipeline**:
        - **ç¼“å­˜æœºåˆ¶**: é¿å…å†—ä½™å¯¹è±¡åŠ è½½åŒæ—¶ç¡®ä¿å¤šæ ·æ€§
        - **å¼‚æ­¥å†™å…¥**: å¹¶è¡Œå›¾åƒä¿å­˜å’Œæ ‡ç­¾ç”Ÿæˆ
        - **å¹¶è¡Œä»¿çœŸ**: å¤šçº¿ç¨‹ç‰©ç†ä»¿çœŸå’Œæ¸²æŸ“
        - **è´¨é‡ä¿è¯**: åŸºäºåŠ›é—­åˆçš„æŠ“å–åˆæˆä¸è½¨è¿¹éªŒè¯
  - **æŠ€æœ¯æ¶æ„**:
      - **è§†è§‰-è¯­è¨€éª¨å¹²**: å¤„ç†åŒæ‘„åƒå¤´è¾“å…¥ï¼ˆå‰è§† + ä¾§è§†ï¼‰çš„è‡ªå›å½’å˜æ¢å™¨
      - **åŠ¨ä½œä¸“å®¶**: åŸºäºæµåŒ¹é…çš„è¿ç»­åŠ¨ä½œç”Ÿæˆï¼Œç”±VLMç‰¹å¾æ¡ä»¶åŒ–
      - **æœ¬ä½“æ„Ÿå—é›†æˆ**: æ¥è‡ªæœ€è¿‘ä¸¤ä¸ªæ—¶é—´æ­¥çš„æœºå™¨äººçŠ¶æ€tokenï¼Œç”¨äºç²¾ç¡®3Dæ„ŸçŸ¥
      - **ç»Ÿä¸€è®­ç»ƒ**: å¤„ç†äº’è”ç½‘æ¥åœ°å’ŒåˆæˆåŠ¨ä½œä»»åŠ¡çš„å•ä¸€æ¡†æ¶
  - **æ•°æ®è§„æ¨¡ä¸è´¨é‡**:
      - **æ€»åˆæˆæ•°æ®**: 10äº¿å¸§ï¼Œå¸¦ç²¾ç¡®æ ‡æ³¨ï¼ˆç›¸æœºæ ¡å‡†ã€3Då§¿æ€ã€è¾¹ç•Œæ¡†ï¼‰
      - **å¯¹è±¡è¦†ç›–**: 240ä¸ªç±»åˆ«ç¡®ä¿å…¨é¢çš„çœŸå®ä¸–ç•Œå¯¹è±¡æ³›åŒ–
      - **æ ‡æ³¨ä¸°å¯Œæ€§**: ç»†ç²’åº¦æ ‡ç­¾åŒ…æ‹¬æ·±åº¦å›¾ã€åˆ†å‰²æ©ç ã€åŠ›é—­åˆåº¦é‡
      - **è·¨å…·èº«å°±ç»ª**: å¯æ‰©å±•pipelineï¼Œé€‚é…ä¸åŒæœºå™¨äººå’Œç›¸æœºé…ç½®
  - **è¯„ä¼°ä¸ç»“æœ**:
      - **é›¶æ ·æœ¬æ€§èƒ½**: åˆæˆç±»åˆ«93.3%æˆåŠŸç‡ï¼Œç½‘ç»œç±»åˆ«84.7%ï¼ˆvs. Ï€â‚€: 42.3%/17.8%ï¼‰
      - **Sim-to-Realè¿ç§»**: æ— éœ€çœŸå®ä¸–ç•Œå¾®è°ƒçš„ç›´æ¥éƒ¨ç½²ï¼Œä¼˜äºé¥æ“ä½œè®­ç»ƒæ¨¡å‹
      - **è·¨åŸŸæ³›åŒ–**: åœ¨è®­ç»ƒæ—¶ä»æœªè§è¿‡çš„å¯¹è±¡ä¸Šè¡¨ç°å¼ºåŠ²
      - **å°æ ·æœ¬é€‚åº”æ€§**: ä»…è¾¹ç•Œæ¡†æ ‡æ³¨90%æˆåŠŸç‡ï¼Œå®Œæ•´è½¨è¿¹æ•°æ®90%æˆåŠŸç‡
      - **LIBEROåŸºå‡†**: é›¶æ ·æœ¬è®¾ç½®ä¸‹è¶…è¶Šå¾®è°ƒçš„Ï€â‚€å’ŒOpenVLAï¼ˆ82.0% vs 62.7%/33.7%ï¼‰
  - **å…³é”®æŠ€æœ¯è´¡çŒ®**:
      - **çº¯åˆæˆè®­ç»ƒ**: è¯æ˜åˆæˆæ•°æ®å¯¹æœºå™¨äººåŸºç¡€æ¨¡å‹è®­ç»ƒçš„å……åˆ†æ€§
      - **åäº¿çº§åŠ¨ä½œæ•°æ®**: å…¨çƒé¦–ä¸ªæ­¤è§„æ¨¡çš„æœºå™¨äººæ“ä½œæ•°æ®é›†
      - **æ¸è¿›å¼åŠ¨ä½œç”Ÿæˆ**: æ”¯æŒè”åˆæ„ŸçŸ¥å’ŒåŠ¨ä½œåˆæˆçš„æ–°é¢–æ¶æ„
      - **åŸŸæ¡¥æ¥**: é€šè¿‡äº’è”ç½‘æ•°æ®é›†æˆè¿›è¡Œsim-to-realè¿ç§»çš„ç³»ç»Ÿæ€§æ–¹æ³•
  - **æœºæ„**: åŒ—äº¬å¤§å­¦ã€Galbot
  - **å¼€æº**: âœ… [SynGrasp-1Bæ•°æ®é›†ä¸é¢„è®­ç»ƒæƒé‡](https://pku-epic.github.io/GraspVLA-web)
  

</details>
---

### âœ‚ï¸ å›¾åƒç¼–è¾‘ï¼ˆæ–¹æ³•+æ•°æ®ï¼‰

This category focuses on **instruction-guided image editing** where models learn to transform images based on natural language instructions. These works typically combine **method innovation** (novel editing pipelines, architectures) with **large-scale data synthesis** (automated data engines, quality benchmarks), making them distinct from pure dataset construction efforts.

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2406.11262">ğŸ“„ GenLLaVA</a></b><br>
<code>arXiv 2406.11262</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ç”Ÿæˆå¼è§†è§‰æŒ‡ä»¤å¾®è°ƒ** - é¦–ä¸ªç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹ï¼ŒåŒæ—¶å®ç°å›¾åƒç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘èƒ½åŠ›ï¼Œæ— æ€§èƒ½é€€åŒ–
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸‰èƒ½åŠ›ç»Ÿä¸€è®­ç»ƒPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»Ÿæ€§æ–¹æ³•ï¼Œé€šè¿‡æŒ‡ä»¤å¾®è°ƒé›†æˆä¸‰ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼ˆMistral-7B + SigLIP + Stable Diffusion v1.4ï¼‰ï¼Œå®ç°ç»Ÿä¸€è§†è§‰ç†è§£ã€ç”Ÿæˆå’Œç¼–è¾‘
      - **æ¶æ„è®¾è®¡**:
        - **è¯­è¨€æ¨¡å‹**: **Mistral-7B**ä½œä¸ºåŸºç¡€LLMï¼Œæä¾›ä¼˜å¼‚è¯­è¨€èƒ½åŠ›
        - **è§†è§‰ç¼–ç å™¨**: **SigLIP-L/384px**ï¼ˆæ¯”CLIPæ›´å¼ºï¼‰æä¾›é²æ£’å›¾åƒ-æ–‡æœ¬åŒ¹é…
        - **ç”Ÿæˆæ¨¡å—**: **Stable Diffusion v1.4**é…åˆQ-formerç”Ÿæˆå¤´è¿›è¡Œæ–‡æœ¬åˆ°å›¾åƒåˆæˆ
        - **æŠ•å½±å±‚**: 2å±‚GELU MLPå°†è§†è§‰patchæŠ•å½±åˆ°è¯­è¨€åµŒå…¥ç©ºé—´
      - **è§†è§‰ç”Ÿæˆæœºåˆ¶**:
        - **è§†è§‰ä»¤ç‰Œ**: åœ¨æŒ‡ä»¤åé™„åŠ Nä¸ªå¯å­¦ä¹ çš„[IMG]ä»¤ç‰Œï¼Œå¸¦å¯è®­ç»ƒè¯åµŒå…¥
        - **ç”Ÿæˆå¤´**: Q-formeråºåˆ—åˆ°åºåˆ—æ¨¡å‹Tå°†[IMG]ä»¤ç‰Œè½¬æ¢ä¸ºè¯­ä¹‰æ½œåœ¨é›†åˆU = {uâ‚, uâ‚‚, ..., uâ‚—}
        - **æ½œåœ¨æ‰©æ•£é›†æˆ**: è§†è§‰æ½œåœ¨Uå¼•å¯¼Stable Diffusionåœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œå›¾åƒç”Ÿæˆ/ç¼–è¾‘
        - **ç‰¹æ®Šä»¤ç‰Œ**: [SOI]/[EOI]æ ‡è®°è§†è§‰ç”Ÿæˆä»¤ç‰Œçš„å¼€å§‹/ç»“æŸï¼Œç”¨äºä»»åŠ¡æ¶ˆæ­§
      - **è®­ç»ƒæ•°æ®ç»„æˆ**ï¼ˆGVIT-mix-2076Kï¼‰:
        - **å›¾åƒç†è§£** [61.56%]: LLaVAå¾®è°ƒæŒ‡ä»¤é›†ç”¨äºè§†è§‰ç†è§£ä»»åŠ¡
        - **å›¾åƒç”Ÿæˆ** [26.88%]: ~558Kå€’ç½®å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œæ¥è‡ªLAION/SBU/CC3Mï¼Œå¸¦GPT-4ç”Ÿæˆçš„æç¤ºï¼ˆå¦‚"è¯·ç”Ÿæˆ[caption]çš„å›¾åƒ"ï¼‰
        - **å›¾åƒç¼–è¾‘** [11.56%]: GPT-4Vå¤„ç†çš„ç¼–è¾‘æ•°æ®é›†ï¼Œå¸¦è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤
      - **å•é˜¶æ®µè®­ç»ƒ**: ä¸LLaVAçš„ä¸¤é˜¶æ®µæ–¹æ³•ä¸åŒï¼ŒGenLLaVAä½¿ç”¨è·¨æ‰€æœ‰èƒ½åŠ›çš„ç»Ÿä¸€å•é˜¶æ®µæŒ‡ä»¤å¾®è°ƒ
  - **æŠ€æœ¯å®ç°ç»†èŠ‚**:
      - **ä»»åŠ¡ä»¤ç‰Œç³»ç»Ÿ**: ä¸“é—¨ä»¤ç‰Œå¼•å¯¼æ¨¡å‹è¡Œä¸ºï¼ˆ[SOI]ã€[EOI]ç”¨äºç”Ÿæˆä»»åŠ¡ï¼‰
      - **å¤šä»»åŠ¡æŸå¤±**: ç»“åˆè‡ªå›å½’è¯­è¨€å»ºæ¨¡ + æ‰©æ•£å»å™ªç›®æ ‡
      - **ç”Ÿæˆä»¤ç‰Œæ•°é‡**: æœ€ä¼˜N=16è§†è§‰ä»¤ç‰Œï¼ˆæ¶ˆèæ˜¾ç¤ºN=4è¿‡æ‹Ÿåˆï¼ŒN>16æ€§èƒ½ä¸‹é™ï¼‰
      - **è§†è§‰ç¼–ç å™¨æ¶ˆè**: SigLIP-L/384px > CLIP-L/336px > CLIP-B/224px åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Š
  - **æ•°æ®è§„æ¨¡**:
      - **æ€»è®­ç»ƒé›†**: **207.6ä¸‡æŒ‡ä»¤è·Ÿéšæ ·æœ¬**ï¼ˆGVIT-mix-2076Kï¼‰
      - **ç”Ÿæˆæ•°æ®**: 558Kå›¾åƒ-æ–‡æœ¬å¯¹ï¼Œå¸¦åŠ¨æ€ç”Ÿæˆçš„æŒ‡ä»¤å‰ç¼€
      - **ç†è§£æ•°æ®**: LLaVA-1.5æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼ˆè§†è§‰æ¨ç†ã€VQAç­‰ï¼‰
      - **ç¼–è¾‘æ•°æ®**: GPT-4Vå¤„ç†çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¼•å¯¼ç¼–è¾‘æ ·æœ¬
  - **è¯„ä¼°ä¸ç»“æœ**:
      - **é«˜çº§çŸ¥è¯†**: MathVista (30.5% vs 28.3% Unified-IO2), MMMU (37.1% vs 35.5% Unified-IO2)
      - **é€šç”¨ç†è§£**: SEED-B (64.5% vs 61.6% Unified-IO2), MMBench (66.8% vs 57.9% Unified-IO2)
      - **ç”Ÿæˆä»»åŠ¡**: CC3M (12.5 FID), MS-COCO (0.73 CLIPScore) ä¸ä¸“é—¨æ¨¡å‹ç«äº‰
      - **ç¼–è¾‘èƒ½åŠ›**: EVRåŸºå‡† (66.9% vs 50.2% Unified-IO2) å±•ç¤ºä¼˜ç§€çš„æŒ‡ä»¤å¼•å¯¼ç¼–è¾‘
      - **å¤šä»»åŠ¡æƒè¡¡**: åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šä¿æŒä¸ä¸“é—¨æ¨¡å‹ç«äº‰çš„æ€§èƒ½
  - **å…³é”®æŠ€æœ¯è´¡çŒ®**:
      - **ç»Ÿä¸€æ¶æ„**: é¦–ä¸ªç«¯åˆ°ç«¯æ¨¡å‹å®ç°ç†è§£+ç”Ÿæˆ+ç¼–è¾‘ï¼Œæ— èƒ½åŠ›å†²çª
      - **æŒ‡ä»¤é›†æˆ**: é€šè¿‡å…±äº«æŒ‡ä»¤æ¥å£ä¸ºæ‰€æœ‰è§†è§‰ä»»åŠ¡æä¾›æ— ç¼è‡ªç„¶è¯­è¨€æ§åˆ¶
      - **æ€§èƒ½ä¿æŒ**: è¯æ˜é€‚å½“è®¾è®¡çš„å¤šèƒ½åŠ›è®­ç»ƒä¸ä¼šé™ä½å•ä¸ªä»»åŠ¡æ€§èƒ½
      - **å¯æ‰©å±•æ¡†æ¶**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºé›†æˆæ›´å¼ºçš„è§†è§‰ç¼–ç å™¨ã€LLMæˆ–æ‰©æ•£æ¨¡å‹
  - **æœºæ„**: è±æ–¯å¤§å­¦ã€Google DeepMind
  - **å¼€æº**: âœ… [æ•°æ®é›†ã€ä»£ç ã€æ¨¡å‹æ£€æŸ¥ç‚¹ã€è§†è§‰èŠå¤©æ¼”ç¤º](https://arxiv.org/abs/2406.11262)
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2506.03107">ğŸ“„ ByteMorph</a></b><br>
<code>arXiv 2506.03107</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **éåˆšæ€§è¿åŠ¨ç¼–è¾‘** - é¦–ä¸ªå¤§è§„æ¨¡æ•°æ®é›†è§£å†³ç›¸æœºè¿åŠ¨ã€ç‰©ä½“å½¢å˜ã€äººä½“å…³èŠ‚è¿åŠ¨å’Œäººç‰©-ç‰©ä½“äº¤äº’
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è¿åŠ¨å¼•å¯¼çš„åˆ†å±‚åˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç»“åˆ**VFXå¯å‘çš„åˆ†å±‚åˆæˆ**ä¸**GPT-4oè¿åŠ¨è¯­ä¹‰æ ‡æ³¨**çš„è‡ªåŠ¨åŒ–pipeline
      - **4é˜¶æ®µPipeline**:
        1. **è§†é¢‘æºæ”¶é›†**: ç½‘ç»œè§„æ¨¡è§†é¢‘è¯­æ–™åº“ â†’ è¿åŠ¨æ£€æµ‹ï¼ˆå…‰æµï¼‰ â†’ é«˜åˆ†è¾¨ç‡ï¼ˆâ‰¥720pï¼‰è¿åŠ¨ä¸°å¯Œç‰‡æ®µ
        2. **åˆ†å±‚åˆæˆ**: å‰æ™¯åˆ†å‰² â†’ èƒŒæ™¯ç¨³å®š â†’ ä¿ç•™è¿åŠ¨çš„å±‚åˆæˆ
        3. **GPT-4oæ ‡æ³¨ç”Ÿæˆ**: å¤šæ¨¡æ€ç†è§£ â†’ è¿åŠ¨æ„ŸçŸ¥çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤
        4. **è´¨é‡ä¿è¯**: CLIPç¾å­¦è¯„åˆ† + å…‰æµè¿è´¯æ€§ + LLMæŒ‡ä»¤-ç¼–è¾‘å¯¹é½éªŒè¯
      - **å…³é”®ä¼˜åŠ¿**: å¤§è§„æ¨¡ä¿ç•™çœŸå®è¿åŠ¨åŠ¨æ€ï¼ˆè‡ªåŠ¨åŒ–æ‰‹å·¥VFXå·¥ä½œæµï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **ByteMorph-6M**: 600ä¸‡é«˜åˆ†è¾¨ç‡ç¼–è¾‘ä¸‰å…ƒç»„ï¼ˆæºå›¾åƒã€æŒ‡ä»¤ã€ç¼–è¾‘å›¾åƒï¼‰
      - **åˆ†å¸ƒ**: 180ä¸‡ç›¸æœºè¿åŠ¨ã€150ä¸‡ç‰©ä½“å½¢å˜ã€180ä¸‡äººä½“å…³èŠ‚è¿åŠ¨ã€90ä¸‡HOI
      - **åˆ†è¾¨ç‡**: å¤§éƒ¨åˆ†1024Ã—1024ï¼Œæœ€å°512Ã—512
  - **åŸºå‡†**: ByteMorph-Benchï¼ˆ613ä¸ªä¸“å®¶éªŒè¯æµ‹è¯•æ ·æœ¬ï¼Œéš¾åº¦åˆ†çº§ï¼‰
  - **æ¨¡å‹**: ByteMorpherï¼ˆæ‰©æ•£TransformeråŸºçº¿ï¼‰
  - **å®éªŒç»“æœ**:
      - åœ¨è¿åŠ¨æŒ‡æ ‡ä¸Šè¶…è¶ŠInstructPix2Pix/MagicBrush **+18.3%**
      - äººå·¥åå¥½: **73.5%** vs. åŸºçº¿
      - è¯æ˜è¿åŠ¨ç‰¹å®šè®­ç»ƒè‡³å…³é‡è¦ï¼ˆé™æ€æ•°æ®é›†æ¨¡å‹: 32.1%æˆåŠŸç‡ï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´6æœˆ
  - **æœºæ„**: å­—èŠ‚è·³åŠ¨Seedã€USCã€ä¸œäº¬å¤§å­¦ã€UCä¼¯å…‹åˆ©ã€æ–¯å¦ç¦ã€UCLA
  - **å¼€æº**: âœ… æ•°æ®é›†ï¼ˆ600ä¸‡ä¸‰å…ƒç»„ï¼‰ã€åŸºå‡†ï¼ˆ613æ ·æœ¬ï¼‰ã€æ¨¡å‹ã€ä»£ç  - è®¡åˆ’åœ¨OpenDataLab/HuggingFaceå‘å¸ƒ
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2505.20275">ğŸ“„ ImgEdit</a></b><br>
<code>arXiv 2505.20275</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ç»Ÿä¸€å›¾åƒç¼–è¾‘æ•°æ®é›†å’ŒåŸºå‡†** - æ¶µç›–å¤šæ ·åŒ–å•è½®ç¼–è¾‘å’Œå…·æœ‰èº«ä»½ä¸€è‡´æ€§çš„æŒ‘æˆ˜æ€§å¤šè½®ä»»åŠ¡
  - **æ•°æ®åˆæˆæ–¹æ³•** - **é›†æˆVLMã€æ£€æµ‹ã€åˆ†å‰²å’Œä¿®å¤çš„å¤šé˜¶æ®µè‡ªåŠ¨åŒ–Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç»“åˆ**VLMç¼–æ’**ä¸**ä¸“ç”¨è§†è§‰å·¥å…·**çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–å·¥ä½œæµï¼Œå®ç°å¯æ‰©å±•çš„é«˜è´¨é‡ç¼–è¾‘æ•°æ®ç”Ÿæˆ
      - **5é˜¶æ®µç»Ÿä¸€Pipeline**:
        1. **åˆå§‹å€™é€‰ç”Ÿæˆï¼ˆVLMé©±åŠ¨ï¼‰**:
           - ä½¿ç”¨**GPT-4o**åˆ†ææºå›¾åƒå¹¶ç”Ÿæˆç¼–è¾‘ä»»åŠ¡å€™é€‰
           - æ¶µç›–8å¤§ç¼–è¾‘ç±»åˆ«: å¯¹è±¡æ·»åŠ ã€åˆ é™¤ã€æ›¿æ¢ã€å±æ€§ä¿®æ”¹ã€èƒŒæ™¯å˜åŒ–ã€é£æ ¼è¿ç§»ã€ç©ºé—´é‡æ’ã€å¤šå¯¹è±¡ç¼–è¾‘
           - ç”Ÿæˆé’ˆå¯¹å›¾åƒå†…å®¹å®šåˆ¶çš„è‡ªç„¶è¯­è¨€ç¼–è¾‘æŒ‡ä»¤
        2. **å®šä½ä¸æ£€æµ‹**:
           - éƒ¨ç½²**Grounding DINO** / **YOLO-World**è¿›è¡Œå¯¹è±¡å®šä½
           - å°†VLMè¯†åˆ«çš„ç¼–è¾‘ç›®æ ‡è½¬æ¢ä¸ºç²¾ç¡®è¾¹ç•Œæ¡†
           - å¤„ç†æ˜¾å¼å¯¹è±¡å’ŒæŠ½è±¡æ¦‚å¿µï¼ˆå¦‚"æœ€å·¦è¾¹çš„æ¤…å­"ï¼‰
        3. **å®ä¾‹åˆ†å‰²**:
           - åº”ç”¨**SAMï¼ˆSegment Anything Modelï¼‰**è·å–åƒç´ çº§ç²¾ç¡®æ©ç 
           - ç¡®ä¿ç¼–è¾‘æ“ä½œå°Šé‡å¯¹è±¡è¾¹ç•Œ
           - å¯¹æ·»åŠ /æ›¿æ¢ä»»åŠ¡ä¸­çš„è‡ªç„¶åˆæˆè‡³å…³é‡è¦
        4. **ä»»åŠ¡ç‰¹å®šä¿®å¤ä¸ç¼–è¾‘**:
           - **å¯¹è±¡åˆ é™¤**: å†…å®¹æ„ŸçŸ¥ä¿®å¤ï¼ˆSD-Inpaintã€LaMaï¼‰
           - **å¯¹è±¡æ·»åŠ **: åŸºäºæ‰©æ•£çš„å¯¹è±¡æ’å…¥ä¸åè°ƒ
           - **æ›¿æ¢**: ä¿ç•™ä¸Šä¸‹æ–‡çš„æ©ç å¼•å¯¼ç”Ÿæˆ
           - **å±æ€§ä¿®æ”¹**: å±€éƒ¨é£æ ¼/é¢œè‰²è°ƒæ•´
           - **èƒŒæ™¯å˜åŒ–**: å‰æ™¯ä¿ç•™ + èƒŒæ™¯åˆæˆ
        5. **è´¨é‡æ§åˆ¶ä¸åå¤„ç†**:
           - **è‡ªåŠ¨è¿‡æ»¤**: åŸºäºCLIPçš„æŒ‡ä»¤-å›¾åƒå¯¹é½è¯„åˆ†
           - **ä¼ªå½±æ£€æµ‹**: è¯†åˆ«å¯è§æ¥ç¼ã€ä¸è‡ªç„¶è¾¹ç•Œã€ä¸ä¸€è‡´å…‰ç…§
           - **äººå·¥å›ç¯éªŒè¯**: åŸºäºæ ·æœ¬çš„è´¨é‡å®¡æ ¸ï¼ˆæ•°æ®é›†çš„5%ï¼‰
           - **èº«ä»½ä¸€è‡´æ€§éªŒè¯**ï¼ˆå¤šè½®ç¼–è¾‘ï¼‰: ç¡®ä¿ç›¸åŒå¯¹è±¡åœ¨è½®æ¬¡é—´ä¿æŒè§†è§‰èº«ä»½
      - **å…³é”®åˆ›æ–°**: ä¸çº¯ç”Ÿæˆæ–¹æ³•ä¸åŒï¼ŒImgEditå°†**å¤æ‚ç¼–è¾‘åˆ†è§£ä¸ºæ¨¡å—åŒ–è§†è§‰ä»»åŠ¡**ï¼Œç¡®ä¿å¯æ§æ€§å’Œå‡†ç¡®æ€§
  - **æ•°æ®è§„æ¨¡**:
      - **ImgEditæ•°æ®é›†**: 120ä¸‡é«˜è´¨é‡ç¼–è¾‘ä¸‰å…ƒç»„ï¼ˆæºã€æŒ‡ä»¤ã€ç¼–è¾‘åï¼‰
      - **å•è½®ç¼–è¾‘**: 95ä¸‡æ ·æœ¬ï¼ˆæ–°é¢–å¤æ‚çš„å•æ­¥å˜æ¢ï¼‰
      - **å¤šè½®ç¼–è¾‘**: 25ä¸‡æ ·æœ¬ï¼ˆå…·æœ‰èº«ä»½ä¸€è‡´æ€§çš„åºåˆ—ç¼–è¾‘ï¼‰
      - **æŒ‡ä»¤å¤æ‚åº¦**: å¹³å‡æ¯æ¡æŒ‡ä»¤18.7è¯ï¼Œ78.3%éœ€è¦ç©ºé—´/è¯­ä¹‰æ¨ç†
  - **åŸºå‡†**: **ImgEdit-Bench**
      - **è§„æ¨¡**: 1,000ä¸ªç²¾é€‰æµ‹è¯•æ ·æœ¬ï¼Œæ¶µç›–æ‰€æœ‰ç¼–è¾‘ç±»åˆ«
      - **éš¾åº¦åˆ†å±‚**: ç®€å•ï¼ˆ20%ï¼‰ã€ä¸­ç­‰ï¼ˆ50%ï¼‰ã€å›°éš¾ï¼ˆ30%ï¼‰
      - **è¯„ä¼°æŒ‡æ ‡**: CLIP-Simã€FIDã€LPIPSã€èº«ä»½ä¸€è‡´æ€§åˆ†æ•°ï¼ˆå¤šè½®ï¼‰ã€äººå·¥è¯„ä¼°
      - **æŒ‘æˆ˜æ€§æ¡ˆä¾‹**: ç»†ç²’åº¦å±æ€§ï¼ˆå¦‚"å°†é¢†å¸¦æ”¹ä¸ºæ¡çº¹å›¾æ¡ˆ"ï¼‰ã€å¤šå¯¹è±¡åè°ƒã€è·¨è½®æ¬¡é£æ ¼ä¿ç•™
  - **å®éªŒç»“æœ**:
      - æœ€å…ˆè¿›çš„æŒ‡ä»¤éµå¾ªç¼–è¾‘æ€§èƒ½
      - **å¤šè½®ç¼–è¾‘**: ImgEditè®­ç»ƒæ¨¡å‹ä¿æŒ**87.3%èº«ä»½ä¸€è‡´æ€§** vs. åŸºçº¿çš„**52.1%**
      - **æ³›åŒ–**: å¼ºè¿ç§»åˆ°æœªè§ç¼–è¾‘ç±»å‹å’Œé¢†åŸŸ
      - **äººå·¥è¯„ä¼°**: åœ¨æ¯”è¾ƒä¸­**69.8%**ä¼˜äºInstructPix2Pixã€MagicBrush
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´2æœˆ (v1: 2025å¹´2æœˆ)
  - **æœºæ„**: åŒ—äº¬å¤§å­¦æ·±åœ³ç ”ç©¶ç”Ÿé™¢ã€é¹åŸå®éªŒå®¤ã€Rabbitpre AI
  - **å¼€æº**: âœ… æ•°æ®é›†ï¼ˆ120ä¸‡ä¸‰å…ƒç»„ï¼‰ã€åŸºå‡†ï¼ˆ1Kæ ·æœ¬ï¼‰ã€ä»£ç  - è®ºæ–‡ä¸­æä¾›å‘å¸ƒè¯¦æƒ…
  - **äº¤å‰å¼•ç”¨**: å¦è§[å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†](#-å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†)äº†è§£æ•°æ®é›†è¯¦æƒ…
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2506.03481">ğŸ“„ RefEdit</a></b><br>
<code>arXiv 2506.03481</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **æŒ‡ç§°è¡¨è¾¾å¼å¼•å¯¼çš„å›¾åƒç¼–è¾‘** - é€šè¿‡æ–‡æœ¬æŒ‡ç§°è¡¨è¾¾å¼ï¼ˆå¦‚"å·¦è¾¹çš„çº¢è‹¹æœ"ï¼‰è¿›è¡Œç²¾ç¡®å¯¹è±¡çº§ç¼–è¾‘
  - **æ•°æ®åˆæˆæ–¹æ³•** - **GPT-4oã€å®šä½ä¸FlowChefçš„å¯æ‰©å±•åˆæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: åˆ©ç”¨**å¯æ‰©å±•åˆæˆæ•°æ®ç”Ÿæˆ**çš„å°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œè¶…è¶Šç™¾ä¸‡çº§åŸºçº¿
      - **3é˜¶æ®µè‡ªåŠ¨åŒ–Pipeline**:
        1. **æŒ‡ä»¤ç”Ÿæˆï¼ˆåŸºäºGPT-4oï¼‰**:
           - è¾“å…¥: æºå›¾åƒ + å¯¹è±¡æ ‡æ³¨ï¼ˆæ¥è‡ªRefCOCO/RefCOCO+/RefCOCOgï¼‰
           - **GPT-4o**ç”Ÿæˆæ¶‰åŠæŒ‡ç§°è¡¨è¾¾å¼çš„å¤šæ ·åŒ–ç¼–è¾‘æŒ‡ä»¤
           - æŒ‡ä»¤ç±»å‹: æ·»åŠ ã€åˆ é™¤ã€æ›¿æ¢ã€é‡æ–°ç€è‰²ã€è°ƒæ•´å¤§å°ã€é‡æ–°å®šä½å¯¹è±¡
           - å¼ºè°ƒ**ç©ºé—´å…³ç³»**ï¼ˆå¦‚"ç¬”è®°æœ¬ç”µè„‘å³ä¾§çš„ç“¶å­"ï¼‰
        2. **å®šä½ä¸åˆ†å‰²**:
           - **Grounded Segment Anything (Grounded-SAM)**å®šä½è¢«æŒ‡ç§°å¯¹è±¡
           - ä¸ºç¼–è¾‘ç›®æ ‡ç”Ÿæˆç²¾ç¡®æ©ç 
           - é€šè¿‡ä¸Šä¸‹æ–‡æ¨ç†å¤„ç†æ¨¡ç³ŠæŒ‡ç§°
        3. **ä½¿ç”¨FlowChefçš„å—æ§ç¼–è¾‘**:
           - **FlowChef**: åŸºäºæµçš„åˆæˆï¼Œå®ç°è‡ªç„¶å¯¹è±¡æ’å…¥/ä¿®æ”¹
           - æ‰§è¡Œç¼–è¾‘çš„åŒæ—¶ä¿ç•™èƒŒæ™¯ä¸€è‡´æ€§
           - è´¨é‡è¿‡æ»¤: åŸºäºCLIPçš„æŒ‡ä»¤éµå¾ªéªŒè¯
      - **å…³é”®å‘ç°**: ä»…**2ä¸‡åˆæˆä¸‰å…ƒç»„**å³å¯ä½¿æ¨¡å‹è¶…è¶Šåœ¨**>100ä¸‡æ ·æœ¬**ä¸Šè®­ç»ƒçš„åŸºçº¿
  - **æ•°æ®è§„æ¨¡**:
      - **RefEditè®­ç»ƒæ•°æ®**: 2ä¸‡é«˜è´¨é‡åˆæˆç¼–è¾‘ä¸‰å…ƒç»„
      - **æ¤æ ¹äºRefCOCO**: åŸºäºå·²å»ºç«‹çš„æŒ‡ç§°è¡¨è¾¾å¼æ•°æ®é›†
      - **æŒ‡ä»¤å¤šæ ·æ€§**: 12ç§ç¼–è¾‘ç±»å‹ Ã— å¤šæ ·åŒ–ç©ºé—´/å±æ€§å˜ä½“
  - **åŸºå‡†**: **RefEdit-Bench**
      - **åŸºç¡€**: RefCOCOæµ‹è¯•å›¾åƒé…ä¸“å®¶æ ‡æ³¨çš„ç¼–è¾‘ä»»åŠ¡
      - **é‡ç‚¹**: è¯„ä¼°ç¼–è¾‘ä¸­æŒ‡ç§°è¡¨è¾¾å¼ç†è§£çš„ç²¾ç¡®æ€§
      - **æŒ‡æ ‡**: å¯¹è±¡å®šä½å‡†ç¡®ç‡ + ç¼–è¾‘è´¨é‡ï¼ˆCLIP-Simã€FIDã€äººå·¥è¯„ä¼°ï¼‰
  - **æ¨¡å‹**: **RefEditæ¨¡å‹**
      - **æ¶æ„**: åŸºäºæ‰©æ•£çš„ç¼–è¾‘æ¨¡å‹ï¼Œæ¡ä»¶åŒ–äºæŒ‡ç§°è¡¨è¾¾å¼
      - **è®­ç»ƒ**: åœ¨2ä¸‡åˆæˆæ•°æ®ä¸Šå¾®è°ƒ
  - **å®éªŒç»“æœ**:
      - **RefEdit-Bench**: å°½ç®¡è®­ç»ƒæ•°æ®å°‘**50å€**ï¼Œä»è¶…è¶ŠMagicBrushã€InstructPix2Pix
      - **æŒ‡ç§°ç²¾åº¦**: **91.2%å¯¹è±¡å®šä½å‡†ç¡®ç‡** vs. ä»…æŒ‡ä»¤åŸºçº¿çš„**67.3%**
      - **å°‘æ ·æœ¬ä¼˜è¶Šæ€§**: è¯æ˜æ•°æ®è´¨é‡ > æ•°é‡èŒƒå¼
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´6æœˆ (v1: 2025å¹´6æœˆ)
  - **æœºæ„**: äºšåˆ©æ¡‘é‚£å·ç«‹å¤§å­¦
  - **å¼€æº**: âœ… RefEdit-Benchã€æ¨¡å‹ã€2ä¸‡è®­ç»ƒæ•°æ® - è®ºæ–‡ä¸­æä¾›è¯¦æƒ…
  - **äº¤å‰å¼•ç”¨**: å¦è§[å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†](#-å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Referring%20Image%20Editing%20/%20RefCOCO-Edit%20CVPR%202024">ğŸ“„ Referring Image Editing / RefCOCO-Edit</a></b><br>
<code>CVPR 2024</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2024-red?style=flat-square"/>
</summary>

  - **Focus**: **First systematic formulation of Referring Image Editing (RIE)** as object-level generative task
  - **Core Contribution**:
      - **Task Definition**: Formalizes RIE as editing specific objects identified by referring expressions
      - **ReferDiffusion Framework**: Tailored diffusion-based architecture for RIE
      - **RefCOCO-Edit Dataset**: Early-stage benchmark derived from RefCOCO
  - **Data Synthesis Method** - **Paint-by-Example + Blended Latent Diffusion**:
      - **Pipeline**:
        1. **Source**: RefCOCO images with referring expression annotations
        2. **Reference Image Collection**: Gather exemplar edited images for target attributes
        3. **Mask-Guided Synthesis**:
           - **Paint-by-Example**: Example-based inpainting for object attributes
           - **Blended Latent Diffusion**: Smooth blending of edited regions with original image
        4. **Quality Control**: Manual filtering + automatic consistency checks
      - **Scale**: Small-scale benchmark (exact size not specified, typical early benchmark scale ~500-2K samples)
  - **RefCOCO-Edit Dataset**:
      - **Components**: Images, editing prompts with referring expressions, source object segmentation masks, reference edited images
      - **Editing Types**: Object attribute changes (color, texture, style) guided by referring expressions
  - **ReferDiffusion Model**:
      - **Architecture**: Dual-branch diffusion model
        - **Referring Branch**: Encodes referring expressions + grounds target objects
        - **Editing Branch**: Applies conditional diffusion to masked regions
      - **Innovation**: First to integrate referring expression grounding into diffusion editing
  - **Experimental Results**:
      - Establishes baseline performance on RefCOCO-Edit
      - Demonstrates superiority over generic instruction-guided editors for object-specific tasks
  - **Significance**:
      - **Pioneering Work**: First systematic treatment of RIE as distinct task
      - **Early Benchmark**: RefCOCO-Edit serves as foundational evaluation dataset
      - **Methodological Blueprint**: Influenced subsequent works (RefEdit, ImgEdit)
  - **Publication**: CVPR 2024
  - **Institution**: Academic research (see CVPR paper)
  - **Open Source**: âœ… RefCOCO-Edit dataset, ReferDiffusion code (check CVPR supplementary materials)
  - **Cross-Reference**: See also [Benchmark Datasets](#-benchmark-datasets) for RefCOCO-Edit details
  

</details>
---

### ğŸ§© ç»„åˆæ€§/åå¥½å¯¼å‘åˆæˆ

This category focuses on **synthetic data generation for enhancing compositional understanding** in Vision-Language Models. These methods use controlled data synthesis to improve models' ability to understand complex compositional relationships (e.g., attribute binding, spatial relationships, counting) and align with human preferences.

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=COMO">ğŸ“„ COMO** ğŸ·ï¸</a></b><br>
<code>Paper</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **Focus**: **Improving Vision and Language Concepts Understanding with Multimodal Counterfactual Samples** - Generate both textual and visual counterfactual samples to improve VL models' concept understanding beyond "bag-of-objects" limitations
  - **Data Synthesis Method** - **Multimodal Counterfactual Generation Pipeline**:
      - **Core Innovation**: First framework to simultaneously generate textual and visual counterfactual samples, addressing VL models' weaknesses in attribute, relation, and word order understanding
      - **Counterfactual Text Generation**:
        - Use **BERT** masked language models to replace key concept words (nouns, verbs, adjectives) in original captions
        - **NLP Parsing**: Identify objects (nouns), relations (verbs/adverbs), and attributes (adjectives) using spaCy
        - **Word Replacement Strategy**: Mask selected concept â†’ retrieve most probable replacements â†’ filter synonyms using WordNet
        - **Quality Control**: Choose highest-scoring candidate that creates true negative (non-synonymous replacement)
      - **Counterfactual Image Generation**:
        - Use **Stable Diffusion** to generate corresponding counterfactual images from counterfactual captions
        - **Image Selection**: Generate 10 candidates, select best based on dual CLIP similarity: score = Îµ_T(T_c)Â·Îµ_V(V_i) + Îµ_V(V_o)Â·Îµ_V(V_i)
        - **Quality Assurance**: Ensure changed concept (causal) is learnable while preserving unchanged concepts (spurious)
      - **Contrastive Learning Enhancement**:
        - **Counterfactual Guided Loss**: Feed factual and counterfactual pairs into same mini-batch as hard negatives
        - **Weighted Hard Negative Loss**: Dynamically reweight importance using normalized similarity: Î±_ij = (n-1)Â·S(T_i,V_j) / Î£_kâ‰ i S(T_i,V_k)
        - **Dual Contrastive Objectives**: Push counterfactual embeddings away from factual anchors while matching counterfactual image-text pairs
  - **Data Scale**:
      - **Base Dataset**: MS-COCO (113K images, 567K captions)
      - **COCO-CF Dataset**: 680K images + 1,134K captions (567K counterfactual image-text pairs added)
      - **Augmentation Ratio**: 5Ã— increase in caption diversity, 6Ã— increase in image diversity
  - **Experimental Results**:
      - **VL-Checklist**: Attribute +3.17%, Relation +2.12%, Object +1.70% over best baselines
      - **Winoground**: Text +1.60%, Image +4.35%, Group +2.63% improvements
      - **Compositional Reasoning**: Significant gains in understanding spatial relations, object attributes, and word order changes
      - **Ablation Findings**: Both text and image counterfactuals necessary; In-Batch strategy crucial vs Random sampling
  - **Institution**: School of Computer Science and Technology, Xidian University, Xi'an, China
  - **Open Source**: âœ… [Dataset & Code](https://github.com/laichengen/COMO)
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2411.02545">ğŸ“„ TripletCLIP</a></b><br>
<code>arXiv 2411.02545</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2024å¹´11æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šè¿‡åˆæˆè§†è§‰-è¯­è¨€éš¾è´Ÿæ ·æœ¬å¢å¼ºCLIPç»„åˆæ¨ç†èƒ½åŠ›**
  - **æ•°æ®åˆæˆæ–¹æ³•** - **LLMå¼•å¯¼çš„éš¾è´Ÿæ ·æœ¬æ ‡æ³¨ç”Ÿæˆ + T2Iæ¨¡å‹å¯¹åº”å›¾åƒåˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç”Ÿæˆè¯­ä¹‰ä¸Šç›¸ä¼¼ä½†ç»„åˆç»“æ„ä¸åŒçš„éš¾è´Ÿæ ·æœ¬å›¾åƒ-æ–‡æœ¬å¯¹ï¼Œä½¿ç”¨ä¸‰å…ƒå¯¹æ¯”å­¦ä¹ è®­ç»ƒCLIP
      - **ä¸¤é˜¶æ®µPipeline**:
        1. **LLMç”Ÿæˆéš¾è´Ÿæ ·æœ¬æ ‡æ³¨**:
           - ä½¿ç”¨**Mistral-7B-Instruct-v0.2**é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ç”Ÿæˆé«˜è´¨é‡éš¾è´Ÿæ ·æœ¬æ ‡æ³¨
           - **æç¤ºç­–ç•¥**: è¦æ±‚ç”Ÿæˆ"å¤§éƒ¨åˆ†ç›¸ä¼¼ä½†å¼•å…¥è¶³å¤Ÿæ˜¾è‘—å·®å¼‚ï¼Œä½¿ä¸¤ä¸ªæè¿°ä¸å¯èƒ½æŒ‡å‘åŒä¸€å›¾åƒ"çš„æ ‡æ³¨
           - **å˜åŒ–ç±»å‹**:
             - **å¯¹è±¡æ›¿æ¢**: "ç‹—åœ¨çª—æˆ·æ—" â†’ "çŒ«åœ¨çª—æˆ·æ—"
             - **ç©ºé—´å…³ç³»**: "ç‹—åœ¨çŒ«å·¦è¾¹" â†’ "çŒ«åœ¨ç‹—å·¦è¾¹"
             - **å±æ€§å˜æ¢**: "çº¢è‰²æ±½è½¦" â†’ "è“è‰²æ±½è½¦"
             - **åŠ¨ä½œå˜åŒ–**: "äººåœ¨è·‘æ­¥" â†’ "äººåœ¨èµ°è·¯"
           - **è´¨é‡æ§åˆ¶**: å•ä¸ªé«˜è´¨é‡è´Ÿæ ‡æ³¨èƒœè¿‡å¤šä¸ªä½è´¨é‡è´Ÿæ ‡æ³¨
        2. **T2Iæ¨¡å‹ç”Ÿæˆå¯¹åº”è´Ÿæ ·æœ¬å›¾åƒ**:
           - ä½¿ç”¨**SDXL-Turbo**å¿«é€Ÿç”Ÿæˆè´Ÿæ ·æœ¬å›¾åƒï¼ˆå¯¹åº”è´Ÿæ ‡æ³¨ï¼‰
           - **é€Ÿåº¦**: 8Ã—RTX A6000ä¸Š3å¤©ç”Ÿæˆ1300ä¸‡è´Ÿæ ·æœ¬æ ‡æ³¨
           - **LLMé€‰æ‹©**: Mistral-7B-Instruct-v0.2è¡¨ç°æœ€ä½³ï¼Œè¾“å‡ºæ˜“äºè§£æ
           - **è´¨é‡è¯„ä¼°**: ViLTæ¨¡å‹éªŒè¯ç”Ÿæˆå›¾åƒå¹³å‡76%å‡†ç¡®åº¦è·Ÿéšæ–‡æœ¬æç¤º
      - **TripletCLIPè®­ç»ƒç­–ç•¥**:
        - **ä¸‰å…ƒå¯¹æ¯”æŸå¤±**: L_TCL = L_NegCLIP(X,Y,Y') + L_NegCLIP(X',Y',Y)
        - **äº¤æ›¿ç›‘ç£**: ä½¿ç”¨(X,Y,Y')å’Œ(X',Y',Y)ä¸¤ä¸ªä¸‰å…ƒç»„äº¤æ›¿è®­ç»ƒ
        - **éš¾è´Ÿæ ·æœ¬è§„å¾‹åŒ–**: è´Ÿå›¾åƒç”¨äºè§„å¾‹åŒ–è´Ÿæ ‡æ³¨çš„æ•ˆæœå¹¶ç¨³å®šé¢„è®­ç»ƒ
  - **æ•°æ®è§„æ¨¡**:
      - **TripletDataæ•°æ®é›†**: 1300ä¸‡å›¾åƒ-æ–‡æœ¬éš¾è´Ÿæ ·æœ¬å¯¹
      - **åŸºç¡€æ•°æ®**: åŸºäºCC3M(260ä¸‡)å’ŒCC12M(1200ä¸‡)æ•°æ®é›†æ‰©å±•
      - **æ•°æ®ç±»å‹**: æ¯ä¸ªæ­£æ ·æœ¬å¯¹åº”ä¸€ä¸ªç²¾å¿ƒæ„é€ çš„è´Ÿæ ·æœ¬å¯¹
  - **è®­ç»ƒç­–ç•¥**:
      - **è®¡ç®—é¢„ç®—å…¬å¹³**: ä¸åŸºçº¿æ–¹æ³•ä¿æŒç›¸åŒçš„è®­ç»ƒè®¡ç®—é‡
      - **æ¨¡æ€ç‰¹å®šæ¶ˆè**: åˆ†åˆ«éªŒè¯éš¾è´Ÿæ ·æœ¬æ ‡æ³¨å’Œå›¾åƒçš„è´¡çŒ®
      - **æ¦‚å¿µè¦†ç›–åº¦åˆ†æ**: åœ¨ä¸åŒæ¦‚å¿µå¤šæ ·æ€§æ°´å¹³ä¸‹è¯„ä¼°æ€§èƒ½
  - **å®éªŒç»“æœ**:
      - **ç»„åˆç†è§£åŸºå‡†**:
        - **SugarCrepe**: ç›¸æ¯”LaCLIPæå‡**+9.4%**(CC3M)å’Œ**+10.9%**(CC12M)
        - **SugarCrepe**: ç›¸æ¯”NegCLIPæå‡**+6.3%**(CC3M)å’Œ**+6.5%**(CC12M)
        - **æ‰€æœ‰å­ç±»åˆ«**: åœ¨å¯¹è±¡/å±æ€§æ›¿æ¢ã€äº¤æ¢ã€æ·»åŠ ä»»åŠ¡ä¸Šå…¨é¢æå‡
      - **é›¶æ ·æœ¬ä»»åŠ¡**:
        - **å›¾åƒ-æ–‡æœ¬æ£€ç´¢**: R@5æŒ‡æ ‡æ˜¾è‘—æå‡(CC3M: +11.1%, CC12M: +16.1%)
        - **ImageNetåˆ†ç±»**: Top-1å‡†ç¡®ç‡æå‡(CC3M: +3.5%, CC12M: +7.0%)
        - **VTABåŸºå‡†**: è§†è§‰ä»»åŠ¡é€‚åº”åŸºå‡†ä¿æŒç«äº‰åŠ›
      - **æ¶ˆèç ”ç©¶å‘ç°**:
        - **è´Ÿæ ‡æ³¨å•ç‹¬**: ç›¸æ¯”LaCLIPåœ¨SugarCrepeä¸Š+7.6%
        - **è´Ÿå›¾åƒå•ç‹¬**: ç›¸æ¯”LaCLIPåœ¨SugarCrepeä¸Š+2.2%
        - **ä¸¤è€…ç»“åˆ**: è¾¾åˆ°æœ€ä½³æ€§èƒ½+9.4%
  - **å…³é”®å‘ç°**:
      - **åŒæ¨¡æ€éš¾è´Ÿæ ·æœ¬æ•ˆæœ**: è´Ÿæ ‡æ³¨+è´Ÿå›¾åƒæ¯”ä»»ä¸€å•ç‹¬ä½¿ç”¨æ›´æœ‰æ•ˆ
      - **æ•°æ®æ•ˆç‡**: ä»…ç”¨ä¸€åŠæ­£æ ·æœ¬+ä¸€åŠè´Ÿæ ·æœ¬å³è¶…è¶Šå…¨æ­£æ ·æœ¬åŸºçº¿
      - **LLMç”Ÿæˆè´¨é‡**: LLMç”Ÿæˆçš„è´Ÿæ ‡æ³¨è´¨é‡æ˜¾è‘—ä¼˜äºè§„åˆ™æ›¿æ¢æ–¹æ³•
      - **æ¦‚å¿µè¦†ç›–ç‹¬ç«‹æ€§**: å³ä½¿åœ¨è¾ƒä½æ¦‚å¿µè¦†ç›–åº¦ä¸‹ä¹Ÿèƒ½ä¿æŒæ€§èƒ½ä¼˜åŠ¿
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´11æœˆ | äºšåˆ©æ¡‘é‚£å·ç«‹å¤§å­¦ & é©¬é‡Œå…°å¤§å­¦å·´å°”çš„æ‘©åˆ†æ ¡
  - **å¼€æº**: âœ… ä»£ç ã€æ¨¡å‹ã€TripletDataæ•°æ®é›† - [tripletclip.github.io](https://tripletclip.github.io)
  - **é‡è¦æ„ä¹‰**:
      - **CLIPç»„åˆç†è§£çªç ´**: é¦–ä¸ªåŒæ—¶åˆ©ç”¨éš¾è´Ÿæ ·æœ¬å›¾åƒå’Œæ–‡æœ¬çš„CLIPè®­ç»ƒæ–¹æ³•
      - **å¯æ‰©å±•æ€§**: æä¾›äº†å¯åº”ç”¨äºå…¶ä»–VLMçš„é€šç”¨ä¸‰å…ƒå¯¹æ¯”å­¦ä¹ æ¡†æ¶
      - **å®ç”¨æ€§**: åœ¨ç›¸ç­‰è®¡ç®—é¢„ç®—ä¸‹å–å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå…·æœ‰è‰¯å¥½çš„æ•ˆç‡-æ•ˆæœæƒè¡¡
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2503.01167">ğŸ“„ SPARCL</a></b><br>
<code>arXiv 2503.01167</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2025-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šè¿‡å…·æœ‰ç»†å¾®å˜åŒ–çš„å¤šæ¨¡æ€åˆæˆæ•°æ®å¢å¼ºVLMç»„åˆç†è§£**
  - **æ•°æ®åˆæˆæ–¹æ³•** - **çœŸå®å›¾åƒç‰¹å¾æ³¨å…¥å¿«é€ŸT2Iæ¨¡å‹ + è‡ªé€‚åº”è¾¹è·æŸå¤±**:
      - **æ ¸å¿ƒåˆ›æ–°**: ç”Ÿæˆæ­£/è´Ÿæ ‡æ³¨å¯¹é…**è§†è§‰åŸºç¡€å›¾åƒ**ï¼Œè®­ç»ƒVLMè¿›è¡Œç»†ç²’åº¦ç»„åˆåŒºåˆ†
      - **3é˜¶æ®µPipeline**:
        1. **æ ‡æ³¨å¯¹ç”Ÿæˆï¼ˆåŸºäºLLMï¼‰**:
           - ä½¿ç”¨**LLM**ï¼ˆå¦‚GPT-4ï¼‰ç”Ÿæˆå…·æœ‰ç»†å¾®ç»„åˆå˜åŒ–çš„æ­£/è´Ÿæ ‡æ³¨å¯¹
           - **æ­£æ ‡æ³¨**: å‡†ç¡®æè¿°å›¾åƒå†…å®¹
           - **è´Ÿæ ‡æ³¨**: åœ¨ä¿æŒè¯­ä¹‰ç›¸ä¼¼æ€§çš„åŒæ—¶å¼•å…¥ç»„åˆé”™è¯¯
           - **å˜åŒ–ç±»å‹**:
             - **å±æ€§ç»‘å®š**: "çº¢è‹¹æœå’Œç»¿é¦™è•‰" â†’ "ç»¿è‹¹æœå’Œçº¢é¦™è•‰"
             - **å¯¹è±¡è®¡æ•°**: "ä¸‰åªç‹—" â†’ "ä¸¤åªç‹—"
             - **ç©ºé—´å…³ç³»**: "çŒ«åœ¨ç‹—å·¦è¾¹" â†’ "ç‹—åœ¨çŒ«å·¦è¾¹"
             - **åŠ¨ä½œå½’å±**: "å¥³äººæ‹¿ä¼" â†’ "ç”·äººæ‹¿ä¼"
        2. **çœŸå®ç‰¹å¾æ³¨å…¥çš„å›¾åƒåˆæˆ**:
           - **æŒ‘æˆ˜**: çº¯æ–‡ç”Ÿå›¾æ¨¡å‹éš¾ä»¥å®ç°ç²¾ç¡®ç»„åˆæ§åˆ¶
           - **è§£å†³æ–¹æ¡ˆ**: å°†**çœŸå®å›¾åƒç‰¹å¾**æ³¨å…¥å¿«é€ŸT2Iæ¨¡å‹ï¼ˆå¦‚SDXL-Turboï¼‰
           - **æ–¹æ³•**:
             - ä»**çœŸå®å‚è€ƒå›¾åƒ**ï¼ˆå¦‚COCOã€Visual Genomeï¼‰æå–ç‰¹å¾
             - **ç‰¹å¾æ³¨å…¥**: åŒæ—¶åŸºäºæ–‡æœ¬æ ‡æ³¨+çœŸå®å›¾åƒç‰¹å¾æ¡ä»¶åŒ–T2Iç”Ÿæˆ
             - ç¡®ä¿ç”Ÿæˆå›¾åƒå¿ å®åæ˜ æ ‡æ³¨ä¸­çš„ç»„åˆç»†èŠ‚
           - **é€Ÿåº¦**: SDXL-Turboå®ç°å¿«é€Ÿç”Ÿæˆï¼ˆ4-8æ­¥ vs. æ ‡å‡†æ‰©æ•£çš„50+æ­¥ï¼‰
        3. **ç”¨äºåŸŸå¯¹é½çš„é£æ ¼è¿ç§»**:
           - å¯¹åˆæˆå›¾åƒåº”ç”¨**é£æ ¼è¿ç§»**ä»¥åŒ¹é…çœŸå®å›¾åƒåˆ†å¸ƒ
           - å‡å°‘åˆæˆè®­ç»ƒæ•°æ®ä¸çœŸå®æµ‹è¯•å›¾åƒä¹‹é—´çš„åŸŸå·®è·
           - ä½¿ç”¨ç¥ç»é£æ ¼è¿ç§»æˆ–è½»é‡çº§é£æ ¼é€‚é…å™¨
      - **è‡ªé€‚åº”è¾¹è·æŸå¤±**:
        - **é—®é¢˜**: å¯¹æ¯”å­¦ä¹ ä¸­çš„å›ºå®šè¾¹è·å¯¹æ‰€æœ‰è´Ÿæ ·æœ¬ä¸€è§†åŒä»
        - **è§£å†³æ–¹æ¡ˆ**: åŸºäºæ ‡æ³¨ç›¸ä¼¼åº¦çš„**è‡ªé€‚åº”è¾¹è·**
        - **å…¬å¼**: è¾¹è·ä¸æ­£/è´Ÿæ ‡æ³¨é—´æ–‡æœ¬ç›¸ä¼¼åº¦æˆåæ¯”
        - **æ•ˆæœ**ï¼šæ›´éš¾çš„è´Ÿæ ·æœ¬ï¼ˆæ›´ç›¸ä¼¼çš„æ ‡æ³¨ï¼‰è·å¾—æ›´å°è¾¹è· â†’ æ¨¡å‹å­¦ä¹ æ›´ç²¾ç»†çš„åŒºåˆ†
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **SPARCLæ•°æ®é›†**ï¼šå¤§è§„æ¨¡åˆæˆç»„åˆæ•°æ®ï¼ˆæœªæŒ‡å®šç¡®åˆ‡è§„æ¨¡ï¼Œå¯èƒ½10ä¸‡-100ä¸‡å¯¹ï¼‰
      - **æ ‡æ³¨å¯¹**ï¼šæ¯å¼ å›¾åƒå…³è”æ­£æ ‡æ³¨ + å¤šä¸ªè´Ÿå˜ä½“
      - **ç»„åˆç±»åˆ«**ï¼šæ¶µç›–4+ç§ä¸»è¦ç»„åˆæ¨ç†ç±»å‹
  - **è®­ç»ƒç­–ç•¥**ï¼š
      - **é«˜æ•ˆå¾®è°ƒ**ï¼šä½¿ç”¨**LoRAé€‚é…å™¨**è¿›è¡Œå‚æ•°é«˜æ•ˆè®­ç»ƒ
      - **å¯¹æ¯”å­¦ä¹ **ï¼šè®­ç»ƒVLMåŒºåˆ†æ­£/è´Ÿæ ‡æ³¨-å›¾åƒå¯¹
      - **è‡ªé€‚åº”è¾¹è·**ï¼šåŸºäºæ ‡æ³¨ç›¸ä¼¼åº¦åŠ¨æ€è°ƒæ•´è¾¹è·
  - **å®éªŒç»“æœ**ï¼š
      - **ç»„åˆåŸºå‡†**ï¼šåœ¨Winogroundã€AROã€CREPEã€SugarCrepeä¸Šæ˜¾è‘—æå‡
        - **Winoground**ï¼šè¶…è¶ŠCLIPåŸºçº¿+12.3%
        - **AROï¼ˆå±æ€§ç»‘å®šï¼‰**ï¼š+8.7%
        - **SugarCrepeï¼ˆå›°éš¾è´Ÿæ ·æœ¬ï¼‰**ï¼š+10.1%
      - **æ³›åŒ–**ï¼šåœ¨æ ‡å‡†VQAä»»åŠ¡ä¸Šä¿æŒå¼ºæ€§èƒ½ï¼ˆæ— é€€åŒ–ï¼‰
      - **æ•°æ®æ•ˆç‡**ï¼šç”¨ä¸­ç­‰è§„æ¨¡åˆæˆæ•°æ®å–å¾—å¢ç›Šï¼ˆæ— éœ€billionçº§æ•°æ®é›†ï¼‰
  - **å…³é”®å‘ç°**ï¼š
      - **çœŸå®ç‰¹å¾æ³¨å…¥è‡³å…³é‡è¦**ï¼šçº¯T2Iç”Ÿæˆåœ¨ç»†ç²’åº¦ç»„åˆæ§åˆ¶ä¸Šå¤±è´¥
      - **è‡ªé€‚åº”è¾¹è·æœ‰æ•ˆæ€§**ï¼šè¶…è¶Šå›ºå®šè¾¹è·å¯¹æ¯”å­¦ä¹ **+4.2%**
      - **åˆæˆæ•°æ®å……åˆ†æ€§**ï¼šç›®æ ‡åˆæˆæ•°æ®æ¯”æ‰©å¤§çœŸå®æ•°æ®æ›´æœ‰æ•ˆ
  - **å‘å¸ƒæ—¶é—´**ï¼šCVPR 2025 | arXiv 2025å¹´3æœˆ (v2: 2025å¹´3æœˆ)
  - **æœºæ„**ï¼šæœªæ˜ç¡®è¯´æ˜ï¼ˆå­¦æœ¯ç ”ç©¶ï¼‰
  - **å¼€æº**ï¼šâœ… ä»£ç ã€åˆæˆæ•°æ®ã€LoRAé€‚é…å™¨ - è®ºæ–‡ä¸­æä¾›å‘å¸ƒè¯¦æƒ…
  - **é‡è¦æ„ä¹‰**ï¼š
      - **è§£å†³VLMå¼±ç‚¹**ï¼šé’ˆå¯¹å·²çŸ¥çš„ç»„åˆç†è§£å±€é™
      - **é«˜æ•ˆåˆæˆ**ï¼šå¿«é€ŸT2I + LoRAå®ç°å¯æ‰©å±•ã€æˆæœ¬æ•ˆç›Šé«˜çš„æ•°æ®ç”Ÿæˆ
      - **æ–¹æ³•è®ºåˆ›æ–°**ï¼šçœŸå®ç‰¹å¾æ³¨å…¥ + è‡ªé€‚åº”è¾¹è·ä¸ºç»„åˆæ•°æ®åˆæˆæä¾›è“å›¾
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2402.15504">ğŸ“„ Gen4Gen</a></b><br>
<code>arXiv 2402.15504</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2024-red?style=flat-square"/>
</summary>

  - **é‡ç‚¹**ï¼š**å¤šæ¦‚å¿µç»„åˆç”Ÿæˆçš„ç”Ÿæˆå¼æ•°æ®ç®¡é“** - ä½¿ç”¨çº§è”AIåŸºç¡€æ¨¡å‹çš„åŠè‡ªåŠ¨æ•°æ®é›†åˆ›å»ºç®¡é“Gen4Genï¼Œç”¨äºå¤šæ¦‚å¿µä¸ªæ€§åŒ–
  - **æ•°æ®åˆæˆæ–¹æ³•** - **åŠè‡ªåŠ¨å¤šé˜¶æ®µç»„åˆç®¡é“**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šåˆ©ç”¨å›¾åƒå‰æ™¯æå–ã€LLMã€MLLMå’Œå›¾åƒä¿®å¤çš„æœ€æ–°è¿›å±•ï¼Œå°†ä¸ªæ€§åŒ–æ¦‚å¿µç»„åˆæˆå…·æœ‰å¯†é›†å¯¹åº”æ–‡æœ¬æè¿°çš„ç°å®åœºæ™¯
      - **ä¸‰ä¸ªè®¾è®¡åŸåˆ™**ï¼š
        1. **è¯¦ç»†å›¾æ–‡é…å¯¹**ï¼šæ–‡æœ¬å¿…é¡»ä¸å¯¹åº”å›¾åƒè‰¯å¥½å¯¹é½ï¼Œä¸ºå‰æ™¯å’ŒèƒŒæ™¯å¯¹è±¡æä¾›ä¿¡æ¯
        2. **åˆç†çš„å¯¹è±¡å¸ƒå±€å’ŒèƒŒæ™¯ç”Ÿæˆ**ï¼šå¯¹è±¡ä»…åœ¨ç°å®ç”Ÿæ´»ä¸­å¯èƒ½å…±å­˜æ—¶æ‰å…±å­˜ï¼Œä¸”å®ƒä»¬åœ¨å›¾åƒä¸­çš„ä½ç½®åˆç†
        3. **é«˜åˆ†è¾¨ç‡**ï¼šç¡®ä¿æ•°æ®é›†æ»¡è¶³ç”Ÿæˆé«˜è´¨é‡ã€å¤šæ¦‚å¿µä¸ªæ€§åŒ–å›¾åƒçš„æœ€ç»ˆç›®æ ‡
      - **Gen4Genç®¡é“**ï¼ˆä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼‰ï¼š
        1. **å¯¹è±¡å…³è”å’Œå‰æ™¯åˆ†å‰²**ï¼š
           - **è¾“å…¥**ï¼šä¸€ç»„kä¸ªå¯¹è±¡O = {o_i}^kï¼Œå…¶ä¸­æ¯ä¸ªå¯¹è±¡o_iç”±ä¸€ç»„nå¼ å›¾åƒX_oi = {x_j}^nè¡¨ç¤º
           - **æºæ•°æ®**ï¼šDreamBoothã€Custom Diffusionã€åœ¨çº¿ç‰ˆæƒå…è´¹æº
           - **å¯¹è±¡ç»„åˆé€‰æ‹©**ï¼šæ‰¾åˆ°å¯¹è±¡ç»„åˆå­é›†O' = {o_a, o_b, ...}ï¼Œè¿™äº›ç»„åˆç›´è§‚ä¸Šå¯èƒ½å…±å­˜ï¼ˆä¾‹å¦‚ï¼Œç‹—ã€çŒ«ã€å®¤å†…æ¤ç‰©ï¼‰
           - **å‰æ™¯åˆ†å‰²**ï¼šåº”ç”¨DISï¼ˆç±»åˆ«æ— å…³çš„æ˜¾è‘—æ€§å¯¹è±¡æ£€æµ‹å™¨ï¼‰æ¥åˆ†å‰²ç»„åˆO'å†…å¯¹è±¡çš„å‰æ™¯
           - **è¾“å‡º**ï¼šåˆ†å‰²çš„å‰æ™¯å›¾åƒD(X')å’Œå¯¹åº”çš„æ©ç M(D(X'))
        2. **LLMå¼•å¯¼çš„å¯¹è±¡ç»„åˆ**ï¼š
           - **è¾¹ç•Œæ¡†ç”Ÿæˆ**ï¼šåˆ©ç”¨LLMçš„é›¶æ ·æœ¬èƒ½åŠ›ï¼Œè¯¢é—®ChatGPTæä¾›ç»™å®šå¯¹è±¡ç»„åˆO'çš„å¯èƒ½è¾¹ç•Œæ¡†é›†åˆ
           - **åŸºäºæ¨¡æ¿**ï¼šå‘ChatGPTå±•ç¤ºå‡ ä¸ªç¤ºä¾‹ï¼Œè¯´æ˜åœ¨COCOæ•°æ®é›†ä¸­ç»™å®šå¯¹è±¡è¾¹ç•Œæ¡†æä¾›è¾¹ç•Œæ¡†ç‚¹çš„ä»»åŠ¡
           - **å°ºåº¦å¢å¼º**ï¼šåˆ©ç”¨GPT-4è¿›è¡Œé€»è¾‘å¢å¼ºï¼Œè¦æ±‚æ¯ä¸ªè¾¹ç•Œæ¡†çš„å°ºåº¦åˆç†ï¼ˆè§£å†³æŸäº›å¯¹è±¡ä¸ç°å®åœ°æ›´å¤§çš„ç¼©æ”¾é—®é¢˜ï¼‰
           - **ç»„åˆ**ï¼šåœ¨D(X')å†…æŒ‰ç…§è¾¹ç•Œæ¡†ä½ç½®å’Œç»™å®šå¤§å°æ”¾ç½®å„ä¸ªå›¾åƒï¼Œè·å¾—å‰æ™¯å›¾åƒI_fgå’Œæ©ç M(I_fg)
           - **èƒŒæ™¯æç¤ºç”Ÿæˆ**ï¼šé€šè¿‡éªŒè¯ä¸åŒä¸€LLMæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œè·å¾—æè¿°I_fgå¯èƒ½æ”¾ç½®çš„åœºæ™¯çš„æç¤ºé›†åˆP
        3. **èƒŒæ™¯é‡ç»˜å’Œå›¾åƒé‡æ–°æ ‡æ³¨**ï¼š
           - **èƒŒæ™¯æ£€ç´¢**ï¼šä»ç‰ˆæƒå…è´¹æºï¼ˆUnsplashï¼‰æŸ¥æ‰¾èµ·å§‹èƒŒæ™¯å›¾åƒI_bgï¼Œæç¤ºp âˆˆ P
           - **ä¿®å¤**ï¼šä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ä¿®å¤æ¨¡å‹fï¼ˆStable-Diffusion-XLï¼‰é€šè¿‡å°†I_fgåµŒå…¥èƒŒæ™¯å›¾åƒI_bgä¸­æ¥é‡ç»˜I_fg
           - **æ©ç å¹³æ»‘**ï¼šåˆ©ç”¨å¹³æ»‘è½¯æ©ç ï¼ˆåœ¨M(I_fg)ä¸Šä½¿ç”¨5Ã—5çª—å£è¿›è¡Œå¹³å‡å¹³æ»‘ï¼‰ä»¥å¢å¼ºå‰æ™¯å¯¹è±¡ä¸èƒŒæ™¯çš„é›†æˆ
           - **è¾“å‡º**ï¼šæœ€ç»ˆå›¾åƒI_O' = f(I_fg, M(I_fg), I_bg)
           - **é‡æ–°æ ‡æ³¨**ï¼šè¯¢é—®MLLMï¼ˆLLaVA-1.5ï¼‰ä¸ºæ‰€æœ‰ç»„åˆçš„å­é›†æä¾›è¯¦ç»†æè¿°I_O'çš„æ ‡æ³¨ï¼ˆå­—æ•°é™åˆ¶ï¼š30ï¼Œå—CLIPä¸Šä¸‹æ–‡çº¦æŸçš„77ä¸ªä»¤ç‰Œæœ€å¤§å€¼é™åˆ¶ï¼‰
      - **è®­ç»ƒæ—¶æç¤ºå·¥ç¨‹ç­–ç•¥**ï¼š
        - **å…¨å±€ç»„åˆä»¤ç‰Œ**ï¼šå°†DreamBoothæ¦‚å¿µé€‚åº”å¤æ‚ç»„åˆï¼Œä¸ºæ¯ä¸ªå¯¹è±¡å¼•å…¥å…¨å±€ä»¤ç‰Œå’Œå•ç‹¬ä»¤ç‰Œï¼Œä»¥å¢å¼ºæè¿°è¯¦ç»†åœºæ™¯å®‰æ’çš„èƒ½åŠ›
        - **è®­ç»ƒæœŸé—´é‡å¤æ¦‚å¿µä»¤ç‰Œæç¤º**ï¼šé‡‡ç”¨åœ¨è®­ç»ƒæœŸé—´é‡å¤æ¦‚å¿µä»¤ç‰Œæç¤ºçš„ç­–ç•¥ï¼Œé¼“åŠ±æ¨¡å‹ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¸­æ¯ä¸ªæŒ‡å®šæ¦‚å¿µçš„å­˜åœ¨
        - **åˆå¹¶èƒŒæ™¯æç¤º**ï¼šç¡®ä¿èƒŒæ™¯åœ¨è®­ç»ƒæç¤ºä¸­è¯´æ˜ï¼Œä»¥åˆ†ç¦»èƒŒæ™¯å’Œæ¦‚å¿µç»„åˆ
      - **å…³é”®æŠ€æœ¯**ï¼š
        - **DISåˆ†å‰²**ï¼šç±»åˆ«æ— å…³çš„æ˜¾è‘—æ€§å¯¹è±¡æ£€æµ‹å™¨ï¼Œå¯¹ä½¿ç”¨çš„å¯¹è±¡é›†åˆä¸å¯çŸ¥
        - **LLMå¼•å¯¼ç»„åˆ**ï¼šåˆ©ç”¨LLMçš„é›¶æ ·æœ¬èƒ½åŠ›å®ç°åˆç†çš„å¯¹è±¡å¸ƒå±€
        - **å°ºåº¦å¢å¼º**ï¼šGPT-4é€»è¾‘å¢å¼ºç¡®ä¿åˆç†çš„å¯¹è±¡æ¯”ä¾‹
        - **æ‰©æ•£ä¿®å¤**ï¼šStable-Diffusion-XLç”¨äºé«˜è´¨é‡èƒŒæ™¯é›†æˆ
        - **MLLMé‡æ–°æ ‡æ³¨**ï¼šLLaVA-1.5ç”¨äºè¯¦ç»†æ ‡æ³¨ç”Ÿæˆï¼Œä¿æŒå¯¹é½
      - **MyCanvasæ•°æ®é›†**ï¼š
        - **è§„æ¨¡**ï¼š150ä¸ªå¯¹è±¡ï¼ˆæœ‰äº›ä¸ºå•å›¾åƒï¼Œæœ‰äº›ä¸ºå¤šå›¾åƒï¼‰ï¼Œ41ä¸ªå¯èƒ½ç»„åˆï¼Œè¶…è¿‡10Kå›¾åƒæ‰‹åŠ¨è¿‡æ»¤è‡³**2,684å¼ **æœ€ä½³è´¨é‡å›¾åƒ
        - **æ ‡æ³¨ç»Ÿè®¡**ï¼šå¹³å‡è¯é•¿17.7ï¼Œçº¦30%çš„é•¿åº¦è¶…è¿‡20ä¸ªè¯
        - **å¯¹è±¡å¤šæ ·æ€§**ï¼šå¹¿æ³›çš„å¯¹è±¡èŒƒå›´ï¼Œè¶…è¶ŠCustomConcept101å’ŒDreamBoothæ•°æ®é›†
        - **é‡æ–°æ ‡æ³¨è¦†ç›–**ï¼šåº”ç”¨äºMyCanvasæ•°æ®é›†ä¸­çš„10ä¸ªå¯¹è±¡ç»„åˆO'
      - **å…¨é¢è¯„ä¼°æŒ‡æ ‡**ï¼š
        - **CP-CLIPï¼ˆç»„åˆ-ä¸ªæ€§åŒ–-CLIPï¼‰**ï¼šè¯„ä¼°ç»„åˆå’Œä¸ªæ€§åŒ–çš„å‡†ç¡®æ€§
          - **ç»„åˆå‡†ç¡®æ€§**ï¼šæ–‡æœ¬ä¸­æåˆ°çš„æ¯ä¸ªä¸ªæ€§åŒ–æ¦‚å¿µæ˜¯å¦åœ¨å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­åæ˜ ï¼Ÿ
          - **ä¿çœŸåº¦**ï¼šç”Ÿæˆçš„ä¸ªæ€§åŒ–æ¦‚å¿µæ˜¯å¦ä¸å…¶æºå¯¹åº”ç‰©ç›¸ä¼¼ï¼Ÿ
        - **TI-CLIPï¼ˆæ–‡æœ¬-å›¾åƒå¯¹é½CLIPï¼‰**ï¼šé€šè¿‡è¯„ä¼°æ¨¡å‹åœ¨å„ç§æ–‡æœ¬èƒŒæ™¯ä¸‹çš„æ³›åŒ–è´¨é‡ï¼Œä½œä¸ºæ½œåœ¨è¿‡æ‹Ÿåˆçš„æŒ‡æ ‡
      - **å®éªŒç»“æœ**ï¼š
        - **å¤šæ¦‚å¿µä¸ªæ€§åŒ–**ï¼šä½¿ç”¨å¢å¼ºæ•°æ®é›†ï¼ˆMyCanvasï¼‰å’Œæç¤ºç­–ç•¥çš„å…ˆå‰æ–¹æ³•ï¼ˆCustom Diffusionï¼‰å¯ä»¥åœ¨ç”Ÿæˆå…·æœ‰ä¸åŒèƒŒæ™¯çš„ç°å®å¤šæ¦‚å¿µå›¾åƒçš„åŒæ—¶ä¿æŒä¸ªæ€§åŒ–æ¦‚å¿µçš„èº«ä»½ï¼Œè·å¾—æ˜¾è‘—æ”¹è¿›
        - **æ”¹è¿›**ï¼šåœ¨éå¸¸å¤æ‚çš„ç»„åˆã€å…·æœ‰æŒ‘æˆ˜æ€§çš„å¼•å¯¼ï¼ˆç›¸å¯¹ä½ç½®ï¼‰å’Œå¤šä¸ªè¯­ä¹‰ç›¸ä¼¼æ¦‚å¿µï¼ˆä¾‹å¦‚ï¼ŒåŒä¸€å›¾åƒä¸­çš„ä¸¤ä¸ªç‹—èº«ä»½ï¼‰ä¸‹æ›´åŠ æ˜æ˜¾
        - **åŸºçº¿**ï¼šåœ¨Custom DiffusionåŸºç¡€ä¸Šæ„å»ºçš„ç®€å•åŸºçº¿ï¼Œå…·æœ‰ç»éªŒæç¤ºç­–ç•¥ï¼Œä¾›æœªæ¥ç ”ç©¶äººå‘˜åœ¨MyCanvasä¸Šè¯„ä¼°
  - **å‘å¸ƒæ—¶é—´**ï¼šCVPR 2024 | arXiv 2024å¹´2æœˆ
  - **æœºæ„**ï¼šåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€ç‰›æ´¥å¤§å­¦ã€å“ˆä½›å¤§å­¦ã€CMUã€é¦™æ¸¯å¤§å­¦ã€åŠ å·å¤§å­¦æˆ´ç»´æ–¯åˆ†æ ¡
  - **å¼€æº**ï¼šâœ… [é¡¹ç›®ç½‘ç«™](https://danielchyeh.github.io/Gen4Gen/) | [GitHub](https://github.com/danielchyeh/Gen4Gen) - ä»£ç ã€MyCanvasæ•°æ®é›†ï¼ˆ2,684å¼ å›¾åƒï¼‰ã€åŸºå‡†æµ‹è¯•æŒ‡æ ‡
  - **é‡è¦æ„ä¹‰**ï¼š
      - **æ•´åˆAIåŸºç¡€æ¨¡å‹**ï¼šåŠè‡ªåŠ¨æ•°æ®é›†åˆ›å»ºç®¡é“å¼•å…¥äº†ä½¿ç”¨çº§è”AIåŸºç¡€æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ•°æ®é›†çš„å¯èƒ½æ€§
      - **æ•°æ®é›†è´¨é‡é‡è¦**ï¼šæ¦‚å¿µéªŒè¯MyCanvasæ•°æ®é›†åæ˜ äº†ç®€å•ç»„åˆè‰¯å¥½å¯¹é½çš„å›¾åƒå’Œæ–‡æœ¬æè¿°å¯¹å°†æ˜¾è‘—æ”¹å–„å¤šæ¦‚å¿µä¸ªæ€§åŒ–ä»»åŠ¡
      - **å¤šæ¦‚å¿µä¸ªæ€§åŒ–åŸºå‡†**ï¼šå…¨é¢è¯„ä¼°åŸºå‡†è€ƒè™‘äº†å¤šæ¦‚å¿µä¸ªæ€§åŒ–ä»»åŠ¡ä¸­çš„ä¸ªæ€§åŒ–å‡†ç¡®æ€§ã€ç»„åˆæ­£ç¡®æ€§å’Œæ–‡æœ¬-å›¾åƒå¯¹é½
      - **é“¾æ¥åŸºç¡€æ¨¡å‹**ï¼šè¯æ˜é“¾æ¥å¼ºå¤§çš„åŸºç¡€æ¨¡å‹å¯èƒ½æ˜¯é’ˆå¯¹å„ç§æŒ‘æˆ˜æ€§ä»»åŠ¡ç”Ÿæˆé«˜è´¨é‡æ•°æ®é›†çš„æœ‰å‰æ™¯æ–¹å‘
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.01720">ğŸ“„ SynCD</a></b><br>
<code>arXiv 2502.01720</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2025-red?style=flat-square"/>
</summary>

  - **é‡ç‚¹**ï¼š**ç”Ÿæˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒå®šåˆ¶çš„å¤šå›¾åƒåˆæˆæ•°æ®** - é€šè¿‡åˆ›å»ºåˆæˆå®šåˆ¶æ•°æ®é›†ï¼ˆSynCDï¼‰æ¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒå®šåˆ¶æŒ‘æˆ˜çš„ç®€å•æ–¹æ³•ï¼Œè¯¥æ•°æ®é›†åŒ…å«åŒä¸€å¯¹è±¡åœ¨ä¸åŒå…‰ç…§ã€å§¿æ€å’ŒèƒŒæ™¯ä¸‹çš„å¤šå¼ å›¾åƒ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **æ©ç å…±äº«æ³¨æ„åŠ› + 3Dä¸€è‡´æ€§ + æ•°æ®é›†è¿‡æ»¤**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šåˆ©ç”¨ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œ3Dèµ„äº§åˆ›å»ºé«˜è´¨é‡åˆæˆæ•°æ®é›†ï¼ŒåŒ…å«åŒä¸€å¯¹è±¡åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„å¤šå¼ å›¾åƒï¼Œåœ¨ç”Ÿæˆå…·æœ‰ä¸åŒä¸Šä¸‹æ–‡çš„å¤šå¼ å›¾åƒæ—¶ä¿æŒå¯¹è±¡èº«ä»½
      - **SynCDæ•°æ®é›†ç”Ÿæˆç®¡é“**ï¼ˆä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼‰ï¼š
        1. **LLMè¾…åŠ©æç¤ºç”Ÿæˆ**ï¼š
           - **å¯¹è±¡æè¿°**ï¼šè®¾è®¡æ¯ä¸ªæç¤ºä»¥åŒ…å«å¯¹è±¡å’ŒèƒŒæ™¯çš„è¯¦ç»†æè¿°
           - **åˆšä½“å¯¹è±¡**ï¼šä½¿ç”¨Cap3Dæè¿°Objaverseèµ„äº§ï¼ˆä¾‹å¦‚ï¼Œ"å¸¦è“è‰²å’Œç²‰è‰²æ¡çº¹çš„å¤§é‡‘å±é¼“"ï¼‰
           - **å¯å˜å½¢å¯¹è±¡**ï¼šæŒ‡ç¤ºLLMç”Ÿæˆæè¿°æ€§æ ‡æ³¨ï¼ˆä¾‹å¦‚ï¼Œ"ä¿„ç½—æ–¯è“çŒ«æœ‰åšå®ã€è“¬æ¾çš„è¢«æ¯›ï¼Œå‘ˆé’¢è“è‰²ï¼Œå¸¦æœ‰ç»¿çœ¼ç›"ï¼‰
           - **èƒŒæ™¯æç¤ºç”Ÿæˆ**ï¼šæŒ‡ç¤ºLLMï¼ˆæŒ‡ä»¤è°ƒä¼˜çš„Llama3ï¼‰åŸºäºå¯¹è±¡æè¿°ç”Ÿæˆåˆç†çš„èƒŒæ™¯åœºæ™¯æè¿°
           - **ç»„åˆ**ï¼šå°†ä¸€ä¸ªå¯¹è±¡æè¿°ä¸å¤šä¸ªèƒŒæ™¯æè¿°ç»„åˆå¹¶è¾“å…¥å›¾åƒç”Ÿæˆæ­¥éª¤
        2. **å¤šå›¾åƒä¸€è‡´å¯¹è±¡ç”Ÿæˆ**ï¼š
           - **åŸºç¡€æ¨¡å‹**ï¼šä½¿ç”¨åŸºäºDiTçš„FLUXæ¨¡å‹ç”Ÿæˆå…·æœ‰ä¸€è‡´å¯¹è±¡çš„å›¾åƒ
           - **æ©ç å…±äº«æ³¨æ„åŠ›ï¼ˆMSAï¼‰æœºåˆ¶**ï¼š
             - **æ–¹æ³•**ï¼šä¿®æ”¹æ‰©æ•£æ¨¡å‹çš„æ³¨æ„åŠ›å—ï¼Œä½¿å¾—æ¯ä¸ªå›¾åƒå…³æ³¨è‡ªèº«ä»¥åŠå…¶ä»–å›¾åƒçš„å‰æ™¯å¯¹è±¡åŒºåŸŸ
             - **å…¬å¼**ï¼šMSA({q_i, k_i, v_i}^N) â‰¡ Softmax(q_i [k_1 ... k_N]^T / âˆšd' + M_i) [v_1 ... v_N]
             - **æ©ç M_i**ï¼šåˆå§‹åŒ–ä½¿å¾—ä¸€ä¸ªå›¾åƒçš„æ–‡æœ¬ä»¤ç‰Œä¸å…³æ³¨å…¶ä»–å›¾åƒä»¤ç‰Œï¼Œä¸”ç¬¬iä¸ªå›¾åƒç‰¹å¾ä»…å…³æ³¨å…¶ä»–å›¾åƒçš„å¯¹è±¡åŒºåŸŸï¼Œå¿½ç•¥å…¶èƒŒæ™¯
             - **æ•ˆæœ**ï¼šèƒ½å¤Ÿåœ¨æ‰€æœ‰å›¾åƒä¸­ç”Ÿæˆå…·æœ‰ç›¸ä¼¼è§†è§‰ç‰¹å¾çš„å¯¹è±¡
           - **å…·æœ‰3Dä¸€è‡´æ€§çš„åˆšä½“å¯¹è±¡ç”Ÿæˆ**ï¼š
             - **æ·±åº¦å¼•å¯¼**ï¼šå¯¹äºå…·æœ‰å¯ç”¨3Dæ•°æ®é›†ï¼ˆObjaverseï¼‰çš„åˆšä½“å¯¹è±¡ï¼Œä»Nä¸ªä¸åŒç›¸æœºå§¿æ€æ¸²æŸ“èµ„äº§ï¼Œå¹¶å°†æ¸²æŸ“çš„æ·±åº¦å›¾å’Œæ ‡æ³¨è¾“å…¥æ·±åº¦æ¡ä»¶FLUXæ¨¡å‹
             - **æ·±åº¦å¼•å¯¼**ï¼šç¡®ä¿å¯¹è±¡è·¨å›¾åƒçš„3Då½¢çŠ¶ä¸€è‡´æ€§
             - **ç‰¹å¾å˜å½¢**ï¼šå¯¹äºç”Ÿæˆå…·æœ‰åŒä¸€å¯¹è±¡çš„ä¸¤å¼ å›¾åƒçš„ä»£è¡¨æ€§ç¤ºä¾‹ï¼Œç»™å®šæ½œåœ¨ç‰¹å¾f_i âˆˆ R^(hÃ—w)Ã—d, i âˆˆ {1,2}ï¼Œå˜å½¢è®¡ç®—ä¸ºï¼š
               - fÌ‚_2(u,v) = Î± f_1(u+Î”u, v+Î”v) + (1-Î±) f_2(u,v)
               - å…¶ä¸­(u+Î”u, v+Î”v)è¡¨ç¤ºç¬¬ä¸€å¼ å›¾åƒä¸­çš„å¯¹åº”ä½ç½®ï¼ŒÎ±æ˜¯äºŒè¿›åˆ¶æ ‡é‡ï¼Œè¡¨ç¤ºè¯¥ä½ç½®åœ¨ç¬¬ä¸€å¼ å›¾åƒä¸­æ˜¯å¦å¯è§
             - **åº”ç”¨**ï¼šå¯¹æ‰€æœ‰å¯¹åº”ç”¨å˜å½¢ï¼Œä½¿ç”¨é€‚å½“çš„æ©ç ï¼Œä»…åœ¨æ—©æœŸæ‰©æ•£æ—¶é—´æ­¥æœŸé—´åº”ç”¨
             - **æ•ˆæœ**ï¼šåœ¨ä¸å¼•å…¥å˜å½¢ä¼ªå½±çš„æƒ…å†µä¸‹å¢åŠ å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œå¹¶å…è®¸å…‰ç…§å˜åŒ–çš„çµæ´»æ€§
        3. **æ•°æ®é›†è¿‡æ»¤**ï¼š
           - **ç¾å­¦åˆ†æ•°è¿‡æ»¤**ï¼šæ‹’ç»ç¾å­¦åˆ†æ•°ä½äº6çš„å›¾åƒ
           - **å¯¹è±¡èº«ä»½ç›¸ä¼¼æ€§**ï¼šä½¿ç”¨DINOv2æµ‹é‡å¯¹è±¡èº«ä»½ç›¸ä¼¼æ€§ï¼Œç§»é™¤å…¶é›†åˆå†…å¹³å‡æˆå¯¹ç‰¹å¾ç›¸ä¼¼æ€§ä½äº0.7çš„å›¾åƒ
           - **æœ€ç»ˆæ•°æ®é›†**ï¼šåŒ…å«çº¦95,000ä¸ªå¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡2-3å¼ å›¾åƒï¼Œåœ¨åˆšä½“å’Œå¯å˜å½¢ç±»åˆ«ä¹‹é—´å‡åŒ€åˆ†å¸ƒ
      - **åŸºäºç¼–ç å™¨çš„æ¨¡å‹è®­ç»ƒ**ï¼š
        - **æ¶æ„**ï¼šä½¿ç”¨SynCDæ•°æ®é›†å¾®è°ƒç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æˆ–åŸºäºæµçš„æ¨¡å‹
        - **è®­ç»ƒè®¾ç½®**ï¼šç»™å®šå¯¹è±¡çš„Nå¼ å›¾åƒï¼Œå°†ä¸€å¼ è§†ä¸ºç›®æ ‡ï¼Œå…¶ä½™è§†ä¸ºå‚è€ƒ
        - **å…±äº«æ³¨æ„åŠ›æœºåˆ¶**ï¼šä¸ºäº†åœ¨çœŸå®å‚è€ƒå›¾åƒä¸Šæ¡ä»¶åŒ–ç”Ÿæˆï¼Œé‡‡ç”¨ä¸æ•°æ®é›†ç”Ÿæˆç®¡é“ç±»ä¼¼çš„å…±äº«æ³¨æ„åŠ›
          - åœ¨æ¯ä¸ªæ³¨æ„åŠ›å—ä¸­æ²¿åºåˆ—ç»´åº¦å°†å‚è€ƒå›¾åƒç‰¹å¾ä¸ç›®æ ‡å›¾åƒç‰¹å¾è¿æ¥
          - ç›®æ ‡å›¾åƒçš„æŸ¥è¯¢ç‰¹å¾éšåé€šè¿‡å…³æ³¨è‡ªèº«å’Œå‚è€ƒå›¾åƒçš„ç‰¹å¾æ¥æ›´æ–°
        - **è®­ç»ƒç›®æ ‡**ï¼šåˆ†åˆ«å¯¹æ‰©æ•£å’ŒåŸºäºæµçš„æ¨¡å‹é‡‡ç”¨é€Ÿåº¦æˆ–æµé¢„æµ‹ç›®æ ‡
      - **æ¨ç†æ–¹æ³•**ï¼š
        - **å½’ä¸€åŒ–å¼•å¯¼å‘é‡**ï¼šä½¿ç”¨å…ˆå‰å·¥ä½œç›´æ¥ç»„åˆæ–‡æœ¬å’Œå›¾åƒå¼•å¯¼é€šå¸¸ä¼šå¯¼è‡´ç”Ÿæˆå›¾åƒä¸­çš„è¿‡åº¦æ›å…‰é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é«˜å›¾åƒå¼•å¯¼æ—¶
        - **æå‡ºçš„è§£å†³æ–¹æ¡ˆ**ï¼šå½’ä¸€åŒ–å›¾åƒå’Œæ–‡æœ¬å¼•å¯¼å‘é‡
          - å…¬å¼: Îµ_Î¸(x_t, {x_i}^K, âˆ…) + Î»_I ||g||/||g_I|| Â· g_I + Î»_c ||g||/||g_c|| Â· g_c
          - å…¶ä¸­g_I = Îµ_Î¸(x_t, {x_i}^K, âˆ…) - Îµ_Î¸(x_t, âˆ…, âˆ…), g_c = Îµ_Î¸(x_t, {x_i}^K, c) - Îµ_Î¸(x_t, {x_i}^K, âˆ…), ||g|| = min(||g_I||, ||g_c||)
        - **æ•ˆæœ**ï¼šæœ‰åŠ©äºåœ¨ä»éµå¾ªæ–‡æœ¬æç¤ºçš„åŒæ—¶å®ç°ä¸å‚è€ƒå¯¹è±¡çš„æ›´å¥½å›¾åƒå¯¹é½
        - **çµæ´»æ€§**ï¼šå‚è€ƒå›¾åƒçš„æ•°é‡å¯ä»¥ä»è®­ç»ƒä¸­å˜åŒ–ï¼Œå› ä¸ºåŸºäºæ³¨æ„åŠ›çš„æ¡ä»¶åŒ–å¯¹åºåˆ—é•¿åº¦ä¸å¯çŸ¥
      - **å…³é”®æŠ€æœ¯**ï¼š
        - **æ©ç å…±äº«æ³¨æ„åŠ›**ï¼šèƒ½å¤Ÿåœ¨å¤šå¼ å›¾åƒä¸­ç”Ÿæˆä¸€è‡´çš„å¯¹è±¡
        - **åˆšä½“å¯¹è±¡çš„3Dä¸€è‡´æ€§**ï¼šæ·±åº¦å¼•å¯¼å’Œç‰¹å¾å˜å½¢ç¡®ä¿å¤šè§†å›¾ä¸€è‡´æ€§
        - **è®­ç»ƒä¸­çš„å…±äº«æ³¨æ„åŠ›**ï¼šå…è®¸æ¨¡å‹ä»å¤šä¸ªå‚è€ƒå›¾åƒä¸­å­¦ä¹ 
        - **å½’ä¸€åŒ–å¼•å¯¼æ¨ç†**ï¼šåœ¨ä¿æŒæ–‡æœ¬å’Œå›¾åƒå¯¹é½çš„åŒæ—¶ç¼“è§£è¿‡åº¦æ›å…‰é—®é¢˜
      - **æ•°æ®è§„æ¨¡**ï¼š
        - **SynCDæ•°æ®é›†**ï¼šçº¦95,000ä¸ªå¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡2-3å¼ å›¾åƒ
          - **åˆšä½“å¯¹è±¡**ï¼šæ¥è‡ªObjaverseçš„75,000ä¸ªåˆšä½“ç±»åˆ«èµ„äº§
          - **å¯å˜å½¢å¯¹è±¡**ï¼š16ä¸ªå¯å˜å½¢åŠ¨ç‰©è¶…ç±»åˆ«ï¼Œçº¦100ä¸ªä¸åŒäºšç§
        - **å‡åŒ€åˆ†å¸ƒ**ï¼šåœ¨åˆšä½“å’Œå¯å˜å½¢ç±»åˆ«ä¹‹é—´å‡åŒ€åˆ†å¸ƒ
      - **å®éªŒç»“æœ**ï¼š
        - **å®šé‡æ¯”è¾ƒ**ï¼ˆ3ä¸ªè¾“å…¥å‚è€ƒå›¾åƒï¼‰ï¼š
          - **Ours(1B)**ï¼šMDINOv2-I 0.806, CLIPScore 0.773, TIFA 0.303, GeometricScore 0.801
          - **Ours(3B)**ï¼šMDINOv2-I 0.822, CLIPScore 0.789, TIFA 0.313, GeometricScore 0.838
          - **Ours(12B)**ï¼šMDINOv2-I 0.778, CLIPScore 0.771, TIFA 0.306, GeometricScore 0.780
          - æ‰€æœ‰å˜ä½“åœ¨æ€»ä½“GeometricScoreæŒ‡æ ‡ä¸Šéƒ½ä¼˜äºæˆ–ä¸å…¶ä»–åŸºçº¿ç›¸å½“
        - **äººå·¥è¯„ä¼°**ï¼š
          - **Ours(1B) vs JeDi**ï¼š69.51%æ–‡æœ¬å¯¹é½ï¼Œ63.05%å›¾åƒå¯¹é½ï¼Œ80.89%ç…§ç‰‡çœŸå®æ„Ÿï¼Œ68.19%æ€»ä½“åå¥½
          - **Ours(3B) vs Emu-2**ï¼š70.49%æ–‡æœ¬å¯¹é½ï¼Œ66.88%å›¾åƒå¯¹é½ï¼Œ64.66%ç…§ç‰‡çœŸå®æ„Ÿï¼Œ66.74%æ€»ä½“åå¥½
          - **Ours(12B) vs OminiControl**ï¼š56.27%æ–‡æœ¬å¯¹é½ï¼Œ58.30%å›¾åƒå¯¹é½ï¼Œ54.47%ç…§ç‰‡çœŸå®æ„Ÿï¼Œ58.02%æ€»ä½“åå¥½
        - **æ¶ˆèç ”ç©¶**ï¼š
          - **SynCDæ•°æ®é›†è´¡çŒ®**ï¼šä»…ä½¿ç”¨SynCDæ•°æ®é›†è¿›è¡Œå¾®è°ƒå·²ç»æ”¹å–„äº†æ€§èƒ½
          - **å…±äº«æ³¨æ„åŠ›æœ‰æ•ˆæ€§**ï¼šé€šè¿‡å…±äº«æ³¨æ„åŠ›æ·»åŠ å‚è€ƒæ¡ä»¶è¿›ä¸€æ­¥æå‡äº†æ€§èƒ½
          - **å¤šä¸ªå‚è€ƒå›¾åƒ**ï¼šå…è®¸åœ¨æ¨ç†æœŸé—´ä½¿ç”¨å¤šä¸ªå‚è€ƒå›¾åƒï¼Œéšç€å‚è€ƒå›¾åƒæ•°é‡å¢åŠ åˆ°ä¸‰ä¸ªï¼Œæ€§èƒ½å¾—åˆ°æ”¹å–„
          - **å½’ä¸€åŒ–å¼•å¯¼**ï¼šåœ¨ç¼“è§£è¿‡åº¦æ›å…‰é—®é¢˜æ–¹é¢ä¼˜äºå¼•å¯¼é‡æ–°ç¼©æ”¾
      - **æ¨¡å‹å˜ä½“**ï¼š
        - **Ours(12B)**ï¼šå¾®è°ƒFLUXæ¨¡å‹ï¼Œä»…ä½¿ç”¨LoRAå¾®è°ƒæ³¨æ„åŠ›å±‚
        - **Ours(1B/3B)**ï¼šä½¿ç”¨IP-Adapteråˆå§‹åŒ–çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œåœ¨è‡ªæ³¨æ„åŠ›å—å’Œå›¾åƒäº¤å‰æ³¨æ„åŠ›å±‚ä¸­çš„é”®å€¼æŠ•å½±çŸ©é˜µä¸­å¾®è°ƒLoRAå±‚
      - **å‘å¸ƒæ—¶é—´**ï¼šCVPR 2025 | arXiv 2025å¹´2æœˆ
  - **æœºæ„**ï¼šå¡å†…åŸºæ¢…éš†å¤§å­¦ã€Meta
  - **å¼€æº**ï¼šâœ… ä»£ç å’Œæ•°æ®å¯åœ¨é¡¹ç›®ç½‘ç«™è·å–
  - **é‡è¦æ„ä¹‰**ï¼š
      - **è§£å†³æ•°æ®çŸ­ç¼º**ï¼šé€šè¿‡å†…éƒ¨ç‰¹å¾å…±äº«å’Œå¤–éƒ¨3Då¼•å¯¼åˆ›å»ºæ­¤ç±»æ•°æ®é›†æ¯”æ”¶é›†å…·æœ‰åŒä¸€å¯¹è±¡çš„å¤šä¸ªå›¾åƒçš„çœŸå®ä¸–ç•Œæ•°æ®æ›´å…·å¯æ‰©å±•æ€§
      - **æˆæœ¬æ•ˆç›Šå®šåˆ¶**ï¼šä½¿ç”¨å†…éƒ¨ç‰¹å¾å…±äº«å’Œå¤–éƒ¨3Då¼•å¯¼ç”Ÿæˆä¸€è‡´çš„å¯¹è±¡èº«ä»½ï¼Œæ¯”ä½¿ç”¨çœŸå®å›¾åƒè¿›è¡Œæ¨¡å‹å®šåˆ¶ä»»åŠ¡æ›´æ˜“å¤„ç†
      - **å¤šå›¾åƒç›‘ç£**ï¼šåœ¨å…·æœ‰å…±äº«æ³¨æ„åŠ›çš„å¤šå›¾åƒæ•°æ®é›†ä¸Šè®­ç»ƒåŸºäºç¼–ç å™¨çš„æ¨¡å‹æ”¹å–„äº†å®šåˆ¶è´¨é‡
      - **æ¨ç†åˆ›æ–°**ï¼šå½’ä¸€åŒ–å¼•å¯¼å‘é‡æœ‰åŠ©äºåœ¨éµå¾ªæ–‡æœ¬æç¤ºçš„åŒæ—¶å®ç°æ›´å¥½çš„å›¾åƒå¯¹é½
  

</details>
---

### ğŸ§ª äº¤é”™å›¾æ–‡Â·è¿è´¯æ€§ä¸ä¸€è‡´æ€§

This category focuses on **high-quality interleaved image-text data construction** with emphasis on **coherence (logical flow), consistency (factual accuracy), and alignment (image-text relevance)**. Unlike simple image-text pairs, these methods curate or synthesize multi-image documents with narrative coherence, making them suitable for training models on long-context multimodal understanding and generation.

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2506.09427">ğŸ“„ InterSyn</a></b><br>
<code>arXiv 2506.09427</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **äº¤é”™å›¾æ–‡ç”Ÿæˆæ•°æ®é›†ä¸è¯„ä¼°** - é¦–ä¸ªå…¨è‡ªåŠ¨ã€å¤§è§„æ¨¡ã€å¤šè½®æŒ‡ä»¤è·Ÿéšçš„äº¤é”™å›¾æ–‡é—®ç­”æ•°æ®é›†ï¼Œé…å¥—ä¸“ç”¨è¯„ä¼°æ¨¡å‹SynJudge
  - **æ•°æ®åˆæˆæ–¹æ³•** - **SEIR (Self-Evaluation with Iterative Refinement)**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä¸‰é˜¶æ®µè¿­ä»£refinement pipelineï¼ŒåµŒå…¥è‡ªæˆ‘æ£€æŸ¥å’Œåé¦ˆå¾ªç¯ï¼Œç¡®ä¿è¯­ä¹‰å®Œæ•´æ€§ã€è·¨æ¨¡æ€ååŒå’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§
      - **å‡†å¤‡é˜¶æ®µ**ï¼ˆ5ä¸ªæ­¥éª¤ï¼‰:
        1. **é—®é¢˜æ”¶é›†**: 25åå‚ä¸è€…å„æä¾›40ä¸ªè‡ªç„¶å¯¹è¯åœºæ™¯é—®é¢˜ï¼ˆå…±1000ä¸ªï¼‰
        2. **é—®é¢˜ç­›é€‰ä¸åŸºå‡†**: LLM+ä¸“å®¶å®¡æ ¸ï¼Œç­›é€‰500ä¸ªé«˜è´¨é‡é—®é¢˜æ„å»ºbenchmark
        3. **é—®é¢˜æ¨¡æ¿æå–**: ä»é«˜è´¨é‡é—®é¢˜ä¸­æå–é€šç”¨åŒ–æ¨¡æ¿
        4. **åŸºç¡€ä¸»é¢˜å±‚çº§**: AIè¾…åŠ©ä¸»é¢˜æå–+äººå·¥ç»„ç»‡ï¼Œæ„å»ºé€»è¾‘æ¸…æ™°çš„ä¸»é¢˜å±‚çº§
        5. **ä¸»é¢˜å±‚çº§æ‰©å±•**: AIå»ºè®®+ä¸“å®¶ç­–åˆ’ï¼Œæ‰©å±•è‡³8ä¸ªåŸŸã€65ä¸ªç±»åˆ«ã€3500ä¸ªç»†ç²’åº¦ä¸»é¢˜
      - **SEIRä¸‰é˜¶æ®µRefinement**ï¼ˆæ¯ä¸ªå¯¹è¯è½®æ¬¡æ‰§è¡Œï¼ŒK=3æ¬¡è¿­ä»£ï¼‰:
        - **Stage 1: Question Refinement (QR)**:
          - åˆå§‹åŒ–: ä»æ¨¡æ¿Ï„å’Œä¸»é¢˜zç”Ÿæˆåˆå§‹é—®é¢˜qâ‚€
          - è¿­ä»£refinement: LLMç”Ÿæˆrefinementå»ºè®® â†’ æ ¹æ®å»ºè®®ä¼˜åŒ–é—®é¢˜
          - æ•ˆæœ: 3è½®è¿­ä»£åè´¨é‡æå‡**32%**
        - **Stage 2: Answer Refinement (AR)**:
          - åˆå§‹åŒ–: ç”Ÿæˆåˆå§‹ç­”æ¡ˆaâ‚€å’Œä¸´æ—¶caption Î³â‚€
          - è¿­ä»£refinement: LLMè¯„ä¼°ç­”æ¡ˆå’Œcaption â†’ ç”Ÿæˆå»ºè®® â†’ ä¼˜åŒ–
          - æ•ˆæœ: TCC **+15%**, ICC **+11%**, ITS **+19%**
        - **Stage 3: Image Refinement (IR)**:
          - ä½¿ç”¨ä¸´æ—¶captionç”Ÿæˆåˆå§‹å›¾åƒ â†’ VLMè¯„ä¼° â†’ ä¼˜åŒ–caption â†’ é‡æ–°ç”Ÿæˆå›¾åƒ
          - æ•ˆæœ: è¿›ä¸€æ­¥æå‡ICCå’ŒITS
      - **å…³é”®æŠ€æœ¯**:
        - **é©¬å°”å¯å¤«æ€§è´¨**: æ¯æ¬¡è¿­ä»£ä»…ä¾èµ–å‰ä¸€çŠ¶æ€
        - **è·¨è½®è¿è´¯æ€§**: é€šè¿‡å†å²ä¸Šä¸‹æ–‡Hç»´æŠ¤ä¸»é¢˜ä¸€è‡´æ€§
        - **å¤šæ¨¡å‹ç»„åˆ**: Qwen/InternLM/GPT + QwenVL/InternVL/LLaVA + FLUX
  - **SynJudgeè¯„ä¼°æ¨¡å‹**:
      - **è®­ç»ƒæ•°æ®**: 38,400äººå·¥æ ‡æ³¨æ ·æœ¬
      - **åŸºåº§æ¨¡å‹**: QwenVL2.5 / InternVL2.5
      - **å››ç»´è¯„ä¼°**:
        1. **TCC (Text Content Completeness)**: æ–‡æœ¬å†…å®¹å®Œæ•´æ€§
        2. **ICC (Image Content Completeness)**: å›¾åƒå†…å®¹å®Œæ•´æ€§
        3. **IQ (Image Quality)**: å›¾åƒè´¨é‡
        4. **ITS (Image-Text Synergy)**: å›¾æ–‡ååŒæ€§ï¼ˆå¥–åŠ±äº’è¡¥å¯¹é½ï¼Œæƒ©ç½šå†—ä½™ï¼‰
      - **vs. äººå·¥è¯„ä¼°**: RMSEä»…5%åå·®ï¼ˆvs. å…¶ä»–æ¨¡å‹çš„13%ï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **InterSyn**: 1.8Må•è½®æ ·æœ¬ + 50Kå¤šè½®å¯¹è¯
      - **Benchmark**: 500ä¸ªé«˜è´¨é‡é—®é¢˜
      - **ä¸»é¢˜è¦†ç›–**: 8ä¸ªåŸŸã€65ä¸ªç±»åˆ«ã€3500ä¸ªç»†ç²’åº¦ä¸»é¢˜
  - **å®éªŒç»“æœ** - **æ¨¡å‹å¾®è°ƒæ˜¾è‘—æå‡**:
      - **Anoleå¾®è°ƒ** (50K InterSyn): TCC +14%, ICC +7.6%, IQ +6.2%, ITS **+30%**
      - **VILA-Uå¾®è°ƒ**: TCC **+29.7%**, ITS **+52.1%**
      - **vs. ç°æœ‰æ¨¡å‹**: InterSynç”Ÿæˆæ ·æœ¬åœ¨æ‰€æœ‰ç»´åº¦ä¸Šè¶…è¶ŠGPT-4o+DALL-E3ï¼ˆ+0.34~0.66ï¼‰
  - **å¼€æº**: âœ… [GitHub](https://github.com/xxx/InterSyn) (å…·ä½“é“¾æ¥å¾…ç¡®è®¤)
  - **æœºæ„**: Nankai University + Shanghai Innovation Institute + Wuhan University + USTC + Shanghai AI Lab
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´6æœˆ
  - **é‡è¦æ„ä¹‰**:
      - **é¦–ä¸ªå¤§è§„æ¨¡äº¤é”™å›¾æ–‡æŒ‡ä»¤æ•°æ®**: å¡«è¡¥instruction-followingäº¤é”™æ•°æ®ç©ºç™½
      - **å®Œå…¨è‡ªåŠ¨åŒ–pipeline**: SEIRå¤§å¹…é™ä½äººå·¥æˆæœ¬
      - **å››ç»´è¯„ä¼°ä½“ç³»**: SynJudgeæä¾›ç»†ç²’åº¦ã€å¯è§£é‡Šè¯„ä¼°
      - **è·¨æ¨¡æ€ååŒ**: å¼ºè°ƒITSæŒ‡æ ‡ï¼Œçªç ´ä¼ ç»Ÿä¸€è‡´æ€§è¯„ä¼°
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2406.10462">ğŸ“„ CoMM</a></b><br>
<code>arXiv 2406.10462</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2025-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **è¿è´¯çš„äº¤é”™å›¾æ–‡æ•°æ®é›†**ï¼Œé…å¤šè§†è§’è´¨é‡è¿‡æ»¤å’Œæ–°é¢–è¯„ä¼°ä»»åŠ¡
  - **æ•°æ®ç­›é€‰æ–¹æ³•** - **å¤šè§†è§’è¿‡æ»¤ç­–ç•¥ + è´¨é‡è¯„ä¼°æ¡†æ¶**:
      - **æ ¸å¿ƒåˆ›æ–°**: éçº¯åˆæˆï¼Œè€Œæ˜¯ä½¿ç”¨**è·¨ä¸‰ä¸ªç»´åº¦çš„å¤šæ¨¡å‹è¿‡æ»¤**å¯¹ç½‘ç»œæŠ“å–çš„äº¤é”™æ•°æ®è¿›è¡Œ**ç³»ç»Ÿæ€§ç­›é€‰å’Œè´¨é‡å¢å¼º**
      - **3è§†è§’è¿‡æ»¤Pipeline**:
        1. **æ–‡æœ¬åºåˆ—è¿‡æ»¤ï¼ˆè¿è´¯æ€§ï¼‰**:
           - **ç›®æ ‡**: ç¡®ä¿æ–‡æœ¬åºåˆ—çš„é€»è¾‘æµç¨‹å’Œå™äº‹è¿è´¯æ€§
           - **æ–¹æ³•**:
             - ä½¿ç”¨**åŸºäºLLMçš„è¿è´¯æ€§è¯„åˆ†**ï¼ˆå¦‚GPT-3.5/4ï¼‰è¯„ä¼°æ–‡æœ¬å¯è¯»æ€§å’Œé€»è¾‘è¿›å±•
             - æ£€æµ‹å¹¶åˆ é™¤å…·æœ‰ä»¥ä¸‹é—®é¢˜çš„æ–‡æ¡£:
               - è¯é¢˜çªå˜
               - å¥å­ä¸è¿è´¯
               - è¯­æ³•ç»“æ„å·®
           - **é˜ˆå€¼**: æ ¡å‡†è¿è´¯æ€§åˆ†æ•° â‰¥ 0.75ï¼ˆ0-1åˆ»åº¦ï¼‰
        2. **å›¾åƒåºåˆ—è¿‡æ»¤ï¼ˆä¸€è‡´æ€§ï¼‰**:
           - **ç›®æ ‡**: ä¿æŒåŒä¸€æ–‡æ¡£ä¸­å›¾åƒåºåˆ—çš„è§†è§‰ä¸€è‡´æ€§å’Œç›¸å…³æ€§
           - **æ–¹æ³•**:
             - **åŸºäºCLIPçš„å›¾åƒç›¸ä¼¼åº¦**: æµ‹é‡è¿ç»­å›¾åƒé—´çš„è§†è§‰è¿è´¯æ€§
             - **å¯¹è±¡/åœºæ™¯ä¸€è‡´æ€§**: ä½¿ç”¨æ£€æµ‹æ¨¡å‹ï¼ˆYOLOã€DINOï¼‰éªŒè¯å›¾åƒé—´ä¸€è‡´çš„å®ä½“
             - **ç¾å­¦è´¨é‡**: è¿‡æ»¤ä½è´¨é‡ã€æ¨¡ç³Šæˆ–é‡æ°´å°å›¾åƒ
           - **æ ‡å‡†**: åˆ é™¤å…·æœ‰ä»¥ä¸‹é—®é¢˜çš„åºåˆ—:
             - å›¾åƒé—´ç›¸ä¼¼åº¦æä½ï¼ˆ< 0.3 CLIPåˆ†æ•°ï¼‰
             - å•ä¸€æ–‡æ¡£å†…é£æ ¼/åŸŸå‰§çƒˆå˜åŒ–
             - å¤§éƒ¨åˆ†å›¾åƒæœªé€šè¿‡è´¨é‡æ£€æŸ¥
        3. **å›¾æ–‡å¯¹é½è¿‡æ»¤ï¼ˆç›¸å…³æ€§ï¼‰**:
           - **ç›®æ ‡**: ç¡®ä¿å›¾åƒä¸å‘¨å›´æ–‡æœ¬ä¹‹é—´çš„ç´§å¯†å¯¹é½
           - **æ–¹æ³•**:
             - **è·¨æ¨¡æ€æ£€ç´¢éªŒè¯**: å¯¹æ¯å¼ å›¾åƒï¼ŒéªŒè¯å…¶åœ¨é’ˆå¯¹å‘¨å›´æ–‡æœ¬æ®µè½æ£€ç´¢æ—¶æ’åé å‰
             - **åŸºäºCLIPçš„å›¾æ–‡åŒ¹é…**: è®¡ç®—å›¾åƒä¸ç›¸é‚»æ–‡æœ¬ä¹‹é—´çš„å¯¹é½åˆ†æ•°
             - **æ ‡æ³¨ä¸€è‡´æ€§æ£€æŸ¥**: ä½¿ç”¨VLMï¼ˆå¦‚BLIP-2ï¼‰ä¸ºå›¾åƒç”Ÿæˆæ ‡æ³¨ï¼ŒéªŒè¯ä¸æ–‡æ¡£æ–‡æœ¬çš„è¯­ä¹‰åŒ¹é…
           - **è¿‡æ»¤**: åˆ é™¤å¯¹é½åˆ†æ•° < 0.5çš„å›¾æ–‡å¯¹
      - **å¤šæ¨¡å‹å…±è¯†**:
        - ç»„åˆå¤šä¸ªæ¨¡å‹ï¼ˆCLIPã€BLIP-2ã€GPT-4ã€å®šåˆ¶åˆ†ç±»å™¨ï¼‰çš„åˆ†æ•°
        - è¦æ±‚è·¨æ¨¡å‹ä¸€è‡´ä»¥é¿å…å•æ¨¡å‹åå·®
        - **é›†æˆç­–ç•¥**: ä½¿ç”¨æ ¡å‡†é˜ˆå€¼çš„åŠ æƒå¹³å‡
      - **æºæ•°æ®**:
        - **ç½‘ç»œçˆ¬å–**: CommonCrawlã€ç»´åŸºç™¾ç§‘ã€æ•™è‚²ç½‘ç«™
        - **åˆå§‹è§„æ¨¡**: è¿‡æ»¤å‰çº¦200ä¸‡åŸå§‹æ–‡æ¡£
        - **è¿‡æ»¤åè§„æ¨¡**: 22.7ä¸‡é«˜è´¨é‡è¿è´¯æ–‡æ¡£
  - **æ•°æ®è§„æ¨¡**:
      - **CoMMæ•°æ®é›†**: 22.7ä¸‡æ–‡æ¡£ã€228ä¸‡å›¾åƒã€1.39äº¿æ–‡æœ¬token
      - **å¹³å‡æ–‡æ¡£é•¿åº¦**: çº¦611 tokenã€æ¯æ–‡æ¡£çº¦10å¼ å›¾åƒ
      - **é¢†åŸŸ**: æ–°é—»æ–‡ç« ã€æ•™ç¨‹ã€æ•™è‚²å†…å®¹ã€æ•…äº‹å™äº‹
  - **æ–°é¢–è¯„ä¼°ä»»åŠ¡ï¼ˆæå‡º4é¡¹ä»»åŠ¡ï¼‰**:
      1. **è¿è´¯å›¾åƒç”Ÿæˆ**: ç»™å®šæ–‡æœ¬å¤§çº²ç”Ÿæˆè¿è´¯å›¾åƒåºåˆ—
      2. **è¿è´¯æ–‡æœ¬ç”Ÿæˆ**: ç»™å®šå›¾åƒåºåˆ—ç”Ÿæˆå™äº‹æ–‡æœ¬
      3. **è¿è´¯æ€§è¯„ä¼°**: è¯„ä¼°äº¤é”™æ–‡æ¡£çš„è¿è´¯æ€§è´¨é‡
      4. **é•¿ä¸Šä¸‹æ–‡è·¨æ¨¡æ€æ£€ç´¢**: åœ¨å¤šå›¾åƒæ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³å›¾åƒ/æ–‡æœ¬
  - **åŸºå‡†æ„å»º**:
      - **æµ‹è¯•é›†**: 5Ké«˜è´¨é‡ç•™å‡ºæ–‡æ¡£
      - **äººå·¥æ ‡æ³¨**: ä¸“å®¶å¯¹è¿è´¯æ€§ã€ä¸€è‡´æ€§ã€å¯¹é½çš„è¯„åˆ†ï¼ˆ3åˆ†åˆ¶ï¼‰
      - **è‡ªåŠ¨æŒ‡æ ‡**: åŸºäºCLIPã€åŸºäºLLMå’Œå®šåˆ¶è¿è´¯æ€§æŒ‡æ ‡
  - **å®éªŒç»“æœ**:
      - **ä½¿ç”¨CoMMé¢„è®­ç»ƒ**: åœ¨CoMMä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨äº¤é”™ç†è§£ä»»åŠ¡ä¸Šæ¯”åœ¨éè¿‡æ»¤æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹æå‡**+8.3%**
      - **è¿è´¯æ€§æŒ‡æ ‡**: CoMMè¿‡æ»¤æ•°æ®å¾—åˆ†**0.82è¿è´¯æ€§** vs. åŸå§‹ç½‘ç»œæ•°æ®çš„**0.61**
      - **å¯¹é½è´¨é‡**: **87.5%**å›¾æ–‡å¯¹é½å‡†ç¡®ç‡ vs. æœªè¿‡æ»¤æ•°æ®çš„**62.3%**
      - **æ³›åŒ–**: å¼ºè¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼ˆé•¿æ–‡æœ¬VQAã€å¤šå›¾åƒæ¨ç†ï¼‰
  - **æ¶ˆèç ”ç©¶**:
      - **æ¯é¡¹è¿‡æ»¤çš„è´¡çŒ®**:
        - æ–‡æœ¬è¿‡æ»¤: +3.1%è¿è´¯æ€§
        - å›¾åƒè¿‡æ»¤: +2.7%ä¸€è‡´æ€§
        - å¯¹é½è¿‡æ»¤: +4.2%ç›¸å…³æ€§
      - **å¤šæ¨¡å‹å…±è¯†**: è¶…è¶Šå•æ¨¡å‹è¿‡æ»¤**+5.8%**
  - **å‘å¸ƒæ—¶é—´**: CVPR 2025 | arXiv 2024å¹´6æœˆ (v3: 2024å¹´6æœˆ)
  - **æœºæ„**: æœªæ˜ç¡®è¯´æ˜ï¼ˆå­¦æœ¯ç ”ç©¶ï¼‰
  - **å¼€æº**: âœ… CoMMæ•°æ®é›†ï¼ˆ22.7ä¸‡æ–‡æ¡£ï¼‰ã€è¯„ä¼°åŸºå‡†ï¼ˆ5Kæµ‹è¯•é›†ï¼‰ã€è¿‡æ»¤ä»£ç ã€è¯„ä¼°æŒ‡æ ‡ - è®ºæ–‡ä¸­æä¾›å‘å¸ƒè¯¦æƒ…
  - **äº¤å‰å¼•ç”¨**: å¦è§[å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†](#-å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†)äº†è§£æ•°æ®é›†è¯¦æƒ…
  - **é‡è¦æ„ä¹‰**:
      - **è´¨é‡é‡äºæ•°é‡**: è¯æ˜ä¸¥æ ¼è¿‡æ»¤ > åŸå§‹è§„æ¨¡å¯¹äº¤é”™æ•°æ®çš„é‡è¦æ€§
      - **å¤šç»´è´¨é‡**: é¦–ä¸ªç³»ç»Ÿæ€§åŒæ—¶è§£å†³è¿è´¯æ€§ã€ä¸€è‡´æ€§å’Œå¯¹é½é—®é¢˜
      - **æ–¹æ³•è®ºè´¡çŒ®**: å¤šè§†è§’è¿‡æ»¤æ¡†æ¶å¯åº”ç”¨äºå…¶ä»–ç½‘ç»œè§„æ¨¡ç­›é€‰ä»»åŠ¡
      - **åŸºå‡†åˆ›æ–°**: ä¸“é—¨ä¸ºè¯„ä¼°äº¤é”™æ•°æ®è´¨é‡æå‡ºæ–°ä»»åŠ¡
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2501.03675">ğŸ“„ SMIR</a></b><br>
<code>arXiv 2501.03675</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **é‡ç‚¹**: **é«˜æ•ˆå¤šå›¾åƒæ¨ç†åˆæˆæ•°æ®ç®¡é“** - ç”¨äºå¤šå›¾åƒæ¨ç†çš„åˆæˆæ•°æ®ç”Ÿæˆç®¡é“ï¼ŒåŒ…å«é«˜è´¨é‡æ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†æµ‹è¯•
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å¤šæ¨¡æ€åµŒå…¥ + è¿­ä»£éšæœºé‡‡æ ·**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä½¿ç”¨å¤šæ¨¡æ€åµŒå…¥é«˜æ•ˆè¯†åˆ«ç›¸å…³å›¾åƒï¼Œåº”ç”¨èšç±»é‡‡æ ·å’Œå›¾è¿­ä»£é‡‡æ ·ç¡®ä¿æŒ‡ä»¤å¾®è°ƒçš„å¤šæ ·æ€§å’Œé²æ£’æ€§
      - **é˜¶æ®µ1: å¤šæ¨¡æ€åµŒå…¥æ„å»º**:
        - **æ–¹æ³•**: ç»“åˆSigLIPæˆ–CLIPå›¾åƒåµŒå…¥ä¸å¯¹åº”çš„æ ‡é¢˜åµŒå…¥
        - **å…¬å¼**: E_multimodal = E_image + cÂ·E_captionï¼ˆå…¶ä¸­c = 0.2ç”¨äºShareGPT4Væ•°æ®é›†ï¼‰
        - **ç›®çš„**: æ•è·è§†è§‰å’Œæ–‡æœ¬å…³ç³»ï¼Œæ›´å¥½åœ°è¯†åˆ«å’Œèšç±»ç›¸å…³å›¾åƒ
        - **é™ç»´**: åº”ç”¨UMAPè¿›è¡Œé™ç»´ï¼Œä¿ç•™åŸºæœ¬æ•°æ®ç»“æ„
      - **é˜¶æ®µ2: è¿­ä»£éšæœºé‡‡æ ·**:
        - **ç®—æ³•**: ä½¿ç”¨åŸºäºç´¯ç§¯è·ç¦»çš„æ¦‚ç‡åˆ†å¸ƒè¿­ä»£é€‰æ‹©è¯­ä¹‰ç›¸å…³å›¾åƒ
        - **æ¦‚ç‡åˆ†å¸ƒ**: p(x_j) âˆ 1/(Î£âˆ¥x_j - x_uâˆ¥^k + Îµ)ï¼Œå…¶ä¸­kï¼ˆé»˜è®¤ï¼š12ï¼‰æ§åˆ¶é‚»è¿‘åº¦å¼ºè°ƒ
        - **ç›®çš„**: å¹³è¡¡è¯­ä¹‰è¿è´¯æ€§å’Œå¤šæ ·æ€§ï¼Œå…è®¸æœ‰æ„ä¹‰çš„å¤šå›¾åƒå…³ç³»åŒæ—¶å¼•å…¥éšæœºæ€§
        - **ä¼˜åŠ¿**: æœ‰æ•ˆèšç±»ç›¸å…³å›¾åƒï¼Œé¿å…æ–­å¼€çš„åˆ†ç»„
      - **é˜¶æ®µ3: åˆæˆæ•°æ®ç”Ÿæˆ**:
        - **LLM**: ä½¿ç”¨Meta Llama 3.1 70B Instruct Turboï¼ˆå¼€æºLLMï¼‰
        - **æˆæœ¬æ•ˆç‡**: æ¯”GPT-4ä¾¿å®œ**50å€**ï¼Œé€Ÿåº¦å¿«**10å€**
        - **ä¸¤ç§ç³»ç»Ÿæç¤ºç±»å‹**:
          1. **LLaVAé£æ ¼æç¤º**: ä¸“æ³¨äºè¾ƒçŸ­çš„è§†è§‰é—®é¢˜ï¼Œé€šå¸¸éœ€è¦åŸºäºOCRçš„ç†è§£
          2. **é•¿å½¢å¼æ¨ç†æç¤º**: è®¾è®¡ç”¨äºå¤šæ­¥æ¨ç†å’Œæ›´æ·±å±‚çš„ä¸Šä¸‹æ–‡ç†è§£
        - **æ•°æ®æº**: ShareGPT4Vï¼ˆ120ä¸‡å›¾åƒ-æ ‡é¢˜å¯¹ï¼‰
        - **æ‰¹å¤„ç†**: æ¯æ‰¹åŒ…å«20,000å¼ å›¾åƒï¼Œç”Ÿæˆ5,000ä¸ªåˆæˆå¯¹è¯
      - **å…³é”®æŠ€æœ¯**:
        - **å¤šæ¨¡æ€åµŒå…¥**: æ•´åˆè§†è§‰å’Œæè¿°æ€§ä¿¡æ¯ä»¥æ›´å¥½åœ°è¯†åˆ«ç›¸å…³æ€§
        - **è¿­ä»£é‡‡æ ·**: ç¡®ä¿å¤šæ ·æ€§åŒæ—¶ä¿æŒè¿è´¯æ€§
        - **å¼€æºLLM**: ä¸é—­æºæ›¿ä»£æ–¹æ¡ˆç›¸æ¯”æ˜¾è‘—é™ä½æˆæœ¬
        - **æ¨¡å—åŒ–è®¾è®¡**: æ˜“äºé€‚åº”æ–°æ•°æ®é›†å’Œåº”ç”¨
  - **SMIR-BENCHè¯„ä¼°åŸºå‡†æµ‹è¯•**:
      - **è§„æ¨¡**: 200ä¸ªå¤šæ ·åŒ–ç¤ºä¾‹ï¼Œæ¶µç›–ä¸ƒä¸ªå¤æ‚æ¨ç†ä»»åŠ¡
      - **ä»»åŠ¡ç±»åˆ«**:
        1. **é¸Ÿç±»**: è¯†åˆ«ç‰©ç§å¹¶æ¨ç†åŒºåˆ†ç‰¹å¾
        2. **åŒ¹é…**: åŸºäºè§†è§‰ç›¸ä¼¼æ€§é…å¯¹ç…§ç‰‡
        3. **OCR**: é˜…è¯»å’Œæ¨ç†å­¦æœ¯æ–‡æœ¬
        4. **æ¨¡å¼**: åœ¨ç»“æ„åŒ–ä»»åŠ¡ä¸­è¯†åˆ«è§†è§‰æ¨¡å¼
        5. **æ’åº**: åŸºäºä¸Šä¸‹æ–‡åå¥½å¯¹å¯¹è±¡æ’åº
        6. **æ•…äº‹å™è¿°**: ä»å›¾åƒåºåˆ—å™è¿°äº‹ä»¶
        7. **è§†è§‰**: åœ¨å›¾åƒä¹‹é—´å»ºç«‹æœ‰æ„ä¹‰çš„è¿æ¥
      - **è¯„ä¼°æ–¹æ³•**:
        - **å¤šè½®**: æ”¯æŒå¤šè½®äº¤äº’
        - **è‡ªç”±å½¢å¼å“åº”**: é€šè¿‡è‡ªç”±å½¢å¼å“åº”å’Œæ¨ç†ç†ç”±è¯„ä¼°æ¨¡å‹
        - **åˆ¤æ–­æ¨¡å‹**: ä½¿ç”¨GPT-4oä½œä¸ºåˆ¤æ–­æ¨¡å‹è¿›è¡Œæˆå¯¹æ¯”è¾ƒ
        - **æ¡†æ¶**: å°†Auto-Hard-Auto v0.1æ¡†æ¶æ‰©å±•åˆ°å¤šæ¨¡æ€è¯„ä¼°
  - **æ•°æ®è§„æ¨¡**:
      - **SMIRæ•°æ®é›†**: 160,000ä¸ªåˆæˆè®­ç»ƒæ ·æœ¬
      - **æºå›¾åƒ**: ä½¿ç”¨640,000ä¸ªå›¾åƒ-æ ‡é¢˜å¯¹ç”Ÿæˆ160,000ä¸ªåˆæˆå¯¹è¯
      - **å¹³å‡ç»Ÿè®¡**:
        - æœ€å¤§è½®æ•°: 24ï¼Œæœ€å°è½®æ•°: 2ï¼Œå¹³å‡è½®æ•°: 9.65
        - æ¯ä¸ªå¯¹è¯å¹³å‡å›¾åƒæ•°: 4.65
        - å¹³å‡ç”¨æˆ·ä»¤ç‰Œ: 25.51ï¼Œå¹³å‡åŠ©æ‰‹ä»¤ç‰Œ: 124.32
  - **å®éªŒç»“æœ**:
      - **æ¨¡å‹å¾®è°ƒ**: åœ¨SMIRä¸Šå¾®è°ƒçš„æ¨¡å‹åœ¨SMIR-BENCHä¸Šæ¯”åŸºç¡€ç‰ˆæœ¬æå‡é«˜è¾¾**8%**
      - **SMIR-8B-SIGLIP-LLAMA3**: 58.1åˆ†ï¼ˆvs Mantis-8B-siglip-llama3åŸºçº¿+8.1%ï¼‰
      - **SMIR-8B-IDEFICS2**: 58.0åˆ†ï¼ˆvs Mantis-8B-Idefics2åŸºçº¿+8.0%ï¼‰
      - **vs. é—­æºæ¨¡å‹**: å°½ç®¡æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼ŒSMIRè®­ç»ƒçš„æ¨¡å‹æ˜¾è‘—ä¼˜äºMANTISå¾®è°ƒçš„å¯¹åº”æ¨¡å‹
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´1æœˆ
  - **æœºæ„**: TogetherAIã€åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€æ–¯å¦ç¦å¤§å­¦ã€åŠ å·ç†å·¥å­¦é™¢
  - **å¼€æº**: âœ… [GitHub](https://github.com/togethercomputer/SMiR) - ä»£ç ã€SMIRæ•°æ®é›†ï¼ˆ16ä¸‡æ ·æœ¬ï¼‰ã€SMIR-BENCHï¼ˆ200ä¸ªç¤ºä¾‹ï¼‰
  - **é‡è¦æ„ä¹‰**:
      - **è§£å†³å¤šå›¾åƒæ¨ç†å·®è·**: é’ˆå¯¹å¼€æºVLMåœ¨å¤šå›¾åƒä»»åŠ¡ä¸­çš„å·²çŸ¥å¼±ç‚¹
      - **æˆæœ¬æ•ˆç›Šåˆæˆ**: å¼€æºLLMé™ä½æˆæœ¬50å€ï¼Œé€Ÿåº¦æå‡10å€
      - **ç›¸å…³å›¾åƒèšç„¦**: ç¡®ä¿å›¾åƒç›¸å…³æ€§ï¼Œæ¨è¿›å¤æ‚å¤šå›¾åƒæ¨ç†
      - **å…¨é¢åŸºå‡†æµ‹è¯•**: SMIR-BENCHæä¾›ä¸¥æ ¼è¯„ä¼°ï¼Œæ”¯æŒå¤šè½®ã€è‡ªç”±å½¢å¼å“åº”
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2501.00958">ğŸ“„ 2.5 Years in Class</a></b><br>
<code>arXiv 2501.00958</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-æµ™æ±Ÿå¤§å­¦_+_é˜¿é‡Œè¾¾æ‘©é™¢-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **æ•™å­¦è§†é¢‘è½¬å¤šæ¨¡æ€æ•™ç§‘ä¹¦** - ä»åœ¨çº¿æ•™å­¦è§†é¢‘ä¸­æ„å»ºé«˜è´¨é‡äº¤é”™å›¾æ–‡"æ•™ç§‘ä¹¦"è¯­æ–™åº“ï¼Œæå‡VLMé¢„è®­ç»ƒæ•ˆæœ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è§†é¢‘è½¬æ•™ç§‘ä¹¦å¤šçº§Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»ŸåŒ–ä»æ•™å­¦è§†é¢‘æ„å»ºäº¤é”™å›¾æ–‡æ•°æ®é›†çš„æ–¹æ³•ï¼Œé€šè¿‡å¤šçº§æå–ï¼ˆè§†é¢‘â†’ASRâ†’å…³é”®å¸§â†’OCRï¼‰ç”Ÿæˆé«˜è´¨é‡æ•™ç§‘ä¹¦çº§æ•°æ®
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰äº¤é”™å›¾æ–‡æ•°æ®é›†ï¼ˆMMC4ã€OBELICSï¼‰æ¥æºäºç½‘é¡µçˆ¬å–ï¼Œå­˜åœ¨**çŸ¥è¯†å¯†åº¦ä½ã€å›¾æ–‡å…³ç³»æ¾æ•£ã€å›¾åƒé—´é€»è¾‘è¿è´¯æ€§å·®**çš„é—®é¢˜
        - åœ¨çº¿æ•™å­¦è§†é¢‘ï¼ˆå¦‚å‡ ä½•è¯¾ç¨‹ï¼‰åŒ…å«ä¸°å¯Œçš„åŸºç¡€çŸ¥è¯†ï¼Œä½†åœ¨VLMè®­ç»ƒä¸­æœªè¢«å……åˆ†åˆ©ç”¨
      - **ä¸‰é˜¶æ®µæ•°æ®æ„å»ºPipeline**:
        1. **æ”¶é›†æ•™å­¦è§†é¢‘**:
           - **çŸ¥è¯†åˆ†ç±»ä½“ç³»æ„å»º**: ä½¿ç”¨GPT-4oæ„å»ºåŒ…å«3915ä¸ªçŸ¥è¯†ç‚¹çš„åˆ†ç±»ä½“ç³»ï¼Œæ¶µç›–6ä¸ªå­¦ç§‘ï¼ˆæ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ã€åœ°çƒç§‘å­¦ã€å·¥ç¨‹ã€è®¡ç®—æœºç§‘å­¦ï¼‰
           - **è§†é¢‘æ£€ç´¢**: åŸºäºçŸ¥è¯†åˆ†ç±»ä½“ç³»åœ¨YouTubeç­‰å¹³å°è‡ªåŠ¨æ£€ç´¢æ•™å­¦è§†é¢‘
           - **å…ƒæ•°æ®è¿‡æ»¤**: ä½¿ç”¨LLMå®¡æ ¸è§†é¢‘å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ã€æè¿°ã€è¯„è®ºï¼‰ï¼Œè¿‡æ»¤éæ•™å­¦å†…å®¹
           - **è§„æ¨¡**: æ”¶é›†159,565ä¸ªæ•™å­¦è§†é¢‘ï¼Œè¿‡æ»¤åä¿ç•™75,000ä¸ªé«˜è´¨é‡è§†é¢‘ï¼ˆ22,697è¯¾æ—¶ï¼Œå¹³å‡18åˆ†é’Ÿ/è§†é¢‘ï¼‰
        2. **è§†é¢‘çº§æå–ä¸è¿‡æ»¤**:
           - **éŸ³é¢‘è½¬å½•ï¼ˆASRï¼‰**: ä½¿ç”¨Whisper-large-v3å°†éŸ³é¢‘è½¬ä¸ºæ–‡æœ¬ï¼Œä¿ç•™æ—¶é—´æˆ³
           - **ASRç²¾ç‚¼**: ä½¿ç”¨Qwen2-72B-Instructç²¾ç‚¼å£è¯­åŒ–ASRæ–‡æœ¬ï¼Œæå‡è¯­æ³•å’Œè¿è´¯æ€§
           - **è´¨é‡è¯„åˆ†**: ä½¿ç”¨DeepSeek-V2å’ŒLlama3-70Bå¯¹ASRæ–‡æœ¬è¯„åˆ†ï¼Œè¿‡æ»¤ä½è´¨é‡è§†é¢‘
        3. **ç‰‡æ®µçº§æå–ï¼ˆLong Videoâ†’Short Clipsï¼‰**:
           - **è§†é¢‘åˆ†å‰²**: æ ¹æ®ASRæ—¶é—´æˆ³å°†é•¿è§†é¢‘åˆ†å‰²ä¸ºçŸ­ç‰‡æ®µï¼ˆæ¯æ®µå¯¹åº”ä¸€ä¸ªå®Œæ•´è¯­ä¹‰å•å…ƒï¼‰
           - **ASRç‰‡æ®µåˆå¹¶**: å°†ä¸å®Œæ•´çš„ASRç‰‡æ®µåˆå¹¶ä¸ºè¯­ä¹‰è¿è´¯çš„æ®µè½
           - **è´¨é‡è¿‡æ»¤**:
             - ä½¿ç”¨VideoLlama2-7Bä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆcaption
             - è®¡ç®—ç‰‡æ®µcaptionä¸ASRçš„ç›¸ä¼¼åº¦ï¼ˆGTE-Qwen2-7B-Instructï¼‰
             - è¿‡æ»¤è§†è§‰å†…å®¹ä¸ASRä¸åŒ¹é…çš„ç‰‡æ®µ
           - **è§„æ¨¡**: ç”Ÿæˆ4Mè§†é¢‘ç‰‡æ®µ
        4. **å…³é”®å¸§çº§æå–**:
           - **å…³é”®å¸§æ£€æµ‹**: ä½¿ç”¨SSIMï¼ˆç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•°ï¼‰ç®—æ³•æ£€æµ‹å¸§é—´å˜åŒ–ï¼Œæå–å…³é”®å¸§
           - **OCRæå–**: ä½¿ç”¨InternVL2æå–å…³é”®å¸§ä¸­çš„æ–‡æœ¬ã€ç¬¦å·ã€å…¬å¼
           - **OCRè¿‡æ»¤**:
             - å»é™¤ä¸ASRæ— å…³çš„OCRï¼ˆå¦‚ä»…æ˜¾ç¤ºæ¼”è®²è€…ï¼‰
             - å»é™¤ä¸å‰ä¸€å¸§ç›¸åŒçš„OCR
             - å»é™¤ç¼ºå°‘æœ‰ç”¨ä¿¡æ¯çš„å…³é”®å¸§
           - **è§„æ¨¡**: æå–6.5Må…³é”®å¸§ï¼Œç”Ÿæˆ0.75Bæ–‡æœ¬tokenï¼ˆASR + OCRï¼‰
        5. **æ•™ç§‘ä¹¦æ ·æœ¬æ„å»º**:
           - å°†å¤šä¸ª `<å…³é”®å¸§, OCR, ASR>` ç‰‡æ®µæ‹¼æ¥ä¸ºå•ä¸ªæ ·æœ¬
           - æ¯ä¸ªæ ·æœ¬å¹³å‡åŒ…å«10.7ä¸ªå…³é”®å¸§å’Œ1,297ä¸ªæ–‡æœ¬token
           - **æœ€ç»ˆè§„æ¨¡**: 610Käº¤é”™å›¾æ–‡æ ·æœ¬
      - **ä¸ç°æœ‰æ•°æ®é›†å¯¹æ¯”ä¼˜åŠ¿**:
        - **In-sample Image Similarityï¼ˆæ ·æœ¬å†…å›¾åƒç›¸ä¼¼åº¦ï¼‰**: 0.686ï¼ˆvs. MMC4 0.319, OBELICS 0.345ï¼‰ï¼Œè¡¨æ˜æ•™å­¦è§†é¢‘çš„å¸§åºåˆ—æ›´è¿è´¯
        - **å¹³å‡å›¾åƒæ•°/æ ·æœ¬**: 10.7ï¼ˆvs. MMC4 5.7, OBELICS 2.5ï¼‰ï¼Œå†…å®¹æ›´ä¸°å¯Œ
        - **å¹³å‡æ–‡æœ¬token/æ ·æœ¬**: 1,297ï¼ˆvs. MMC4 417, OBELICS 816ï¼‰ï¼ŒçŸ¥è¯†å¯†åº¦æ›´é«˜
  - **æ•°æ®ç»Ÿè®¡**:
      - **è§†é¢‘è§„æ¨¡**: 75Kæ•™å­¦è§†é¢‘ï¼Œ22,697è¯¾æ—¶ï¼ˆ2.5å¹´ï¼‰
      - **å…³é”®å¸§**: 6.5M
      - **æ–‡æœ¬**: 259M ASR tokens + 500M OCR tokens
      - **æœ€ç»ˆæ ·æœ¬**: 610Käº¤é”™å›¾æ–‡æ ·æœ¬
      - **å­¦ç§‘åˆ†å¸ƒ**: æ•°å­¦ï¼ˆ21.7Kè§†é¢‘ï¼‰ã€ç‰©ç†ï¼ˆ11Kï¼‰ã€åŒ–å­¦ï¼ˆ4.5Kï¼‰ã€åœ°çƒç§‘å­¦ï¼ˆ12Kï¼‰ã€å·¥ç¨‹ï¼ˆ13Kï¼‰ã€è®¡ç®—æœºç§‘å­¦ï¼ˆ12.8Kï¼‰
  - **å®éªŒç»“æœ** - **æ˜¾è‘—æå‡çŸ¥è¯†ä¸æ¨ç†å¯†é›†å‹åŸºå‡†**:
      - **é¢„è®­ç»ƒLLaVA-1.5-7B**ï¼ˆåœ¨610Kæ•™ç§‘ä¹¦æ•°æ®ä¸ŠæŒç»­é¢„è®­ç»ƒï¼‰:
        - **MathVista**: 1-shot 43.4%ï¼ˆvs. MMC4 30.0%, OBELICS 28.5%ï¼Œ**+13.4%~14.9%**ï¼‰
        - **ScienceQA**: 1-shot 29.4%ï¼ˆvs. MMC4 1.6%, OBELICS 2.8%ï¼Œ**+26.6%~27.8%**ï¼‰
        - **MathVision**: 1-shot 25.6%ï¼ˆvs. MMC4 21.3%, OBELICS 20.1%ï¼Œ**+4.3%~5.5%**ï¼‰
        - **å¹³å‡æå‡**: åœ¨7ä¸ªVQAåŸºå‡†ä¸Šå¹³å‡æå‡**+11.5%**ï¼ˆvs. OBELICSï¼‰
      - **é¢„è®­ç»ƒIdefics2-8B**:
        - **MathVista**: 8-shot 29.7%ï¼ˆvs. MMC4 27.8%, OBELICS 27.6%ï¼‰
        - **æŒç»­é¢„è®­ç»ƒ**: ä»Idefics2-8B-baseæŒç»­é¢„è®­ç»ƒï¼Œæ‰€æœ‰åŸºå‡†å‡æœ‰æå‡
      - **In-Context Learningå¢å¼º**:
        - æ•™ç§‘ä¹¦æ•°æ®æ˜¾è‘—æå‡æ¨¡å‹åˆ©ç”¨few-shotä¸Šä¸‹æ–‡çš„èƒ½åŠ›
        - åœ¨"1-shot Cheat"å®éªŒä¸­ï¼ˆæµ‹è¯•æ ·æœ¬ç›´æ¥æ”¾å…¥ä¸Šä¸‹æ–‡ï¼‰ï¼Œæ•™ç§‘ä¹¦è®­ç»ƒæ¨¡å‹å‡†ç¡®ç‡è¾¾94.1%ï¼ˆMathVistaï¼‰ï¼Œè¿œè¶…MMC4ï¼ˆ72.6%ï¼‰å’ŒOBELICSï¼ˆ67.7%ï¼‰
      - **SFTé˜¶æ®µè¿ç§»**: é¢„è®­ç»ƒæ”¶ç›Šå¯è¿ç§»åˆ°æŒ‡ä»¤å¾®è°ƒé˜¶æ®µï¼Œè¿›ä¸€æ­¥æå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - **ASRç²¾ç‚¼è‡³å…³é‡è¦**: å»é™¤ASRç²¾ç‚¼åï¼Œå›°æƒ‘åº¦ä»13.92å‡è‡³16.86ï¼Œå‡†ç¡®ç‡ä¸‹é™4.9%
      - **OCRé‡è¦æ€§**: å»é™¤OCRåï¼Œå‡†ç¡®ç‡ä¸‹é™2.3%ï¼Œå¯¹æ•°å­¦ç›¸å…³ä»»åŠ¡å½±å“æ›´å¤§
      - **SSIMä¼˜äºå…¶ä»–å…³é”®å¸§æå–æ–¹æ³•**: Pixel-levelæå–å™¨äº§ç”Ÿ18Må…³é”®å¸§ï¼ˆè¿‡å¤šå†—ä½™ï¼‰ï¼ŒCLIP-basedä»…äº§ç”Ÿ1.7Mï¼ˆé—æ¼å…³é”®å¸§ï¼‰ï¼ŒSSIMæå–çš„6.5Må…³é”®å¸§æœ€ä¼˜
      - **å›¾åƒé¡ºåºé‡è¦**: æ‰“ä¹±å›¾åƒé¡ºåºåï¼Œå‡†ç¡®ç‡ä»31.1%é™è‡³22.1%ï¼ˆ-9%ï¼‰ï¼Œè¯æ˜è§†é¢‘å¸§çš„æ—¶åºè¿è´¯æ€§å¯¹å­¦ä¹ è‡³å…³é‡è¦
  - **æœºæ„**: æµ™æ±Ÿå¤§å­¦ã€é˜¿é‡Œè¾¾æ‘©é™¢
  - **ä½œè€…**: Wenqi Zhang, Hang Zhang, Xin Li, Jiashuo Sun, Yongliang Shen, Weiming Lu, Deli Zhao, Yueting Zhuang, Lidong Bing
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´1æœˆï¼ˆv4ï¼‰
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2501.00958](https://arxiv.org/abs/2501.00958)
  - **é¡¹ç›®ä¸»é¡µ**: https://multimodal-interleaved-textbook.github.io/
  - **æ„ä¹‰**:
      - **æ•°æ®æ¥æºåˆ›æ–°**: é¦–æ¬¡ç³»ç»ŸåŒ–ä»æ•™å­¦è§†é¢‘æ„å»ºVLMé¢„è®­ç»ƒæ•°æ®ï¼Œå¡«è¡¥"æ•™ç§‘ä¹¦çº§"å¤šæ¨¡æ€æ•°æ®ç©ºç™½
      - **çŸ¥è¯†å¯†åº¦é«˜**: ç›¸æ¯”ç½‘é¡µçˆ¬å–æ•°æ®ï¼Œæ•™å­¦è§†é¢‘å†…å®¹æ›´ç»“æ„åŒ–ã€çŸ¥è¯†å¯†åº¦æ›´é«˜ã€å›¾æ–‡å…³ç³»æ›´ç´§å¯†
      - **In-Context Learningæå‡**: æ˜¾è‘—å¢å¼ºVLMçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ¨¡å‹æ›´æœ‰æ•ˆåˆ©ç”¨few-shotç¤ºä¾‹
      - **å¯æ‰©å±•æ€§**: Pipelineå®Œå…¨è‡ªåŠ¨åŒ–ï¼Œå¯è½»æ¾æ‰©å±•åˆ°æ›´å¤šå­¦ç§‘å’Œè¯­è¨€
  

</details>
---

### å›¾åƒä¸å˜æ–‡æœ¬å¢å¼º

This category of methods keeps original images fixed while enriching and improving paired text quality through various techniques. **This is currently the most mainstream multimodal data synthesis paradigm.**

> **Note**: Only includes papers that explicitly describe data synthesis/generation methods, with specific synthesis components annotated.

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=MM-IFEngine%20ICCV%202025">ğŸ“„ MM-IFEngine</a></b><br>
<code>ICCV 2025</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ICCV_2025-red?style=flat-square"/>
</summary>

  - **Focus**: **Multimodal Instruction Following Data Generation Engine** - Automatically generating high-quality multimodal instruction following data and evaluation benchmarks with complex constraints
  - **Data Synthesis Method** - **LLM-Driven Constraint Integration and Verification Pipeline**:
      - **Core Innovation**: First systematic multimodal instruction following (MMIF) data generation engine that automatically integrates diverse constraints into visual instructions and constructs comprehensive evaluation benchmarks through LLM
      - **Problem Identification**:
        - Existing MMIF training data is scarce and constraints are simple (e.g., VisIT-Bench, MIA-Bench only contain atomic-level constraints)
        - Weak correlation between constraints and visual content leads to insufficient instruction following ability in real-world scenarios
        - Imprecise evaluation methods: LLM-as-a-judge has misjudgment issues on tasks requiring precise output constraints (e.g., word count)
      - **Four-Step Generation Pipeline**:
        1. **Image Filtering (Step 1)**:
           - **Objective**: Select semantically rich natural scene images
           - **Data Sources**: CC3M, ALLaVA, MultiUI, Geo170k, ChartQA and other multi-source data
           - **Quality Metrics**:
             - **IC9600 Metric**: Evaluates image semantic complexity (information content, category diversity, etc.)
             - **RAM Metric**: Identifies salient objects and scene elements in images
           - **Selection Criteria**: Prioritize natural scene images with rich semantic content (non-low-resolution, non-simple backgrounds)
           - **Rationale**: Rich semantic content supports designing more comprehensive and complex instruction following tasks
        2. **Task Generation (Step 2)**:
           - **For datasets with original QA (e.g., ALLaVA)**:
             - Use regular expressions and length limits to filter questions
             - Exclude questions containing few-shot examples (Q_fs)
             - Exclude questions containing options (Q_op)
             - Formula: Q_s = {qâˆˆQ | qâˆ‰Q_fs âˆ§ qâˆ‰Q_op}
             - Obtain task instruction set T* suitable for constraint integration
           - **For datasets without original QA (e.g., CC3M)**:
             - Design predefined task instruction template pool P_T
             - Include multiple task types such as description, creation, analysis
             - Task design considers compatibility with subsequent constraint integration
        3. **Constraint Integration (Step 3 - Core Step)**:
           - **Constraint Pool P_C Construction**:
             - **6 major categories with 32 subcategories**, forming multi-level constraint taxonomy:
               a) **Format Constraints**: JSON format, list format, code block format, paragraph structure
               b) **Length Constraints**: Word limit, sentence limit, paragraph limit
               c) **Style Constraints**: Formal/informal tone, humorous style, poetic form, academic style
               d) **Keyword Constraints**: Must include specific words, avoid specific words, use synonyms
               e) **Composition Constraints**: Complex requirements combining multiple constraint types
               f) **Perception Constraints**: Constraints based on visual content (color, objects, position, etc.)
             - **Constraint-Visual Content Association**: Ensure constraints are related to image semantics, avoiding conflicts
           - **Constraint Sampling and Generation**:
             - Sample k constraint types from constraint pool P_C (typically 3-12)
             - **Two-Stage Selection Strategy** (for data with original QA):
               - First stage: Roughly select mostly compatible constraint types from P_C
               - Second stage: LLM precisely selects and generates specific constraint content
             - **Direct Sampling Strategy** (for data without original QA):
               - Directly sample k constraint types
               - LLM generates compatible specific constraint content
           - **Constraint Integration**:
             - LLM (GPT-4o) naturally integrates selected constraints into task instructions
             - Ensures mutual compatibility between constraints (no contradictions)
             - Outputs complex instructions containing multiple constraints
        4. **Answer Generation and Quality Control (Step 4)**:
           - **Answer Generation**: GPT-4o generates high-quality answers based on images and constraint instructions
           - **Quality Control**:
             - **Accuracy Threshold**: 80% (through GPT-4o self-evaluation)
             - **Constraint Verification**: Generated answers must satisfy all specified constraints
             - **Multi-round Iteration**: Samples not meeting quality requirements are discarded or regenerated
      - **Key Technical Advantages**:
        - **Complex Constraints**: Average 6.5 constraints per sample, far exceeding existing datasets (typically 1-2)
        - **Visual-Constraint Association**: Constraint design considers image content, ensuring instruction rationality and executability
        - **Automation**: End-to-end automated generation without human annotation
        - **Scalability**: Constraint pool can be flexibly expanded to support new constraint types
  - **MM-IFInstruct-23K Dataset**:
      - **Total Scale**: 23K high-quality instruction following data
      - **Data Source Distribution**:
        - CC3M: 16K (70%)
        - ALLaVA: 6K (26%)
        - MultiUI/Geo170k/ChartQA: 1K (4%)
      - **Constraint Statistics**:
        - **Average Constraints**: 6.5 per sample
        - **Constraint Distribution**: 3-12 constraints per sample, forming systematic complexity gradient
        - **Constraint Type Distribution**: 6 major categories with 32 subcategories, covering multi-dimensional instruction following requirements
      - **Data Characteristics**:
        - Contains complex constraints common in real application scenarios (e.g., "output in JSON format", "use at least 2 synonyms")
        - Diverse constraint combinations, training model's ability to satisfy multiple constraints simultaneously
  - **MM-IFDPO-23K Preference Dataset**:
      - **Objective**: For Direct Preference Optimization (DPO) training
      - **Construction Method**:
        - **Chosen Samples**: Directly use high-quality data from MM-IFInstruct-23K
        - **Rejected Samples**: 4 negative sample generation strategies
          1. Randomly delete 33% of constraints (retain 67%)
          2. Randomly delete 66% of constraints (retain 34%)
          3. Delete all constraints (retain 0%)
          4. Do not provide image input, generate answers based on text only
        - Use Qwen2-VL-7B-Instruct to generate rejected answers
      - **Scale**: 23K (chosen, rejected) pairs
      - **Effect**: DPO training further improves instruction following precision
  - **MM-IFEval Evaluation Benchmark**:
      - **Scale**: 400 high-quality evaluation samples
      - **Constraint Classification**: 6 major categories with 32 subcategories, forming complete instruction following evaluation system
      - **Question Types**:
        - **Compose-Level**: Text constraint-focused (300 samples)
        - **Perception-Level**: Requires strong visual perception ability constraints (100 samples)
          - Includes multiple image types such as natural scenes, user interfaces, charts, mathematical expressions
      - **Hybrid Evaluation Method** (Innovation):
        1. **Rule-Based Evaluation**: For precise constraints (e.g., word count, format)
           - Design predefined functions to verify if output satisfies constraints
           - LLM extracts relevant parameters, function executes verification
        2. **LLM Direct Judgment**: For clearly verifiable constraints (e.g., keyword inclusion)
        3. **Comparative Judgment**: For subjective constraints (e.g., tone, style)
           - Generate unconstrained control output
           - LLM compares both outputs to judge which better conforms to constraints
        - **Advantage**: Avoids LLM-as-a-judge misjudgment on precise constraints, improving evaluation accuracy
  - **Experimental Results** - **Open-Source Models Show Significant Improvements After Fine-tuning, Maintain VQA Capabilities**:
      - **Performance on MM-IFEval**:
        - Qwen2-VL-7B Baseline: 42.0% (Compose) / 80.5% (Overall)
        - +MM-IFInstruct-23K: 52.3% (+10.3%)
        - +MM-IFDPO-23K: **52.2%** (+10.2%)
        - LLaVA-NeXT-Llama3-8B Baseline: 39.7%
        - +MM-IFDPO-23K: **49.3%** (+9.6%)
      - **Cross-Benchmark Generalization (MIA-Bench)**:
        - Qwen2-VL-7B: Baseline 80.5% â†’ Finetuned **88.1%** (+7.6%)
        - LLaVA-NeXT-Llama3-8B: Baseline 83.3% â†’ Finetuned **90.0%** (+6.7%)
      - **Text Instruction Following (IFEval)**:
        - Qwen2-VL-7B: Baseline 47.4% â†’ Finetuned **59.7%** (+12.3%)
        - LLaVA-NeXT-Llama3-8B: Baseline 50.7% â†’ Finetuned **69.1%** (+18.4%)
      - **VQA Capability Preservation** (Key Validation):
        - On 8 VQA benchmarks including MMMU, MMBench, MMStar, MMT-Bench, AI2D, OCRBench, MMVet, POPE
        - Fine-tuned model performance comparable to or slightly better than baseline
        - **Conclusion**: MM-IFDPO-23K training does not harm model's original visual understanding capabilities
      - **Commercial Model Comparison** (MM-IFEval):
        - GPT-4o: 64.6% (Compose) / 44.0% (Perception)
        - Claude-3.5-Sonnet: 67.5% (Compose) / 44.0% (Perception)
        - Finetuned Qwen2-VL-7B: 55.2% (Compose) / 43.0% (Perception)
        - **Conclusion**: Open-source 7B models after fine-tuning approach commercial models on Compose-Level, but still have gaps on Perception-Level
  - **Ablation Study Key Findings**:
      - **DPO Negative Sample Strategy Comparison**:
        - Deleting 100% constraints (no constraints) negative samples work best
        - Deleting 33% or 66% constraints negative samples also effective
        - No image input negative samples slightly less effective
        - **Conclusion**: Clear positive-negative contrast (with constraints vs without constraints) most effective for DPO training
      - **Data Scale Impact**: 23K data volume achieves good performance-cost balance
      - **Constraint Quantity Impact**: Gradient distribution of 3-12 constraints helps model learn instruction following at different complexity levels
  - **Institution**: Fudan University, Shanghai AI Laboratory, Shanghai Jiao Tong University, The Chinese University of Hong Kong
  - **Authors**: Shengyuan Ding, Shenxi Wu, Xiangyu Zhao, Yuhang Zang, Haodong Duan, Xiaoyi Dong, Pan Zhang, Yuhang Cao, Dahua Lin, Jiaqi Wang
  - **Publication**: ICCV 2025
  - **Open Source**: âœ… [Code and Data](https://github.com/xxx/MM-IFEngine) (GitHub link TBD)
  - **Significance**:
      - **Problem Solving**: Systematically addresses scarcity of multimodal instruction following training data and imprecise evaluation methods
      - **Method Innovation**:
        - Proposes first constraint pool-driven multimodal instruction data automatic generation framework
        - Innovative hybrid evaluation method (rule + LLM + comparative), solving LLM-as-a-judge limitations
      - **Data Contribution**:
        - Provides 23K high-quality complex constraint instruction data (MM-IFInstruct-23K)
        - Provides 23K DPO preference data (MM-IFDPO-23K)
        - Provides 400-sample comprehensive evaluation benchmark (MM-IFEval)
      - **Practical Value**:
        - Significantly improves open-source models' instruction following ability, narrowing gap with commercial models
        - Does not harm original VQA capabilities, directly applicable to practical applications
        - Constraint pool is extensible, supporting customized instruction following capability cultivation
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.05970">ğŸ“„ CIRHS</a></b><br>
<code>arXiv 2507.05970</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ç»„åˆå›¾åƒæ£€ç´¢çš„é«˜è´¨é‡ä¸‰å…ƒç»„è‡ªåŠ¨åˆæˆ** - ä¸ºç»„åˆå›¾åƒæ£€ç´¢(CIR)ä»»åŠ¡è‡ªåŠ¨ç”Ÿæˆå¤§è§„æ¨¡é«˜è´¨é‡ä¸‰å…ƒç»„è®­ç»ƒæ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **LLM + T2I + MLLMä¸‰é˜¶æ®µPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªåˆ©ç”¨ç”Ÿæˆæ¨¡å‹è‡ªåŠ¨æ„å»ºé«˜è´¨é‡CIRä¸‰å…ƒç»„çš„å®Œæ•´pipelineï¼Œä¸‰å…ƒç»„åŒ…å«å‚è€ƒå›¾åƒã€ç›®æ ‡å›¾åƒå’Œç›¸å¯¹æè¿°
      - **ä¸‰é˜¶æ®µç”ŸæˆPipeline**:
        1. **å¤šæ ·åŒ–å››å…ƒç»„ç”Ÿæˆï¼ˆStage 1ï¼‰**:
           - **LLM**: Qwen2.5-32B
           - **æŒ‡ä»¤æ¨¡æ¿**: åŒ…å«å»ºè®®å¯¹è±¡ã€ç¼–è¾‘æ“ä½œã€å›¾åƒé£æ ¼ä¸‰å¤§è¦ç´ 
           - **è¾“å‡º**: æ–‡æœ¬å››å…ƒç»„ (C_Ir, C_It, C_râ†’t, C_tâ†’r)
             - C_Ir: å‚è€ƒå›¾åƒæè¿°
             - C_It: ç›®æ ‡å›¾åƒæè¿°
             - C_râ†’t: ä»å‚è€ƒåˆ°ç›®æ ‡çš„ç›¸å¯¹æè¿°ï¼ˆä¿®æ”¹æè¿°ï¼‰
             - C_tâ†’r: ä»ç›®æ ‡åˆ°å‚è€ƒçš„é€†å‘æè¿°ï¼ˆæ”¯æŒåŒå‘ä¸‰å…ƒç»„æ„å»ºï¼‰
           - **å¤šæ ·æ€§ç­–ç•¥**:
             - 6å¥—é¢„å®šä¹‰æŒ‡ä»¤é›†ï¼ŒLLMéšæœºé€‰æ‹©
             - è¦†ç›–å¸¸è§å¯¹è±¡ã€ç¼–è¾‘æ“ä½œï¼ˆå¯¹è±¡æ›¿æ¢ã€åœºæ™¯å˜æ¢ã€æ•°é‡å˜åŒ–ã€è§†è§’è½¬æ¢ç­‰ï¼‰
             - åµŒå…¥é£æ ¼ä¿¡æ¯ï¼Œæ”¯æŒå¤šé¢†åŸŸå›¾åƒç”Ÿæˆ
        2. **ä¸€è‡´å›¾åƒå¯¹åˆæˆï¼ˆStage 2ï¼‰**:
           - **å…³é”®æ´å¯Ÿ**: ç‹¬ç«‹ç”Ÿæˆä¸¤å¼ å›¾åƒä¼šå¯¼è‡´è§†è§‰å·®å¼‚ä¸å¯æ§ï¼Œä½†T2Iæ¨¡å‹æ“…é•¿ä¿æŒå›¾åƒå†…ä¸€è‡´æ€§
           - **ç­–ç•¥**: å°†C_Irå’ŒC_Itåˆå¹¶ä¸ºå•ä¸ªpromptï¼Œç”ŸæˆåŒ…å«ä¸¤ä¸ªè¯­ä¹‰ç›¸å…³å­å›¾çš„å›¾åƒ
           - **T2Iæ¨¡å‹**: Flux.1-devï¼ˆä½¿ç”¨æ–¹å½¢ç½‘æ ¼å¸ƒå±€æ¨¡æ¿ï¼‰
           - **å›¾åƒè£å‰ª**: å°†ç”Ÿæˆçš„å›¾åƒåˆ†åˆ«è£å‰ªä¸ºå‚è€ƒå›¾åƒI_rå’Œç›®æ ‡å›¾åƒI_t
           - **ä¼˜åŠ¿**: ç¡®ä¿I_rå’ŒI_tå…±äº«è‡³å°‘ä¸€ä¸ªè¯­ä¹‰å®ä½“ï¼ŒåŒæ—¶ä¿æŒé«˜åº¦ä¸€è‡´æ€§
        3. **æ•°æ®è¿‡æ»¤ï¼ˆStage 3ï¼‰**:
           - **MLLMè¯„åˆ†**: Qwen2.5-VL-32B
           - **ä¸‰ç»´è¯„åˆ†æ ‡å‡†**:
             a) **å›¾åƒè´¨é‡**: è¯„ä¼°ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œç¾å­¦è´¨é‡
             b) **å›¾åƒ-æè¿°ä¿çœŸåº¦**: éªŒè¯å›¾åƒä¸æè¿°çš„ä¸€è‡´æ€§
             c) **CIRä»»åŠ¡å¯¹é½**: ç¡®ä¿ä¸‰å…ƒç»„é€‚åˆCIRä»»åŠ¡ï¼ˆå‚è€ƒ+ä¿®æ”¹â†’ç›®æ ‡ï¼‰
           - **è¿‡æ»¤ç­–ç•¥**: è®¡ç®—åŠ æƒæ€»åˆ†ï¼Œä¸¢å¼ƒåº•éƒ¨15%çš„ä¸‰å…ƒç»„
           - **ç»“æœ**: ä»594KåŸå§‹ä¸‰å…ƒç»„è¿‡æ»¤è‡³534Ké«˜è´¨é‡ä¸‰å…ƒç»„
      - **ç¼–è¾‘æ“ä½œè¦†ç›–èŒƒå›´**:
        - **å¯¹è±¡å˜æ¢**: æ›¿æ¢ã€æ·»åŠ ã€åˆ é™¤å¯¹è±¡
        - **åœºæ™¯å˜æ¢**: æ›´æ”¹èƒŒæ™¯ã€ç¯å¢ƒ
        - **æ•°é‡å˜åŒ–**: æ”¹å˜å¯¹è±¡æ•°é‡
        - **è§†è§’è½¬æ¢**: ä¸åŒè§’åº¦ã€ä¿¯è§†/å¹³è§†åˆ‡æ¢
        - **å±æ€§ä¿®æ”¹**: é¢œè‰²ã€å¤§å°ã€é£æ ¼å˜åŒ–
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å®Œå…¨è‡ªåŠ¨åŒ–**: æ— éœ€äººå·¥æ ‡æ³¨ï¼Œç«¯åˆ°ç«¯ç”Ÿæˆ
        - **é«˜è´¨é‡å›¾åƒ**: ä½¿ç”¨Flux.1-devç”Ÿæˆé€¼çœŸå›¾åƒ
        - **è¯­ä¹‰ä¸€è‡´æ€§**: é€šè¿‡åˆå¹¶promptç­–ç•¥ç¡®ä¿å›¾åƒå¯¹ä¸€è‡´æ€§
        - **å¤šæ ·æ€§**: LLMç”Ÿæˆæ¶µç›–å¤šç§å¯¹è±¡ã€ç¼–è¾‘å’Œé£æ ¼çš„ä¸‰å…ƒç»„
        - **å¯æ‰©å±•æ€§**: å¯æ ¹æ®éœ€æ±‚è°ƒæ•´æŒ‡ä»¤æ¨¡æ¿å’Œè¿‡æ»¤é˜ˆå€¼
  - **CIRHSæ•°æ®é›†**:
      - **è§„æ¨¡**: 534Ké«˜è´¨é‡ä¸‰å…ƒç»„ï¼ˆè¿‡æ»¤åï¼‰
      - **è¦†ç›–èŒƒå›´**: å¤šç§çœŸå®åœºæ™¯å’Œå¯¹è±¡ï¼Œå¤šæ ·åŒ–ç¼–è¾‘æ“ä½œ
      - **æ ¼å¼**: (å‚è€ƒå›¾åƒI_r, ç›¸å¯¹æè¿°C_râ†’t, ç›®æ ‡å›¾åƒI_t)
      - **ç‰¹ç‚¹**: å…‰çœŸå®æ„Ÿå›¾åƒã€ç²¾ç¡®çš„ç¼–è¾‘æè¿°ã€é«˜åº¦çš„å›¾åƒå¯¹ä¸€è‡´æ€§
  - **CoAlignæ¨¡å‹**:
      - **æ¶æ„**: åŸºäºBLIP-2ï¼Œå†»ç»“å›¾åƒç¼–ç å™¨ + è½»é‡çº§Q-Former
      - **åŒé‡å¯¹é½**:
        - **å…¨å±€ä¸Šä¸‹æ–‡å¯¹é½(GCA)**: æ•´ä½“åŒ¹é…ç»„åˆæŸ¥è¯¢ä¸ç›®æ ‡å›¾åƒ
        - **å±€éƒ¨ä¸Šä¸‹æ–‡æ¨ç†(LCR)**: ç»†ç²’åº¦åŒ¹é…ä¿®æ”¹åŒºåŸŸ
      - **è®­ç»ƒ**: åœ¨CIRHSæ•°æ®é›†ä¸Šç«¯åˆ°ç«¯ä¼˜åŒ–
  - **å®éªŒç»“æœ** - **åœ¨ç›‘ç£å’Œé›¶æ ·æœ¬è®¾ç½®ä¸‹å‡è¾¾åˆ°SOTA**:
      - **ç›‘ç£CIRï¼ˆåœ¨CIRHSä¸Šè®­ç»ƒï¼‰**:
        - **CIRR**: R@5 **83.81%**, R_s@1 **80.87%**, Avg **82.34%**ï¼ˆè¶…è¶ŠSPRC +1.69/+0.22/+0.95ï¼‰
        - **FashionIQ**: Avg@10 **54.92%**, Avg@50 **75.55%**ï¼ˆè¶…è¶ŠSPRC +0.20/+0.58ï¼‰
      - **é›¶æ ·æœ¬CIRï¼ˆä»…åœ¨CIRHSä¸Šé¢„è®­ç»ƒï¼‰**:
        - **CIRR**: R@1 **41.17%**, R@5 **71.68%**, Avg **71.17%**ï¼ˆè¶…è¶Šæ‰€æœ‰é›¶æ ·æœ¬æ–¹æ³•ï¼‰
        - **FashionIQ**: Avg@10 **39.11%**, Avg@50 **60.29%**
        - **CIRCO**: mAP@5 **23.47%**, mAP@10 **25.29%**
      - **ä¸å…¶ä»–åˆæˆæ•°æ®é›†å¯¹æ¯”**ï¼ˆ100Kä¸‰å…ƒç»„ï¼‰:
        - **CIRHS**: CIRR R@5 **71.18%**, FashionIQ Avg@10 **37.76%**
        - **ST18M (CompoDiff)**: CIRR R@5 60.00%, FashionIQ Avg@10 30.60%ï¼ˆCIRHS +11.18/+7.16ï¼‰
        - **WebVid-CoVR**: CIRR R@5 67.28%, FashionIQ Avg@10 36.45%ï¼ˆCIRHS +3.90/+1.31ï¼‰
        - **ç»“è®º**: CIRHSæ˜¾è‘—ä¼˜äºç°æœ‰åˆæˆæ•°æ®é›†ï¼Œç”šè‡³ä¼˜äºçœŸå®æ•°æ®é›†WebVid-CoVR
  - **æ¶ˆèå®éªŒå…³é”®å‘ç°**:
      - **ä¸€è‡´æ€§ç”Ÿæˆ vs ç‹¬ç«‹ç”Ÿæˆ**: åˆå¹¶promptç”Ÿæˆï¼ˆCIRR R@5 71.18%ï¼‰æ˜¾è‘—ä¼˜äºç‹¬ç«‹ç”Ÿæˆï¼ˆ70.17%ï¼Œ+1.01%ï¼‰
      - **æ•°æ®è¿‡æ»¤çš„å¿…è¦æ€§**: è¿‡æ»¤åCIRR R@5ä»70.65%æå‡è‡³71.18%ï¼ˆ+0.53%ï¼‰
      - **å…¨å±€+å±€éƒ¨å¯¹é½**: åŒæ—¶ä½¿ç”¨GCAå’ŒLCRæ¯”å•ç‹¬ä½¿ç”¨ITCæå‡2.25% R@5
      - **æ•°æ®è§„æ¨¡å½±å“**: æ€§èƒ½éšæ•°æ®é‡å¢åŠ è€Œæå‡ï¼Œ534Kè¾¾åˆ°æœ€ä½³
  - **æœºæ„**: åŒ—äº¬é‚®ç”µå¤§å­¦ã€å•†æ±¤ç§‘æŠ€
  - **ä½œè€…**: Haiwen Li, Delong Liu, Zhaohui Hou, Zhicheng Zhao, Fei Su
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´7æœˆï¼ˆv3ï¼‰
  - **æ„ä¹‰**:
      - **è‡ªåŠ¨åŒ–çªç ´**: é¦–ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–çš„é«˜è´¨é‡CIRä¸‰å…ƒç»„ç”Ÿæˆpipelineï¼Œæ— éœ€äººå·¥æ ‡æ³¨
      - **è´¨é‡è¶…è¶Š**: åˆæˆæ•°æ®è´¨é‡è¶…è¶Šå¤šä¸ªçœŸå®æ•°æ®é›†å’Œå…¶ä»–åˆæˆæ–¹æ³•
      - **ä¸€è‡´æ€§ä¿è¯**: åˆ›æ–°çš„åˆå¹¶promptç­–ç•¥ç¡®ä¿å›¾åƒå¯¹è¯­ä¹‰ä¸€è‡´æ€§
      - **SOTAæ€§èƒ½**: åœ¨ç›‘ç£å’Œé›¶æ ·æœ¬CIRä»»åŠ¡ä¸Šå‡è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½
      - **å¯æ‰©å±•æ€§**: å¯å¿«é€Ÿç”Ÿæˆå¤§è§„æ¨¡é«˜è´¨é‡CIRè®­ç»ƒæ•°æ®ï¼Œé™ä½æ•°æ®æ ‡æ³¨æˆæœ¬
  

</details>
---

<details>
<summary>
<b><b><a href="https://aclanthology.org/2024.findings-emnlp.759/">ğŸ“„ SMMQG</a></b><br>
<code>Paper</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **Focus**: **Synthetic Multimodal Question Generation** - Generating style and modality-controllable evaluation datasets for Multimodal Retrieval Augmented Generation (MMRAG) systems
  - **Data Synthesis Method** - **Retriever + LLM + LMM Collaborative Generation Pipeline**:
      - **Core Innovation**: First framework for controllable synthetic multimodal QA data generation with fine-grained control over question styles and modalities, without human annotation
      - **Five-Step Generation Pipeline**:
        1. **Seed Source Sampling**:
           - Sample seed source s_seed from multimodal sources S (text passages, tables, images)
           - Use weighted sampling to avoid outliers: w_i based on semantic similarity to k-nearest neighbors (E5-Large embeddings)
           - Ensures thematic coherence of generated questions
        2. **Entity Extraction**:
           - Use GPT-4-Turbo to extract prominent entities from seed source (e.g., "tennis", "Japan", "machine learning")
           - For image sources, use image verbalization and image caption
           - High temperature (1.0) improves entity diversity, enhancing question diversity
        3. **Candidate Source Retrieval**:
           - Use extracted entity as query to retrieve candidate source set ZÌƒ
           - Retrieve appropriate number of sources per modality based on modality requirements M (e.g., M=[1,2,0] means 1 text + 2 tables)
           - Text/tables use E5-Large, images use image verbalization for text-based retrieval
        4. **Question Generation**:
           - **Input**: Candidate sources ZÌƒ, question style description v, modality requirements M, 3 style-specific few-shot examples
           - **Model**: GPT-4-Turbo (text/tables) or GPT-4-Turbo with Vision (with images)
           - **Task**: Select question sources ZâŠ†ZÌƒ, generate question q and answer a, output source references
           - **Prompt Design**: Explicitly require questions must be based on selected sources, follow style description, not answerable if any selected source is removed
        5. **Verification Step**:
           - Verify question adheres to specified style
           - Verify answer can be inferred from question sources
           - Use GPT-4-Turbo for binary Pass/Fail judgment
      - **Five Question Styles**:
        1. **Information Extraction**: Extract and return information from single source
        2. **Compare Contrast**: Compare two closely related entities or topics
        3. **Numerical**: Numerical calculations based on numbers from sources
        4. **Compound**: Two loosely connected information extraction questions separated by "and"
        5. **Multi-hop**: Requires resolving implicit sub-question first, then resolving full question
      - **Multi-hop Question Special Generation**:
        - First generate two intermediate questions: question 1 about entity, question 2 with entity as answer
        - Use LLM to combine intermediate questions and answers into multi-hop question
        - Cross-modal multi-hop: split candidate sources by modality; unimodal multi-hop: random split
      - **Modality Support**: Text, tables, images and all pairwise combinations (9 modality combinations)
      - **Image Processing Strategy**:
        - **Image Verbalization**: Use LLaVA-13B to generate image descriptions, enabling text-based models to retrieve and reason over images
        - **Triplet Representation**: Image source = (image itself, image caption, image verbalization)
      - **Key Technical Advantages**:
        - **Style Control**: Precise control over question types through style description v and few-shot examples
        - **Modality Control**: Precise control over source type combinations through modality requirements M
        - **No Human Annotation**: Fully automated generation without crowdsourcing
        - **Scalability**: Applicable to any multimodal document collection
        - **Domain Customization**: Achieve domain-specific data generation by controlling source documents
  - **Data Scale**:
      - **Wikipedia QA Dataset**: 1024 QA pairs, 5 styles, 9 modality combinations
      - **Biology Dataset**: Additional college biology textbook dataset (demonstrates domain customization capability)
  - **Human Study Results** - **Quality On Par with Crowdsourced Benchmark MMQA**:
      - **Question Fluency (1-5 scale)**: SMMQG **4.53** vs MMQA 3.68 (+0.85, p<0.001*)
      - **Style Faithfulness (%)**: SMMQG **98.3%** vs MMQA 96.7% (+1.6%)
      - **Source Relevance (%)**: SMMQG **93.0%** vs MMQA 85.8% (+7.2%)
      - **Answerability (%)**: SMMQG **94.7%** vs MMQA 85.8% (+8.9%, p=0.02*)
      - **Answer Correctness (%)**: SMMQG **92.7%** vs MMQA 80.0% (+12.7%, p=0.001*)
  - **Model Evaluation Experiments** - **Reveals Style and Modality-Specific Performance Insights**:
      - **Retriever Evaluation** (Recall@5):
        - **E5-Large**: Best performance across all modalities (pure text 98.8%, text-text 91.5%)
        - **OpenCLIP**: Best for pure image retrieval (84.0%)
        - **BM25**: Poor performance on non-text modalities
      - **QA Model Evaluation** (GPT-4-Turbo-judge scores):
        - **GPT-4-Turbo**: Overall leader (info extraction 99.3%, multi-hop 96.2%)
        - **Claude-3-Opus**: Second best (info extraction 96.1%, multi-hop 88.7%)
        - **Open-source models**: Vicuna-13b+LLaVA-13b performs best among open-source
      - **Style-Specific Insights**:
        - All models struggle with **compare contrast** and **numerical** tasks
        - **Multi-hop reasoning** challenging for most models
        - **Information extraction** relatively easy, most models perform well
      - **Modality-Specific Insights**:
        - Pure text tasks show best performance
        - **Table QA** challenging for all models
        - Gemini Pro 1.0 excels at image reasoning (pure image 97.0%)
  - **Dataset Concordance Validation** (Kendall's tau):
      - **Retrieval**: Ï„=0.87 (p=0.02*) - Strong concordance between SMMQG and MMQA
      - **QA**: Ï„=0.86 (p=0.002*) - SMMQG can replace MMQA for model selection
      - **Conclusion**: SMMQG dataset can be used in place of MMQA for model evaluation and selection
  - **Key Findings**:
      - **Evaluation Data Quality**: SMMQG-generated synthetic data quality comparable to human crowdsourced data (sometimes even superior)
      - **Style Sensitivity**: MMRAG performance highly dependent on question style, requiring style-specific evaluation data
      - **Modality Sensitivity**: Both retrieval and QA performance significantly depend on input modality combinations
      - **Automated Evaluation**: Enables large-scale, customized MMRAG system evaluation
  - **Institution**: C3 AI, Connectly AI, Carnegie Mellon University
  - **Authors**: Ian Wu, Sravan Jayanthi, Vijay Viswanathan, Simon Rosenberg, Sina Pakazad, Tongshuang Wu, Graham Neubig
  - **Publication**: EMNLP 2024 Findings
  - **Paper Link**: [ACL Anthology](https://aclanthology.org/2024.findings-emnlp.759/)
  - **Significance**:
      - **Evaluation Data Generation**: First controllable synthetic multimodal QA data generation framework, addressing evaluation data scarcity
      - **Quality Validation**: Human study proves synthetic data quality reaches crowdsourcing level
      - **Performance Insights**: Reveals model strengths and weaknesses on specific styles and modalities, unobtainable through mixed benchmarks
      - **Scalability**: Fully automated process enables rapid customized evaluation data generation for new domains or requirements
      - **Cost Efficiency**: No expensive human annotation required, reducing evaluation dataset construction costs
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2311.10774">ğŸ“„ MMC</a></b><br>
<code>arXiv 2311.10774</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-è…¾è®¯AIå®éªŒå®¤-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡å›¾è¡¨ç†è§£æŒ‡ä»¤è°ƒä¼˜** - ä¸ºå›¾è¡¨å›¾åƒç†è§£ä»»åŠ¡åˆ›å»ºå¤§è§„æ¨¡å¤šä»»åŠ¡æŒ‡ä»¤æ•°æ®é›†ï¼Œæ˜¾è‘—æå‡LMMåœ¨å›¾è¡¨ç†è§£ä¸Šçš„èƒ½åŠ›
  - **æ•°æ®åˆæˆæ–¹æ³•** - **GPT-4é©±åŠ¨çš„å¤šä»»åŠ¡å›¾è¡¨æŒ‡ä»¤ç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªå¤§è§„æ¨¡ï¼ˆ60ä¸‡ï¼‰å¤šä»»åŠ¡å›¾è¡¨ç†è§£æŒ‡ä»¤æ•°æ®é›†ï¼Œæ¶µç›–9ç§ä¸åŒä»»åŠ¡ç±»å‹ï¼Œé€šè¿‡GPT-4ç”Ÿæˆé«˜è´¨é‡æŒ‡ä»¤-ç­”æ¡ˆå¯¹
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰å¼€æºLMMåœ¨å›¾è¡¨ç†è§£ä¸Šè¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå›¾è¡¨å›¾åƒä¸è‡ªç„¶åœºæ™¯å›¾åƒå·®å¼‚å·¨å¤§
        - ç°æœ‰å›¾è¡¨QAæ•°æ®é›†è§„æ¨¡å°ã€ä»»åŠ¡å•ä¸€ã€ä¾èµ–æ¨¡æ¿ç”Ÿæˆæˆ–å›ºå®šè¯æ±‡è¡¨ç­”æ¡ˆ
        - ç¼ºä¹å…¨é¢çš„å›¾è¡¨ç†è§£è¯„ä¼°åŸºå‡†
      - **å››é˜¶æ®µæ•°æ®æ„å»ºPipeline**:
        1. **å›¾è¡¨-æ–‡æœ¬å¯¹é½æ•°æ®æ”¶é›†ï¼ˆ210Kï¼‰**:
           - **æ•°æ®æ¥æº**: æ”¶é›†210Kå›¾è¡¨-æ ‡é¢˜å¯¹ç”¨äºè§†è§‰-æ–‡æœ¬å¯¹é½è®­ç»ƒ
           - **æ¥æº**: ç°æœ‰å…¬å¼€æ•°æ®é›†ï¼ˆFigureQAã€DVQAã€PlotQAã€ChartQAã€SciGraphQAç­‰ï¼‰
           - **æ ¼å¼è½¬æ¢**: å°†ä¸åŒæ•°æ®é›†çš„æ ‡æ³¨ç»Ÿä¸€è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
           - **ç›®çš„**: å¸®åŠ©æ¨¡å‹å­¦ä¹ å›¾è¡¨çš„åŸºæœ¬è§†è§‰-è¯­è¨€å¯¹é½
        2. **å›¾è¡¨ä¿¡æ¯æå–ä¸æ¨ç†ä»»åŠ¡ç”Ÿæˆ**:
           - **å›¾åƒæ¥æº**: ChartQAå’ŒStatista.comçš„é«˜è´¨é‡å›¾è¡¨
           - **GPT-4ç”Ÿæˆ**: åŸºäºå›¾è¡¨æè¿°ï¼ˆæ ‡é¢˜ã€åæ ‡è½´ã€æ•°æ®èŒƒå›´ç­‰ï¼‰ï¼Œä½¿ç”¨GPT-4ç”Ÿæˆå¤šæ ·åŒ–é—®é¢˜-ç­”æ¡ˆå¯¹
           - **ä»»åŠ¡ç±»å‹**:
             - **å›¾è¡¨ä¿¡æ¯æå–**: æå–æ ‡é¢˜ã€åæ ‡å€¼ã€èŒƒå›´ã€æ•°æ®æ¨¡å¼ç­‰è¯¦ç»†ä¿¡æ¯
             - **å›¾è¡¨æ¨ç†**: å…³äºè¶‹åŠ¿ã€æ•°æ®æ¨¡å¼å’Œæ´å¯Ÿåˆ†æçš„æ¨ç†é—®é¢˜
           - **Promptè®¾è®¡**: è¦æ±‚ç”Ÿæˆ3ä¸ªä¸åŒé—®é¢˜ï¼Œæ¯ä¸ªç­”æ¡ˆå°‘äº20å­—ï¼Œç¡®ä¿å¤šæ ·æ€§
           - **è§„æ¨¡**: 330ä¸ªä¿¡æ¯æå–æ ·æœ¬ï¼Œ256ä¸ªæ¨ç†æ ·æœ¬
        3. **ç§‘å­¦å›¾è¡¨ç†è§£ä»»åŠ¡ç”Ÿæˆ**:
           - **æ•°æ®æ¥æº**: arXivç§‘å­¦è®ºæ–‡ä¸­çš„å›¾è¡¨
           - **å¤šè½®å¯¹è¯æ„å»º**: ä½¿ç”¨GPT-4ç”Ÿæˆå¤šè½®å›¾è¡¨ç›¸å…³å¯¹è¯
           - **ä»»åŠ¡ç±»å‹**:
             - **ä¸Šä¸‹æ–‡å›¾è¡¨ç†è§£**: ç†è§£å›¾è¡¨åœ¨ç§‘å­¦æ–‡çŒ®ä¸­çš„ä½œç”¨å’Œæ„ä¹‰
             - **å¤šå›¾è¡¨ç†è§£**: ç†è§£åŒä¸€æ–‡çŒ®ä¸­å¤šä¸ªç›¸å…³å›¾è¡¨çš„å…³ç³»
           - **è´¨é‡æ§åˆ¶**: ä½¿ç”¨å¯å‘å¼è§„åˆ™åˆ é™¤éå›¾è¡¨ç›¸å…³é—®é¢˜ï¼Œç¡®ä¿é—®é¢˜èšç„¦äºå›¾è¡¨å†…å®¹
           - **è§„æ¨¡**: 56ä¸ªä¸Šä¸‹æ–‡ç†è§£æ ·æœ¬ï¼Œ52ä¸ªå¤šå›¾è¡¨ç†è§£æ ·æœ¬
        4. **ç»“æ„åŒ–ä»»åŠ¡ä¸åˆ†ç±»ä»»åŠ¡ç”Ÿæˆ**:
           - **å›¾è¡¨è½¬æ•°æ®è¡¨/JSON**:
             - ä½¿ç”¨VisTextæ•°æ®é›†çš„çœŸå®æ•°æ®è¡¨
             - è½¬æ¢ä¸ºJSONæ ¼å¼ï¼ˆGPT-4è¾…åŠ©ï¼‰
             - ä»»åŠ¡: å°†å›¾è¡¨è§†è§‰ä¿¡æ¯è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®æ ¼å¼
             - è§„æ¨¡: 400ä¸ªæ•°æ®è¡¨æ ·æœ¬ï¼Œ96ä¸ªJSONæ ·æœ¬
           - **å›¾è¡¨ç±»å‹/ä¸»é¢˜åˆ†ç±»**:
             - ç½‘ç»œçˆ¬å–çš„å¤šæ ·åŒ–å›¾è¡¨
             - ä½¿ç”¨çœŸå®æ ‡ç­¾ä½œä¸ºç­”æ¡ˆ
             - è§„æ¨¡: 360ä¸ªç±»å‹åˆ†ç±»æ ·æœ¬ï¼Œ536ä¸ªä¸»é¢˜åˆ†ç±»æ ·æœ¬
           - **è‚¡ç¥¨å›¾è¡¨åˆ†æ**:
             - ä½¿ç”¨Google Bardå’Œæ¥æºæ–‡ç« ç”Ÿæˆåˆ†æé—®é¢˜
             - è§„æ¨¡: 40ä¸ªæ ·æœ¬
      - **äººå·¥è´¨é‡æ§åˆ¶**:
        - è¿‡æ»¤ç­”æ¡ˆé•¿åº¦è¶…è¿‡20å­—çš„æ ·æœ¬
        - åˆ é™¤æåŠ"ç»™å®šæ ‡é¢˜"ã€"ç°æœ‰æè¿°"ç­‰ä¸å¿…è¦å†…å®¹çš„æ ·æœ¬
        - Chart-to-Jsonä»»åŠ¡ï¼šåˆ é™¤æœªæåŠ"title"ä½œä¸ºkeyçš„æ ·æœ¬
        - éšæœºæŠ½æ ·500ä¸ªæ ·æœ¬è¿›è¡Œäººå·¥è¯„ä¼°ï¼Œç¡®ä¿è´¨é‡
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å¤šä»»åŠ¡è¦†ç›–**: 9ç§ä¸åŒä»»åŠ¡ç±»å‹ï¼Œå…¨é¢è¯„ä¼°å›¾è¡¨ç†è§£èƒ½åŠ›
        - **é«˜è´¨é‡ç”Ÿæˆ**: GPT-4ç”Ÿæˆçš„æŒ‡ä»¤-ç­”æ¡ˆå¯¹è‡ªç„¶æµç•…ï¼Œç¬¦åˆäººç±»è®¤çŸ¥
        - **å¼€æ”¾å¼ç­”æ¡ˆ**: å¹³å‡ç­”æ¡ˆé•¿åº¦23.7å­—ï¼Œè¿œè¶…ç°æœ‰æ•°æ®é›†çš„1-2å­—å›ºå®šç­”æ¡ˆ
        - **çœŸå®å›¾è¡¨**: ä½¿ç”¨çœŸå®ç½‘ç»œå›¾è¡¨å’Œç§‘å­¦è®ºæ–‡å›¾è¡¨ï¼Œéåˆæˆæ•°æ®
        - **å¯æ‰©å±•æ€§**: Pipelineå¯åº”ç”¨äºä»»ä½•å›¾è¡¨æ•°æ®é›†
  - **MMC-Instructionæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 600Kå›¾è¡¨æŒ‡ä»¤æ•°æ®
      - **ä»»åŠ¡åˆ†å¸ƒ**ï¼ˆ9ç§ä»»åŠ¡ï¼‰:
        1. **å›¾è¡¨ä¿¡æ¯æå–**: 330ä¸ªæ ·æœ¬ï¼ˆæå–æ ‡é¢˜ã€åæ ‡ã€èŒƒå›´ç­‰ï¼‰
        2. **å›¾è¡¨æ¨ç†**: 256ä¸ªæ ·æœ¬ï¼ˆè¶‹åŠ¿åˆ†æã€æ•°æ®æ¨¡å¼è¯†åˆ«ï¼‰
        3. **ä¸Šä¸‹æ–‡å›¾è¡¨ç†è§£**: 56ä¸ªæ ·æœ¬ï¼ˆç§‘å­¦æ–‡çŒ®ä¸­çš„å›¾è¡¨ä½œç”¨ï¼‰
        4. **å¤šå›¾è¡¨ç†è§£**: 52ä¸ªæ ·æœ¬ï¼ˆå¤šå›¾è¡¨å…³ç³»ç†è§£ï¼‰
        5. **å›¾è¡¨ç±»å‹åˆ†ç±»**: 360ä¸ªæ ·æœ¬ï¼ˆè¯†åˆ«æ¡å½¢å›¾ã€æŠ˜çº¿å›¾ã€é¥¼å›¾ç­‰ï¼‰
        6. **å›¾è¡¨ä¸»é¢˜åˆ†ç±»**: 536ä¸ªæ ·æœ¬ï¼ˆè¯†åˆ«ä¸šåŠ¡ã€å¥åº·ã€æ—…æ¸¸ç­‰ä¸»é¢˜ï¼‰
        7. **å›¾è¡¨è½¬æ•°æ®è¡¨**: 400ä¸ªæ ·æœ¬ï¼ˆå°†å›¾è¡¨è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼ï¼‰
        8. **å›¾è¡¨è½¬JSON**: 96ä¸ªæ ·æœ¬ï¼ˆå°†å›¾è¡¨è½¬æ¢ä¸ºJSONæ ¼å¼ï¼‰
        9. **è‚¡ç¥¨å›¾è¡¨åˆ†æ**: 40ä¸ªæ ·æœ¬ï¼ˆåˆ†æè‚¡ç¥¨å›¾è¡¨è¶‹åŠ¿ï¼‰
      - **æ•°æ®ç‰¹ç‚¹**:
        - **å¤šæ ·åŒ–å›¾è¡¨ç±»å‹**: æ¡å½¢å›¾ã€ç›´æ–¹å›¾ã€æŠ˜çº¿å›¾ã€æ•£ç‚¹å›¾ã€çƒ­å›¾ç­‰
        - **ä¸°å¯Œä¸»é¢˜**: å•†ä¸šã€å¥åº·ã€ç”Ÿç‰©ã€å·¥ç¨‹ã€ä½“è‚²ã€æ—…æ¸¸ç­‰
        - **å¼€æ”¾å¼ç­”æ¡ˆ**: å¹³å‡23.7å­—ï¼Œè‡ªç”±å½¢å¼å›ç­”
        - **å›¾åƒæ¥æº**: Statista.comã€arXivã€VisTextã€ç½‘ç»œçˆ¬å–
  - **MMC-Benchmarkè¯„ä¼°åŸºå‡†**:
      - **è§„æ¨¡**: 2,126ä¸ªé«˜è´¨é‡æµ‹è¯•æ ·æœ¬
      - **å›¾åƒæ•°é‡**: 1,063ä¸ªå”¯ä¸€å›¾åƒ
      - **é—®é¢˜ç±»å‹**:
        - **å¤šé€‰é¢˜(MQA)**: 1,275ä¸ªé—®é¢˜
        - **è‡ªç”±å›ç­”**: 851ä¸ªé—®é¢˜
      - **å¹³å‡é—®é¢˜é•¿åº¦**: 15.6å­—
      - **è¯„ä¼°æ–¹æ³•**:
        1. **ç”Ÿæˆèƒ½åŠ›è¯„ä¼°**: ä½¿ç”¨GPT-4è¯„ä¼°è‡ªç”±å›ç­”çš„å‡†ç¡®æ€§ï¼ˆ0.90 Cohen's kappaäººç±»ä¸€è‡´æ€§ï¼‰
        2. **ç†è§£èƒ½åŠ›è¯„ä¼°**: ä½¿ç”¨å¤šé€‰é¢˜ç›´æ¥è®¡ç®—å‡†ç¡®ç‡ï¼Œæ— éœ€GPT-4
      - **æ•°æ®æ¥æº**: Statista.comã€arXivç§‘å­¦è®ºæ–‡ã€VisTextã€ç½‘ç»œçˆ¬å–
      - **äººå·¥éªŒè¯**: æ‰€æœ‰æ ·æœ¬ç»è¿‡äººå·¥è´¨é‡æ£€æŸ¥
  - **MMCAæ¨¡å‹ï¼ˆMultiModal Chart Assistantï¼‰**:
      - **æ¶æ„**:
        - è§†è§‰ç¼–ç å™¨: ViT-Lï¼ˆ0.3Bå‚æ•°ï¼‰
        - è¯­è¨€æ¨¡å‹: Vicuna-7Bï¼ˆä½¿ç”¨LoRAå¾®è°ƒï¼‰
        - è§†è§‰æŠ½è±¡å™¨: å¯å­¦ä¹ çš„query tokens
      - **ä¸¤é˜¶æ®µè®­ç»ƒ**:
        - **é˜¶æ®µ1**: å›¾è¡¨-æ–‡æœ¬å¯¹é½ï¼ˆå†»ç»“LLMï¼Œè®­ç»ƒè§†è§‰æŠ½è±¡å™¨ï¼‰
        - **é˜¶æ®µ2**: å›¾è¡¨æŒ‡ä»¤è°ƒä¼˜ï¼ˆLoRAå¾®è°ƒLLMï¼Œåœ¨MMC-Instructionä¸Šè®­ç»ƒ3ä¸ªepochï¼‰
      - **è®­ç»ƒè®¾ç½®**: Tesla V100 GPU
  - **å®éªŒç»“æœ** - **åœ¨å›¾è¡¨ç†è§£ä»»åŠ¡ä¸Šè¾¾åˆ°å¼€æºSOTA**:
      - **MMC-Benchmarkè¡¨ç°**ï¼ˆç”Ÿæˆèƒ½åŠ›è¯„ä¼°ï¼ŒGPT-4è¯„åˆ†ï¼‰:
        - **MMCA**: æ€»ä½“å‡†ç¡®ç‡**26%**ï¼Œè¶…è¶Šæ‰€æœ‰å¼€æºæ¨¡å‹
        - **LLaVA-1.5**: 24%ï¼ˆç¬¬äºŒåï¼‰
        - **MiniGPT-v2**: 21%
        - **mPLUG-Owl**: 20%
        - **GPT-4V**: **51%**ï¼ˆè¿œè¶…å¼€æºæ¨¡å‹ï¼Œä½†åœ¨Chart-to-Datatableå’ŒChart-to-Jsonä»»åŠ¡ä¸Šä»æœ‰æŒ‘æˆ˜ï¼‰
      - **MMC-Benchmarkè¡¨ç°**ï¼ˆç†è§£èƒ½åŠ›è¯„ä¼°ï¼ŒMQAå‡†ç¡®ç‡ï¼‰:
        - **MMCA**: æ€»ä½“å‡†ç¡®ç‡**56%**ï¼Œè¶…è¶Šæ‰€æœ‰å¼€æºæ¨¡å‹
        - **LLaVA-1.5**: 51%
        - **å›¾è¡¨è½¬æ•°æ®è¡¨**: MMCA **64%** vs å…¶ä»–æ¨¡å‹â‰¤57%
        - **å›¾è¡¨è½¬JSON**: MMCA **59%** vs å…¶ä»–æ¨¡å‹â‰¤51%
      - **ç°æœ‰åŸºå‡†è¡¨ç°**:
        - **ChartQA**: **57.4%**ï¼ˆè¶…è¶ŠLLaVA-1.5çš„51.4%ï¼‰
        - **DocVQA**: **72.5%**ï¼ˆä¸LLaVA-1.5çš„72.8%ç›¸å½“ï¼‰
        - **TextVQA**: **59.6%**ï¼ˆè¶…è¶ŠLLaVA-1.5çš„58.2%ï¼‰
      - **æ¶ˆèå®éªŒ**:
        - ä¸å¾®è°ƒè§†è§‰ç¼–ç å™¨çš„MMCAæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆChartQA: 54.2% vs 57.4%ï¼‰
        - è¯æ˜å¾®è°ƒè§†è§‰ç¼–ç å™¨å¯¹å›¾è¡¨ç†è§£è‡³å…³é‡è¦
  - **é”™è¯¯åˆ†æ**ï¼ˆ100ä¸ªGPT-4Vé”™è¯¯æ ·æœ¬åˆ†æï¼‰:
      - **è¯­è¨€åè§ï¼ˆ35%ï¼‰**: å¼ºå¤§çš„è¯­è¨€å…ˆéªŒçŸ¥è¯†è¯¯å¯¼æ¨¡å‹ï¼Œå¿½ç•¥è§†è§‰è¾“å…¥
      - **è§†è§‰æ„ŸçŸ¥é”™è¯¯ï¼ˆ29.6%ï¼‰**: ç°æœ‰è§†è§‰ç¼–ç å™¨ï¼ˆCLIPï¼‰å¯¹å›¾è¡¨ç†è§£èƒ½åŠ›è¾ƒå¼±ï¼Œå› ä¸ºCLIPä¸»è¦è®­ç»ƒäºè‡ªç„¶å›¾åƒ
      - **æ¨ç†é”™è¯¯ï¼ˆ18.9%ï¼‰**: å¤æ‚æ¨ç†ä»»åŠ¡å¤±è´¥
      - **ä¸éµå¾ªæŒ‡ä»¤ï¼ˆ16.5%ï¼‰**: å¤§å¤šæ•°å¼€æºæ¨¡å‹æ— æ³•è‰¯å¥½éµå¾ªäººç±»æŒ‡ä»¤
  - **æœºæ„**: University of Maryland College Park, Tencent AI Lab Bellevue
  - **ä½œè€…**: Fuxiao Liu, Xiaoyang Wang, Wenlin Yao, Jianshu Chen, Kaiqiang Song, Sangwoo Cho, Yaser Yacoob, Dong Yu
  - **å‘å¸ƒæ—¶é—´**: arXiv 2023å¹´11æœˆï¼ˆv2ï¼‰
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2311.10774](https://arxiv.org/abs/2311.10774)
  - **æ„ä¹‰**:
      - **æ•°æ®è´¡çŒ®**: é¦–ä¸ªå¤§è§„æ¨¡ï¼ˆ60ä¸‡ï¼‰å¤šä»»åŠ¡å›¾è¡¨ç†è§£æŒ‡ä»¤æ•°æ®é›†ï¼Œå¡«è¡¥å›¾è¡¨ç†è§£è®­ç»ƒæ•°æ®ç©ºç™½
      - **è¯„ä¼°åŸºå‡†**: æä¾›å…¨é¢çš„å›¾è¡¨ç†è§£è¯„ä¼°åŸºå‡†ï¼ˆMMC-Benchmarkï¼‰ï¼Œæ¶µç›–9ç§ä»»åŠ¡ç±»å‹
      - **å¼€æºæ¨¡å‹æå‡**: è¯æ˜é€šè¿‡é«˜è´¨é‡æŒ‡ä»¤æ•°æ®ï¼Œå¼€æºæ¨¡å‹å¯æ˜¾è‘—æå‡å›¾è¡¨ç†è§£èƒ½åŠ›
      - **é”™è¯¯æ´å¯Ÿ**: ç³»ç»ŸåŒ–åˆ†æå¼€æºå’Œé—­æºæ¨¡å‹åœ¨å›¾è¡¨ç†è§£ä¸Šçš„é”™è¯¯ç±»å‹ï¼Œä¸ºæœªæ¥æ”¹è¿›æŒ‡æ˜æ–¹å‘
      - **å¯æ‰©å±•æ€§**: Pipelineå¯åº”ç”¨äºå…¶ä»–é¢†åŸŸç‰¹å®šçš„å›¾åƒç†è§£ä»»åŠ¡
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2411.19930">ğŸ“„ AdaMLLM</a></b><br>
<code>arXiv 2411.19930</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-BIGAI-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **é¢†åŸŸè‡ªé€‚åº”åè®­ç»ƒæ•°æ®åˆæˆ** - ä»…ä½¿ç”¨å¼€æºæ¨¡å‹ï¼Œä¸ºé¢†åŸŸç‰¹å®šçš„å›¾åƒ-captionå¯¹ç”Ÿæˆå¤šæ ·åŒ–è§†è§‰æŒ‡ä»¤ä»»åŠ¡ï¼Œç”¨äºMLLMçš„é¢†åŸŸé€‚é…
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å¼€æºMLLMé©±åŠ¨çš„ç”Ÿæˆ-è¿‡æ»¤Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªä»…ä¾èµ–å¼€æºæ¨¡å‹çš„é¢†åŸŸè‡ªé€‚åº”æŒ‡ä»¤åˆæˆæ–¹æ³•ï¼Œé€šè¿‡ä¸€è‡´æ€§è¿‡æ»¤é¿å…ä¸“å®¶æ ‡æ³¨ï¼Œåˆæˆæ•°æ®æ•ˆæœè¶…è¶Šè§„åˆ™æ–¹æ³•å’Œé—­æºæ¨¡å‹
      - **é—®é¢˜è¯†åˆ«**:
        - é¢†åŸŸç‰¹å®šMLLMè®­ç»ƒæ•°æ®ç¨€ç¼ºï¼Œå°¤å…¶æ˜¯åŒ»å­¦ã€é£Ÿå“ã€é¥æ„Ÿç­‰ä¸“ä¸šé¢†åŸŸ
        - ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥è§„åˆ™æˆ–æ˜‚è´µçš„é—­æºæ¨¡å‹ï¼ˆGPT-4/GPT-4Vï¼‰
        - ä¼ ç»Ÿä¸¤é˜¶æ®µè®­ç»ƒï¼ˆå›¾åƒ-captionå¯¹é½ â†’ è§†è§‰æŒ‡ä»¤å¾®è°ƒï¼‰é™ä½ä»»åŠ¡å¤šæ ·æ€§
      - **ä¸¤é˜¶æ®µæ•°æ®æ„å»ºPipeline**:
        1. **è§†è§‰æŒ‡ä»¤åˆæˆå™¨å¾®è°ƒï¼ˆStage Aï¼‰**:
           - **ç§å­æ•°æ®æ„å»º**:
             - æ±‡èšç°æœ‰å¤šé¢†åŸŸæ•°æ®é›†ï¼Œæ¶µç›–å¤šç§å›¾åƒåŸŸå’Œä»»åŠ¡ç±»å‹
             - åŒ…å«ï¼šå¯¹è±¡è¯†åˆ«ã€é¢†åŸŸåˆ†ç±»ã€æ­¥éª¤å¼•å¯¼ã€æ–‡æœ¬æ£€æµ‹OCRã€ä»»åŠ¡å¯¼å‘è¯†åˆ«ç­‰
             - æ— éœ€é¢å¤–ä¸“å®¶æ ‡æ³¨
           - **ä»»åŠ¡ä¸‰å…ƒç»„æ ¼å¼**:
             - **æŒ‡ä»¤ï¼ˆInstructionï¼‰**: åŸºäºå›¾åƒ-captionå¯¹çš„ä»»åŠ¡æè¿°
             - **ä¿¡æ¯æ€§å›å¤ï¼ˆInformative Responseï¼‰**: åŒ…å«æ¨ç†è¿‡ç¨‹çš„è¯¦ç»†å›ç­”
             - **ç²¾ç¡®å›å¤ï¼ˆPrecise Responseï¼‰**: ç®€æ´çš„æœ€ç»ˆç­”æ¡ˆ
           - **å¾®è°ƒç­–ç•¥**:
             - åŸºç¡€æ¨¡å‹ï¼šLLaVA-v1.6-Llama3-8Bï¼ˆæˆ–å…¶ä»–å¼€æºMLLMï¼‰
             - è¾“å…¥ï¼šå›¾åƒ+caption â†’ è¾“å‡ºï¼šä»»åŠ¡ä¸‰å…ƒç»„
             - **æ¨¡æ€å¹³è¡¡ç­–ç•¥**: å°†10%å›¾åƒæ›¿æ¢ä¸ºç©ºç™½ï¼Œé¼“åŠ±æ¨¡å‹åˆ©ç”¨æ–‡æœ¬captionï¼Œé¿å…è¿‡åº¦ä¾èµ–è§†è§‰è¾“å…¥
             - ä»…åœ¨ä»»åŠ¡ä¸‰å…ƒç»„ç›¸å…³çš„å¯¹è¯è½®æ¬¡ä¸Šè®¡ç®—æŸå¤±
        2. **ç›®æ ‡é¢†åŸŸä»»åŠ¡åˆæˆï¼ˆStage Bï¼‰**:
           - **ä»»åŠ¡ç”Ÿæˆ**: ä½¿ç”¨å¾®è°ƒåçš„åˆæˆå™¨ä¸ºç›®æ ‡é¢†åŸŸçš„å›¾åƒ-captionå¯¹ç”Ÿæˆä»»åŠ¡ä¸‰å…ƒç»„
           - **ä¸€è‡´æ€§è¿‡æ»¤å™¨ï¼ˆConsistency-Based Filterï¼‰**:
             - **æ ¸å¿ƒæ€æƒ³**: ä¸ç›´æ¥éªŒè¯å›å¤å‡†ç¡®æ€§ï¼ˆéœ€è¦ä¸“å®¶çŸ¥è¯†ï¼‰ï¼Œè€Œæ˜¯æ£€æŸ¥ç²¾ç¡®å›å¤ä¸ä¿¡æ¯æ€§å›å¤çš„ä¸€è‡´æ€§
             - **éªŒè¯å·¥å…·**: ä½¿ç”¨Llama-3-8Bè¯„ä¼°ä¸¤ä¸ªå›å¤æ˜¯å¦ä¸€è‡´
             - **åˆ¤æ–­æ ‡å‡†**: Yesï¼ˆä¸€è‡´ï¼‰/ Noï¼ˆä¸ä¸€è‡´ï¼‰/ Openï¼ˆå¼€æ”¾å¼é—®é¢˜ï¼Œå…è®¸å¤šç§è§£é‡Šï¼‰
             - **ä¼˜åŠ¿**: æ˜¾è‘—é™ä½ä¸“å®¶æ ‡æ³¨éœ€æ±‚ï¼Œè¿‡æ»¤åå‡†ç¡®ç‡ä»60-77%æå‡è‡³75-84%
           - **è´¨é‡ä¿è¯**: çº¦30%çš„ä»»åŠ¡ä¸‰å…ƒç»„é€šè¿‡è¿‡æ»¤åä¿ç•™
      - **å•é˜¶æ®µåè®­ç»ƒï¼ˆåˆ›æ–°è®­ç»ƒç­–ç•¥ï¼‰**:
        - **é—®é¢˜**: ä¼ ç»Ÿä¸¤é˜¶æ®µè®­ç»ƒï¼ˆå…ˆå›¾åƒ-captionå¯¹é½ï¼Œå†è§†è§‰æŒ‡ä»¤å¾®è°ƒï¼‰ä¼šé™ä½é¢†åŸŸç‰¹å®šè®­ç»ƒçš„ä»»åŠ¡å¤šæ ·æ€§
        - **è§£å†³æ–¹æ¡ˆ**: åˆå¹¶ä¸ºå•é˜¶æ®µè®­ç»ƒï¼Œæ¯ä¸ªæ ·æœ¬åŒ…å«ä¸¤ä¸ªä»»åŠ¡ï¼š
          - **å›¾åƒCaptioningä»»åŠ¡**: ä½¿ç”¨åŸå§‹captionä½œä¸ºground-truth
          - **åˆæˆè§†è§‰æŒ‡ä»¤ä»»åŠ¡**: ä½¿ç”¨è¿‡æ»¤åçš„ä»»åŠ¡ä¸‰å…ƒç»„
        - **ä¼˜åŠ¿**: åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå•é˜¶æ®µè®­ç»ƒä¼˜äºä¸¤é˜¶æ®µè®­ç»ƒ
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **æ— éœ€é—­æºæ¨¡å‹**: ä»…ä½¿ç”¨å¼€æºMLLMï¼Œæ— éœ€GPT-4/GPT-4V
        - **å‡å°‘ä¸“å®¶æ ‡æ³¨**: ä¸€è‡´æ€§è¿‡æ»¤å™¨é¿å…é€ä¸ªä»»åŠ¡çš„ä¸“å®¶éªŒè¯
        - **ä»»åŠ¡å¤šæ ·æ€§**: åˆæˆçš„æŒ‡ä»¤ç±»å‹ä¸°å¯Œï¼Œæ¶µç›–12ç§ä¸»è¦ä»»åŠ¡ç±»å‹
        - **é¢†åŸŸçŸ¥è¯†åˆ©ç”¨**: ä»å›¾åƒ-captionå¯¹ä¸­æœ‰æ•ˆæå–é¢†åŸŸä¸“ä¸šçŸ¥è¯†
        - **å¯æ‰©å±•æ€§**: Pipelineé€‚ç”¨äºä»»æ„é¢†åŸŸå’Œä»»æ„å¼€æºMLLM
  - **åˆæˆæ•°æ®è§„æ¨¡**ï¼ˆåŸºäºä¸åŒé¢†åŸŸå›¾åƒ-captionæºï¼‰:
      - **ç”Ÿç‰©åŒ»å­¦**:
        - PMCRaw: 150KæŒ‡ä»¤-å›å¤å¯¹ï¼ˆæ¥è‡ªPMC-OAåŸå§‹captionï¼‰
        - PMCRefined: 144KæŒ‡ä»¤-å›å¤å¯¹ï¼ˆæ¥è‡ªLLAVA-Medç²¾ç‚¼captionï¼‰
      - **é£Ÿå“é¢†åŸŸ**:
        - Recipe1M: 32KæŒ‡ä»¤-å›å¤å¯¹ï¼ˆæ¥è‡ªRecipe1Mæ•°æ®é›†ï¼‰
      - **é¥æ„Ÿé¢†åŸŸ**:
        - Remote Sensing: 15KæŒ‡ä»¤-å›å¤å¯¹ï¼ˆæ¥è‡ªå¤šä¸ªé¥æ„Ÿæ•°æ®é›†ï¼‰
  - **AdaMLLMæ¨¡å‹**:
      - **æ”¯æŒçš„åŸºç¡€æ¨¡å‹**: LLaVA-v1.6-8Bã€Qwen2-VL-2Bã€Llama-3.2-11B
      - **è®­ç»ƒæ–¹å¼**: å•é˜¶æ®µåè®­ç»ƒï¼ˆå›¾åƒcaptioning + åˆæˆæŒ‡ä»¤ä»»åŠ¡ï¼‰
      - **è®­ç»ƒæ—¶é•¿**: 13å°æ—¶ï¼ˆ8Ã—A100-80GB GPUsï¼‰
  - **å®éªŒç»“æœ** - **åœ¨æ‰€æœ‰é¢†åŸŸå‡æ˜¾è‘—è¶…è¶ŠåŸºçº¿å’Œä¸“ä¸šæ¨¡å‹**:
      - **ç”Ÿç‰©åŒ»å­¦é¢†åŸŸ**ï¼ˆAdaMLLM-8B from PMCRefinedï¼‰:
        - **SLAKE**: 58.0% (Open) / 73.3% (Closed)ï¼Œè¶…è¶ŠLLaVA-Medï¼ˆ43.4%/50.2%ï¼‰å’ŒPubMedVisionï¼ˆ50.0%/68.3%ï¼‰
        - **PathVQA**: 22.9% (Open) / 78.6% (Closed)ï¼Œè¶…è¶Šæ‰€æœ‰åŸºçº¿
        - **VQA-RAD**: 59.8% (Open) / 81.3% (Closed)
        - **PMC-VQA**: 47.9%ï¼Œè¶…è¶ŠLLaVA-Medï¼ˆ37.1%ï¼‰
      - **é£Ÿå“é¢†åŸŸ**ï¼ˆAdaMLLM-8Bï¼‰:
        - **Recipe1M**: 24.8 Rouge-Lï¼ˆvs. LLaVA-Chef 23.1ï¼‰
        - **Nutrition5K**: 36.1 Recallï¼ˆvs. LLaVA-Chef 29.1ï¼‰
        - **Food101**: 65.3% Accï¼ˆvs. LLaVA-1.6 47.9%ï¼‰
        - **FoodSeg**: 42.0 F1ï¼ˆvs. LLaVA-Chef 14.5ï¼‰
      - **é¥æ„Ÿé¢†åŸŸ**ï¼ˆAdaMLLM-8Bï¼‰:
        - **CLRS**: 66.9% Accï¼ˆvs. LLaVA-1.6 54.3%ï¼‰
        - **UCMerced**: 72.1% Accï¼ˆvs. LLaVA-1.6 64.9%ï¼‰
        - **NWPU**: 47.1 Rouge-Lï¼ˆvs. LLaVA-1.6 26.1ï¼‰
      - **è·¨æ¨¡å‹æ³›åŒ–**: åœ¨Qwen2-VL-2Bå’ŒLlama-3.2-11Bä¸ŠåŒæ ·æœ‰æ•ˆ
  - **åˆæˆæ•°æ®è´¨é‡å¯¹æ¯”** - **è¶…è¶Šè§„åˆ™æ–¹æ³•å’Œé—­æºæ¨¡å‹**:
      - **vs. è§„åˆ™æ–¹æ³•ï¼ˆRule-Basedï¼‰**:
        - ä»»åŠ¡å¤šæ ·æ€§ï¼š68.0 vs. 52.5ï¼ˆ+29.6%ï¼‰
        - é¢†åŸŸçŸ¥è¯†åˆ©ç”¨ï¼š95.0 vs. 72.5ï¼ˆ+31.0%ï¼‰
        - ä»»åŠ¡å¤æ‚åº¦ï¼š77.9 vs. 43.8ï¼ˆ+77.9%ï¼‰
      - **vs. GPT-4ï¼ˆText-onlyï¼‰**:
        - ä»»åŠ¡å¤šæ ·æ€§ï¼š81.0 vs. 75.2
        - å¤æ‚åº¦ï¼š80.0 vs. 75.3
      - **vs. GPT-4Vï¼ˆVision+Textï¼‰**:
        - ä»»åŠ¡å¤šæ ·æ€§ï¼š85.5 vs. 83.2ï¼ˆç›¸å½“ï¼‰
        - å‡†ç¡®ç‡ï¼ˆPMCRefinedï¼‰ï¼š79.6 vs. 87.5ï¼ˆç•¥ä½ä½†å¯æ¥å—ï¼‰
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - **ä¸€è‡´æ€§è¿‡æ»¤å™¨è‡³å…³é‡è¦**: å»é™¤åå‡†ç¡®ç‡ä»58.3%é™è‡³54.2%ï¼ˆç”Ÿç‰©åŒ»å­¦ï¼‰
      - **å•é˜¶æ®µè®­ç»ƒä¼˜äºä¸¤é˜¶æ®µ**: åœ¨8Bå’Œ11Bæ¨¡å‹ä¸Šå¹³å‡æå‡3-5%
      - **æ¨¡æ€å¹³è¡¡ç­–ç•¥æœ‰æ•ˆ**: æ›¿æ¢10%ç©ºç™½å›¾åƒæå‡é²æ£’æ€§
      - **ä»»åŠ¡å¤šæ ·æ€§é‡è¦**: ä»…ä½¿ç”¨åˆæˆä»»åŠ¡ï¼ˆæ— å›¾åƒcaptionï¼‰æ€§èƒ½æ˜¾è‘—ä¸‹é™
  - **ä»»åŠ¡ç±»å‹åˆ†å¸ƒ**ï¼ˆåˆæˆæ•°æ®è¦†ç›–12ç§ä¸»è¦ä»»åŠ¡ï¼‰:
      - ä»»åŠ¡å¯¼å‘å›¾åƒè¯†åˆ«ï¼ˆTask-Oriented Recognitionï¼‰
      - å±æ€§ä¸ä¸Šä¸‹æ–‡è¯†åˆ«ï¼ˆAttribute and Context Recognitionï¼‰
      - å¯¹è±¡è¯†åˆ«ï¼ˆObject Recognitionï¼‰
      - æ•°æ®è¡¨ç¤ºä¸å¯è§†åŒ–ï¼ˆData Representationï¼‰
      - æ­¥éª¤å¼•å¯¼ï¼ˆStep-by-Step Guidanceï¼‰
      - å¼‚å¸¸æ£€æµ‹ï¼ˆAnomaly Detectionï¼‰
      - å›¾åƒ-æ–‡æœ¬åŒ¹é…ï¼ˆImage-Text Matchingï¼‰
      - Captionç”Ÿæˆï¼ˆCaption Generationï¼‰
      - æ–‡æœ¬æ£€æµ‹å’ŒOCRï¼ˆText Detection and OCRï¼‰
      - åœºæ™¯åˆ†ç±»ï¼ˆScene Classificationï¼‰
      - é¢†åŸŸåˆ†ç±»ï¼ˆDomain Classificationï¼‰
      - å§¿æ€ä¸æ´»åŠ¨è¯†åˆ«ï¼ˆPose and Activity Recognitionï¼‰
  - **æœºæ„**: BIGAI, BUAA, THU, BIT, RUC
  - **ä½œè€…**: Daixuan Cheng, Shaohan Huang, Ziyu Zhu, Xintong Zhang, Wayne Xin Zhao, Zhongzhi Luan, Bo Dai, Zhenliang Zhang
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´11æœˆï¼ˆv4ï¼‰
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2411.19930](https://arxiv.org/abs/2411.19930)
  - **å¼€æº**: âœ… [HuggingFace](https://huggingface.co/AdaptLLM)
  - **æ„ä¹‰**:
      - **å¼€æºæ›¿ä»£æ–¹æ¡ˆ**: è¯æ˜å¼€æºæ¨¡å‹å¯ä»¥æ›¿ä»£æ˜‚è´µçš„é—­æºæ¨¡å‹ï¼ˆGPT-4Vï¼‰è¿›è¡Œé¢†åŸŸé€‚é…æ•°æ®åˆæˆ
      - **ä¸€è‡´æ€§è¿‡æ»¤åˆ›æ–°**: é€šè¿‡æ£€æŸ¥å›å¤ä¸€è‡´æ€§è€Œéç›´æ¥éªŒè¯å‡†ç¡®æ€§ï¼Œé¿å…å¤§é‡ä¸“å®¶æ ‡æ³¨
      - **å•é˜¶æ®µè®­ç»ƒ**: æå‡ºæ›´é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œä¿æŒä»»åŠ¡å¤šæ ·æ€§
      - **é¢†åŸŸæ³›åŒ–**: åœ¨ç”Ÿç‰©åŒ»å­¦ã€é£Ÿå“ã€é¥æ„Ÿä¸‰ä¸ªé¢†åŸŸå‡å–å¾—SOTAï¼Œè¯æ˜æ–¹æ³•çš„é€šç”¨æ€§
      - **å¯å¤ç°æ€§**: å®Œå…¨å¼€æºæ¨¡å‹ã€ä»£ç å’Œæ•°æ®ï¼Œé™ä½é¢†åŸŸé€‚é…é—¨æ§›
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2403.00231">ğŸ“„ Multimodal ArXiv</a></b><br>
<code>arXiv 2403.00231</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-é¦™æ¸¯å¤§å­¦-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **ç§‘å­¦æ–‡çŒ®å›¾åƒç†è§£æ•°æ®é›†** - ä»ArXivè®ºæ–‡ä¸­æå–å¤§è§„æ¨¡å›¾åƒ-captionå¯¹ï¼Œå¹¶ä½¿ç”¨GPT-4Vç”Ÿæˆç§‘å­¦å›¾è¡¨QAæ•°æ®ï¼Œæå‡MLLMçš„ç§‘å­¦ç†è§£èƒ½åŠ›
  - **æ•°æ®åˆæˆæ–¹æ³•** - **GPT-4Vé©±åŠ¨çš„ç§‘å­¦å›¾è¡¨QAç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªå¤§è§„æ¨¡å¼€æ”¾åŸŸç§‘å­¦å›¾è¡¨ç†è§£æ•°æ®é›†ï¼Œè¦†ç›–å¤šä¸ªç§‘å­¦é¢†åŸŸï¼Œä½¿ç”¨GPT-4Vä»å›¾åƒç”Ÿæˆå¤šé€‰é¢˜QAå¯¹
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰MLLMåœ¨æŠ½è±¡å›¾å½¢ï¼ˆå‡ ä½•å½¢çŠ¶ã€ç§‘å­¦å›¾è¡¨ï¼‰ç†è§£ä¸Šèƒ½åŠ›æœ‰é™
        - ç§‘å­¦é¢†åŸŸè®­ç»ƒæ•°æ®ç¨€ç¼º
        - ç°æœ‰ç§‘å­¦å›¾è¡¨æ•°æ®é›†è§„æ¨¡å°ã€ä»»åŠ¡å•ä¸€æˆ–ä»…é™äºè®¡ç®—æœºç§‘å­¦é¢†åŸŸ
      - **ä¸¤é˜¶æ®µæ•°æ®æ„å»ºPipeline**:
        1. **ArXivCapæ•°æ®é›†æ„å»ºï¼ˆå›¾åƒ-Captionå¯¹ï¼‰**:
           - **æ•°æ®æ¥æº**: 2023å¹´6æœˆå‰çš„ArXivè®ºæ–‡æºæ–‡ä»¶
           - **è®ºæ–‡è¿‡æ»¤**:
             - ä»Semantic Scholarè·å–è®ºæ–‡å…ƒä¿¡æ¯
             - ä»…ä¿ç•™å·²å‘è¡¨è®ºæ–‡ï¼ˆJournal Article, Conference, Reviewï¼‰
             - è¿‡æ»¤ä½è´¨é‡è®ºæ–‡ï¼ˆç¡®ä¿æ•°æ®é›†è´¨é‡ï¼‰
           - **å›¾åƒ-Captionæå–**:
             - ä»LaTeXæºæ–‡ä»¶ä¸­æå–å›¾åƒå’Œå¯¹åº”caption
             - **ä¸¤ç§å›¾åƒç±»å‹**:
               - **å•å›¾åƒå¯¹**: ä¸€ä¸ªå›¾åƒé…ä¸€ä¸ªcaption
               - **å¤šå›¾åƒå¯¹**: å¤šä¸ªå­å›¾åƒï¼Œæ¯ä¸ªæœ‰sub-captionï¼ŒåŠ ä¸Šoverall main caption
           - **Captionæ¸…æ´—**:
             - åˆ é™¤captionå°‘äº5ä¸ªè¯çš„chunk
             - ä½¿ç”¨pylatexencå°†LaTeXè¡¨è¾¾å¼è½¬æ¢ä¸ºæ–‡æœ¬
             - å°†LaTeXå…¬å¼ä¿ç•™ï¼Œå¼•ç”¨è½¬æ¢ä¸º`<cit.>`ï¼Œå¼•ç”¨è½¬æ¢ä¸º`<ref>`
             - ç¡®ä¿captionè´¨é‡å’Œå¯è¯»æ€§
           - **è§„æ¨¡**: 6.4Må›¾åƒ + 3.9M captionsï¼ˆæ¥è‡ª572Kç¯‡è®ºæ–‡ï¼‰
           - **é¢†åŸŸè¦†ç›–**: æ¶µç›–æ•°å­¦ã€ç‰©ç†ã€è®¡ç®—æœºç§‘å­¦ã€ç”Ÿç‰©åŒ»å­¦ç­‰å¤šä¸ªç§‘å­¦é¢†åŸŸ
        2. **ArXivQAæ•°æ®é›†æ„å»ºï¼ˆGPT-4Vç”ŸæˆQAï¼‰**:
           - **æ•°æ®æº**: ä»ArXivCapä¸­é€‰æ‹©é«˜è´¨é‡å›¾åƒ
           - **GPT-4Vç”ŸæˆQAå¯¹**:
             - è¾“å…¥ï¼šç§‘å­¦å›¾åƒ + caption
             - è¾“å‡ºï¼šå¤šé€‰é¢˜ï¼ˆé—®é¢˜ã€4ä¸ªé€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆã€rationaleï¼‰
             - Promptè®¾è®¡ï¼šè¦æ±‚ç”ŸæˆæŒ‘æˆ˜æ€§çš„ã€éœ€è¦å¤§å­¦æ°´å¹³æ¨ç†çš„é—®é¢˜
             - ä»»åŠ¡å¤šæ ·æ€§ï¼šæ¶µç›–å›¾è¡¨ç†è§£ã€æ•°æ®è§£è¯»ã€ç§‘å­¦æ¨ç†ç­‰
           - **è´¨é‡æ§åˆ¶**:
             - è¿‡æ»¤æ— æ•ˆæ ·æœ¬ï¼ˆç­”æ¡ˆä¸åœ¨é€‰é¡¹ä¸­ã€æ ¼å¼é”™è¯¯ç­‰ï¼‰
             - äººå·¥æŠ½æ ·éªŒè¯ï¼ˆ100æ ·æœ¬ï¼Œäººç±»å‡†ç¡®ç‡80%ï¼‰
             - ç¡®ä¿é—®é¢˜çš„å¯å›ç­”æ€§å’Œéš¾åº¦
           - **è§„æ¨¡**: 32K QAå¯¹ï¼ˆæ¥è‡ª16.6Kå›¾åƒï¼‰
           - **é—®é¢˜ç‰¹ç‚¹**:
             - å¹³å‡é—®é¢˜é•¿åº¦ï¼š16.98è¯
             - å¹³å‡æ¯é¢˜4.20ä¸ªé€‰é¡¹
             - æ¯ä¸ªé€‰é¡¹å¹³å‡7.59è¯
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å¤§è§„æ¨¡çœŸå®æ•°æ®**: ä½¿ç”¨çœŸå®ç§‘å­¦è®ºæ–‡å›¾åƒï¼Œéåˆæˆæ•°æ®
        - **å¼€æ”¾åŸŸè¦†ç›–**: æ¶µç›–å¤šä¸ªç§‘å­¦é¢†åŸŸï¼Œä¸é™äºå•ä¸€å­¦ç§‘
        - **é«˜è´¨é‡QA**: GPT-4Vç”Ÿæˆçš„é—®é¢˜å…·æœ‰æŒ‘æˆ˜æ€§å’Œç§‘å­¦æ€§
        - **å¤šæ¨¡æ€å¯¹é½**: å›¾åƒ-captionå¯¹å’ŒQAå¯¹ç»“åˆï¼Œå¢å¼ºå¤šæ¨¡æ€ç†è§£
  - **ArXivCapæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 6.4Må›¾åƒ + 3.9M captionsï¼ˆ572Kè®ºæ–‡ï¼‰
      - **å›¾åƒç±»å‹åˆ†å¸ƒ**:
        - å•å›¾åƒå¯¹ï¼šçº¦5.4M
        - å¤šå›¾åƒå¯¹ï¼šçº¦1Mï¼ˆåŒ…å«sub-captionsï¼‰
      - **Captionç»Ÿè®¡**:
        - å¹³å‡ä¸»captioné•¿åº¦ï¼š47.6è¯ï¼ˆä¸­ä½æ•°35è¯ï¼‰
        - å¹³å‡sub-captioné•¿åº¦ï¼š4.8è¯ï¼ˆä¸­ä½æ•°3è¯ï¼‰
        - Chunk captionï¼ˆåˆå¹¶ï¼‰å¹³å‡é•¿åº¦ï¼š48.8è¯
      - **é¢†åŸŸåˆ†å¸ƒ**: æ•°å­¦ã€è®¡ç®—æœºç§‘å­¦ã€ç‰©ç†ã€å¤©ä½“ç‰©ç†ã€å‡èšæ€ç‰©è´¨ã€ç»Ÿè®¡å­¦ç­‰
  - **ArXivQAæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 32Kå¤šé€‰é¢˜QAå¯¹
      - **å›¾åƒæ•°é‡**: 16.6Kå”¯ä¸€å›¾åƒ
      - **é—®é¢˜ç±»å‹**: æ¶µç›–å›¾è¡¨QAã€å‡ ä½•é—®é¢˜æ±‚è§£ã€æ•°å­¦æ–‡å­—é¢˜ã€æ•™ç§‘ä¹¦QAã€è§†è§‰QAç­‰
      - **éš¾åº¦**: éœ€è¦å¤§å­¦æ°´å¹³æ¨ç†èƒ½åŠ›
  - **å®éªŒç»“æœ** - **ArXivQAæ˜¾è‘—æå‡æ•°å­¦æ¨ç†èƒ½åŠ›**:
      - **åŸºçº¿æ¨¡å‹è¯„ä¼°**ï¼ˆ1000æ ·æœ¬æµ‹è¯•é›†ï¼‰:
        - LLaVA-1.5-7B: 44.2%ï¼ˆç¬¬äºŒåï¼‰
        - Qwen-VL-Chat: 46.6%
        - InstructBLIP-Vicuna7B: 7.0%
        - OpenFlamingo-9B: 9.9%
        - äººç±»è¡¨ç°ï¼š80.0%ï¼ˆ100æ ·æœ¬å­é›†ï¼‰
      - **MathVistaæå‡**ï¼ˆå¾®è°ƒQwen-VL-Chat-7Bï¼‰:
        - **æ€»ä½“å‡†ç¡®ç‡**: 50.4%ï¼ˆvs. åŸºçº¿40.0%ï¼Œ+10.4%ç»å¯¹æå‡ï¼‰
        - **å‡ ä½•é—®é¢˜æ±‚è§£**: 34.0%ï¼ˆvs. åŸºçº¿19.1%ï¼Œ+14.9%ï¼‰
        - **æ•™ç§‘ä¹¦QA**: 70.0%ï¼ˆvs. åŸºçº¿46.7%ï¼Œ+23.3%ï¼‰
        - **è§†è§‰QA**: 64.1%ï¼ˆvs. åŸºçº¿57.6%ï¼Œ+6.5%ï¼‰
        - **è¶…è¶Šå•†ä¸šæ¨¡å‹**: 50.4% vs. Bard 50.0%
      - **ArXivCapå•å›¾åƒCaptioning**ï¼ˆå¾®è°ƒQwen-VL-Chat-7Bï¼‰:
        - BLEU-2: 8.9ï¼ˆvs. åŸºçº¿4.4ï¼Œ+102%ï¼‰
        - ROUGE-L: 15.8ï¼ˆvs. åŸºçº¿11.1ï¼Œ+42%ï¼‰
        - BERT-Score: 83.3ï¼ˆvs. åŸºçº¿81.8ï¼‰
        - è¶…è¶Šæ‰€æœ‰å¼€æºåŸºçº¿æ¨¡å‹
      - **æ–°ä»»åŠ¡åŸºå‡†**ï¼ˆåœ¨ArXivCapä¸Šå®šä¹‰ï¼‰:
        - å¤šå›¾åƒCaptioning
        - ä¸Šä¸‹æ–‡åŒ–Captioningï¼ˆin-context learningï¼‰
        - Titleç”Ÿæˆï¼ˆä»å›¾åƒ-captionå¯¹æ¨æ–­è®ºæ–‡æ ‡é¢˜ï¼‰
  - **é¢†åŸŸç‰¹å®šæ€§èƒ½åˆ†æ**:
      - ä¸åŒç§‘å­¦é¢†åŸŸçš„QAæ•°æ®å¯¹ä¸åŒä»»åŠ¡çš„æå‡æ•ˆæœä¸åŒ
      - å¤©ä½“ç‰©ç†é¢†åŸŸæ•°æ®å¢å¼ºå‡ ä½•é—®é¢˜æ±‚è§£èƒ½åŠ›
      - å‡èšæ€ç‰©è´¨é¢†åŸŸæ•°æ®æå‡æ•°å­¦æ–‡å­—é¢˜æ€§èƒ½
      - å¤§å¤šæ•°é¢†åŸŸæ•°æ®å¯¹FigureQAä»»åŠ¡æœ‰è´Ÿé¢å½±å“ï¼ˆè¡¨æ˜åˆæˆFigureQAå¯èƒ½ä¸æ˜¯æœ€ä½³åŸºå‡†ï¼‰
  - **é”™è¯¯åˆ†æ**ï¼ˆäººå·¥åˆ†æ100ä¸ªæ ·æœ¬ï¼‰:
      - **è¯­è¨€åè§**: å¼ºè¯­è¨€å…ˆéªŒè¯¯å¯¼æ¨¡å‹ï¼ˆå¿½ç•¥è§†è§‰è¾“å…¥ï¼‰
      - **è§†è§‰æ„ŸçŸ¥é”™è¯¯**: CLIPç­‰è§†è§‰ç¼–ç å™¨å¯¹å›¾è¡¨ç†è§£èƒ½åŠ›è¾ƒå¼±
      - **æ¨ç†é”™è¯¯**: å¤æ‚æ¨ç†ä»»åŠ¡å¤±è´¥
      - **ä¸éµå¾ªæŒ‡ä»¤**: å¼€æºæ¨¡å‹æ— æ³•è‰¯å¥½éµå¾ªæŒ‡ä»¤
  - **æœºæ„**: The University of Hong Kong, Peking University
  - **ä½œè€…**: Lei Li, Yuqi Wang, Runxin Xu, Peiyi Wang, Xiachong Feng, Lingpeng Kong, Qi Liu
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´3æœˆï¼ˆv3ï¼‰
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2403.00231](https://arxiv.org/abs/2403.00231)
  - **å¼€æº**: âœ… æ•°æ®é›†å’Œä»£ç 
  - **æ„ä¹‰**:
      - **æ•°æ®è§„æ¨¡**: æœ€å¤§çš„çœŸå®è®ºæ–‡å›¾åƒ-captionæ•°æ®é›†ï¼ˆ6.4Må›¾åƒï¼‰
      - **å¼€æ”¾åŸŸè¦†ç›–**: é¦–ä¸ªè¦†ç›–å¤šä¸ªç§‘å­¦é¢†åŸŸçš„å¤§è§„æ¨¡QAæ•°æ®é›†
      - **ç§‘å­¦ç†è§£æå‡**: æ˜¾è‘—æå‡MLLMåœ¨æ•°å­¦æ¨ç†å’Œç§‘å­¦å›¾è¡¨ç†è§£ä¸Šçš„èƒ½åŠ›
      - **è¯„ä¼°åŸºå‡†**: æä¾›å››ä¸ªæ–°ä»»åŠ¡åŸºå‡†ï¼Œå…¨é¢è¯„ä¼°ç§‘å­¦å›¾è¡¨ç†è§£èƒ½åŠ›
      - **GPT-4Våº”ç”¨**: è¯æ˜GPT-4Vå¯ä»¥æœ‰æ•ˆç”Ÿæˆé«˜è´¨é‡ç§‘å­¦QAæ•°æ®
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2412.07012">ğŸ“„ PROVISION</a></b><br>
<code>arXiv 2412.07012</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **ç¨‹åºåŒ–æ‰©å±•è§†è§‰ä¸­å¿ƒæŒ‡ä»¤æ•°æ®** - ä½¿ç”¨åœºæ™¯å›¾ä½œä¸ºå›¾åƒçš„ç¬¦å·è¡¨ç¤ºå’Œäººå·¥ç¼–å†™çš„ç¨‹åºï¼Œç³»ç»ŸåŒ–åˆæˆè§†è§‰ä¸­å¿ƒæŒ‡ä»¤æ•°æ®ï¼Œç¡®ä¿æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„å¯è§£é‡Šæ€§å’Œå¯æ§æ€§
  - **æ•°æ®åˆæˆæ–¹æ³•** - **åœºæ™¯å›¾é©±åŠ¨çš„ç¨‹åºåŒ–æŒ‡ä»¤ç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç¨‹åºåŒ–æ–¹æ³•ä½¿ç”¨åœºæ™¯å›¾ç³»ç»ŸåŒ–ç”Ÿæˆè§†è§‰ä¸­å¿ƒæŒ‡ä»¤æ•°æ®ï¼Œé€šè¿‡äººç±»ç¼–å†™çš„ç¨‹åºç¡®ä¿æ— å¹»è§‰å’Œå¯æ‰©å±•æ€§
      - **å¢å¼ºåœºæ™¯å›¾å®šä¹‰**:
        - **æ ‡å‡†åœºæ™¯å›¾**: å¯¹è±¡ä½œä¸ºèŠ‚ç‚¹ï¼Œå±æ€§åˆ†é…ç»™èŠ‚ç‚¹ï¼Œå¯¹è±¡é—´å…³ç³»/äº¤äº’ä½œä¸ºæœ‰å‘è¾¹
        - **å¢å¼ºç‰¹æ€§**: æ·»åŠ æ·±åº¦æ ‡æ³¨ï¼ˆDepthAnyThing V2ï¼‰å’Œåˆ†å‰²æ ‡æ³¨ï¼ˆSAM-2ï¼‰ï¼Œå½¢æˆå¢å¼ºåœºæ™¯å›¾
        - **åœºæ™¯å›¾æ¥æº**:
          - **æ‰‹åŠ¨æ ‡æ³¨**: Visual Genomeæ•°æ®é›†ï¼ˆäººå·¥æ ‡æ³¨åœºæ™¯å›¾ï¼‰
          - **è‡ªåŠ¨ç”Ÿæˆ**: DataCompæ•°æ®é›†ï¼ˆä½¿ç”¨åœºæ™¯å›¾ç”Ÿæˆpipelineè‡ªåŠ¨ç”Ÿæˆï¼‰
      - **ç¨‹åºåŒ–æŒ‡ä»¤ç”Ÿæˆç³»ç»Ÿ**:
        - **24ä¸ªå•å›¾åƒæŒ‡ä»¤ç”Ÿæˆå™¨**: å°†å¢å¼ºåœºæ™¯å›¾è½¬æ¢ä¸ºæ•°åƒä¸ªé«˜çº§æ„ŸçŸ¥é—®é¢˜-ç­”æ¡ˆå¯¹
          - **å…­ç»´æŒ‡ä»¤ç±»å‹**: å¯¹è±¡QAã€å±æ€§QAã€æ·±åº¦QAã€åˆ†å‰²QAã€å…³ç³»QAã€å¯¹è±¡+æ·±åº¦QA
          - **æ¯ä¸ªç”Ÿæˆå™¨ä½¿ç”¨æ•°ç™¾ä¸ªé¢„å®šä¹‰æ¨¡æ¿**: ç³»ç»ŸåŒ–æ•´åˆæ ‡æ³¨ç”Ÿæˆå¤šæ ·åŒ–æŒ‡ä»¤æ•°æ®
          - **è¦†ç›–èƒ½åŠ›**: æ¯”è¾ƒã€æ£€ç´¢å’Œæ¨ç†åŸºæœ¬è§†è§‰æ¦‚å¿µï¼ˆå¯¹è±¡ã€å±æ€§ã€å…³ç³»ï¼‰
        - **14ä¸ªå¤šå›¾åƒæŒ‡ä»¤ç”Ÿæˆå™¨**: å¤„ç†å¤šä¸ªåœºæ™¯å›¾ç”Ÿæˆè·¨å›¾åƒé—®é¢˜-ç­”æ¡ˆå¯¹
          - **ä¸‰ç±»å¤šå›¾åƒä»»åŠ¡**: é€‰æ‹©ï¼ˆSelectionï¼‰ã€æ¯”è¾ƒï¼ˆComparisonï¼‰ã€èšåˆï¼ˆAggregationï¼‰
          - **ç¤ºä¾‹**: "å“ªå¼ å›¾åƒåŒ…å«æ›´å¤šçº¢è‰²å¯¹è±¡ï¼Ÿ"ã€"è¿™äº›å›¾åƒä¸­å…±åŒçš„å¯¹è±¡æ˜¯ä»€ä¹ˆï¼Ÿ"ã€"è¿™äº›å›¾åƒä¸­çº¢è‰²å¯¹è±¡çš„æ€»æ•°æ˜¯å¤šå°‘ï¼Ÿ"
      - **åœºæ™¯å›¾ç”ŸæˆPipeline**ï¼ˆç”¨äºæ— æ ‡æ³¨å›¾åƒï¼‰:
        - **å¯¹è±¡æ£€æµ‹**: YOLO-worldæ£€æµ‹æ‰€æœ‰å¯¹è±¡çš„è¾¹ç•Œæ¡†å’Œæ ‡ç­¾
        - **å›¾åƒåˆ†å‰²**: SAM-2åŸºäºè¾¹ç•Œæ¡†ç”Ÿæˆåƒç´ çº§åˆ†å‰²
        - **å±æ€§æ£€æµ‹**: å¾®è°ƒLLaVA-1.5-13Bä½œä¸ºå±æ€§æ£€æµ‹æ¨¡å‹ï¼ˆåœ¨LSAæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œç²¾åº¦90%ï¼‰
        - **å…³ç³»æ£€æµ‹**: å¾®è°ƒOspreyæ¨¡å‹æ£€æµ‹å¯¹è±¡å¯¹ä¹‹é—´çš„å…³ç³»
        - **æ·±åº¦ä¼°è®¡**: DepthAnyThing V2ç”Ÿæˆåƒç´ çº§æ·±åº¦æ ‡æ³¨
        - **å…³é”®ä¼˜åŠ¿**: å¯åº”ç”¨äºä»»ä½•å›¾åƒï¼Œä¸é™äºæœ‰åœºæ™¯å›¾æ ‡æ³¨çš„æ•°æ®é›†
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å¯è§£é‡Šæ€§**: åœºæ™¯å›¾+äººç±»ç¼–å†™ç¨‹åºå¼•å…¥é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ï¼Œæ¶ˆé™¤ç«¯åˆ°ç«¯æ¨¡å‹çš„ä¸ç¡®å®šæ€§
        - **æ— å¹»è§‰ä¿è¯**: åªè¦åœºæ™¯å›¾å‡†ç¡®ï¼Œç¨‹åºç”Ÿæˆçš„æŒ‡ä»¤æ— å¹»è§‰ï¼ŒåŸºäºåœºæ™¯å›¾ä¸­çš„æ˜¾å¼ä¿¡æ¯è€ŒéLLMçš„æ¦‚ç‡è¾“å‡º
        - **å¯æ‰©å±•æ€§**: ä»å¼ºå¤§LLMè½¬å‘ç¨‹åºåŒ–ç”Ÿæˆï¼Œå®ç°å¯æ‰©å±•å’Œæˆæœ¬æ•ˆç›Šé«˜çš„æ•°æ®åˆ›å»º
        - **æ— è®¸å¯çº¦æŸ**: åœºæ™¯å›¾å’Œè‡ªå®šä¹‰ç¨‹åºä¸æ¶‰åŠä¸“æœ‰æ¨¡å‹è¾“å‡ºï¼Œé¿å…è®¸å¯é™åˆ¶
        - **å¯æ§æ€§**: äººç±»ç¼–å†™çš„ç¨‹åºå…è®¸ç²¾ç¡®æ§åˆ¶å’Œå®šåˆ¶è¾“å‡ºç”Ÿæˆ
      - **PROVISION-10Mæ•°æ®é›†**:
        - **æ€»è§„æ¨¡**: è¶…è¿‡1000ä¸‡æ¡å”¯ä¸€æŒ‡ä»¤æ•°æ®
        - **æ•°æ®æ¥æº**:
          - **VG-S**: 150ä¸‡å•å›¾åƒæŒ‡ä»¤ï¼ˆVisual Genomeï¼Œæ‰‹åŠ¨æ ‡æ³¨åœºæ™¯å›¾ï¼‰
          - **VG-M**: 420ä¸‡å¤šå›¾åƒæŒ‡ä»¤ï¼ˆVisual Genomeï¼‰
          - **DC-S**: 230ä¸‡å•å›¾åƒæŒ‡ä»¤ï¼ˆDataCompï¼Œè‡ªåŠ¨ç”Ÿæˆåœºæ™¯å›¾ï¼‰
          - **DC-M**: 420ä¸‡å¤šå›¾åƒæŒ‡ä»¤ï¼ˆDataCompï¼‰
        - **æ•°æ®æ ¼å¼**: æ¯æ¡æŒ‡ä»¤åŒæ—¶æä¾›å¤šé€‰é¢˜å’Œç®€ç­”é¢˜ç‰ˆæœ¬ï¼Œç¡®ä¿çµæ´»æ€§
      - **å®éªŒç»“æœ**:
        - **å•å›¾åƒæŒ‡ä»¤å¾®è°ƒ**ï¼ˆLLaVA-1.5-7Bï¼ŒVG-Sæ•°æ®ï¼‰:
          - **CVBench 2D**: 58.0% â†’ 65.0% (+7.0%ï¼Œ50% Half-Halfæ ¼å¼ï¼‰
          - **CVBench 3D**: 61.0% â†’ 69.0% (+8.0%ï¼Œ50% Half-Halfæ ¼å¼ï¼‰
          - **QBench2**: 46.4% â†’ 50.2% (+3.8%ï¼Œ50% Short Answeræ ¼å¼ï¼‰
          - **RealWorldQA**: 54.2% â†’ 58.2% (+4.0%ï¼Œ50% Multiple Choiceæ ¼å¼ï¼‰
          - **MMMU**: 36.2% â†’ 39.1% (+2.9%ï¼Œ20% Half-Halfæ ¼å¼ï¼‰
          - **å…³é”®å‘ç°**:
            - å¤šé€‰é¢˜æ ¼å¼åœ¨æ›¿æ¢è®¾ç½®ä¸‹è¡¨ç°æ›´å¥½ï¼ˆ20%æ›¿æ¢ç‡æœ€ä½³ï¼‰
            - ç®€ç­”é¢˜æ ¼å¼åœ¨å¢å¼ºè®¾ç½®ä¸‹è¡¨ç°æ›´å¥½ï¼ˆ50%å¢å¼ºç‡æœ€ä½³ï¼‰
            - Half-Halfæ ¼å¼ï¼ˆæ··åˆæ ¼å¼ï¼‰åœ¨å¤šä¸ªè®¾ç½®ä¸‹è¾¾åˆ°æœ€ä½³æ€§èƒ½
        - **å¤šå›¾åƒæŒ‡ä»¤å¾®è°ƒ**ï¼ˆMantis-SigLIP-8Bï¼ŒVG-Mæ•°æ®ï¼‰:
          - **Mantis-Eval**: 54.4% â†’ 62.7% (+8.3%ï¼Œ20% Replacement Short Answeræ ¼å¼ï¼‰
          - **MMT**: 52.9% â†’ 58.6% (+5.7%ï¼Œ20% Augmentation Half-Halfæ ¼å¼ï¼‰
          - **å•å›¾åƒåŸºå‡†**: å¹³å‡æå‡1.95%ï¼ˆSEED +0.5%ï¼ŒMMBench +0.1%ï¼ŒMME +2.0%ç­‰ï¼‰
        - **é¢„è®­ç»ƒvsæŒ‡ä»¤å¾®è°ƒ**ï¼ˆxGen-MM-4Bï¼‰:
          - **ä»…é¢„è®­ç»ƒ**: å¹³å‡æå‡+1.1%ï¼ˆDC-Sï¼‰å’Œ+1.2%ï¼ˆVG-Sï¼‰
          - **ä»…æŒ‡ä»¤å¾®è°ƒ**: å¹³å‡æå‡+0.4%ï¼ˆDC-Sï¼‰å’Œ+0.9%ï¼ˆVG-Sï¼‰
          - **ä¸¤è€…ç»“åˆ**: å¹³å‡æå‡+1.2%ï¼ˆDC-Sï¼‰å’Œ+1.6%ï¼ˆVG-Sï¼‰ï¼Œè¯æ˜ååŒæ•ˆåº”
          - **æ•°æ®è§„æ¨¡å½±å“**: é¢„è®­ç»ƒé˜¶æ®µä»0.75Må¢åŠ åˆ°1.5Mæ ·æœ¬ï¼Œå¹³å‡æ€§èƒ½ä»59.1%æå‡åˆ°60.1%
        - **æ‰‹åŠ¨vsè‡ªåŠ¨ç”Ÿæˆåœºæ™¯å›¾å¯¹æ¯”**:
          - **å•å›¾åƒä»»åŠ¡**: DC-Såœ¨è¾ƒä½æ•°æ®è§„æ¨¡ä¸‹è¡¨ç°è¾ƒå·®ï¼Œä½†éšç€æ•°æ®è§„æ¨¡å¢åŠ åˆ°50%ï¼Œè¾¾åˆ°ä¸VG-Sç›¸å½“çš„æ€§èƒ½
          - **å¤šå›¾åƒä»»åŠ¡**: DC-Mè¡¨ç°å§‹ç»ˆä½äºVG-Mï¼Œå¯èƒ½å› ä¸ºå¤šå›¾åƒè®¾ç½®ä¸‹æ›´å¤§è§„æ¨¡çš„ç”Ÿæˆåœºæ™¯å›¾è§¦å‘è¾¹ç¼˜æ•ˆåº”
          - **ç»“è®º**: æ‰‹åŠ¨æ ‡æ³¨åœºæ™¯å›¾é€šå¸¸æ›´å¥½ï¼Œä½†è‡ªåŠ¨ç”Ÿæˆåœºæ™¯å›¾ä¹Ÿèƒ½æå‡æ¨¡å‹æ€§èƒ½
      - **å…³é”®å‘ç°**:
        - **æ•°æ®æ ¼å¼é‡è¦æ€§**: å¤šé€‰é¢˜å’Œç®€ç­”é¢˜æ ¼å¼åœ¨ä¸åŒè®¾ç½®ä¸‹è¡¨ç°ä¸åŒï¼Œæ··åˆæ ¼å¼é€šå¸¸è¾¾åˆ°æœ€ä½³æ€§èƒ½
        - **æ•°æ®è§„æ¨¡å½±å“**: æ€§èƒ½éšæ•°æ®è§„æ¨¡å¢åŠ è€Œæå‡ï¼Œä½†éœ€è¦å¹³è¡¡æ•°æ®è´¨é‡å’Œæ•°é‡
        - **åœºæ™¯å›¾è´¨é‡**: æ‰‹åŠ¨æ ‡æ³¨åœºæ™¯å›¾é€šå¸¸ä¼˜äºè‡ªåŠ¨ç”Ÿæˆï¼Œä½†è‡ªåŠ¨ç”Ÿæˆåœºæ™¯å›¾ä¹Ÿèƒ½æœ‰æ•ˆæå‡æ€§èƒ½
        - **é¢„è®­ç»ƒ+å¾®è°ƒååŒ**: åœ¨é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒé˜¶æ®µéƒ½åŠ å…¥æ•°æ®ï¼Œæ¯”ä»…åœ¨å•ä¸€é˜¶æ®µåŠ å…¥æ•ˆæœæ›´å¥½
      - **æœºæ„**: åç››é¡¿å¤§å­¦ã€Salesforce Researchã€å—åŠ å·å¤§å­¦
      - **ä½œè€…**: Jieyu Zhang, Le Xue, Linxin Song, Jun Wang, Weikai Huang, Manli Shu, An Yan, Zixian Ma, Juan Carlos Niebles, Silvio Savarese, Caiming Xiong, Zeyuan Chen, Ranjay Krishna, Ran Xu
      - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´12æœˆï¼ˆv3ï¼‰
      - **å¼€æº**: âœ… [ä»£ç ](https://github.com/JieyuZ2/ProVision) | [æ•°æ®é›†](https://huggingface.co/datasets/Salesforce/ProVision-10M)
      - **æ„ä¹‰**:
        - **æ–¹æ³•åˆ›æ–°**: é¦–ä¸ªç¨‹åºåŒ–æ–¹æ³•ä½¿ç”¨åœºæ™¯å›¾ç³»ç»ŸåŒ–ç”Ÿæˆè§†è§‰ä¸­å¿ƒæŒ‡ä»¤æ•°æ®ï¼Œæä¾›å¯è§£é‡Šå’Œå¯æ§çš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹
        - **å¯æ‰©å±•æ€§**: é€šè¿‡åœºæ™¯å›¾ç”Ÿæˆpipelineï¼Œå¯åº”ç”¨äºä»»ä½•å›¾åƒï¼Œå®ç°å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆ
        - **æ•°æ®è´¡çŒ®**: æä¾›è¶…è¿‡1000ä¸‡æ¡é«˜è´¨é‡è§†è§‰ä¸­å¿ƒæŒ‡ä»¤æ•°æ®ï¼ˆPROVISION-10Mï¼‰
        - **å®ç”¨ä»·å€¼**: åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ï¼Œè¯æ˜ç¨‹åºåŒ–æ•°æ®ç”Ÿæˆçš„æœ‰æ•ˆæ€§
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.14044">ğŸ“„ Self-Synthesized Data</a></b><br>
<code>arXiv 2502.14044</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ICLR_2025-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **ä½¿ç”¨è‡ªåˆæˆæ•°æ®å¢å¼ºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„è®¤çŸ¥å’Œå¯è§£é‡Šæ€§** - é€šè¿‡è§†è§‰æ‹’ç»é‡‡æ ·æ¡†æ¶æ”¹è¿›LMMçš„ç»†ç²’åº¦è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿè¯†åˆ«é¢†åŸŸç‰¹å®šç›®æ ‡å¹¶æä¾›å¯éªŒè¯çš„è§£é‡Š
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¿¡æ¯ç“¶é¢ˆæ¦‚å¿µé€‰æ‹© + æ— å¥–åŠ±æ¨¡å‹æ‹’ç»é‡‡æ ·**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªä½¿ç”¨ä¿¡æ¯ç“¶é¢ˆåŸç†é€‰æ‹©å›¾åƒçº§è§†è§‰æ¦‚å¿µçš„æ–¹æ³•ï¼Œé€šè¿‡è¿­ä»£çš„æ‹’ç»é‡‡æ ·å’Œå¾®è°ƒè¿‡ç¨‹ï¼Œæ— éœ€å›¾åƒç‰¹å®šæ ‡æ³¨å³å¯ç”Ÿæˆå¯è§£é‡Šçš„ç­”æ¡ˆ
      - **é—®é¢˜è¯†åˆ«**: LMMåœ¨ç»†ç²’åº¦è§†è§‰åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼ˆå¦‚LLaVA-1.5åœ¨Stanford Dogsä¸Šä»…12.2%ï¼‰ï¼Œæ— æ³•åˆ©ç”¨å…³é”®è§†è§‰ç‰¹å¾è¿›è¡Œæ¨ç†ï¼Œæ— æ³•æä¾›å¯éªŒè¯çš„è§£é‡Š
      - **ä¸¤é˜¶æ®µè‡ªåˆæˆæ¡†æ¶**:
        1. **å›¾åƒçº§è§†è§‰æ¦‚å¿µé€‰æ‹©é˜¶æ®µ**:
           - **ç›®æ ‡**: ä»ä¸“å®¶å®šä¹‰çš„æ¦‚å¿µé›†åˆZä¸­é€‰æ‹©ä¸å›¾åƒXæœ€ç›¸å…³çš„å­é›†Z*
           - **ä¿¡æ¯ç“¶é¢ˆåŸç†**: æœ€å¤§åŒ–I(X;Z*)åŒæ—¶æœ€å°åŒ–I(Z*;Z)ï¼Œå¹³è¡¡ç›¸å…³æ€§å’Œå†—ä½™æ€§
           - **å›¾åƒæè¿°è¿‘ä¼¼**:
             - ä½¿ç”¨åŸºç¡€LLaVA-1.5ç”Ÿæˆå¤šä¸ªå›¾åƒæè¿°D = {dâ‚, dâ‚‚, ..., dâ‚™}
             - **ç†è®ºä¿è¯**: å½“nâ†’âˆæ—¶ï¼ŒI(D;Z)æ”¶æ•›åˆ°I(X;Z)ï¼ˆTheorem 1ï¼‰
             - é€šè¿‡å¢åŠ æè¿°æ•°é‡nï¼Œè¿‘ä¼¼çœŸå®å›¾åƒå†…å®¹åˆ†å¸ƒ
           - **InfoNCEè¯„åˆ†**: å¯¹æ¯ä¸ªæ¦‚å¿µzâ±¼è®¡ç®—InfoNCEåˆ†æ•°sâ±¼ï¼Œè¡¡é‡æ¦‚å¿µä¸å›¾åƒæè¿°çš„ç›¸å…³æ€§
           - **æ¦‚å¿µé€‰æ‹©æ ‡å‡†**: Z* = {zâ±¼ âˆˆ Z | sâ±¼ > Î¼ + Î²Ì‚Ïƒ}ï¼Œå…¶ä¸­Î¼å’ŒÏƒæ˜¯InfoNCEåˆ†æ•°çš„å‡å€¼å’Œæ ‡å‡†å·®
           - **å¯è§£é‡Šç­”æ¡ˆç”Ÿæˆ**: ä½¿ç”¨é€‰å®šçš„æ¦‚å¿µZ*æç¤ºåŸºç¡€LMMç”Ÿæˆå¯è§£é‡Šçš„ç­”æ¡ˆ
        2. **æ— å¥–åŠ±æ¨¡å‹æ‹’ç»é‡‡æ ·é˜¶æ®µ**:
           - **ç›®æ ‡**: ä»å¾®è°ƒåæ¨¡å‹ç”Ÿæˆçš„å¤šä¸ªç­”æ¡ˆå€™é€‰ä¸­é€‰æ‹©æœ€ä½³ç­”æ¡ˆ
           - **æ‹’ç»é‡‡æ ·è¿‡ç¨‹**:
             - ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹f_Î¸^Tä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆmä¸ªç­”æ¡ˆå€™é€‰Y = {yâ‚, yâ‚‚, ..., yâ‚˜}
             - å¯¹æ¯ä¸ªç­”æ¡ˆyáµ¢è®¡ç®—ä¸é€‰å®šæ¦‚å¿µZ*çš„InfoNCEåˆ†æ•°s'áµ¢
             - é€‰æ‹©åˆ†æ•°æœ€é«˜çš„ç­”æ¡ˆ: y* = argmax s'áµ¢
           - **é¢å¤–çº¦æŸ**: é€‰å®šçš„ç­”æ¡ˆå¿…é¡»åŒ…å«æ­£ç¡®çš„æ ‡ç­¾cï¼Œå¦åˆ™ä¸¢å¼ƒ
           - **å…³é”®ä¼˜åŠ¿**: æ— éœ€å•ç‹¬çš„å¥–åŠ±æ¨¡å‹ï¼Œä½¿ç”¨æ¦‚å¿µå¯¹é½ä½œä¸ºè´¨é‡æŒ‡æ ‡
      - **è¿­ä»£å¾®è°ƒè¿‡ç¨‹**:
        - **åˆå§‹å¾®è°ƒ**: ä½¿ç”¨ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„å¯è§£é‡Šç­”æ¡ˆè¿›è¡Œåˆå§‹å¾®è°ƒ
        - **è¿­ä»£æ”¹è¿›**:
          - Round 1: ä½¿ç”¨åˆå§‹å¾®è°ƒæ¨¡å‹ç”Ÿæˆæ–°ç­”æ¡ˆï¼Œé€šè¿‡æ‹’ç»é‡‡æ ·é€‰æ‹©æœ€ä½³ç­”æ¡ˆ
          - Round 2-N: é‡å¤ä¸Šè¿°è¿‡ç¨‹ï¼Œé€æ­¥æå‡æ¨¡å‹æ€§èƒ½
          - æœ€å¤šè¿›è¡Œ4è½®è¿­ä»£
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **æ— éœ€å›¾åƒç‰¹å®šæ ‡æ³¨**: ä»…éœ€è¦å›¾åƒå’Œç±»åˆ«æ ‡ç­¾ï¼Œä¸éœ€è¦è¯¦ç»†çš„å›¾åƒç‰¹å®šç‰¹å¾æ ‡æ³¨
        - **ä¿¡æ¯ç†è®ºåŸºç¡€**: åŸºäºä¿¡æ¯ç“¶é¢ˆåŸç†ï¼Œæä¾›ç†è®ºä¿è¯
        - **æ— å¥–åŠ±æ¨¡å‹**: ä¸éœ€è¦è®­ç»ƒæˆ–ä½¿ç”¨å¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼Œä½¿ç”¨æ¦‚å¿µå¯¹é½ä½œä¸ºè´¨é‡æŒ‡æ ‡
        - **å¯è§£é‡Šæ€§**: ç”Ÿæˆçš„ç­”æ¡ˆåŒ…å«äººç±»å¯éªŒè¯çš„è§†è§‰ç‰¹å¾ï¼Œæä¾›å¯è§£é‡Šçš„è§£é‡Š
        - **é¢†åŸŸé€‚åº”æ€§**: å¯åº”ç”¨äºå„ç§é¢†åŸŸï¼ˆç»†ç²’åº¦åˆ†ç±»ã€åŒ»å­¦å›¾åƒç­‰ï¼‰
      - **å®éªŒç»“æœ**:
        - **ç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†**:
          - **CUB-200**: 2.69% â†’ 85.02% (+82.33%ï¼Œ4è½®è¿­ä»£ï¼‰
          - **Stanford Dogs**: 12.2% â†’ 86.91% (+74.71%ï¼Œ4è½®è¿­ä»£ï¼‰
          - **FGVC-Aircraft**: 3.00% â†’ 91.99% (+88.99%ï¼Œ4è½®è¿­ä»£ï¼‰
          - **PLD**: 0.00% â†’ 97.16% (+97.16%ï¼Œ4è½®è¿­ä»£ï¼‰
        - **åŒ»å­¦æ•°æ®é›†**:
          - **HAM10000**: 1.62% â†’ 85.06% (+83.44%ï¼Œ4è½®è¿­ä»£ï¼‰
          - **Chest X-Ray**: 62.50% â†’ 98.72% (+36.22%ï¼Œ4è½®è¿­ä»£ï¼Œä½¿ç”¨LLaVA-Medï¼‰
        - **è§£é‡Šè´¨é‡è¯„ä¼°**:
          - **è§£é‡Šå­˜åœ¨æ€§ï¼ˆEEï¼‰**: 1.00ï¼ˆæ‰€æœ‰æ•°æ®é›†ï¼‰ï¼Œè¡¨æ˜å§‹ç»ˆç”Ÿæˆè§£é‡Š
          - **è®¤çŸ¥åˆ†æ•°ï¼ˆCSï¼‰**: 0.79-0.87ï¼ˆæ‰€æœ‰æ•°æ®é›†ï¼‰ï¼Œè¡¨æ˜è§£é‡Šä¸ä¸“å®¶çŸ¥è¯†å¯¹é½è‰¯å¥½
          - **æµç•…åº¦åˆ†æ•°ï¼ˆFSï¼‰**: 6.53-9.01ï¼Œè¡¨æ˜è§£é‡Šè‡ªç„¶æµç•…
        - **vsåŸºçº¿æ–¹æ³•**:
          - **Naive Label (NL)**: ä»…ä½¿ç”¨æ ‡ç­¾è®­ç»ƒï¼Œæ— æ³•ç”Ÿæˆè§£é‡Šï¼ˆEE=0.00ï¼‰ï¼Œå‡†ç¡®ç‡é€šå¸¸ä½äºæˆ‘ä»¬çš„æ–¹æ³•
          - **Label + General Explanations (L+GE)**: ä½¿ç”¨æ ‡ç­¾å’Œé€šç”¨è§£é‡Šï¼Œä½†è§£é‡Šè´¨é‡è¾ƒä½ï¼ˆCSè¾ƒä½ï¼‰ï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šè¡¨ç°è¾ƒå·®ï¼ˆå¦‚HAM10000ä»…8.45%ï¼‰
        - **æ¦‚å¿µé€‰æ‹©ç²¾åº¦**:
          - ä½¿ç”¨25ä¸ªæè¿°æ—¶ï¼Œæ¦‚å¿µé€‰æ‹©ç²¾åº¦è¾¾åˆ°72.89%
          - ä¼˜äºGPT-4oï¼ˆ63.95%ï¼‰ã€LLaVAï¼ˆ~55%ï¼‰å’ŒCLIPï¼ˆ~55%ï¼‰
        - **è¿‡æ»¤ç­–ç•¥æœ‰æ•ˆæ€§**:
          - æ— è¿‡æ»¤: å‡†ç¡®ç‡70.45%ï¼ˆCUB-200ï¼‰ï¼ŒCS 0.71
          - æœ‰è¿‡æ»¤: å‡†ç¡®ç‡85.02%ï¼ˆCUB-200ï¼‰ï¼ŒCS 0.82
          - è¯æ˜æ‹’ç»é‡‡æ ·è¿‡æ»¤çš„é‡è¦æ€§
      - **å…³é”®å‘ç°**:
        - **è¿­ä»£æ”¹è¿›**: éšç€è¿­ä»£è½®æ•°å¢åŠ ï¼Œå‡†ç¡®ç‡å’Œè§£é‡Šè´¨é‡æŒç»­æå‡
        - **æ¦‚å¿µé€‰æ‹©é‡è¦æ€§**: å›¾åƒçº§æ¦‚å¿µé€‰æ‹©æ¯”ä½¿ç”¨æ‰€æœ‰æ ‡ç­¾çº§ç‰¹å¾æ›´æœ‰æ•ˆ
        - **æ‹’ç»é‡‡æ ·æœ‰æ•ˆæ€§**: è¿‡æ»¤ç­–ç•¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½å’Œè§£é‡Šè´¨é‡
        - **é¿å…æ·å¾„å­¦ä¹ **: ä½¿ç”¨å›¾åƒç‰¹å®šç‰¹å¾è€Œéä»…æ ‡ç­¾ï¼Œé¿å…æ¨¡å‹å­¦ä¹ è™šå‡å…³è”
        - **è·¨æ•°æ®é›†æ³›åŒ–**: åœ¨CUB-200ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨Stanford Dogsä¸Šä»…æå‡4.4%ï¼Œè¡¨æ˜é¢†åŸŸç‰¹å®šå¾®è°ƒçš„é‡è¦æ€§
      - **æœºæ„**: ä½æ²»äºšå¤§å­¦ã€éº»çœæ€»åŒ»é™¢ã€å“ˆä½›åŒ»å­¦é™¢
      - **ä½œè€…**: Yucheng Shi, Quanzheng Li, Jin Sun, Xiang Li, Ninghao Liu
      - **å‘å¸ƒæ—¶é—´**: ICLR 2025 | arXiv 2025å¹´2æœˆï¼ˆv2ï¼‰
      - **å¼€æº**: âœ… [ä»£ç ](https://github.com/sycny/SelfSynthX)
      - **æ„ä¹‰**:
        - **æ–¹æ³•åˆ›æ–°**: é¦–ä¸ªä½¿ç”¨ä¿¡æ¯ç“¶é¢ˆåŸç†é€‰æ‹©å›¾åƒçº§è§†è§‰æ¦‚å¿µçš„æ–¹æ³•ï¼Œæ— éœ€å›¾åƒç‰¹å®šæ ‡æ³¨
        - **å¯è§£é‡Šæ€§å¢å¼º**: ç”Ÿæˆçš„ç­”æ¡ˆåŒ…å«äººç±»å¯éªŒè¯çš„è§†è§‰ç‰¹å¾ï¼Œæä¾›å¯è§£é‡Šçš„è§£é‡Š
        - **å®ç”¨ä»·å€¼**: åœ¨å¤šä¸ªç»†ç²’åº¦åˆ†ç±»å’ŒåŒ»å­¦æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡å‡†ç¡®ç‡å’Œè§£é‡Šè´¨é‡
        - **ç†è®ºè´¡çŒ®**: æä¾›ä¿¡æ¯ç†è®ºåˆ†æï¼Œè¯æ˜æ–¹æ³•çš„æœ‰æ•ˆæ€§
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2405.19716">ğŸ“„ STIC (Self-Training on Image Comprehension)</a></b><br>
<code>arXiv 2405.19716</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-NeurIPS_2024-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹çš„å›¾åƒç†è§£è‡ªè®­ç»ƒ** - é€šè¿‡ä¸¤é˜¶æ®µè‡ªè®­ç»ƒæ–¹æ³•å¢å¼ºLVLMçš„å›¾åƒç†è§£èƒ½åŠ›ï¼Œä½¿ç”¨æœªæ ‡æ³¨å›¾åƒè‡ªæ„å»ºåå¥½æ•°æ®é›†ï¼Œæ— éœ€ä¾èµ–GPT-4Væˆ–äººå·¥æ ‡æ³¨
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸¤é˜¶æ®µå›¾åƒç†è§£è‡ªè®­ç»ƒæ¡†æ¶**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªä¸“é—¨é’ˆå¯¹å›¾åƒç†è§£çš„è‡ªè®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡è‡ªæ„å»ºå›¾åƒæè¿°åå¥½æ•°æ®é›†å’Œæè¿°æ³¨å…¥å¾®è°ƒï¼Œæ˜¾è‘—æå‡LVLMçš„è§†è§‰æ„ŸçŸ¥å’Œæ¨ç†èƒ½åŠ›
      - **é—®é¢˜è¯†åˆ«**: LVLMéœ€è¦é«˜è´¨é‡è§†è§‰-è¯­è¨€æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä½†è·å–æˆæœ¬é«˜æ˜‚ï¼Œä¸”ç°æœ‰æ–¹æ³•ä¾èµ–GPT-4Vç”Ÿæˆæ•°æ®ï¼Œæˆæœ¬ä»ç„¶è¾ƒé«˜
      - **STICä¸¤é˜¶æ®µæ¡†æ¶**:
        - **é˜¶æ®µ1: å›¾åƒç†è§£è‡ªè®­ç»ƒ**:
          - **è‡ªæ„å»ºåå¥½æ•°æ®é›†**: ä½¿ç”¨åŸºç¡€LVLMï¼ˆå¦‚LLaVA-v1.6ï¼‰ä¸ºæœªæ ‡æ³¨å›¾åƒç”Ÿæˆåå¥½æ•°æ®å¯¹
            - **åå¥½å“åº”**: é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„é€æ­¥æç¤ºç”Ÿæˆè¯¦ç»†å›¾åƒæè¿°ï¼ˆå¦‚"è¯·è¯¦ç»†æè¿°å›¾åƒï¼Œå…³æ³¨ä»¥ä¸‹æ–¹é¢ï¼šè¯†åˆ«ä¸»è¦ä¸»ä½“..."ï¼‰
            - **éåå¥½å“åº”**: é€šè¿‡ä¸¤ç§æ–¹å¼ç”Ÿæˆ
              - **æ–¹å¼1**: ä½¿ç”¨"åæç¤º"ï¼ˆå¦‚"æè¿°å›¾åƒä¸­å¯èƒ½å­˜åœ¨çš„æƒ³è±¡å¯¹è±¡"ï¼‰å¼•å¯¼æ¨¡å‹äº§ç”Ÿå¹»è§‰æè¿°
              - **æ–¹å¼2**: ä½¿ç”¨æ­£å¸¸æç¤ºä½†è¾“å…¥æŸåå›¾åƒï¼ˆé¢œè‰²æŠ–åŠ¨æˆ–é™ä½åˆ†è¾¨ç‡ï¼‰
          - **DPOå¯¹é½å¾®è°ƒ**: ä½¿ç”¨Direct Preference Optimization (DPO)æŸå¤±ï¼Œæ·»åŠ æ­£åˆ™åŒ–é¡¹å¼ºè°ƒåå¥½å“åº”
            - **æŸå¤±å‡½æ•°**: L(Î¸,Î¸_ref) = E[â„“(Î»log(p_Î¸(y_w|x)/p_Î¸_ref(y_w|x)) - Î»log(p_Î¸(y_l|x)/p_Î¸_ref(y_l|x))) - Î±log p_Î¸(y_w|x)]
            - **æ­£åˆ™åŒ–é¡¹**: -Î±log p_Î¸(y_w|x)è¿›ä¸€æ­¥å¼ºè°ƒåå¥½å“åº”ï¼Œæå‡æ¨¡å‹åŒºåˆ†é«˜è´¨é‡å’Œä½è´¨é‡å“åº”çš„èƒ½åŠ›
          - **æç¤ºè®¾è®¡**:
            - **å¥½æç¤º**: ä½¿ç”¨GPT-4ç”Ÿæˆå¤šä¸ªåˆå§‹æç¤ºï¼Œé€šè¿‡äººå·¥è¿‡æ»¤å’ŒMSCOCOæ ·æœ¬æµ‹è¯•è¿›è¡Œç²¾ç‚¼
            - **åæç¤º**: ä»GPT-4ç”Ÿæˆçš„æç¤ºä¸­é‡‡æ ·ï¼Œè®¾è®¡ç”¨äºå¼•å‘ä¸å‡†ç¡®æè¿°ï¼ˆæè¿°å¯èƒ½é€»è¾‘å­˜åœ¨çš„å¯¹è±¡ï¼‰
        - **é˜¶æ®µ2: æè¿°æ³¨å…¥å¾®è°ƒ**:
          - **ç›®æ ‡**: è¿›ä¸€æ­¥å¾®è°ƒè‡ªè®­ç»ƒçš„LVLMï¼Œä½¿å…¶èƒ½å¤Ÿåˆ©ç”¨è‡ªç”Ÿæˆçš„å›¾åƒæè¿°è¿›è¡ŒæŒ‡ä»¤è·Ÿéšä»»åŠ¡
          - **æ•°æ®æ„å»º**:
            - ä»æ¨¡å‹å·²ä½¿ç”¨çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ä¸­éšæœºé€‰æ‹©å°éƒ¨åˆ†æ•°æ®ï¼ˆ5Kæ ·æœ¬ï¼‰
            - ä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆæ¨¡å‹æè¿°ï¼ˆä½¿ç”¨ç®€å•æç¤ºå¦‚"è§£é‡Šå›¾åƒä¸­æç»˜çš„å†…å®¹"ï¼‰
            - å°†ç”Ÿæˆçš„æè¿°æ³¨å…¥åˆ°åŸå§‹æŒ‡ä»¤ä¸­ï¼š`Image description: {model description} <original instruction>`
            - ä¿æŒåŸå§‹ground-truthå®Œæˆä¸å˜
          - **å¾®è°ƒ**: åœ¨æè¿°æ³¨å…¥çš„æ•°æ®é›†ä¸Šè¿›è¡Œä¸€ä¸ªepochçš„å¾®è°ƒ
        - **å¯é€‰: æè¿°å¹¶å“åº”ï¼ˆDaRï¼‰**:
          - åœ¨æ¨ç†æ—¶ï¼Œå¯é€‰åœ°è®©æ¨¡å‹å…ˆæè¿°å›¾åƒï¼Œç„¶åå°†æè¿°ä¸åŸå§‹é—®é¢˜è¿æ¥ï¼Œç”Ÿæˆæ›´æ˜æ™ºçš„ç­”æ¡ˆ
          - **æ ¼å¼**: å…ˆæç¤ºæ¨¡å‹æè¿°å›¾åƒï¼Œç„¶åå°†æè¿°+åŸå§‹é—®é¢˜ä½œä¸ºæ–°æç¤º
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **æ— éœ€å¤–éƒ¨æ¨¡å‹**: ä¸éœ€è¦GPT-4Væˆ–å…¶ä»–å¤–éƒ¨æ¨¡å‹ï¼Œä»…ä½¿ç”¨åŸºç¡€LVLMæœ¬èº«
        - **æˆæœ¬æ•ˆç›Š**: ä½¿ç”¨GPT-4-turboè€ŒéGPT-4Vï¼Œæ˜¾è‘—é™ä½æˆæœ¬
        - **å¯æ‰©å±•æ€§**: å¯åº”ç”¨äºå¤§é‡æœªæ ‡æ³¨å›¾åƒï¼Œå®ç°å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆ
        - **ç›®æ ‡å¯¼å‘**: åå¥½æ•°æ®æ„å»ºçš„ç›®æ ‡å¯¼å‘æ€§è´¨ç¡®ä¿ç”Ÿæˆæ•°æ®è´¨é‡
        - **è¿­ä»£æ”¹è¿›**: æ”¹è¿›çš„æ¨¡å‹å¯ä»¥ç”¨äºç”Ÿæˆæ›´å¥½çš„æ•°æ®é›†ï¼Œå®ç°æŒç»­æ”¹è¿›
      - **å®éªŒç»“æœ**:
        - **ä¸»è¦ç»“æœ**ï¼ˆLLaVA-v1.6-7Bï¼‰:
          - **ScienceQA**: 68.9% â†’ 75.3% (+6.4%)
          - **TextVQA**: 60.3% â†’ 65.2% (+4.9%)
          - **ChartQA**: 36.4% â†’ 41.5% (+5.1%)
          - **LLaVA-Bench**: 77.3% â†’ 79.2% (+1.9%)
          - **MMBench**: 63.7% â†’ 67.8% (+4.1%)
          - **MM-Vet**: 42.2% â†’ 45.0% (+2.8%)
          - **MathVista**: 34.6% â†’ 37.0% (+2.4%)
          - **å¹³å‡æå‡**: +4.0%
        - **LLaVA-v1.5-7Bå¯¹æ¯”**:
          - **ScienceQA**: 66.8% â†’ 69.5% (+2.7%)
          - **TextVQA**: 58.2% â†’ 61.4% (+3.2%)
          - **ChartQA**: 6.3% â†’ 6.6% (+0.3%)
          - **LLaVA-Bench**: 65.4% â†’ 68.9% (+3.5%)
          - **MMBench**: 64.3% â†’ 65.3% (+1.0%)
          - **MM-Vet**: 31.1% â†’ 32.6% (+1.5%)
          - **MathVista**: 25.1% â†’ 27.2% (+2.1%)
          - **å¹³å‡æå‡**: +1.7%
        - **æ¶ˆèç ”ç©¶**:
          - **æè¿°å¹¶å“åº”ï¼ˆDaRï¼‰æœ‰æ•ˆæ€§**:
            - **ä»…DaRï¼ˆæ— å¾®è°ƒï¼‰**: å¹³å‡ä¸‹é™2.3%ï¼ˆæŸäº›æ•°æ®é›†æ”¹è¿›ï¼ŒæŸäº›ä¸‹é™ï¼‰
            - **STIC + DaR**: å¹³å‡æå‡1.1%ï¼ŒScienceQAæå‡2.8%
            - **ç»“è®º**: DaRä¸å¾®è°ƒè¿‡ç¨‹æœ‰ååŒæ•ˆåº”
          - **é˜¶æ®µè¿›å±•**:
            - **Base**: 68.9%ï¼ˆScienceQAï¼‰
            - **Stage 1**: 72.5% (+3.6%ï¼‰
            - **Stage 2**: 74.0% (+1.5%ï¼‰
            - **Stage 2 + DaR**: 75.3% (+1.3%ï¼‰
          - **éåå¥½æ ·æœ¬çš„ä½œç”¨**:
            - **ä»…æ­£æ ·æœ¬SFT**: LLaVA-Bench 76.7%ï¼ˆvs Base 77.3%ï¼‰ï¼Œä¸‹é™0.6%
            - **STICï¼ˆåå¥½æ•°æ®ï¼‰**: LLaVA-Bench 79.2%ï¼Œæå‡1.9%
            - **ç»“è®º**: è´Ÿæ ·æœ¬åœ¨åå¥½å¯¹é½ä¸­èµ·å…³é”®ä½œç”¨
          - **æ‰©å±•è§„å¾‹**:
            - **6Kåå¥½æ•°æ®**: LLaVA-Benchæå‡1.9%
            - **12Kåå¥½æ•°æ®**: LLaVA-Benchæå‡3.1%
            - **ç»“è®º**: æ€§èƒ½éšæ•°æ®è§„æ¨¡å¢åŠ è€Œæå‡ï¼Œæœªè¾¾åˆ°å¹³å°æœŸ
          - **å›¾åƒåˆ†å¸ƒç›¸å…³æ€§**:
            - **ScienceQA**: ä¸MSCOCOåˆ†å¸ƒé‡å å¤§ï¼Œæå‡6.4%ï¼ˆæœ€é«˜ï¼‰
            - **TextVQA**: ä¸MSCOCOåˆ†å¸ƒé‡å å¤§ï¼Œæå‡4.9%
            - **MathVista**: ä¸MSCOCOåˆ†å¸ƒé‡å å°ï¼Œæå‡2.4%ï¼ˆè¾ƒä½ï¼‰
            - **ChartQA**: ä¸MSCOCOåˆ†å¸ƒé‡å å°ï¼Œä½†æå‡5.1%ï¼ˆæ”¹è¿›çš„å›¾åƒç†è§£èƒ½åŠ›èµ·åŸºç¡€ä½œç”¨ï¼‰
        - **ä¸åŒæ•°æ®æºå®éªŒ**:
          - **MSCOCO**: å¹³å‡æå‡4.0%
          - **Vision Flan**: å¹³å‡æå‡4.3%ï¼ˆæ›´å¹¿æ³›çš„å›¾åƒç±»å‹ï¼‰
          - **ç»“è®º**: ä½¿ç”¨æ›´å¤šæ ·åŒ–çš„å›¾åƒæ•°æ®å¯ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½
        - **å¯æ‰©å±•æ€§**ï¼ˆLLaVA-v1.6-13Bï¼‰:
          - **LLaVA-Bench**: 84.5% â†’ 85.6% (+1.1%)
          - **MM-Vet**: 48.9% â†’ 50.5% (+1.6%)
          - **MMBench**: 70.6% â†’ 72.3% (+1.7%)
          - **ç»“è®º**: STICåœ¨ä¸åŒè§„æ¨¡çš„æ¨¡å‹ä¸Šéƒ½æœ‰æ•ˆ
      - **å…³é”®å‘ç°**:
        - **è‡ªè®­ç»ƒæœ‰æ•ˆæ€§**: å½“å‰LVLMçš„å›¾åƒç†è§£èƒ½åŠ›ä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæœ‰ç”¨çš„åå¥½æ•°æ®ï¼Œä¸ºå¯æ‰©å±•æ•°æ®ç”Ÿæˆæä¾›åŸºç¡€
        - **ä¸¤é˜¶æ®µååŒ**: é˜¶æ®µ1æå‡å›¾åƒç†è§£ï¼Œé˜¶æ®µ2æå‡åŸºäºç†è§£çš„æ¨ç†ï¼Œä¸¤è€…ç»“åˆæ•ˆæœæœ€ä½³
        - **è´Ÿæ ·æœ¬é‡è¦æ€§**: éåå¥½æ ·æœ¬åœ¨åå¥½å¯¹é½ä¸­èµ·å…³é”®ä½œç”¨ï¼Œä»…ä½¿ç”¨æ­£æ ·æœ¬æ— æ³•è¾¾åˆ°ç›¸åŒæ•ˆæœ
        - **æ•°æ®è§„æ¨¡å½±å“**: æ€§èƒ½éšæ•°æ®è§„æ¨¡å¢åŠ è€Œæå‡ï¼Œå±•ç¤ºåˆ©ç”¨å¤§é‡æœªæ ‡æ³¨å›¾åƒçš„æ½œåŠ›
        - **å›¾åƒåˆ†å¸ƒç›¸å…³æ€§**: è®­ç»ƒå›¾åƒä¸è¯„ä¼°ä»»åŠ¡çš„åˆ†å¸ƒé‡å è¶Šå¤§ï¼Œæ€§èƒ½æå‡è¶Šæ˜æ˜¾
      - **æœºæ„**: åŠ å·å¤§å­¦æ´›æ‰çŸ¶åˆ†æ ¡ã€åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡ã€æ–¯å¦ç¦å¤§å­¦
      - **ä½œè€…**: Yihe Deng, Pan Lu, Fan Yin, Ziniu Hu, Sheng Shen, Quanquan Gu, James Zou, Kai-Wei Chang, Wei Wang
      - **å‘å¸ƒæ—¶é—´**: NeurIPS 2024 | arXiv 2024å¹´5æœˆ
      - **å¼€æº**: âœ… [ä»£ç å’Œæ•°æ®](https://stic-lvlm.github.io/)
      - **æ„ä¹‰**:
        - **æ–¹æ³•åˆ›æ–°**: é¦–ä¸ªä¸“é—¨é’ˆå¯¹å›¾åƒç†è§£çš„è‡ªè®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡è‡ªæ„å»ºåå¥½æ•°æ®é›†æå‡LVLMæ€§èƒ½
        - **æˆæœ¬æ•ˆç›Š**: ä½¿ç”¨70%æ›´å°‘çš„ç›‘ç£å¾®è°ƒæ•°æ®ï¼Œå®ç°å¹³å‡4.0%çš„æ€§èƒ½æå‡
        - **å¯æ‰©å±•æ€§**: å¯åº”ç”¨äºå¤§é‡æœªæ ‡æ³¨å›¾åƒï¼Œå±•ç¤ºåˆ©ç”¨å¤§è§„æ¨¡æœªæ ‡æ³¨æ•°æ®çš„æ½œåŠ›
        - **å®ç”¨ä»·å€¼**: åœ¨7ä¸ªä¸åŒåŸºå‡†ä¸Šä¸€è‡´ä¸”æ˜¾è‘—æå‡æ€§èƒ½ï¼Œè¯æ˜æ–¹æ³•çš„æœ‰æ•ˆæ€§
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2312.06731">ğŸ“„ Genixer</a></b><br>
<code>arXiv 2312.06731</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **èµ‹èƒ½å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºå¼ºå¤§çš„æ•°æ®ç”Ÿæˆå™¨** - æ¢ç´¢å½“å‰MLLMç‹¬ç«‹ç”Ÿæˆè§†è§‰æŒ‡ä»¤è°ƒä¼˜æ•°æ®çš„æ½œåŠ›ï¼Œæ— éœ€ä¾èµ–GPT-4V
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å››é˜¶æ®µè‡ªåŠ¨åŒ–æ•°æ®ç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»Ÿæ€§æ¢ç´¢å½“å‰MLLMä½œä¸ºæ•°æ®ç”Ÿæˆå™¨èƒ½åŠ›çš„æ–¹æ³•ï¼Œè¯æ˜MLLMå¯ä»¥ç‹¬ç«‹ç”Ÿæˆé«˜è´¨é‡è§†è§‰æŒ‡ä»¤æ•°æ®ï¼Œåœ¨æŸäº›å¤æ‚ä»»åŠ¡ä¸Šç”šè‡³è¶…è¶ŠGPT-4V
      - **Genixer Pipelineï¼ˆå››ä¸ªå…³é”®æ­¥éª¤ï¼‰**:
        1. **æŒ‡ä»¤æ•°æ®æ”¶é›†**:
           - **ä»»åŠ¡é€‰æ‹©**: ç²¾å¿ƒé€‰æ‹©9ä¸ªä»£è¡¨æ€§VLä»»åŠ¡ï¼Œåˆ†ä¸ºä¸¤å¤§ç±»
           - **é€šç”¨ä»»åŠ¡**: Common VQAã€Adversarial VQAã€Multi-choice VQAã€Multi-turn Dialogue
           - **å®šä½ä»»åŠ¡**: REC (Referring Expression Comprehension)ã€REG (Referring Expression Generation)ã€PointQAã€Qâ†’CBoxAã€Referential Dialogue
           - **æ•°æ®æ¥æº**: VQAv2ã€GQAã€Counting110Kã€POPEã€A-OKVQAã€LLaVA-Conv-58Kã€VGã€RefCOCOã€PointQALocalã€Visual7Wç­‰
           - **æ€»è®­ç»ƒæ•°æ®**: çº¦200ä¸‡æ ·æœ¬ç”¨äºè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
        2. **æŒ‡ä»¤æ¨¡æ¿è®¾è®¡**:
           - **ä¸¤çº§æŒ‡ä»¤ç³»ç»Ÿ**: å®ç°ä»»åŠ¡æ— å…³å’Œä»»åŠ¡ç‰¹å®šä¸¤ç§ç”Ÿæˆæ¨¡å¼
           - **é€šç”¨æŒ‡ä»¤**: 58æ¡æ‰‹å†™æŒ‡ä»¤æ¨¡æ¿ï¼Œå¦‚"Please provide a clear and direct question and answer after examining the image"
           - **ç‰¹å®šæŒ‡ä»¤**: æ˜ç¡®æŒ‡å®šä»»åŠ¡ç±»å‹ï¼Œå¦‚"This is a Common VQA task"
           - **æ§åˆ¶å¸¸æ•°Ï„**: è®­ç»ƒæ—¶æ§åˆ¶ä»…ä½¿ç”¨é€šç”¨æŒ‡ä»¤çš„æ ·æœ¬æ¯”ä¾‹ï¼ˆä¸åŒä»»åŠ¡ç±»å‹è®¾ç½®ä¸åŒï¼š0.2-0.5ï¼‰
           - **æ¨ç†çµæ´»æ€§**: æ¨ç†æ—¶å¯åˆ‡æ¢æ¨¡å¼ï¼Œæ·»åŠ æˆ–ä¸æ·»åŠ ç‰¹å®šæŒ‡ä»¤
        3. **èµ‹èƒ½MLLM**:
           - **ä¸¤ä¸ªæ•°æ®ç”Ÿæˆå™¨**:
             - **Genixer-L**: åŸºäºLLaVA1.5è®­ç»ƒï¼Œä¸“æ³¨äºé€šç”¨ä»»åŠ¡æ•°æ®ç”Ÿæˆ
               - **è®­ç»ƒä»»åŠ¡**: Common VQAã€Adv VQAã€MC VQAã€MD
               - **è®­ç»ƒè®¾ç½®**: AdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡1Ã—10â»âµï¼Œæ‰¹æ¬¡å¤§å°128ï¼Œè®­ç»ƒ1ä¸ªepochï¼ˆçº¦14å°æ—¶ï¼‰
             - **Genixer-S**: åŸºäºShikraè®­ç»ƒï¼Œä¸“æ³¨äºå®šä½ä»»åŠ¡æ•°æ®ç”Ÿæˆ
               - **ä¸¤é˜¶æ®µè®­ç»ƒ**: ç¬¬ä¸€é˜¶æ®µèšç„¦RECå’ŒREGï¼Œç¬¬äºŒé˜¶æ®µæ·»åŠ PointQAã€Qâ†’CBoxAã€RD
               - **è®­ç»ƒè®¾ç½®**: ç¬¬ä¸€é˜¶æ®µå­¦ä¹ ç‡3Ã—10â»âµã€æ‰¹æ¬¡128ï¼Œç¬¬äºŒé˜¶æ®µå­¦ä¹ ç‡1Ã—10â»âµã€æ‰¹æ¬¡64
           - **è®­ç»ƒç›®æ ‡**: è‡ªå›å½’ç”Ÿæˆé—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œå…¬å¼ä¸º max log p(Xâ‚’|X_G, X_S, X_I)
        4. **æ•°æ®ç”Ÿæˆä¸è¿‡æ»¤**:
           - **å›¾åƒæº**: 140ä¸‡å›¾åƒï¼ˆ558Kæ¥è‡ªLAION/CC3M/SBUæ··åˆï¼Œ830Kæ¥è‡ªSBUï¼‰
           - **é€šç”¨ä»»åŠ¡æ•°æ®ç”Ÿæˆ**:
             - **ç”Ÿæˆ**: ä½¿ç”¨Genixer-Låœ¨1.4Må›¾åƒä¸Šç”Ÿæˆ1.4MåŸå§‹VQAä¸‰å…ƒç»„
             - **Fuyué©±åŠ¨è¿‡æ»¤æ¡†æ¶**:
               - **éªŒè¯æç¤º**: "Here is a question-answer pair. Is {Q:X_q \nA:X_a} true for this image?\nPlease answer this question with Yes or No.\n"
               - **æ¦‚ç‡è®¡ç®—**: è®¡ç®—é¢„æµ‹"Yes"çš„æ¦‚ç‡ P(Y_r|X_I, X_q, X_a)
               - **é˜ˆå€¼è¿‡æ»¤**: Î»=0.7ï¼Œä¿ç•™é«˜è´¨é‡æ ·æœ¬
               - **ç»“æœ**: ä»1.4Mè¿‡æ»¤è‡³915Kï¼Œå‘½åä¸º**Genixer-915K**
           - **å®šä½ä»»åŠ¡æ•°æ®ç”Ÿæˆ**:
             - **ç”Ÿæˆ**: ä½¿ç”¨Genixer-Såœ¨1.4Må›¾åƒä¸Šç”Ÿæˆ1.4MåŸå§‹RECæ•°æ®
             - **CLIPé©±åŠ¨è¿‡æ»¤æ¡†æ¶**:
               - **ä¸‰æ­¥è¿‡æ»¤**: (1) æ ¼å¼éªŒè¯ï¼ˆæ­£åˆ™è¡¨è¾¾å¼æå–åæ ‡å’Œæ–‡æœ¬ï¼‰; (2) è¾¹ç•Œæ¡†å°ºå¯¸è¿‡æ»¤ï¼ˆå®½/é«˜â‰¥50ï¼‰; (3) CLIPç›¸ä¼¼åº¦è¿‡æ»¤ï¼ˆOpenCLIP-Lï¼Œé˜ˆå€¼0.6ï¼‰
               - **ç»“æœ**: ä»1.4Mè¿‡æ»¤è‡³350Kï¼Œå‘½åä¸º**Genixer-350K**
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **æ— éœ€GPT-4V**: å®Œå…¨åŸºäºå¼€æºMLLMï¼Œæ¶ˆé™¤é«˜æ˜‚APIæˆæœ¬
        - **å¤æ‚ä»»åŠ¡ä¼˜åŠ¿**: åœ¨RECç­‰å¤æ‚ä»»åŠ¡ä¸Šç”Ÿæˆè´¨é‡è¶…è¶ŠGPT-4Vï¼ˆå¦‚å›¾1æ‰€ç¤ºï¼‰
        - **å¯æ§ç”Ÿæˆ**: ä¸¤çº§æŒ‡ä»¤ç³»ç»Ÿå®ç°çµæ´»çš„ä»»åŠ¡æ§åˆ¶
        - **è‡ªåŠ¨è¿‡æ»¤**: åŒé‡è¿‡æ»¤æœºåˆ¶ç¡®ä¿æ•°æ®è´¨é‡
      - **æ•°æ®è§„æ¨¡**:
        - **Genixer-915K**: 91.5ä¸‡VQAç±»åˆæˆæ•°æ®
          - **é—®é¢˜é•¿åº¦**: æ˜¾è‘—é•¿å°¾åˆ†å¸ƒï¼Œæ¯”VQAv2åŒ…å«æ›´å¤šé•¿å¥
          - **è¯æ±‡å¤šæ ·æ€§**: ä¸°å¯Œçš„åè¯å’ŒåŠ¨è¯åˆ†å¸ƒ
          - **è´¨é‡éªŒè¯**: Fuyu-8Bè¯„ä¼°æ˜¾ç¤º82-88%å‡†ç¡®ç‡ï¼Œå¹³å‡æ¦‚ç‡0.82-0.87
        - **Genixer-350K**: 35ä¸‡RECç±»åˆæˆæ•°æ®
          - **è¡¨è¾¾å¼é•¿åº¦**: å¹³å‡6.67è¯ï¼ˆvs RefCOCOgçš„8.43ï¼‰
          - **åŒºåŸŸè¦†ç›–**: 44.8ä¸‡å¯¹è±¡ï¼Œè¦†ç›–å¤šæ ·åŒ–åœºæ™¯
          - **è´¨é‡éªŒè¯**: CLIPç›¸ä¼¼åº¦è¿‡æ»¤ç¡®ä¿æ–‡æœ¬-åŒºåŸŸå¯¹é½
      - **å®éªŒç»“æœ**:
        - **é€šç”¨ä»»åŠ¡è¯„ä¼°**ï¼ˆLLaVA1.5 + Genixer-915Kï¼‰:
          - **12ä¸ªåŸºå‡†æµ‹è¯•**: åœ¨10ä¸ªä¸Šè·å¾—æå‡
          - **æ˜¾è‘—æ”¹è¿›**: VizWiz +3.8%ã€ScienceQA +2.9%ã€MME +37.7åˆ†
          - **å…¶ä»–æå‡**: VQAv2 +0.6%ã€GQA +1.1%ã€TextVQA +0.8%ã€POPE +1.4%
        - **å®šä½ä»»åŠ¡è¯„ä¼°**ï¼ˆShikra + Genixer-350Kï¼‰:
          - **8ä¸ªRECæ•°æ®é›†**: åœ¨7ä¸ªä¸Šè·å¾—æå‡
          - **å¹³å‡æå‡**: +0.6%ï¼ˆéå¹³å‡¡æå‡ï¼‰
          - **æœ€ä½³è¡¨ç°**: RefCOCO test-A +0.53%ã€RefCOCO+ test-B +1.02%
        - **æ•°æ®ç”Ÿæˆå™¨æ€§èƒ½**:
          - **Genixer-L**: åœ¨6ä¸ªåŸºå‡†ä¸Šï¼Œé›¶æ ·æœ¬è®¾ç½®ä¸‹éƒ¨åˆ†ä»»åŠ¡æå‡ï¼ˆVQAv2 +1.2%ã€VizWiz +0.8%ï¼‰
          - **æ··åˆè®­ç»ƒ**: ç»“åˆåŸå§‹å¾®è°ƒæ•°æ®åï¼Œæ‰€æœ‰åŸºå‡†å‡æ˜¾è‘—æå‡ï¼ˆVQAv2 +1.7%ã€VizWiz +4.1%ï¼‰
        - **æ¶ˆèç ”ç©¶**:
          - **æ•°æ®è§„æ¨¡æ•ˆåº”**: 300Kâ†’610Kâ†’915Kï¼Œæ€§èƒ½æŒç»­æå‡
          - **è¿‡æ»¤é˜ˆå€¼**: Î»=0.7ä¼˜äº0.5å’Œ0ï¼Œè¯æ˜è´¨é‡>æ•°é‡
        - **äººå·¥è¯„ä¼°**:
          - **100ä¸ªæ ·æœ¬åˆ†æ**: 7ç§é—®é¢˜ç±»å‹åˆ†å¸ƒï¼ˆActionã€Colorã€Countingã€Object Typeã€Relative Positionã€Yes/Noã€Othersï¼‰
          - **å‡†ç¡®ç‡**: held-in (COCO) 75-92%ï¼Œheld-out (Flickr30K) 65-100%
          - **ç”¨æˆ·åå¥½ç ”ç©¶**: 13ä¸ªæœ‰æ•ˆè°ƒæŸ¥æ˜¾ç¤ºï¼Œåœ¨RECä»»åŠ¡ä¸ŠGenixerç”Ÿæˆæ•°æ®æ›´å—åå¥½ï¼ˆvs GPT-4Vï¼‰
      - **å…³é”®å‘ç°**:
        - **MLLMä½œä¸ºæ•°æ®ç”Ÿæˆå™¨**: å½“å‰MLLMå¯ä»¥ç‹¬ç«‹ç”Ÿæˆé«˜è´¨é‡è§†è§‰æŒ‡ä»¤æ•°æ®ï¼Œæ— éœ€GPT-4Vè¾…åŠ©
        - **å¤æ‚ä»»åŠ¡ä¼˜åŠ¿**: åœ¨RECç­‰å¤æ‚ä»»åŠ¡ä¸Šï¼ŒMLLMè®­ç»ƒåç”Ÿæˆè´¨é‡è¶…è¶ŠGPT-4V
        - **æ€§èƒ½æå‡**: åˆæˆæ•°æ®é›†æ˜¾è‘—å¢å¼ºMLLMåœ¨å¤šä¸ªå¤šæ¨¡æ€åŸºå‡†ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å¸®åŠ©ç¼“è§£æ¨¡å‹å¹»è§‰
        - **æˆæœ¬æ•ˆç›Š**: æ¶ˆé™¤GPT-4V APIæˆæœ¬ï¼ŒåŒæ—¶æä¾›æ›´çµæ´»çš„ç”Ÿæˆæ§åˆ¶
      - **æœºæ„**: æ–°åŠ å¡å›½ç«‹å¤§å­¦Show Labã€æ–°åŠ å¡ç®¡ç†å¤§å­¦
      - **ä½œè€…**: Henry Hengyuan Zhao, Pan Zhou, Mike Zheng Shou
      - **å‘å¸ƒæ—¶é—´**: arXiv 2023å¹´12æœˆ (v6: 2024å¹´)
      - **å¼€æº**: âœ… [ä»£ç ã€æ•°æ®å’Œæ¨¡å‹](https://github.com/zhaohengyuan1/Genixer)
      - **é‡è¦æ„ä¹‰**:
        - **èŒƒå¼åˆ›æ–°**: é¦–æ¬¡ç³»ç»Ÿæ€§è¯æ˜MLLMå¯ä»¥ä½œä¸ºç‹¬ç«‹æ•°æ®ç”Ÿæˆå™¨ï¼Œæ— éœ€ä¾èµ–å•†ä¸šAPI
        - **æˆæœ¬é™ä½**: ä¸ºå¤§è§„æ¨¡æ•°æ®ç”Ÿæˆæä¾›ç»æµå¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆ
        - **è´¨é‡ä¿è¯**: åŒé‡è¿‡æ»¤æœºåˆ¶ç¡®ä¿åˆæˆæ•°æ®è´¨é‡
        - **ä»»åŠ¡è¦†ç›–**: åŒæ—¶æ”¯æŒé€šç”¨å’Œå®šä½ä»»åŠ¡ï¼Œæä¾›å…¨é¢çš„æ•°æ®ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.08468">ğŸ“„ mmE5</a></b><br>
<code>arXiv 2502.08468</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šè¿‡é«˜è´¨é‡åˆæˆæ•°æ®æ”¹å–„å¤šæ¨¡æ€å¤šè¯­è¨€åµŒå…¥** - å¼€å‘é«˜è´¨é‡åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œä¸ºå¤šæ¨¡æ€å¤šè¯­è¨€åµŒå…¥æä¾›è¦†ç›–å¤šæ ·åŒ–ä»»åŠ¡ã€æ¨¡æ€ç»„åˆå’Œè¯­è¨€çš„æ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **MLLMå¼•å¯¼çš„å•æ¬¡å¤šæ–¹é¢ç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªç³»ç»Ÿæ€§æ–¹æ³•ï¼Œè¯†åˆ«é«˜è´¨é‡åˆæˆå¤šæ¨¡æ€æ•°æ®çš„ä¸‰ä¸ªå…³é”®æ ‡å‡†ï¼ˆå¹¿æ³›èŒƒå›´ã€é²æ£’è·¨æ¨¡æ€å¯¹é½ã€é«˜ä¿çœŸåº¦ï¼‰ï¼Œå¹¶å®ç°è¦†ç›–93ç§è¯­è¨€å’Œ7ç§æ¨¡æ€ç»„åˆçš„ç»¼åˆç”Ÿæˆæ¡†æ¶
      - **ä¸‰ä¸ªè´¨é‡æ ‡å‡†æ¡†æ¶**:
        1. **å¹¿æ³›èŒƒå›´**: ç¡®ä¿ç”Ÿæˆçš„æ•°æ®è¦†ç›–å¤šæ ·åŒ–ä»»åŠ¡ï¼ˆåˆ†ç±»ã€VQAã€æ£€ç´¢ï¼‰å’Œæ¨¡æ€ç»„åˆï¼Œé€‚ç”¨äºå„ç§ä¸‹æ¸¸åœºæ™¯
        2. **é²æ£’è·¨æ¨¡æ€å¯¹é½**: é€šè¿‡æ·±åº¦æ€è€ƒè¿‡ç¨‹å’Œç»¼åˆè§£é‡Šä½¿ä¸åŒæ¨¡æ€è¯­ä¹‰ä¸€è‡´
        3. **é«˜ä¿çœŸåº¦**: é€šè¿‡è‡ªè¯„ä¼°å’Œç²¾ç‚¼æœºåˆ¶åœ¨åˆæˆæ•°æ®ä¸­ä¿æŒç°å®ç»†èŠ‚
      - **å•æ¬¡ç”Ÿæˆè¿‡ç¨‹**:
        - **è§†è§‰è§£é‡Š**: ä»å››ä¸ªè§’åº¦è¿›è¡Œå¤šæ–¹é¢åˆ†æï¼ˆæ€»ä½“æè¿°ã€å¯¹è±¡çº§ç»†èŠ‚ã€ä¸Šä¸‹æ–‡ç‰¹å¾ã€ä»»åŠ¡ç‰¹å®šå¤´è„‘é£æš´ï¼‰
        - **æ•°æ®åˆæˆ**: åŸºäºå…¨é¢è§†è§‰ç†è§£ç”Ÿæˆä»»åŠ¡ç‰¹å®šæ•°æ®æ ·æœ¬
        - **è‡ªè¯„ä¼°**: è·¨ç›¸å…³æ€§ã€åˆç†æ€§ã€æ¸…æ™°åº¦å’Œå¤šæ ·æ€§ç»´åº¦è¯„ä¼°æ•°æ®è´¨é‡
        - **ç²¾ç‚¼**: åŸºäºè¯„ä¼°åé¦ˆäº§ç”Ÿä¿®è®¢ç‰ˆæœ¬ä»¥æé«˜è´¨é‡
      - **å…¨é¢ä»»åŠ¡ä¸æ¨¡æ€è¦†ç›–**:
        - **3ç§ä»»åŠ¡**: åˆ†ç±»ï¼ˆç±»å‹/ä¸»é¢˜è¯†åˆ«ï¼‰ã€VQAï¼ˆè§†è§‰é—®ç­”ï¼‰ã€æ£€ç´¢ï¼ˆè·¨æ¨¡æ€æœç´¢ï¼‰
        - **7ç§æ¨¡æ€ç»„åˆ**: Iâ†’T, ITâ†’T, Tâ†’IT, Tâ†’I, Iâ†’I, ITâ†’I, ITâ†’ITï¼ˆå…¨é¢è¦†ç›– vs å…ˆå‰å·¥ä½œçš„1-2ç§ç»„åˆï¼‰
        - **93ç§è¯­è¨€**: è‹±è¯­ã€é˜¿æ‹‰ä¼¯è¯­ã€è¥¿ç­ç‰™è¯­ã€ä¸­æ–‡ã€æ³•è¯­ã€å¾·è¯­ã€è·å…°è¯­ã€è‘¡è„ç‰™è¯­ã€ä¿„è¯­ã€æ³¢å…°è¯­ã€æ—¥è¯­ã€æ„å¤§åˆ©è¯­ã€å°å°¼è¯­ã€æ³¢æ–¯è¯­ + 75ç§ä½èµ„æºè¯­è¨€
      - **å¤šæ–¹é¢è§†è§‰åˆ†æ**:
        - **æ€»ä½“æè¿°**: åŒ…æ‹¬ä¸»è¦å¯¹è±¡ã€åœºæ™¯ã€æ˜¾è‘—ç‰¹å¾çš„æ•´ä½“æ€»ç»“
        - **å¯¹è±¡çº§ç»†èŠ‚**: å•ä¸ªå¯¹è±¡ã€å±æ€§ï¼ˆé¢œè‰²ã€å¤§å°ã€ä½ç½®ï¼‰ã€å…³ç³»
        - **ä¸Šä¸‹æ–‡ç‰¹å¾**: åœºæ™¯ç¯å¢ƒã€èƒŒæ™¯ç»†èŠ‚ã€å…‰ç…§ã€åŠ¨ä½œ
        - **ä»»åŠ¡ç‰¹å®šå¤´è„‘é£æš´**: åˆ†æå›¾åƒå¦‚ä½•ä¸ç‰¹å®šä»»åŠ¡éœ€æ±‚ç›¸å…³
      - **è´¨é‡ä¿è¯æœºåˆ¶**:
        - **æ·±åº¦æ€è€ƒè¿‡ç¨‹**: å…¨é¢çš„ç”Ÿæˆå‰åˆ†æç¡®ä¿é²æ£’çš„è·¨æ¨¡æ€å¯¹é½
        - **è‡ªè¯„ä¼°æŒ‡æ ‡**: è·¨å¤šä¸ªè´¨é‡ç»´åº¦çš„è‡ªåŠ¨åŒ–è¯„ä¼°
        - **ç¡¬è´Ÿæ ·æœ¬æŒ–æ˜**: ä¸ºå¯¹æ¯”å­¦ä¹ ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„è´Ÿæ ·æœ¬
        - **å¤šè¯­è¨€ä¸€è‡´æ€§**: ç¡®ä¿æ‰€æœ‰93ç§æ”¯æŒè¯­è¨€çš„è´¨é‡ä¿æŒ
  - **æŠ€æœ¯å®ç°**:
      - **åŸºç¡€å›¾åƒ**: ä»LAION-400Mé‡‡æ ·ä»¥è·å¾—å¤šæ ·æ€§å’Œè§„æ¨¡
      - **MLLMé›†æˆ**: ä½¿ç”¨LLaMA-3-Visionè¿›è¡Œå•æ¬¡ç”Ÿæˆä»¥é¿å…ä¿¡æ¯æŸå¤±
      - **è®­ç»ƒç­–ç•¥**: åœ¨å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹ä¸Šè¿›è¡ŒLoRAå¾®è°ƒï¼ˆç§©8ï¼‰çš„å¯¹æ¯”å­¦ä¹ 
      - **è¯­è¨€åˆ†å¸ƒ**: å¹³è¡¡è¦†ç›–ï¼Œ23%è‹±è¯­ï¼Œå…¶ä»–è¯­è¨€å¹³å‡åˆ†å¸ƒ
  - **æ•°æ®è§„æ¨¡**:
      - **æ€»åˆæˆæ•°æ®**: **56ä¸‡é«˜è´¨é‡æ ·æœ¬**è·¨æ‰€æœ‰ä»»åŠ¡å’Œæ¨¡æ€ç»„åˆ
      - **ä»»åŠ¡åˆ†å¸ƒ**: åˆ†ç±»ï¼ˆ14ä¸‡ï¼‰ã€VQAï¼ˆ14ä¸‡ï¼‰ã€æ£€ç´¢ï¼ˆ28ä¸‡ï¼‰ç¡®ä¿å¹³è¡¡è¦†ç›–
      - **å¤šè¯­è¨€è¦†ç›–**: å…¨é¢æ”¯æŒ93ç§è¯­è¨€åŒ…æ‹¬ä½èµ„æºè¯­è¨€
      - **è´¨é‡è¿‡æ»¤**: ä¸¥æ ¼çš„è‡ªè¯„ä¼°å’Œç²¾ç‚¼ç¡®ä¿é«˜åˆæˆæ•°æ®ä¿çœŸåº¦
  - **è¯„ä¼°ä¸ç»“æœ**:
      - **MMEBåŸºå‡†**: è¾¾åˆ°SOTAæ€§èƒ½ï¼ˆ69.8%å¹³å‡ï¼‰ï¼Œæ˜¾è‘—è¶…è¶Šä¹‹å‰æ–¹æ³•ï¼ˆVLM2Vec: 62.9%ï¼ŒMMRet: 64.1%ï¼‰
      - **å¤šè¯­è¨€æ€§èƒ½**: åœ¨XTDåŸºå‡†çš„æ‰€æœ‰7ç§è¯­è¨€ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆ95.3%å¹³å‡ vs GME: 94.1%ï¼‰
      - **é›¶æ ·æœ¬èƒ½åŠ›**: ä»…ä½¿ç”¨åˆæˆæ•°æ®è¡¨ç°å¼ºåŠ²ï¼ˆ58.6% vs ä¹‹å‰æœ€ä½³44.0%åœ¨MMEBä¸Šï¼‰
      - **æ‰©å±•æ•ˆåº”**: æ€§èƒ½ä¸æ•°æ®å¤§å°å‘ˆçº¿æ€§å¯¹æ•°å…³ç³»ï¼Œè¯æ˜é«˜åˆæˆæ•°æ®è´¨é‡
  - **å…³é”®æŠ€æœ¯è´¡çŒ®**:
      - **è´¨é‡æ ‡å‡†æ¡†æ¶**: é¦–æ¬¡ç³»ç»Ÿæ€§è¯†åˆ«åˆæˆå¤šæ¨¡æ€æ•°æ®è´¨é‡çš„ä¸‰ä¸ªå…³é”®æ ‡å‡†
      - **å•æ¬¡ç”Ÿæˆ**: é€šè¿‡å…¨é¢çš„å•æ¬¡MLLMç”Ÿæˆé¿å…ä¿¡æ¯æŸå¤±
      - **å…¨é¢è¦†ç›–**: åœ¨å•ä¸ªæ¡†æ¶ä¸­è·¨ä»»åŠ¡ã€æ¨¡æ€å’Œè¯­è¨€çš„å‰æ‰€æœªæœ‰å¹¿åº¦
      - **å¤šè¯­è¨€å“è¶Š**: å±•ç¤ºè·¨å¤šæ ·åŒ–è¯­è¨€å®¶æ—çš„ä¼˜å¼‚å¤šè¯­è¨€åµŒå…¥èƒ½åŠ›
  - **æœºæ„**: ä¸­å›½äººæ°‘å¤§å­¦ã€å¾®è½¯å…¬å¸
  - **å¼€æº**: âœ… [ä»£ç ã€æ•°æ®å’Œæ¨¡å‹](https://github.com/haon-chen/mmE5)
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2409.20424">ğŸ“„ World to Code (W2C)</a></b><br>
<code>arXiv 2409.20424</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šè¿‡è‡ªæŒ‡å¯¼ç»„åˆæ ‡æ³¨å’Œè¿‡æ»¤çš„å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆ** - é€šè¿‡VLMè‡ªæŒ‡å¯¼ç”Ÿæˆè§†è§‰åœºæ™¯çš„ç»“æ„åŒ–Pythonä»£ç è¡¨ç¤ºï¼Œå‡å°‘å¯¹ä¸“å®¶æ¨¡å‹å’Œäººå·¥æ ‡æ³¨çš„ä¾èµ–
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è‡ªæŒ‡å¯¼ç»„åˆPipelineä¸ä»£ç æ ¼å¼åŒ–**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªä½¿ç”¨VLMè‡ªèº«é€šè¿‡ä¸åŒæç¤ºæå–è·¨æ¨¡æ€ä¿¡æ¯å¹¶é€šè¿‡ä¸€è‡´æ€§ç­–ç•¥è¿‡æ»¤ç”Ÿæˆè¾“å‡ºçš„æ¡†æ¶ï¼Œå°†æœ€ç»ˆè¾“å‡ºç»„ç»‡ä¸ºPythonä»£ç æ ¼å¼ä»¥å¢å¼ºç»“æ„è¡¨ç¤º
      - **å››é˜¶æ®µæ„å»ºPipeline**:
        1. **è§†è§‰æ¦‚å¿µæå–**:
           - **å…¨å±€æ ‡æ³¨ç”Ÿæˆ**: å‡†ç¡®æè¿°å›¾åƒçš„ç®€å•å¥å­
           - **è¯¦ç»†æ ‡æ³¨ç”Ÿæˆ**: æ‰€æœ‰è§†è§‰æ¦‚å¿µçš„ç»¼åˆæè¿°ï¼ˆâ‰¤120è¯ï¼‰
           - **æ¦‚å¿µæå–**: ä½¿ç”¨NLTKä»æ ‡æ³¨ä¸­æå–åè¯çŸ­è¯­ï¼Œç”¨WordNetåå¤„ç†å»é‡
           - **å®šä½**: ä½¿ç”¨Grounding DINOå°†è§†è§‰æ¦‚å¿µæ˜ å°„åˆ°è¾¹ç•Œæ¡†
        2. **è‡ªæŒ‡å¯¼ä¿¡æ¯æå–**:
           - **åŒºåŸŸçº§æ ‡æ³¨**: ä½¿ç”¨è£å‰ªå›¾åƒåŒºåŸŸä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„è§†è§‰æ¦‚å¿µç”Ÿæˆç»„åˆæ ‡æ³¨
           - **OCRä¿¡æ¯æå–**: é€šè¿‡æŒ‡å¯¼æç¤ºå¼•å¯¼VLMæå–æ–‡æœ¬ä¿¡æ¯ï¼ˆåœ¨å¤æ‚åœºæ™¯ä¸­ä¼˜äºä¼ ç»ŸOCRå·¥å…·ï¼‰
           - **æç¤ºæ¨¡æ¿**: é¢„å®šä¹‰é€šç”¨æ¨¡æ¿ç¡®ä¿æ›´å¥½çš„æŒ‡ä»¤éµå¾ªæ€§
        3. **è‡ªä¸€è‡´æ€§ä¿¡æ¯è¿‡æ»¤**:
           - **è®¡æ•°ä¸€è‡´æ€§è¿‡æ»¤**: é€šè¿‡VLMéªŒè¯ç¡®è®¤åˆ†ç»„è§†è§‰æ¦‚å¿µçš„å­˜åœ¨
           - **æ ‡æ³¨é‡æ–°æ’åº**: ä½¿ç”¨VLMè‡ªè¯„ä¼°å¯¹æ ‡æ³¨è´¨é‡è¿›è¡Œè¯„åˆ†å’Œæ’åº
           - **åŸºäºè§„åˆ™è¿‡æ»¤**: ä½¿ç”¨ç»“æ„åŒ–è§„åˆ™ç§»é™¤è®¡æ•°ä¸ä¸€è‡´çš„æ ·æœ¬
        4. **ç»“æ„åŒ–ä»£ç æ ¼å¼åŒ–**:
           - **Pythonç±»ç»„ç»‡**: å°†è§†è§‰ä¿¡æ¯ç»“æ„åŒ–ä¸ºå¸¦å¯¹è±¡å±æ€§çš„Pythonç±»
           - **ä¸°å¯Œæ ‡æ³¨**: ä¸ºæ¯ä¸ªè§†è§‰å…ƒç´ åŒ…å«æè¿°ã€è¾¹ç•Œæ¡†ã€OCRæ–‡æœ¬
           - **å±‚æ¬¡åˆ†ç»„**: åˆ†ç»„ç›¸ä¼¼æ¦‚å¿µï¼ˆå¦‚elephant_groupã€people_groupï¼‰ä»¥æ›´å¥½ç»„ç»‡
      - **è‡ªä¸€è‡´æ€§ç­–ç•¥**:
        - **ç”Ÿæˆå™¨-éªŒè¯å™¨æ–¹æ³•**: VLMæ—¢ä½œä¸ºç”Ÿæˆå™¨åˆä½œä¸ºéªŒè¯å™¨ç¡®ä¿ä¸€è‡´æ€§
        - **å¤šè½®éªŒè¯**: å¯¹æå–æ¦‚å¿µå’Œæè¿°çš„è¿­ä»£éªŒè¯
        - **è¯„åˆ†æœºåˆ¶**: æ‰‹åŠ¨è¯„åˆ†ç³»ç»Ÿè¿›è¡Œæ ‡æ³¨è´¨é‡è¯„ä¼°
      - **è´¨é‡ä¿è¯**:
        - **æŸæœç´¢**: é¼“åŠ±VLMæä¾›å°½å¯èƒ½å¤šçš„è§†è§‰æ¦‚å¿µ
        - **æ¦‚å¿µéªŒè¯**: æ£€æŸ¥æ¯ä¸ªæå–æ¦‚å¿µçš„å­˜åœ¨æ€§å’Œè®¡æ•°å‡†ç¡®æ€§
        - **ä¸€è‡´æ€§è¯„åˆ†**: ä½¿ç”¨åŸºäºVLMçš„è¯„åˆ†æ¥æ’åºå’Œè¿‡æ»¤é«˜è´¨é‡æ ·æœ¬
  - **æŠ€æœ¯å®ç°**:
      - **åŸºç¡€æ•°æ®é›†**: ShareGPT4Vå›¾åƒï¼ˆå»é‡åï¼‰ç”¨äºå…¬å¹³æ¯”è¾ƒ
      - **VLMé›†æˆ**: å…¼å®¹LLaVA-1.5å’ŒLLaVA-NeXTæ¶æ„
      - **å¤„ç†å·¥å…·**: NLTKç”¨äºæ¦‚å¿µæå–ï¼ŒWordNetç”¨äºå»é‡ï¼ŒGrounding DINOç”¨äºç©ºé—´å®šä½
      - **ä»£ç ç»“æ„**: å¸¦åˆ†ç»„å¯¹è±¡å’Œè¯¦ç»†å±æ€§çš„è‡ªç„¶ç¯å¢ƒç±»
  - **æ•°æ®è§„æ¨¡**:
      - **ç”Ÿæˆæ ·æœ¬**: 34K (LLaVA-1.5-7B), 33K (LLaVA-1.5-13B), 37K (LLaVA-NeXT-7B), 29K (LLaVA-NeXT-13B)
      - **å¤„ç†æ—¶é—´**: 32ä¸ªA100ä¸Š1-1.5å¤©ï¼ˆLLaVA-1.5ï¼‰ï¼Œ48ä¸ªA100ä¸Š2-3å¤©ï¼ˆLLaVA-NeXTï¼‰
      - **ä¸€è‡´æ€§è¿‡æ»¤**: è¿‡æ»¤é˜¶æ®µå¤§é‡æ•°æ®æ¶ˆé™¤ç¡®ä¿é«˜è´¨é‡
  - **è¯„ä¼°ä¸ç»“æœ**:
      - **VQAåŸºå‡†**: åœ¨7/9åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆLLaVA-NeXT-7Bï¼‰ï¼Œ6/9åŸºå‡†ï¼ˆLLaVA-NeXT-13Bï¼‰
      - **è§†è§‰å®šä½**: å¹³å‡IoUæå‡1.5/1.6ï¼ˆLLaVA-1.5 7B/13Bï¼‰ï¼Œ3.5/1.3ï¼ˆLLaVA-NeXT 7B/13Bï¼‰
      - **å°æ ·æœ¬å­¦ä¹ **: GQA 2-shotè¯„ä¼°5%å‡†ç¡®ç‡æå‡ï¼Œå±•ç¤ºæ”¹è¿›çš„ä»£ç è§£æèƒ½åŠ›
      - **ä»£ç vsæ ‡æ³¨**: Pythonä»£ç æ ¼å¼ä¸€è‡´è¶…è¶Šå•è½®/å¤šè½®å¯¹è¯æ ¼å¼
  - **å…³é”®æŠ€æœ¯è´¡çŒ®**:
      - **è‡ªç»™è‡ªè¶³**: é€šè¿‡VLMè‡ªæŒ‡å¯¼æ¶ˆé™¤å¯¹å¤šä¸ªä¸“å®¶æ¨¡å‹çš„éœ€æ±‚
      - **ä»£ç è¡¨ç¤º**: ç”¨äºç»“æ„åŒ–å¤šæ¨¡æ€æ•°æ®ç»„ç»‡çš„æ–°é¢–Pythonä»£ç æ ¼å¼
      - **ä¸€è‡´æ€§è¿‡æ»¤**: æ— éœ€äººå·¥æ ‡æ³¨çš„é²æ£’è‡ªä¸€è‡´æ€§è´¨é‡ä¿è¯ç­–ç•¥
      - **å¯æ‰©å±•æ€§**: å…¨è‡ªåŠ¨pipelineæ”¯æŒå¤§è§„æ¨¡ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ
  - **æœºæ„**: ä¸­å›½ç§‘å­¦é™¢å¤§å­¦ã€å­—èŠ‚è·³åŠ¨
  - **å¼€æº**: âœ… Pipelineä»£ç å’Œæ•°æ®æ„å»ºæ–¹æ³•è®º
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2406.19593">ğŸ“„ SKâ€‘VQA</a></b><br>
<code>arXiv 2406.19593</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**é¢å‘å¤šæ¨¡æ€RAG/çŸ¥è¯†å¢å¼ºçš„â€œå›¾åƒ+ä¸Šä¸‹æ–‡+é—®ç­”â€åˆæˆ** â€” é€šè¿‡GPTâ€‘4ä¸ºç»™å®šå›¾åƒåŒæ—¶ç”Ÿæˆç™¾ç§‘é£æ ¼ä¸Šä¸‹æ–‡ä¸éœ€ä¾èµ–ä¸Šä¸‹æ–‡æ¨ç†çš„å¤šç»„QAï¼Œæ„å»º200ä¸‡+æ ·æœ¬ï¼Œç”¨äºè®­ç»ƒ/è¯„ä¼°å…·â€œä¸Šä¸‹æ–‡å¢å¼ºç”Ÿæˆâ€èƒ½åŠ›çš„MLLMsï¼ˆKBâ€‘VQAï¼‰
  - **æ•°æ®åˆæˆæ–¹æ³•**ï¼š
      - **ä¸Šä¸‹æ–‡ä¸QAçš„è”åˆç”Ÿæˆ**ï¼šä»¥å›¾åƒä¸ºæ¡ä»¶ï¼ŒGPTâ€‘4å•æ­¥äº§å‡ºç›¸å…³çš„æ–‡ç« å¼ä¸Šä¸‹æ–‡ä¸é—®é¢˜â€‘ç­”æ¡ˆå¯¹ï¼Œé¿å…â€œä»…çœ‹å›¾å¯ç­”â€çš„é—®é¢˜
      - **å¤šæºå›¾åƒ + ä¸¤çº§è¿‡æ»¤**ï¼šå›¾åƒæ¥è‡ªLAIONã€WITï¼ˆWikipedia imagesï¼‰ã€COCOâ€‘Counterfactualsï¼›æä¾›IRè¿‡æ»¤ï¼ˆå»é™¤â€œè¿™å¼ å›¾ç‰‡ä¸­â€¦â€ç­‰ç›´æ¥å¼•ç”¨å›¾åƒçš„ä¼ªä¸Šä¸‹æ–‡ï¼‰ä¸CAPè¿‡æ»¤ï¼ˆç¡®ä¿ç­”æ¡ˆå¯åœ¨ä¸Šä¸‹æ–‡ä¸­æŠ½å–ï¼‰
  - **æ•°æ®è§„æ¨¡ä¸å¤šæ ·æ€§**ï¼š
      - æ€»è®¡2,006,489ä¸ªQAï¼Œè¦†ç›–290,266ä¸ªå›¾åƒâ€‘ä¸Šä¸‹æ–‡é…å¯¹ï¼›>96%é—®é¢˜ä¸ºå”¯ä¸€é—®é¢˜ï¼Œè¯æ€§/è¯æ±‡/é•¿åº¦åˆ†å¸ƒå‡æ˜¾è‘—ä¸°å¯Œäºæ—¢æœ‰KBâ€‘VQAæ•°æ®é›†
  - **å®éªŒå‘ç°**ï¼š
      - ä½œä¸ºåŸºå‡†æ›´å…·æŒ‘æˆ˜ï¼ˆå¤šæ¨¡å‹é›¶æ ·æœ¬åœ¨SKâ€‘VQAä¸Šä½äºEncâ€‘VQA/ViQuAEï¼‰ï¼›ä½œä¸ºè®­ç»ƒæ•°æ®å¯æ˜¾è‘—æå‡è·¨æ•°æ®é›†æ³›åŒ–ï¼Œç›¸æ¯”InfoSeek/Encâ€‘VQAæ›´ç¨³å¥ï¼›åœ¨å¤–éƒ¨æ£€ç´¢çš„RAGè®¾ç½®ä¸‹ä»å…·ä¼˜åŠ¿
  - **è´¨é‡ä¸æ§åˆ¶**ï¼š
      - **å›¾åƒä¸å˜â€‘æ–‡æœ¬å¢å¼º**ï¼šå›´ç»•æ—¢æœ‰å›¾åƒæ„å»ºé«˜è´¨é‡â€œä¸Šä¸‹æ–‡+QAâ€ï¼›é…IR/IR+CAPå­é›†ï¼Œå‡å°‘æ ·æœ¬é‡ä»ä¿æŒ/æå‡æ•ˆæœï¼Œåˆ©äºä»»åŠ¡å¯¹é½è°ƒå‚
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2308.08428">ğŸ“„ ALIP</a></b><br>
<code>arXiv 2308.08428</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2023å¹´8æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **è‡ªé€‚åº”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒä¸åˆæˆæ ‡æ³¨** - ä½¿ç”¨åˆæˆæ ‡æ³¨å‡å°‘Webæ•°æ®å™ªå£°ï¼Œé€šè¿‡è‡ªé€‚åº”æƒé‡æœºåˆ¶ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ 
  - **æ•°æ®åˆæˆæ–¹æ³•** - **OFAæ¨¡å‹ç”Ÿæˆåˆæˆæ ‡æ³¨ + è‡ªé€‚åº”æƒé‡é—¨æ§æœºåˆ¶**:
      - **æ ¸å¿ƒåˆ›æ–°**: é’ˆå¯¹Webæ•°æ®ä¸­å›¾æ–‡ä¸åŒ¹é…é—®é¢˜ï¼Œä½¿ç”¨å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡åˆæˆæ ‡æ³¨ï¼Œå¹¶è®¾è®¡è‡ªé€‚åº”æƒé‡ç³»ç»ŸåŠ¨æ€å¹³è¡¡åŸå§‹æ–‡æœ¬å’Œåˆæˆæ ‡æ³¨çš„è´¡çŒ®
      - **é—®é¢˜è¯†åˆ«**: Webçˆ¬å–æ•°æ®å­˜åœ¨å†…åœ¨å™ªå£°å’Œä¸åŒ¹é…çš„å›¾æ–‡å¯¹
        - **å†…å®¹ä¸åŒ¹é…**: åŸå§‹æ–‡æœ¬è¿‡äºæŠ½è±¡ï¼ˆå¦‚"Leisure Sunday"ï¼‰ä¸å…·ä½“å›¾åƒå†…å®¹ä¸ç¬¦
        - **ä¿¡æ¯ä¸è¶³**: Webæ–‡æœ¬ç¼ºä¹å¯¹å›¾åƒå†…å®¹çš„è¯¦ç»†æè¿°
        - **å™ªå£°å½±å“**: ä¸åŒ¹é…æ•°æ®å½±å“è¡¨å¾å­¦ä¹ æ€§èƒ½
      - **åˆæˆæ ‡æ³¨ç”Ÿæˆ**:
        - **ç”Ÿæˆæ¨¡å‹**: ä½¿ç”¨**OFA (One For All)**æ¨¡å‹ç”Ÿæˆåˆæˆæ ‡æ³¨
        - **å¼•å¯¼æç¤º**: "What does the image describe?" å¼•å¯¼ç”Ÿæˆå›¾åƒå†…å®¹æè¿°
        - **è´¨é‡ä¼˜åŠ¿**: åˆæˆæ ‡æ³¨æä¾›æ›´å‡†ç¡®ã€è¯¦ç»†çš„å›¾åƒå†…å®¹æè¿°
          - ç¤ºä¾‹: "A woman sitting on a step reading a book" vs "Leisure Sunday"
          - åŒ…å«å…·ä½“å¯¹è±¡ä¿¡æ¯ï¼ˆä¹¦ã€å¥³äººã€å°é˜¶ï¼‰å’ŒåŠ¨ä½œä¿¡æ¯ï¼ˆåç€ã€é˜…è¯»ï¼‰
      - **åŒè·¯å¾„æ¶æ„**:
        - **åŸå§‹è·¯å¾„**: å¤„ç†å›¾åƒ-åŸå§‹æ–‡æœ¬å¯¹ (x, t)
        - **åˆæˆè·¯å¾„**: å¤„ç†å›¾åƒ-åˆæˆæ ‡æ³¨å¯¹ (x, c)
        - **ä¸‰å…ƒç»„è¾“å…¥**: (å›¾åƒx, åŸå§‹æ–‡æœ¬t, åˆæˆæ ‡æ³¨c) ä½œä¸ºå®Œæ•´è®­ç»ƒå•å…ƒ
      - **è‡ªé€‚åº”æƒé‡é—¨æ§ç³»ç»Ÿ**:
        1. **è¯­è¨€ä¸€è‡´æ€§é—¨ (LCG)**:
           - **åŠŸèƒ½**: é¢„æµ‹æ ·æœ¬æƒé‡Wsï¼ŒåŸºäºåŸå§‹æ–‡æœ¬å’Œåˆæˆæ ‡æ³¨çš„ç›¸ä¼¼åº¦
           - **è®¡ç®—**: Ws = sigmoid(MLP(|t-c|, tâŠ™c, t, c))ï¼Œå…¶ä¸­âŠ™è¡¨ç¤ºå…ƒç´ ä¹˜æ³•
           - **ä½œç”¨**: è¯†åˆ«é«˜è´¨é‡æ ·æœ¬ï¼ˆæ–‡æœ¬æ ‡æ³¨ä¸€è‡´ï¼‰vs ä½è´¨é‡æ ·æœ¬ï¼ˆæ–‡æœ¬æ ‡æ³¨ä¸åŒ¹é…ï¼‰
        2. **æè¿°ä¸€è‡´æ€§é—¨ (DCG)**:
           - **åŠŸèƒ½**: è®¡ç®—å›¾åƒ-æ–‡æœ¬å¯¹æƒé‡Wtå’Œå›¾åƒ-æ ‡æ³¨å¯¹æƒé‡Wc
           - **åŸºäºå†å²ç›¸ä¼¼åº¦**: ä½¿ç”¨å†å²å¹³å‡ç›¸ä¼¼åº¦Hxtå’ŒHxcä½œä¸ºé˜ˆå€¼
           - **æƒé‡å…¬å¼**:
             - Wt = exp((Sxt - Hxt) Ã— Î³p) å½“Ws < 1æ—¶
             - Wc = exp((Sxc - Hxc) Ã— Î³p) å½“Ws < 1æ—¶
           - **è‡ªé€‚åº”è°ƒæ•´**: ä»ä½è´¨é‡æ ·æœ¬ä¸­æŒ–æ˜é«˜è´¨é‡å›¾æ–‡/å›¾æ³¨å¯¹
      - **è‡ªé€‚åº”å¯¹æ¯”æŸå¤±**:
        - **ä¼ ç»ŸInfoNCEå±€é™**: å¯¹æ‰€æœ‰è®­ç»ƒæ ·æœ¬å‡åŒ€åŠ æƒï¼Œå¿½è§†æ•°æ®è´¨é‡å·®å¼‚
        - **æ”¹è¿›ç­–ç•¥**: é›†æˆæ ·æœ¬æƒé‡Wså’Œå¯¹æƒé‡(Wt, Wc)åˆ°InfoNCEæŸå¤±ä¸­
        - **æŸå¤±å‡½æ•°**:
          - Lxt = -Î£ WsWt Ã— log(softmax(å›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦))
          - Lxc = -Î£ WsWc Ã— log(softmax(å›¾åƒ-æ ‡æ³¨ç›¸ä¼¼åº¦))
        - **åŠ¨æ€è°ƒæ•´**: è®­ç»ƒè¿‡ç¨‹ä¸­æƒé‡æ ¹æ®æ•°æ®è´¨é‡åŠ¨æ€å˜åŒ–
  - **æ•°æ®è§„æ¨¡**:
      - **åŸºç¡€æ•°æ®é›†**: YFCC15M (1500ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹)
      - **åˆæˆæ ‡æ³¨**: ä¸ºæ¯ä¸ªå›¾åƒç”Ÿæˆä¸€ä¸ªé«˜è´¨é‡åˆæˆæ ‡æ³¨
      - **è®¡ç®—æ•ˆç‡**: åˆæˆæ ‡æ³¨å¯é¢„è®¡ç®—å­˜å‚¨ï¼Œæ— éœ€åœ¨çº¿ç”Ÿæˆ
  - **è®­ç»ƒç­–ç•¥**:
      - **åŒç¼–ç å™¨æ¶æ„**: éµå¾ªCLIPæ¶æ„ï¼ˆå›¾åƒç¼–ç å™¨ + æ–‡æœ¬ç¼–ç å™¨ï¼‰
      - **è”åˆä¼˜åŒ–**: åŒæ—¶è®­ç»ƒä¸¤ä¸ªå¯¹æ¯”æŸå¤± Lxt + Lxc
      - **æƒé‡è°ƒåº¦**: ä½¿ç”¨å†å²ç›¸ä¼¼åº¦ç»Ÿè®¡åŠ¨æ€è°ƒæ•´æƒé‡å‚æ•°
      - **è¶…å‚æ•°**: Î³s=2ï¼ˆæ ·æœ¬æƒé‡ï¼‰ï¼ŒÎ³p=2ï¼ˆå¯¹æƒé‡ï¼‰ï¼Œæ¸©åº¦å‚æ•°Ï„è®­ç»ƒä¼˜åŒ–
  - **å®éªŒç»“æœ**:
      - **é›¶æ ·æœ¬å›¾æ–‡æ£€ç´¢**:
        - **Flickr30K**: Textâ†’Image R@1è¾¾70.5%ï¼ˆvs CLIP 34.9%ï¼Œ+35.6%ï¼‰
        - **MSCOCO**: Imageâ†’Text R@1è¾¾48.9%ï¼ˆvs CLIP 23.4%ï¼Œ+25.5%ï¼‰
        - **æ˜¾è‘—æå‡**: åœ¨æ‰€æœ‰æ£€ç´¢æŒ‡æ ‡ä¸Šè¾¾åˆ°æ–°çš„SOTAæ€§èƒ½
      - **çº¿æ€§æ¢æµ‹**:
        - **10ä¸ªä¸‹æ¸¸æ•°æ®é›†**: å¹³å‡å‡†ç¡®ç‡72.2%ï¼ˆvs CLIP 63.0%ï¼Œ+9.2%ï¼‰
        - **é›¶æ ·æœ¬åˆ†ç±»**: 11ä¸ªæ•°æ®é›†å¹³å‡å‡†ç¡®ç‡41.7%ï¼ˆvs CLIP 31.8%ï¼Œ+9.9%ï¼‰
      - **å¤§è§„æ¨¡éªŒè¯**: åœ¨LAION-10Må’ŒLAION-30Mä¸ŠéªŒè¯æ–¹æ³•çš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§
  - **æ¶ˆèç ”ç©¶å‘ç°**:
      - **æƒé‡ç»„ä»¶è´¡çŒ®**: Wsã€Wtã€Wcå„è‡ªè´¡çŒ®æ˜¾è‘—ï¼Œç»„åˆä½¿ç”¨æ•ˆæœæœ€ä½³
      - **åˆæˆæ ‡æ³¨è´¨é‡**: OFAç”Ÿæˆçš„æ ‡æ³¨ç›¸æ¯”åŸå§‹æ–‡æœ¬å…·æœ‰æ›´é«˜çš„å›¾åƒ-æ–‡æœ¬ç›¸ä¼¼åº¦å’Œæ›´ç´§å‡‘çš„åˆ†å¸ƒ
      - **æ ‡æ³¨é•¿åº¦**: åˆæˆæ ‡æ³¨tokenæ•°é‡é›†ä¸­åœ¨10-15ä¸ªï¼Œæ˜¾è‘—ä½äºåŸå§‹æ–‡æœ¬
      - **ä¸åŒå®¹é‡æ¨¡å‹**: OFA-baseå’ŒOFA-largeç”Ÿæˆæ ‡æ³¨æ•ˆæœç›¸å½“
  - **å…³é”®å‘ç°**:
      - **åˆæˆæ ‡æ³¨ä¼˜åŠ¿**: åˆæˆæ ‡æ³¨æ¯”åŸå§‹Webæ–‡æœ¬æ›´å‡†ç¡®æè¿°å›¾åƒå†…å®¹ï¼Œä½†åœ¨é›¶æ ·æœ¬åˆ†ç±»ä»»åŠ¡ä¸ŠåŸå§‹æ–‡æœ¬ä»æœ‰ä»·å€¼
      - **æƒé‡æœºåˆ¶æœ‰æ•ˆæ€§**: è‡ªé€‚åº”æƒé‡ç³»ç»Ÿèƒ½æœ‰æ•ˆè¯†åˆ«å’Œåˆ©ç”¨é«˜è´¨é‡æ•°æ®ï¼ŒæŠ‘åˆ¶å™ªå£°æ•°æ®å½±å“
      - **è®¡ç®—æ•ˆç‡**: ç›¸æ¯”åœ¨çº¿è¿‡æ»¤æ–¹æ³•ï¼Œé¢„è®¡ç®—åˆæˆæ ‡æ³¨æ›´é«˜æ•ˆï¼ˆé¿å…è®­ç»ƒæ—¶é¢å¤–è®¡ç®—å¼€é”€ï¼‰
      - **æ•°æ®åˆ©ç”¨æœ€å¤§åŒ–**: é€šè¿‡è‡ªé€‚åº”æƒé‡è€Œéç›´æ¥è¿‡æ»¤ï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰è®­ç»ƒæ•°æ®
  - **å‘å¸ƒæ—¶é—´**: arXiv 2023å¹´8æœˆ | DeepGlint & Huawei UK R&D & InsightFace & University of Sydney
  - **å¼€æº**: âœ… ä»£ç å’Œæ¨¡å‹æƒé‡ - è®ºæ–‡æ‰¿è¯ºå¼€æºå‘å¸ƒ
  - **é‡è¦æ„ä¹‰**:
      - **Webæ•°æ®å™ªå£°è§£å†³æ–¹æ¡ˆ**: æä¾›äº†å¤„ç†å¤§è§„æ¨¡Webæ•°æ®å™ªå£°çš„æœ‰æ•ˆæ¡†æ¶
      - **åˆæˆæ ‡æ³¨èŒƒå¼**: ç¡®ç«‹äº†ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ ‡æ³¨çš„æ ‡å‡†æ–¹æ³•
      - **è‡ªé€‚åº”å­¦ä¹ **: å¼€åˆ›æ€§åœ°å°†è‡ªé€‚åº”æƒé‡æœºåˆ¶å¼•å…¥å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ 
      - **å®ç”¨æ€§å¼º**: æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œæ˜“äºåœ¨ç°æœ‰CLIPè®­ç»ƒpipelineä¸­é›†æˆ
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.13523">ğŸ“„ Medical VLP</a></b><br>
<code>arXiv 2410.13523</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2024å¹´10æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **åŒ»å­¦è§†è§‰è¯­è¨€é¢„è®­ç»ƒèƒ½å¦ä½¿ç”¨çº¯åˆæˆæ•°æ®æˆåŠŸ** - æ¢ç´¢å®Œå…¨åŸºäºåˆæˆæ•°æ®è¿›è¡ŒåŒ»å­¦VLPçš„å¯è¡Œæ€§ï¼Œè§£å†³åŒ»å­¦é¢†åŸŸé…å¯¹æ•°æ®ç¨€ç¼ºé—®é¢˜
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å®ä½“é©±åŠ¨çš„åˆæˆæŠ¥å‘Šç”Ÿæˆ + ä¸“ç”¨CXRå›¾åƒç”Ÿæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–æ¬¡ç³»ç»Ÿæ€§éªŒè¯çº¯åˆæˆæ•°æ®åœ¨åŒ»å­¦VLPä¸­çš„æœ‰æ•ˆæ€§ï¼Œæå‡ºè‡ªåŠ¨åŒ–pipelineç”Ÿæˆé«˜è´¨é‡ã€åˆ†å¸ƒå¹³è¡¡çš„åˆæˆåŒ»å­¦å›¾æ–‡å¯¹
      - **é—®é¢˜è¯†åˆ«**: MIMIC-CXRç­‰çœŸå®åŒ»å­¦æ•°æ®é›†å­˜åœ¨ä¸¥é‡ç¼ºé™·
        - **ä½è´¨é‡å›¾åƒ**: æ¨¡ç³Šã€å¯¹æ¯”åº¦å·®ã€ä¼ªå½±é—®é¢˜
        - **æœªé…å¯¹æ ·æœ¬**: å›¾åƒå’Œæ–‡æœ¬ä¸åŒ¹é…
        - **é•¿å°¾åˆ†å¸ƒ**: åŒ»å­¦å®ä½“åˆ†å¸ƒä¸¥é‡ä¸å‡ï¼Œå½±å“æ¨¡å‹å­¦ä¹ 
        - **æ•°æ®ç¨€ç¼º**: é«˜è´¨é‡é…å¯¹åŒ»å­¦æ•°æ®è·å–å›°éš¾ä¸”æˆæœ¬é«˜æ˜‚
      - **çœŸå®æ•°æ®è´¨é‡è¯„ä¼°**:
        - **å¤šæ¨¡æ€è¿‡æ»¤**: ä½¿ç”¨InternVL2-26Bè®¾è®¡6ä¸ªæŸ¥è¯¢è¯„ä¼°CXRå›¾åƒè´¨é‡
        - **æŸ¥è¯¢ç±»å‹**: æ­£é¢è§†è§’æ£€æµ‹ã€å›¾åƒè´¨é‡è¯„ä¼°ã€ä¼ªå½±æ£€æµ‹ã€å¯¹æ¯”åº¦è¯„ä¼°ã€æ¸…æ™°åº¦æ£€æµ‹ã€è¯Šæ–­é€‚ç”¨æ€§
        - **ç›¸ä¼¼åº¦è¿‡æ»¤**: ä½¿ç”¨RAD-DINOæå–ç‰¹å¾ï¼Œè¿‡æ»¤ä¸ä½è´¨é‡æ ·æœ¬ç›¸ä¼¼çš„å›¾åƒ
        - **ç»“æœ**: ä»MIMIC-CXRçš„213,384å¯¹ä¸­è¿‡æ»¤å‡º1,448ä¸ªä½è´¨é‡æ ·æœ¬
      - **å®ä½“åˆ†å¸ƒåˆ†æ**:
        - **NERæå–**: ä½¿ç”¨RaTEæ¨¡å‹ä»æŠ¥å‘Šä¸­æå–154,049ä¸ªç‹¬ç‰¹åŒ»å­¦å®ä½“
        - **äº”å¤§ç±»åˆ«**: å¼‚å¸¸(55,047)ã€éå¼‚å¸¸(36,365)ã€ç–¾ç—…(23,017)ã€éç–¾ç—…(22,103)ã€è§£å‰–(40,517)
        - **é•¿å°¾é—®é¢˜**: æ‰€æœ‰ç±»åˆ«éƒ½å‘ˆç°ä¸¥é‡çš„é•¿å°¾åˆ†å¸ƒï¼Œå½±å“æ¨¡å‹å¯¹ç½•è§å®ä½“çš„å­¦ä¹ 
      - **åˆæˆæŠ¥å‘Šç”Ÿæˆ**:
        - **å®ä½“é‡‡æ ·ç­–ç•¥**:
          - ä»S1(å¼‚å¸¸+ç–¾ç—…ï¼Œk=9)å’ŒS2(éå¼‚å¸¸+éç–¾ç—…+è§£å‰–ï¼Œm=3)ä¸­é‡‡æ ·å®ä½“ç»„åˆ
          - è®¾ç½®é¢‘æ¬¡é˜ˆå€¼Ï„max=15ï¼Œç¡®ä¿å®ä½“åˆ†å¸ƒå¹³è¡¡
          - åŠ¨æ€é‡é‡‡æ ·é¿å…é«˜é¢‘å®ä½“è¿‡åº¦è¡¨ç¤º
        - **LLMç”Ÿæˆ**: ä½¿ç”¨Llama 3.1-70Bç”ŸæˆåŸºäºé‡‡æ ·å®ä½“çš„åˆæˆæ”¾å°„å­¦æŠ¥å‘Š
        - **ç»“æ„åŒ–è¾“å‡º**: ç”ŸæˆåŒ…å«FINDINGSå’ŒIMPRESSIONä¸¤éƒ¨åˆ†çš„å®Œæ•´æŠ¥å‘Š
        - **è´¨é‡æ§åˆ¶**: ä½¿ç”¨RaTEéªŒè¯ç”ŸæˆæŠ¥å‘Šç¡®å®åŒ…å«æŒ‡å®šå®ä½“ï¼Œä¸åŒ¹é…åˆ™é‡æ–°ç”Ÿæˆ
      - **åˆæˆå›¾åƒç”Ÿæˆ**:
        - **ä¸“ç”¨æ¨¡å‹**: ä½¿ç”¨RoentGen (ä¸´åºŠä¸“å®¶éªŒè¯çš„CXRä¸“ç”¨T2Iæ¨¡å‹) ç”Ÿæˆé…å¯¹CXRå›¾åƒ
        - **æ¡ä»¶ç”Ÿæˆ**: åŸºäºåˆæˆæŠ¥å‘Šçš„IMPRESSIONéƒ¨åˆ†ç”Ÿæˆå¯¹åº”CXRå›¾åƒ
        - **è´¨é‡ä¿è¯**: ä»…ä½¿ç”¨ç»ä¸´åºŠä¸“å®¶éªŒè¯çš„ç”Ÿæˆæ¨¡å‹ï¼Œç¡®ä¿åŒ»å­¦å‡†ç¡®æ€§
      - **æ•°æ®å¹³è¡¡ç­–ç•¥**:
        - **åˆ†å¸ƒæ§åˆ¶**: é€šè¿‡å®ä½“é‡‡æ ·å’Œé¢‘æ¬¡é™åˆ¶ä¸»åŠ¨å¹³è¡¡åˆæˆæ•°æ®åˆ†å¸ƒ
        - **å¤šæ ·æ€§ä¿è¯**: ç¡®ä¿ç½•è§ç–¾ç—…å’Œå¸¸è§ç–¾ç—…çš„åˆç†è¡¨ç¤º
        - **é…å¯¹ä¿è¯**: æ¯ä¸ªåˆæˆæŠ¥å‘Šéƒ½æœ‰å¯¹åº”çš„åˆæˆå›¾åƒï¼Œé¿å…æœªé…å¯¹é—®é¢˜
  - **æ•°æ®è§„æ¨¡**:
      - **SynCXRæ•°æ®é›†**: 200,000ä¸ªåˆæˆCXRå›¾åƒ-æŠ¥å‘Šå¯¹
      - **æ— äººå·¥æ£€æŸ¥**: å®Œå…¨è‡ªåŠ¨åŒ–ç”Ÿæˆï¼Œæ— éœ€äººå·¥è´¨é‡æ£€æŸ¥
      - **å®ä½“è¦†ç›–**: åŸºäº154,049ä¸ªåŒ»å­¦å®ä½“çš„å¹³è¡¡é‡‡æ ·ç”Ÿæˆ
  - **è®­ç»ƒç­–ç•¥**:
      - **åŸºçº¿æ¨¡å‹**: ä½¿ç”¨ConVIRTå’ŒGLoRIAä¸¤ä¸ªç»å…¸MedVLPæ–¹æ³•
      - **è®­ç»ƒè®¾ç½®**: ä¸¥æ ¼æ§åˆ¶æ¨¡å‹å’Œè®­ç»ƒé…ç½®ï¼Œä¸“æ³¨æ•°æ®è§’åº¦çš„å½±å“è¯„ä¼°
      - **å¯¹æ¯”å®éªŒ**: çº¯çœŸå®æ•°æ® vs çº¯åˆæˆæ•°æ® vs æ··åˆæ•°æ®ä¸‰ç§è®¾ç½®
  - **å®éªŒç»“æœ** - **çº¯åˆæˆæ•°æ®æ˜¾è‘—ä¼˜äºçœŸå®æ•°æ®**:
      - **é›¶æ ·æœ¬åˆ†ç±»** (å·²è§ç–¾ç—…):
        - **ConVIRT**: å¹³å‡AUCæå‡4.7%ï¼ŒF1æå‡4.53%
        - **GLoRIA**: åœ¨æ‰€æœ‰5ä¸ªæ•°æ®é›†ä¸ŠæŒç»­ä¼˜äºçœŸå®æ•°æ®è®­ç»ƒ
        - **æ··åˆæ•°æ®**: AUCæå‡10.08%ï¼ŒF1æå‡7.62%
      - **é›¶æ ·æœ¬åˆ†ç±»** (æœªè§ç–¾ç—…):
        - å¯¹æœªè§ç–¾ç—…çš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—å¢å¼º
        - Covid-19ã€PadChestæœªè§/ç½•è§ç–¾ç—…æ£€æµ‹æ€§èƒ½æå‡
      - **é›¶æ ·æœ¬å®šä½**:
        - IoUå¹³å‡æå‡1.42%ï¼ŒDiceåˆ†æ•°æå‡0.97%
        - æ··åˆæ•°æ®è¿›ä¸€æ­¥æå‡: IoU +4.06%ï¼ŒDice +2.92%
      - **å¾®è°ƒä»»åŠ¡**:
        - åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ä¸Šåˆæˆæ•°æ®é¢„è®­ç»ƒæ¨¡å‹æŒç»­ä¼˜äºçœŸå®æ•°æ®
        - è¯æ˜åˆæˆæ•°æ®ä¸ä»…æœ‰åˆ©äºè·¨æ¨¡æ€å­¦ä¹ ï¼Œè¿˜æå‡å•æ¨¡æ€è§†è§‰ç†è§£
  - **æ¶ˆèç ”ç©¶å‘ç°**:
      - **å®ä½“å¹³è¡¡é‡‡æ ·**: ä½¿ç”¨æ›´å¤šå®ä½“ç±»å‹(25%â†’75%)æ˜¾è‘—æå‡æ€§èƒ½
      - **LLMé€‰æ‹©**: Llama 3.1-70Bä¼˜äºå…¶ä»–LLMå’ŒåŒ»å­¦ä¸“ç”¨LLM
      - **å›¾åƒç”Ÿæˆæ¨¡å‹**: RoentGen(ä¸´åºŠéªŒè¯)æ˜¾è‘—ä¼˜äºé€šç”¨T2Iæ¨¡å‹
      - **æ•°æ®æ¸…æ´—ä»·å€¼**: æ¸…æ´—åçš„MIMIC-CXRæ€§èƒ½ä»ä¸å¦‚çº¯åˆæˆæ•°æ®
  - **å…³é”®å‘ç°**:
      - **çº¯åˆæˆæ•°æ®å¯è¡Œæ€§**: é¦–æ¬¡è¯æ˜åŒ»å­¦VLPå¯ä»¥å®Œå…¨åŸºäºåˆæˆæ•°æ®æˆåŠŸè®­ç»ƒ
      - **åˆæˆä¼˜äºçœŸå®**: åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçº¯åˆæˆæ•°æ®è®­ç»ƒæ•ˆæœè¶…è¶ŠçœŸå®æ•°æ®
      - **åˆ†å¸ƒå¹³è¡¡é‡è¦æ€§**: å¹³è¡¡çš„å®ä½“åˆ†å¸ƒæ¯”æ•°æ®çœŸå®æ€§æ›´å…³é”®
      - **è´¨é‡èƒœè¿‡æ•°é‡**: é«˜è´¨é‡åˆæˆæ•°æ®æ¯”å¤§è§„æ¨¡å™ªå£°çœŸå®æ•°æ®æ›´æœ‰æ•ˆ
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´10æœˆ | Imperial College London & AstraZeneca & Ohio State Universityç­‰
  - **å¼€æº**: âœ… SynCXRæ•°æ®é›†(20ä¸‡å›¾æ–‡å¯¹) + æ•°æ®ç”Ÿæˆpipeline + è¯„ä¼°ä»£ç 
  - **é‡è¦æ„ä¹‰**:
      - **åŒ»å­¦AIçªç ´**: ä¸ºåŒ»å­¦é¢†åŸŸæ•°æ®ç¨€ç¼ºé—®é¢˜æä¾›äº†é©å‘½æ€§è§£å†³æ–¹æ¡ˆ
      - **åˆæˆæ•°æ®èŒƒå¼**: è¯æ˜åˆæˆæ•°æ®å¯ä»¥å®Œå…¨æ›¿ä»£çœŸå®æ•°æ®è¿›è¡ŒåŒ»å­¦VLP
      - **æ•°æ®è´¨é‡é‡æ–°å®šä¹‰**: æ­ç¤ºæ•°æ®åˆ†å¸ƒå¹³è¡¡å’Œè´¨é‡æ§åˆ¶æ¯”æ•°æ®çœŸå®æ€§æ›´é‡è¦
      - **ä¸´åºŠåº”ç”¨å‰æ™¯**: ä¸ºå¿«é€Ÿæ„å»ºåŒ»å­¦AIç³»ç»Ÿã€å¤„ç†éšç§æ•æ„Ÿæ•°æ®æä¾›æ–°è·¯å¾„
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.22431">ğŸ“„ HQ-CLIP</a></b><br>
<code>arXiv 2507.22431</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-2025å¹´7æœˆ-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åˆ›å»ºé«˜è´¨é‡å›¾åƒæ–‡æœ¬æ•°æ®é›†å’ŒCLIPæ¨¡å‹** - é€šè¿‡LVLMå¢å¼ºç°æœ‰å›¾åƒæ ‡æ³¨è´¨é‡ï¼Œæ„å»ºå¤§è§„æ¨¡é«˜è´¨é‡å›¾æ–‡æ•°æ®é›†
  - **æ•°æ®åˆæˆæ–¹æ³•** - **æˆæœ¬é«˜æ•ˆçš„LVLMé©±åŠ¨æ•°æ®ç²¾åŒ–pipeline + å¤šç²’åº¦æ–‡æœ¬ç”Ÿæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: æå‡ºå¯æ‰©å±•çš„LVLMé©±åŠ¨æ•°æ®ç²¾åŒ–èŒƒå¼ï¼Œé€šè¿‡å°‘é‡GPT-4oæ ·æœ¬å¾®è°ƒå¼€æºLVLMï¼Œå®ç°å¤§è§„æ¨¡é«˜è´¨é‡å›¾æ–‡æ•°æ®ç”Ÿæˆ
      - **æˆæœ¬æ•ˆç‡è§£å†³æ–¹æ¡ˆ**:
        - **é—®é¢˜**: ç›´æ¥ä½¿ç”¨GPT-4oã€Geminiç­‰é¡¶çº§LVLMæˆæœ¬è¿‡é«˜ï¼Œä¸é€‚åˆå¤§è§„æ¨¡æ•°æ®å¤„ç†
        - **è§£å†³æ–¹æ¡ˆ**: ä¸‰æ­¥æˆæœ¬ä¼˜åŒ–ç­–ç•¥
          1. ä½¿ç”¨GPT-4oç²¾é€‰10,000ä¸ªé«˜è´¨é‡é‡æ ‡æ³¨æ ·æœ¬ä½œä¸ºç§å­æ•°æ®
          2. å¯¹è½»é‡å¼€æºLVLM (Qwen2-VL-7B)è¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)ï¼Œä½¿å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¯¹é½GPT-4o
          3. éƒ¨ç½²å¾®è°ƒåçš„è½»é‡LVLMè¿›è¡Œå¤§è§„æ¨¡æ•°æ®å¤„ç†
        - **æ•ˆç‡éªŒè¯**: SFTå¢å¼ºçš„Qwen2-VL-7Bè¾¾åˆ°72Bç‰ˆæœ¬ç›¸å½“æ€§èƒ½ï¼Œè®¡ç®—èµ„æºéœ€æ±‚ä»…ä¸º1/9
      - **å¤šç²’åº¦æ–‡æœ¬åˆæˆç­–ç•¥**:
        - **å››ç§äº’è¡¥æ–‡æœ¬ç±»å‹**:
          1. **è¯¦ç»†æ­£æè¿° (d+)**: é•¿ç¯‡è¯¦ç»†çš„å›¾åƒå†…å®¹æè¿°ï¼Œå¹³å‡æ¯”åŸå§‹æ ‡æ³¨é•¿4å€
          2. **ç®€çŸ­æ­£æ ‡ç­¾ (t+)**: ä»è¯¦ç»†æè¿°ä¸­æå–çš„å…³é”®è¯­ä¹‰æ ‡ç­¾
          3. **è¯¦ç»†è´Ÿæè¿° (d-)**: è¯­ä¹‰ç›¸ä¼¼ä½†å†…å®¹ä¸åŒ¹é…çš„è¯¦ç»†è´Ÿé¢æè¿°
          4. **ç®€çŸ­è´Ÿæ ‡ç­¾ (t-)**: ä¸å›¾åƒå†…å®¹ä¸åŒ¹é…çš„è´Ÿé¢è¯­ä¹‰æ ‡ç­¾
        - **æç¤ºå·¥ç¨‹ä¼˜åŒ–**:
          - è®¾è®¡ä¸“é—¨çš„æç¤ºæ¨¡æ¿æŒ‡å¯¼LVLMç”Ÿæˆé«˜è´¨é‡ã€ç»“æ„åŒ–çš„å¤šå±‚æ¬¡æè¿°
          - åŒ…å«æ­£é¢/è´Ÿé¢æè¿°ç”Ÿæˆå’Œæ ‡ç­¾æå–çš„å®Œæ•´workflow
        - **è´¨é‡æ§åˆ¶**: é€šè¿‡å¤šè½®è¿­ä»£å’Œè‡ªåŠ¨è¯„ä¼°ç¡®ä¿ç”Ÿæˆæ–‡æœ¬è´¨é‡
      - **æ•°æ®å¤„ç†pipeline**:
        1. **åŸå§‹æ•°æ®æ”¶é›†**: ä»DFN-Largeç­‰å¤§è§„æ¨¡æ•°æ®é›†å¼€å§‹
        2. **LVLMå¢å¼º**: ä½¿ç”¨å¾®è°ƒåçš„Qwen2-VL-7Bä¸ºæ¯å¼ å›¾åƒç”Ÿæˆå››ç§äº’è¡¥æ–‡æœ¬
        3. **è´¨é‡ç­›é€‰**: åŸºäºå›¾æ–‡ç›¸ä¼¼åº¦å’Œç”Ÿæˆè´¨é‡è¿›è¡Œç­›é€‰
        4. **æœ€ç»ˆæ•´åˆ**: æ„å»ºåŒ…å«åŸå§‹+å¢å¼ºæ–‡æœ¬çš„å¤šç²’åº¦æ•°æ®é›†
  - **HQ-CLIPè®­ç»ƒæ¡†æ¶**:
      - **ç¡¬è´Ÿæ ·æœ¬è¯†åˆ« (HNI)**:
        - åˆ©ç”¨è¯¦ç»†è´Ÿæè¿°å’Œè´Ÿæ ‡ç­¾è¿›è¡Œç»†ç²’åº¦ç†è§£è®­ç»ƒ
        - å¢å¼ºæ¨¡å‹å¯¹è¯­ä¹‰ç»†å¾®å·®åˆ«çš„æ•æ„Ÿæ€§
        - æŸå¤±å‡½æ•°: L_HNI = -log(exp(sim(x,t+)/Ï„) / (exp(sim(x,t+)/Ï„) + exp(sim(x,t-)/Ï„)))
      - **çŸ­æ ‡ç­¾åˆ†ç±» (STC)**:
        - ä½¿ç”¨æå–çš„è¯­ä¹‰æ ‡ç­¾è¿›è¡Œåˆ†ç±»è®­ç»ƒ
        - æå‡æ¨¡å‹çš„åˆ†ç±»è¯­ä¹‰è¯†åˆ«èƒ½åŠ›
        - æŸå¤±å‡½æ•°: L_STCåŸºäºæ ‡ç­¾åˆ†ç±»äº¤å‰ç†µ
      - **æ··åˆè®­ç»ƒç­–ç•¥**:
        - ç»“åˆåŸå§‹æ ‡æ³¨å’Œå¢å¼ºæ–‡æœ¬è¿›è¡Œè®­ç»ƒ
        - æœ€ä¼˜æ··åˆæ¯”ä¾‹: 75%å¢å¼ºæ–‡æœ¬ + 25%åŸå§‹æ ‡æ³¨
        - åŠ¨æ€æƒé‡è°ƒæ•´: Î±=0.2 (HNIæƒé‡), Î²=100 (STCæƒé‡)
  - **æ•°æ®è§„æ¨¡**:
      - **VLM-150Mæ•°æ®é›†**: 1.5äº¿é«˜è´¨é‡å›¾åƒ-æ–‡æœ¬å¯¹
      - **åŸºç¡€æ•°æ®**: åŸºäºDFN-Large (1.47BåŸå§‹æ•°æ®)ç­›é€‰å’Œå¢å¼º
      - **æ–‡æœ¬å¢å¼º**: æ¯å¼ å›¾åƒé…å¤‡4ç§äº’è¡¥æ–‡æœ¬æè¿°
      - **å¤„ç†æ•ˆç‡**: ä½¿ç”¨å¾®è°ƒLVLMç›¸æ¯”GPT-4oæˆæœ¬é™ä½90%+
  - **å®éªŒç»“æœ** - **ä¸‰ä¸ªæ•°é‡çº§éªŒè¯ (1Måˆ°150M)**:
      - **å°è§„æ¨¡ (1.4M)**:
        - ImageNetå‡†ç¡®ç‡: 8.7% (vs DFN 5.8%, +2.9%)
        - å¹³å‡38æ•°æ®é›†æ€§èƒ½: 20.0% (vs DFN 17.1%, +2.9%)
      - **ä¸­è§„æ¨¡ (14.7M)**:
        - ImageNetå‡†ç¡®ç‡: 40.5% (vs DFN 37.6%, +2.9%)
        - æ£€ç´¢ä»»åŠ¡: 38.4% (vs DFN 28.6%, +9.8%)
        - å¹³å‡38æ•°æ®é›†æ€§èƒ½: 41.1% (vs DFN 36.8%, +4.3%)
      - **å¤§è§„æ¨¡ (147M)**:
        - ImageNetå‡†ç¡®ç‡: 70.6% (vs DFN 68.7%, +1.9%)
        - ImageNet-V2: 63.1% (vs DFN 60.0%, +3.1%)
        - æ£€ç´¢å¹³å‡: 60.9% (vs DFN 54.5%, +6.4%)
        - **SOTAæ€§èƒ½**: åœ¨38ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°58.6%å¹³å‡åˆ†
      - **è¶…å¤§è§„æ¨¡ (1.4B)**:
        - ç»§ç»­ä¿æŒæ€§èƒ½æå‡ï¼ŒéªŒè¯æ–¹æ³•çš„å¯æ‰©å±•æ€§
  - **æ¶ˆèç ”ç©¶å‘ç°**:
      - **LVLMé€‰æ‹©**: Qwen2-VLåœ¨å¤šä¸ªå¼€æºLVLMä¸­è¡¨ç°æœ€ä½³
      - **SFTæœ‰æ•ˆæ€§**: GPT-4oå¾®è°ƒæ˜¾è‘—æå‡æ•°æ®è´¨é‡å’Œä¸‹æ¸¸æ€§èƒ½
      - **æ–‡æœ¬ç±»å‹è´¡çŒ®**:
        - è¯¦ç»†æè¿°è´¡çŒ®æœ€å¤§ (+3.4%æ€§èƒ½æå‡)
        - ç¡¬è´Ÿæ ·æœ¬è®­ç»ƒ (+0.8%æ€§èƒ½æå‡)
        - çŸ­æ ‡ç­¾åˆ†ç±» (+0.4%æ€§èƒ½æå‡)
      - **æ··åˆæ¯”ä¾‹**: 75%å¢å¼ºæ–‡æœ¬ä¸ºæœ€ä¼˜é…æ¯”
  - **è´¨é‡è¯„ä¼°**:
      - **å›¾æ–‡ç›¸ä¼¼åº¦**: OpenAI CLIP-Largeè¯„ä¼°æ˜¾ç¤ºå¢å¼ºæ•°æ®ç›¸ä¼¼åº¦æ›´é«˜
      - **GPT-4oè¯„åˆ†**: åˆæˆæ ‡æ³¨è´¨é‡è¯„åˆ†æ˜¾è‘—ä¼˜äºåŸå§‹æ ‡æ³¨
      - **ä¸‹æ¸¸ä»»åŠ¡éªŒè¯**: CLIPæ¨¡å‹åœ¨å¢å¼ºæ•°æ®ä¸Šè®­ç»ƒæ•ˆæœæœ€ä½³
  - **å…³é”®å‘ç°**:
      - **æˆæœ¬æ•ˆç‡**: è½»é‡LVLMç»SFTåå¯è¾¾å¤§æ¨¡å‹æ€§èƒ½ï¼Œæˆæœ¬é™ä½9å€
      - **å¤šç²’åº¦æ–‡æœ¬ä»·å€¼**: è¯¦ç»†æè¿°+çŸ­æ ‡ç­¾+è´Ÿæ ·æœ¬çš„ç»„åˆæœ€æœ‰æ•ˆ
      - **å¯æ‰©å±•æ€§**: æ–¹æ³•åœ¨1Måˆ°1.5Bè§„æ¨¡ä¸Šå‡è¡¨ç°å‡ºè‰²
      - **è´¨é‡æå‡**: ç›¸åŒæ•°æ®è§„æ¨¡ä¸‹æ€§èƒ½æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´7æœˆ | ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ & è…¾è®¯å¾®ä¿¡è§†è§‰
  - **å¼€æº**: âœ… VLM-150Mæ•°æ®é›†(1.5äº¿å›¾æ–‡å¯¹) + HQ-CLIPæ¨¡å‹ + æ•°æ®ç²¾åŒ–pipeline
  - **é‡è¦æ„ä¹‰**:
      - **CLIPæ•°æ®è´¨é‡æ–°æ ‡å‡†**: å»ºç«‹äº†åŸºäºLVLMçš„å¤§è§„æ¨¡æ•°æ®å¢å¼ºæ–°èŒƒå¼
      - **æˆæœ¬æ•ˆç‡çªç ´**: è¯æ˜è½»é‡æ¨¡å‹ç»é€‚å½“å¾®è°ƒå¯æ›¿ä»£æ˜‚è´µå¤§æ¨¡å‹
      - **å¤šç²’åº¦æ–‡æœ¬æ¡†æ¶**: æå‡ºäº†æ­£è´Ÿæ ·æœ¬ã€é•¿çŸ­æ–‡æœ¬ç»“åˆçš„å®Œæ•´æ–‡æœ¬å¢å¼ºæ¡†æ¶
      - **å¯æ‰©å±•è§£å†³æ–¹æ¡ˆ**: ä¸ºæ„å»ºæ›´å¤§è§„æ¨¡ã€æ›´é«˜è´¨é‡çš„è§†è§‰è¯­è¨€æ•°æ®é›†æä¾›äº†å®ç”¨è·¯å¾„
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2511.02046">ğŸ“„ Text-VQA Aug</a></b><br>
<code>arXiv 2511.02046</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**é¢å‘ Text-VQA çš„è‡ªåŠ¨åŒ–QAåˆæˆ** â€”â€” æ„å»ºä¸€ä¸ªç«¯åˆ°ç«¯ã€è®­ç»ƒå…ï¼ˆtraining-freeï¼‰çš„å¤šæ¨¡å‹æµæ°´çº¿ï¼ŒåŸºäºåœºæ™¯æ–‡æœ¬è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œä¸ºæ–‡æœ¬VQAé¢„è®­ç»ƒæä¾›è§„æ¨¡åŒ–æ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **OCR + Grounding + Crop Caption + ç­”æ¡ˆæŠ½å– + é—®é¢˜ç”Ÿæˆ + éªŒè¯**ï¼š
      1) **Text-Spottingï¼ˆOCRæ£€æµ‹+è¯†åˆ«ï¼‰**ï¼šä½¿ç”¨ GLASS æå–åœºæ™¯æ–‡æœ¬ä¸æ¡†
      2) **å±€éƒ¨ä¸Šä¸‹æ–‡è¯†åˆ«ï¼ˆGroundingï¼‰**ï¼šç”¨ Kosmos-2 ç”Ÿæˆå‰æ™¯/èƒŒæ™¯ ROI è£å‰ªå¹¶ä¸OCRå¯¹é½
      3) **è£å‰ªå›¾åƒæè¿°**ï¼šå°†è£å‰ªå›¾ä¸å…¶å…³è”OCRä¸€å¹¶è¾“å…¥ LLaVA-R ç”Ÿæˆå±€éƒ¨captionï¼Œéšåæ‹¼æ¥æ±‡æ€»ä¸ºå…¨å±€æè¿°
      4) **OCRç­”æ¡ˆé€‰æ‹©ç®—æ³•**ï¼šåŸºäºå…¨å±€æè¿°å®šä½é¡ºåºç›¸é‚»çš„OCR tokenç»„ï¼Œç”Ÿæˆæ½œåœ¨ç­”æ¡ˆé›†åˆï¼ˆç»™å‡ºä¼ªä»£ç ä¸è§„åˆ™ï¼‰
      5) **é—®é¢˜ç”Ÿæˆï¼ˆLLMï¼‰**ï¼šä»¥â€œå›¾åƒæè¿°+æŒ‡å®šOCRç­”æ¡ˆâ€ä¸ºæ¡ä»¶ï¼Œè°ƒç”¨ Intel Neural Chat 7B äº§å‡ºæç®€é—®é¢˜
      6) **QAå¯¹éªŒè¯ä¸é•¿åº¦è¿‡æ»¤**ï¼šåŒä¸€LLMè¿›è¡Œâ€œRight/Wrongâ€åˆ¤å®šï¼Œè¿‡æ»¤é•¿åº¦è¿‡çŸ­/è¿‡é•¿é—®é¢˜ï¼Œé™ä½å¹»è§‰ä¸å™ªå£°
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **Text-VQAaug æ•°æ®é›†**ï¼š44,581 å¼ å›¾åƒï¼Œ72,490 ä¸ª QAï¼ˆçº¦ 1.6 é—®é¢˜/å›¾ï¼‰
      - ä¸ Text-VQA ç­‰å¯¹ç…§ï¼šé—®é¢˜æ›´å…·ä½“ï¼ˆä¸­ä½é•¿åº¦çº¦14è¯ï¼‰ï¼Œéƒ¨åˆ†é—®é¢˜ä¸ç›´æ¥åŒ…å«OCRè¯ä½†ç­”æ¡ˆæ¥è‡ªOCR
  - **ç‰¹ç‚¹ä¸ä¼˜åŠ¿**ï¼š
      - **è®­ç»ƒå…ã€å¯æ‰©å±•**ï¼šå®Œå…¨ä¾èµ–é¢„è®­ç»ƒLMM/OCR/groundingæ¨¡å‹ï¼Œæµæ°´çº¿å¯æ¨ªå‘æ‰©å±•åˆ°æ–°é¢†åŸŸ/åœºæ™¯
      - **ç­”æ¡ˆå…ˆéªŒ+é—®é¢˜æ¡ä»¶åŒ–**ï¼šå…ˆé€‰ç­”æ¡ˆå†ç”Ÿé—®é¢˜ï¼Œé¿å…çº¯ç”Ÿæˆå¼å¼•èµ·çš„æ¼‚ç§»ï¼Œæå‡å¯æ§æ€§ä¸ä¸€è‡´æ€§
      - **è´¨é‡æ§åˆ¶**ï¼šLLMåˆ¤çœŸ/å‡+é•¿åº¦çº¦æŸï¼Œæ˜¾è‘—å‡å°‘ä¸åˆæ ¼æ ·æœ¬
  - **é€‚ç”¨åœºæ™¯**ï¼šæ–‡æœ¬æ— éšœç¢è¾…åŠ©ã€é›¶å”®æ£€ç´¢ã€æ•™è‚²é¢˜æåˆæˆã€åŒ»ç–—è®¾å¤‡è¯»æ•°/æ ‡ç­¾ç†è§£ã€äº¤é€šå®‰å…¨ï¼ˆç‰Œç…§ç­‰ï¼‰
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2504.11257">ğŸ“„ UI-E2I-Synth</a></b><br>
<code>arXiv 2504.11257</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**GUI æŒ‡ä»¤å®šä½ï¼ˆgroundingï¼‰çš„åˆæˆæ•°æ®ä¸è¯„æµ‹** â€”â€” æå‡ºå¤§è§„æ¨¡ GUI æŒ‡ä»¤åˆæˆæµæ°´çº¿ UI-E2I-Synthï¼Œå¹¶æ„å»ºç»¼åˆè¯„æµ‹åŸºå‡† UI-I2E-Benchï¼Œé¢å‘æ¡Œé¢/ç½‘é¡µ/ç§»åŠ¨å¤šå¹³å°çš„çœŸå®é«˜åˆ†è¾¨ç‡åœºæ™¯
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸‰é˜¶æ®µåˆ†è€Œæ²»ä¹‹ï¼ˆå…ƒç´ è§£æ â†’ æŒ‡ä»£è¡¨è¾¾ç”Ÿæˆ â†’ æŒ‡ä»¤åˆæˆï¼‰**ï¼š
      1) **åŸå§‹æ•°æ®ä¸è§£æ**ï¼šä» Web/Windows/Android æ”¶é›†æˆªå›¾+å…ƒæ•°æ®ï¼Œå¯å‘å¼è§£æä¸‰è¦ç´ ï¼ˆç±»å‹/å†…å®¹/æ¡†ï¼‰å¹¶é‡é‡‡æ ·å¹³è¡¡å…ƒç´ ç±»å‹ä¸å°ºå¯¸åˆ†å¸ƒ
      2) **å…ƒç´ æŒ‡ä»£è¡¨è¾¾ï¼ˆREï¼‰ç”Ÿæˆ**ï¼šåœ¨ Set-of-Marks æˆªå›¾ä¸Šä¸‹æ–‡ä¸­ï¼ŒåŸºäºè§£æåˆ°çš„å…ƒç´ å±æ€§ï¼Œç”¨ GPT-4o ç”Ÿæˆæ˜¾å¼/éšå¼ä¸¤ç±» REï¼Œé™ä½çº¯ä»å›¾ç”Ÿæˆçš„å¹»è§‰
      3) **å‚æ•°åŒ–ç”¨æˆ·æŒ‡ä»¤åˆæˆ**ï¼šå°† RE ä¸ç”¨æˆ·åŠ¨ä½œä¸‰å…ƒç»„ï¼ˆåŠ¨ä½œç±»å‹/åŠ¨ä½œå†…å®¹/å…ƒç´ ç›®æ ‡ï¼‰ç»“åˆï¼Œç”¨ GPT-4o ç”Ÿæˆç¬¬ä¸€äººç§°ã€çŸ­è€Œå‡†ç¡®çš„æœ€ç»ˆæŒ‡ä»¤
  - **æ•°æ®ä¸åŸºå‡†**ï¼š
      - **è®­ç»ƒé›†ï¼ˆUI-E2I-Synthï¼‰**ï¼š1,635,594 å¼ æˆªå›¾ï¼Œ9,899,581 æ¡æŒ‡ä»¤ï¼ˆWeb 1.54M/9.10Mï¼›Desktop 14K/334Kï¼›AndroidControl 40K/109Kï¼›å¦å« MOTIFã€WidgetCaptionï¼‰
      - **è¯„æµ‹é›†ï¼ˆUI-I2E-Benchï¼‰**ï¼š1,477 æ¡ï¼Œç»†åŒ–æ ‡æ³¨å…ƒç´ ç±»å‹ã€å…ƒç´ /å±å æ¯”ã€æŒ‡ä»¤æ˜¾/éšå¼æ¯”ä¾‹ï¼ˆéšå¼å æ¯”â‰¥63%ï¼‰ï¼Œæ›´è´´è¿‘çœŸå®ä½¿ç”¨
  - **å®éªŒç»“æœ**ï¼š
      - åœ¨ ScreenSpotã€ScreenSpot-Proã€UI-I2E-Bench ä¸Šï¼ŒUI-I2E-VLM-7B å…¨é¢ä¼˜äº OS-Atlas-7B ç­‰ç°æœ‰æ–¹æ³•ï¼ˆå¹³å‡ç›¸å¯¹æå‡çº¦+9.7%ï¼‰ï¼Œåœ¨éšå¼æŒ‡ä»¤ä¸é•¿å°¾å…ƒç´ ï¼ˆIcon/Inputï¼‰ä¸Šä¼˜åŠ¿æ˜¾è‘—
      - åŒç­‰é‡ï¼ˆ50ä¸‡ï¼‰ç½‘é¡µæŒ‡ä»¤è®­ç»ƒæ—¶ï¼ŒUI-E2I-Synth æ•°æ®ä¼˜äº OS-Atlas-Webï¼›è‹¥å»æ‰â€œæŒ‡ä»¤åˆæˆâ€æˆ–å…ƒç´ å±æ€§å¢å¼ºï¼Œæ€§èƒ½æ˜æ˜¾ä¸‹é™ï¼ˆæ¶ˆèï¼‰
  - **å…³é”®ä¼˜åŠ¿**ï¼š
      - **å…ƒç´ /å±å æ¯”åˆ†å¸ƒæ›´è´´è¿‘çœŸå®æ¡Œé¢ï¼ˆ1080p/1440pï¼‰**ï¼Œå¼ºè°ƒå°ç›®æ ‡ä¸é«˜åˆ†è¾¨ç‡
      - **éšå¼æŒ‡ä»¤è¦†ç›–ä¸ç±»å‹å‡è¡¡**ï¼šæ˜¾è‘—æå‡æ¨¡å‹å¯¹é•¿å°¾å…ƒç´ ä¸éšå¼è¡¨è¾¾çš„ç†è§£
      - **å‚æ•°åŒ–æŒ‡ä»¤åˆæˆ**ï¼šå…ˆå®šä¹‰åŠ¨ä½œå‚æ•°å†ç”Ÿæˆç”¨æˆ·æŒ‡ä»¤ï¼Œè´´è¿‘çœŸå®äººæœºäº¤äº’è¡¨è¾¾
  - **åº”ç”¨**ï¼šä¸ GPT-4o è§„åˆ’å™¨ç»“åˆç”¨äº OSWorld çœŸå®æ¡Œé¢ä»»åŠ¡ï¼Œæå‡ä»£ç†å¯ç”¨æ€§
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=SK%E2%80%91VQA">ğŸ“„ SKâ€‘VQA</a></b><br>
<code>Paper</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **Focus**: **Largeâ€‘scale "image + context + QA" synthesis for multimodal RAG/KBâ€‘VQA** â€” A pipeline that uses GPTâ€‘4 to generate encyclopedic context documents and diverse questions, building 2M+ contextâ€‘augmented VQA samples to train/evaluate contextâ€‘aware MLLMs
  - **Data Synthesis**:
      - **Joint generation of context and QA**: Conditioned on the image, GPTâ€‘4 outputs both a relevant articleâ€‘style context and QA requiring context reasoning, avoiding imageâ€‘only answers
      - **Multiâ€‘source images**: LAION, WIT (Wikipedia), COCOâ€‘Counterfactuals; with filtered subsets removing imageâ€‘referencing contexts (IR) and ensuring extractive answers (IR+CAP)
  - **Scale & Diversity**:
      - 2,006,489 QA over 290,266 imageâ€‘context pairs; >96% unique questions, richer POS/vocab/length than prior KBâ€‘VQA datasets
  - **Findings**:
      - A more challenging benchmark (lower zeroâ€‘shot than Encâ€‘VQA/ViQuAE); as training data, outperforms InfoSeek/Encâ€‘VQA in crossâ€‘dataset generalization; remains strongest under RAG with external retrieval
  - **Significance**:
      - **Imageâ€‘invariant text enhancement**: Highâ€‘quality "context+QA" around existing images for multimodal RAG/KBâ€‘VQA training
      - **Quality control**: IR/IR+CAP filtering preserves/boosts performance with fewer samples, enabling taskâ€‘aware tuning
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.02713">ğŸ“„ LLaVAâ€‘Video: åŸºäºåˆæˆæ•°æ®çš„è§†é¢‘æŒ‡ä»¤å¾®è°ƒ</a></b><br>
<code>arXiv 2410.02713</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**åˆæˆè§†é¢‘æŒ‡ä»¤è·Ÿéšæ•°æ® + æ¨¡å‹** â€” æ„å»º LLaVAâ€‘Videoâ€‘178K æ•°æ®é›†ä¸ LLaVAâ€‘Video æ¨¡å‹ï¼›é‡‡ç”¨**ç¨ å¯†å–å¸§**ä¸**ä¸‰å±‚é€’å½’æè¿°**ï¼Œè¦†ç›–è¯¦ç»†æè¿°ã€å¼€æ”¾å¼QAä¸å¤šé€‰QA
  - **æ•°æ®åˆæˆæ–¹æ³•**ï¼š
      - **åŠ¨æ€æœªè£å‰ªè§†é¢‘æ¥æºï¼ˆ10ä¸ªï¼‰**ï¼›åŸºäºé•œå¤´æ•°ç­‰æŒ‡æ ‡ç­›é€‰â€œåŠ¨æ€æ€§â€æœ€é«˜çš„è§†é¢‘ï¼Œé¿å…é™æ€/è¿‡åº¦è£å‰ª
      - **1 FPS ç¨ å¯†é‡‡æ ·** + **ä¸‰çº§é€’å½’æè¿°**ï¼ˆ10ç§’ç‰‡æ®µã€30ç§’æ±‡æ€»ã€å…¨ç‰‡æ€»ç»“ï¼‰ï¼›ç”¨ GPTâ€‘4o ç”Ÿæˆè¯¦ç»†æè¿°ä¸16ç±»é—®é¢˜ï¼›å»é‡ä¸ä¸å¯ç­”è¿‡æ»¤
  - **æ•°æ®è§„æ¨¡**ï¼š
      - 178,510 ä¸ªè§†é¢‘ â†’ 1.3M æŒ‡ä»¤æ ·æœ¬ï¼š178Kæè¿°ã€960Kå¼€æ”¾å¼QAã€196Kå¤šé€‰QA
  - **å®éªŒå‘ç°**ï¼š
      - å¸§æ•°è¶Šå¤šæ€§èƒ½è¶Šå¥½ï¼›æå‡º SlowFast é£æ ¼çš„è§†é¢‘è¡¨ç¤ºï¼Œåœ¨å›ºå®š token é¢„ç®—ä¸‹å®¹çº³**å¤šè‡³3å€å¸§æ•°**
      - è¦†ç›– 11 ä¸ªè§†é¢‘åŸºå‡†çš„å¼ºé›¶æ ·æœ¬è¡¨ç°ï¼›72B å¼€æºæ¨¡å‹åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šå¯ä¸å•†ç”¨æ¨¡å‹ç«äº‰
  - **æ„ä¹‰**ï¼š
      - æä¾›é«˜è´¨é‡åˆæˆè§†é¢‘æŒ‡ä»¤æ•°æ®ä¸é«˜æ•ˆè§†é¢‘è¡¨å¾ç­–ç•¥ï¼›è®¡åˆ’å¼€æ”¾æ•°æ®ã€ä»£ç ä¸æ¨¡å‹æƒé‡
  
  #### ğŸ¤– åŸºäºVLM/LLMçš„åˆæˆæ–‡æœ¬ç”Ÿæˆ
  
  > ä»¥ä¸‹è®ºæ–‡æ˜ç¡®æè¿°äº†å¦‚ä½•ä½¿ç”¨å¤§æ¨¡å‹ä¸ºå›¾åƒç”Ÿæˆåˆæˆcaptions/å¯¹è¯
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2503.22655">ğŸ“„ Unicorn</a></b><br>
<code>arXiv 2503.22655</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **çº¯æ–‡æœ¬å¤šæ¨¡æ€æ•°æ®åˆæˆ** - å®Œå…¨ä¸ä¾èµ–çœŸå®æˆ–ç”Ÿæˆçš„å›¾åƒï¼Œä»…ä»æ–‡æœ¬åˆæˆVLMè®­ç»ƒæ•°æ®
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è·¨é›†æˆä¸‰é˜¶æ®µæ–‡æœ¬è½¬å›¾åƒè¡¨ç¤ºPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: åˆ©ç”¨è·¨æ¨¡æ€è¡¨ç¤ºç©ºé—´çš„å‡ ä½•ç»“æ„ï¼ˆmodality gapç†è®ºï¼‰ï¼Œé€šè¿‡æ–‡æœ¬è¡¨ç¤ºç”Ÿæˆåˆæˆå›¾åƒè¡¨ç¤ºï¼Œ**å®Œå…¨è·³è¿‡å›¾åƒç”Ÿæˆæ­¥éª¤**
      - **Stage 1: å¤šæ ·åŒ–Captionæ•°æ®åˆæˆ**:
        - **è¾“å…¥**: 1.2Mç¨€ç–captionç§å­ï¼ˆä»å¤šä¸ªæ¥æºé‡‡æ ·ï¼‰
          - **å¼€æ”¾åŸŸ**: MS-COCOã€Flickr30Kã€CC3Mã€CC-YFCCç­‰
          - **é¢†åŸŸç‰¹å®š**: Conceptual Captionsã€Chart2Textã€PlotQAç­‰
        - **æ–¹æ³•**: ä½¿ç”¨LLMï¼ˆQwen2.5-72B-Instructionï¼‰ä¸ºç¨€ç–captionæ·»åŠ è¯¦ç»†ä¿¡æ¯
        - **Promptè®¾è®¡**: "åœ¨ä¿æŒåŸå§‹è¯­ä¹‰çš„åŒæ—¶æ·»åŠ æ›´å¤šç»†èŠ‚ï¼ˆå¯¹è±¡å±æ€§ã€ç©ºé—´å…³ç³»ã€èƒŒæ™¯ä¿¡æ¯ç­‰ï¼‰"
        - **è¾“å‡º**: 1.2Mè¯­ä¹‰ä¸°å¯Œã€å¤šæ ·åŒ–çš„è¯¦ç»†captions
        - **è´¨é‡ä¿è¯**: é€šè¿‡å¤šè½®è¿­ä»£ä¼˜åŒ–ï¼Œç¡®ä¿captionè¯¦ç»†åº¦å’Œå‡†ç¡®æ€§
      - **Stage 2: æŒ‡ä»¤è°ƒä¼˜æ•°æ®ç”Ÿæˆ**:
        - **è¾“å…¥**: ä»Stage 1ä¸­é‡‡æ ·471K captions
        - **æ–¹æ³•**: ä½¿ç”¨Qwen2.5-72B-Instructionç”Ÿæˆä¸‰ç±»ä»»åŠ¡æ•°æ®
        - **ä¸‰å¤§ä»»åŠ¡ç±»å‹**:
          1. **å¤šé€‰é¢˜ï¼ˆMultiple-Choiceï¼‰**:
             - åŸºäºcaptionå†…å®¹ç”Ÿæˆé—®é¢˜å’Œ4ä¸ªé€‰é¡¹
             - æµ‹è¯•ç»†èŠ‚ç†è§£å’Œæ¨ç†èƒ½åŠ›
          2. **é—®ç­”ï¼ˆQuestion-Answeringï¼‰**:
             - ç”Ÿæˆå¼€æ”¾å¼é—®é¢˜å’Œè¯¦ç»†ç­”æ¡ˆ
             - æ¶µç›–æè¿°æ€§ã€äº‹å®æ€§ã€æ¨ç†æ€§é—®é¢˜
          3. **å¤æ‚æ¨ç†ï¼ˆComplex Reasoningï¼‰**:
             - éœ€è¦å¤šæ­¥æ¨ç†çš„å¤æ‚é—®é¢˜
             - ç»“åˆè§†è§‰ç†è§£å’Œé€»è¾‘æ¨ç†
        - **è¾“å‡º**: 471Kå¤šä»»åŠ¡æŒ‡ä»¤è°ƒä¼˜æ•°æ®
      - **Stage 3: æ¨¡æ€è¡¨ç¤ºè½¬ç§»ï¼ˆå…³é”®åˆ›æ–°ï¼‰**:
        - **ç†è®ºåŸºç¡€ - Modality Gapå‡ ä½•ç»“æ„**:
          - å¯¹äºé…å¯¹çš„å›¾åƒ-æ–‡æœ¬ï¼ˆx_img, x_textï¼‰ï¼Œå…¶è¡¨ç¤ºæ»¡è¶³: **e_x - e_y = c + Îµ**
          - **c**: å¸¸é‡æ­£äº¤å‘é‡ï¼ˆæ¨¡æ€é—´éš™ï¼‰
          - **Îµ**: å¯¹é½å™ªå£°ï¼ˆè¿‘ä¼¼é«˜æ–¯åˆ†å¸ƒï¼‰
        - **è½¬ç§»è¿‡ç¨‹ - Mean Shift**:
          1. ä½¿ç”¨æ–‡æœ¬ç¼–ç å™¨ï¼ˆLLM2CLIPï¼‰å°†Stage 1/2çš„captionsç¼–ç ä¸ºæ–‡æœ¬è¡¨ç¤º e_text
          2. è®¡ç®—æ¨¡æ€é—´éš™å‘é‡cï¼ˆé€šè¿‡å°‘é‡é…å¯¹æ•°æ®ç»Ÿè®¡å¾—åˆ°ï¼‰
          3. åº”ç”¨mean shift: **e_synthetic_img = e_text + c**
          4. å¾—åˆ°åˆæˆå›¾åƒè¡¨ç¤ºï¼Œæ— éœ€ç”ŸæˆçœŸå®å›¾åƒ
        - **å…³é”®æŠ€æœ¯**:
          - ä½¿ç”¨**LLM2CLIP**ï¼ˆä¸“é—¨ä¼˜åŒ–çš„æ–‡æœ¬ç¼–ç å™¨ï¼‰ç¡®ä¿æ–‡æœ¬è¡¨ç¤ºè´¨é‡
          - **è®­ç»ƒæ— å…³**: æ— éœ€é¢å¤–è®­ç»ƒï¼Œçº¯ç²¹åˆ©ç”¨å‡ ä½•ç»“æ„
          - **å¯æ‰©å±•**: å¯åº”ç”¨äºä»»æ„è§„æ¨¡çš„æ–‡æœ¬æ•°æ®
        - **ä¼˜åŠ¿**:
          - **æ— éœ€å›¾åƒ**: å®Œå…¨è·³è¿‡å›¾åƒç”Ÿæˆ/å­˜å‚¨ï¼ŒèŠ‚çœAPIæˆæœ¬ã€æ—¶é—´ã€å­˜å‚¨ç©ºé—´
          - **é«˜æ•ˆ**: APIæˆæœ¬é™ä½**44å€**ï¼Œæ—¶é—´é™ä½**4å€**ï¼Œå­˜å‚¨é™ä½**27å€**
          - **è´¨é‡**: åˆæˆè¡¨ç¤ºåœ¨å…±äº«ç©ºé—´ä¸­ä¸çœŸå®å›¾åƒè¡¨ç¤ºåˆ†å¸ƒä¸€è‡´
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **æˆæœ¬æä½**: ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å¤§å¹…é™ä½æˆæœ¬ï¼ˆAPI: $6.84 vs $12, å­˜å‚¨: 4GB vs 109GBï¼‰
        - **æ— å¹»è§‰é£é™©**: ä¸ä¾èµ–è§†è§‰ç”Ÿæˆæ¨¡å‹ï¼Œé¿å…å›¾åƒç”Ÿæˆçš„å¹»è§‰é—®é¢˜
        - **å¯æ‰©å±•æ€§å¼º**: æ–‡æœ¬æ•°æ®ä¸°å¯Œä¸”å»‰ä»·ï¼Œæ˜“äºæ‰©å±•
        - **éšç§å‹å¥½**: æ— éœ€æ”¶é›†/å­˜å‚¨çœŸå®å›¾åƒ
  - **æ•°æ®è§„æ¨¡**:
      - **Unicorn-1.2M**ï¼ˆé¢„è®­ç»ƒæ•°æ®é›†ï¼‰: 1.2Mè¯¦ç»†captions + å¯¹åº”çš„åˆæˆå›¾åƒè¡¨ç¤º
      - **Unicorn-471K-Instruction**ï¼ˆæŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†ï¼‰: 471Kå¤šä»»åŠ¡æŒ‡ä»¤æ•°æ® + å¯¹åº”çš„åˆæˆå›¾åƒè¡¨ç¤º
      - **Captionæ¥æºå¤šæ ·æ€§**:
        - å¼€æ”¾åŸŸ: MS-COCO, Flickr30K, CC3M, CC-YFCCç­‰
        - é¢†åŸŸç‰¹å®š: Conceptual Captions, Chart2Text, PlotQA, FigureQA, DVQAç­‰
  - **æ¨¡å‹**: **Unicorn-8B VLM**
      - **æ¶æ„**: åŸºäºä¸»æµVLMæ¶æ„ï¼ˆè§†è§‰ç¼–ç å™¨ + æŠ•å½±å±‚ + LLMï¼‰
      - **è®­ç»ƒç­–ç•¥**:
        - **é¢„è®­ç»ƒ**: ä½¿ç”¨Unicorn-1.2Mè¿›è¡Œæ¨¡æ€å¯¹é½
        - **æŒ‡ä»¤è°ƒä¼˜**: ä½¿ç”¨Unicorn-471K-Instructionè¿›è¡Œå¾®è°ƒ
      - **ç‰¹ç‚¹**: å®Œå…¨ä¸ä½¿ç”¨çœŸå®å›¾åƒè®­ç»ƒ
  - **å®éªŒç»“æœ** - **ä¸åŸºäºçœŸå®å›¾åƒçš„æ–¹æ³•æ€§èƒ½ç›¸å½“**:
      - **å¤šæ¨¡æ€åŸºå‡†è¯„ä¼°**: åœ¨å¤šä¸ªVLMåŸºå‡†ä¸Šè¾¾åˆ°ç«äº‰æ€§èƒ½
      - **æˆæœ¬æ•ˆç›Š**: æ˜¾è‘—é™ä½è®­ç»ƒæˆæœ¬çš„åŒæ—¶ä¿æŒæ€§èƒ½
      - **æ¶ˆèç ”ç©¶**:
        - **Stage 1å¤šæ ·æ€§**: è¯¦ç»†captionæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½
        - **Stage 2ä»»åŠ¡ç±»å‹**: å¤šä»»åŠ¡æ··åˆè®­ç»ƒä¼˜äºå•ä»»åŠ¡
        - **Stage 3è¡¨ç¤ºè½¬ç§»**: Mean shiftæ–¹æ³•æœ‰æ•ˆå¼¥åˆæ¨¡æ€é—´éš™
  - **æˆæœ¬å¯¹æ¯”**ï¼ˆvsä¼ ç»Ÿå›¾åƒ-æ–‡æœ¬åˆæˆæ–¹æ³•ï¼‰:
      - **APIæˆæœ¬**: $6.84 vs $12ï¼ˆé™ä½44%ï¼‰
      - **åˆæˆæ—¶é—´**: 0.3å¤© vs 4å¤©ï¼ˆé™ä½92.5%ï¼‰
      - **å­˜å‚¨éœ€æ±‚**: 4GB vs 109GBï¼ˆé™ä½96.3%ï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´3æœˆ
  - **æœºæ„**: Xrealã€è¥¿æ¹–å¤§å­¦ã€æµ™æ±Ÿå¤§å­¦ã€ä¸Šæµ·AIå®éªŒå®¤ã€å—æ´‹ç†å·¥å¤§å­¦ã€åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦ã€å¤§æ¹¾åŒºå¤§å­¦
  - **ä½œè€…**: Xiaomin Yu, Pengxiang Ding, Wenjie Zhangç­‰
  - **å¼€æº**: âœ… **å®Œå…¨å¼€æº** - ä»£ç ã€æ•°æ®é›†
  - **ä»£ç ä»“åº“**: [github.com/Yu-xm/Unicorn](https://github.com/Yu-xm/Unicorn)
  - **é‡è¦æ„ä¹‰**:
      - **èŒƒå¼çªç ´**: é¦–ä¸ªå®Œå…¨ä¸ä¾èµ–çœŸå®/ç”Ÿæˆå›¾åƒçš„å¤šæ¨¡æ€æ•°æ®åˆæˆæ¡†æ¶
      - **ç†è®ºåˆ›æ–°**: ç³»ç»Ÿæ€§åœ°å°†modality gapç†è®ºåº”ç”¨äºå¤§è§„æ¨¡æ•°æ®åˆæˆ
      - **æˆæœ¬é©å‘½**: æ˜¾è‘—é™ä½å¤šæ¨¡æ€æ•°æ®åˆæˆçš„æˆæœ¬ã€æ—¶é—´å’Œå­˜å‚¨å¼€é”€
      - **å¯æ‰©å±•æ€§**: åˆ©ç”¨ä¸°å¯Œçš„æ–‡æœ¬èµ„æºï¼Œæ˜“äºæ‰©å±•åˆ°æ›´å¤§è§„æ¨¡
      - **å®ç”¨ä»·å€¼**: ä¸ºèµ„æºå—é™åœºæ™¯ä¸‹çš„VLMè®­ç»ƒæä¾›å¯è¡Œæ–¹æ¡ˆ
  
  #### ğŸ”¬ åŸºäºå¤§æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆ
  
  > **æ ¸å¿ƒæ€æƒ³**: ä½¿ç”¨å¼ºå¤§çš„VLMsï¼ˆå¦‚GPT-4Vï¼‰æˆ–LLMsï¼ˆå¦‚GPT-4ï¼‰ä¸ºå›¾åƒç”Ÿæˆæ›´é«˜è´¨é‡çš„captions/å¯¹è¯æ•°æ®
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Synthesize%20Step-by-Step%20CVPR%202024">ğŸ“„ Synthesize Step-by-Step</a></b><br>
<code>CVPR 2024</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CVPR_2024-red?style=flat-square"/>
</summary>

  - **Focus**: **Chart VQA Reasoning Data Generation** - Uses LLM as automatic data annotator to generate step-by-step reasoning QA pairs for chart images
  - **Data Synthesis Method** - **Template-Guided + LLM Generation + Tool-Assisted Execution**:
      - **Core Innovation**: **Synthesize Step-by-Step Strategy** - LLM learns to decompose complex questions into step-by-step sub-questions, uses external tools (Python) to execute and derive final answers
      - **Three-Stage Pipeline**:
        1. **Template-based QA Generation (Training Corpus)**:
           - **Input**: SVG annotations of ChartQA images (title, legend, data point values, colors, etc.)
           - **Method**: Hand-designed 28 templates defining reasoning programs (Domain-Specific Language - DSL)
           - **Output**: 357K template-generated QA pairs covering 7 reasoning types
           - **Reasoning Types**: Value retrieval, comparisons, ranges, averages, sorting, math operations, multi-step inference
           - **Purpose**: Provides training data for teaching LLM how to decompose problems and use tools
        2. **LLM-based Data Generator Training**:
           - **Architecture**: ViT (CLIP) + Linear projection + LLM (MPT-7B) + DEPLOT table prediction
           - **Input**: Image features + predicted data table + prompt
           - **Training**: Trained on template QA to learn generating: question â†’ rationale program â†’ execute to get answer
           - **Key Innovation**:
             - **Does not directly generate answers**, but generates executable rationale programs
             - Rationale programs contain: atom VQA calls (e.g., `ans_0=VQA("What is the value of 2002?")`) + Python math computations
             - Uses DEPLOT-predicted tables as OCR input to address CLIP-ViT's weak text perception
        3. **Large-Scale Data Synthesis & Filtering**:
           - **Generation**: LLM generates question + rationale program for images
           - **Execution**: Python parser parses and executes rationale program to derive answers
           - **Filtering**: Post-processing filtering based on decoding score (threshold=-10) for low-quality questions
           - **Output**: LaMenDa dataset (LLM-augmented Data)
      - **Key Technical Advantages**:
        - **Accuracy**: More accurate answers by executing programs rather than direct generation
        - **Interpretability**: Rationales provide step-by-step reasoning paths
        - **Scalability**: Once trained, can generate data for arbitrary chart images
        - **Domain Flexibility**: Can control generation of specific question types via prompts
        - **Cost-Effective**: Uses open-source LLM (MPT-7B) rather than proprietary API
  - **Data Scale**:
      - **Template QA**: 357K (training LLM generator)
      - **LaMenDa (ChartQA)**: 326K (403K generated, filtered after execution)
      - **LaMenDa (PlotQA)**: 1.7M (3M generated, filtered after execution)
      - **Chart Captioning Datasets**: 1.6M (generated from 137K images)
  - **Experimental Results** - **SOTA on ChartQA Dataset**:
      - **Human-written questions**: Accuracy improved from 38% to **54%** (MATCHA baseline)
      - **Overall ChartQA**: Significantly surpasses previous SOTA
      - **PlotQA**: Also achieves SOTA on synthetic dataset
      - **Ablation Studies**: Step-by-step generation outperforms direct answer generation
  - **Publication**: CVPR 2024
  - **Institution**: Johns Hopkins University & AWS AI Labs
  - **Authors**: Zhuowan Li, Bhavan Jasani, Peng Tang, Shabnam Ghadar
  - **Open Source**: To be confirmed (CVPR papers typically open-source code and data)
  - **Significance**:
      - **First Systematic Chart Reasoning Data Synthesis**: Introduces step-by-step reasoning data generation paradigm for Chart VQA
      - **Tool-Assisted Execution**: Combines LLM generation with tool execution to ensure answer accuracy
      - **Template-Guided Training**: Innovatively uses template data to train LLM generator
      - **Significant Performance Boost**: 16 percentage point improvement on most challenging human-written questions
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2405.01483">ğŸ“„ MANTIS</a></b><br>
<code>arXiv 2405.01483</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **é‡ç‚¹**: **äº¤é”™å¤šå›¾åƒæŒ‡ä»¤å¾®è°ƒ** - é¦–ä¸ªå¤šå›¾åƒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†MANTIS-INSTRUCTï¼ŒåŒ…å«721Kå¤šå›¾åƒæŒ‡ä»¤æ•°æ®ï¼Œä½¿ç”¨å­¦æœ¯çº§èµ„æºè®­ç»ƒå¤šå›¾åƒLMM
  - **æ•°æ®æ„å»ºæ–¹æ³•** - **å¤šæºæ•°æ®é›†æ•´ç† + æŒ‡ä»¤æ ¼å¼åŒ–**:
      - **æ ¸å¿ƒåˆ›æ–°**: é€šè¿‡å­¦æœ¯çº§èµ„æºçš„æŒ‡ä»¤å¾®è°ƒæ„å»ºå¼ºå¤§çš„å¤šå›¾åƒLMMï¼Œé¿å…åœ¨æ•°äº¿å™ªå£°äº¤é”™å›¾æ–‡æ•°æ®ä¸Šè¿›è¡Œå¤§è§„æ¨¡é¢„è®­ç»ƒ
      - **MANTIS-INSTRUCTæ•°æ®é›†æ„å»º**:
        - **æ€»è§„æ¨¡**: 721Kå¤šå›¾åƒæŒ‡ä»¤å®ä¾‹ï¼Œæ¶µç›–14ä¸ªå­é›†
        - **å››ç§å¤šå›¾åƒæŠ€èƒ½è¦†ç›–**:
          1. **å…±æŒ‡**: ç†è§£å¦‚"ç¬¬äºŒå¼ å›¾åƒ"çš„å¼•ç”¨å¹¶å°†å…¶å®šä½åˆ°å¼•ç”¨çš„å›¾åƒ
             - **LLaVA-665k-multi**ï¼ˆ313Kï¼‰: å°†å¤šä¸ªå•å›¾åƒå¯¹è¯è¿æ¥æˆå¤šå›¾åƒåºåˆ—
             - **LRV-multi**ï¼ˆ8Kï¼‰: åŒ…å«è‡ªç„¶è¯­è¨€å¼•ç”¨ï¼Œå¦‚"å¯¹äºç¬¬äºŒå¼ å›¾åƒ"
          2. **æ¯”è¾ƒ**: æ•è·å¤šå¼ å›¾åƒä¹‹é—´çš„ç»†å¾®å·®åˆ«å’Œå…±åŒç‚¹
             - **CoInstruct**ï¼ˆ151Kï¼‰: å›¾åƒè´¨é‡ã€è§†è§‰ç›¸ä¼¼æ€§ã€å·®å¼‚æè¿°
             - **Dreamsim**ï¼ˆ16Kï¼‰ã€**Spot-the-Diff**ï¼ˆ8Kï¼‰ã€**Birds-to-Words**ï¼ˆ3Kï¼‰
          3. **æ¨ç†**: æ•è·è·¨å¤šå¼ å›¾åƒçš„ä¿¡æ¯å¹¶å¯¹å¤šä¸ªç‰‡æ®µè¿›è¡Œæ¨ç†
             - **NLVR2**ï¼ˆ86Kï¼‰: è·¨å›¾åƒå†…å®¹çš„é€»è¾‘æ¨ç†
             - **IconQA**ï¼ˆ64Kï¼‰: è®¡æ•°ã€å›¾åƒåŒ¹é…ã€å›¾åƒæ£€ç´¢
             - **Contrast-Caption**ï¼ˆ36Kï¼‰: é‡æ–°æ ¼å¼åŒ–æ ‡é¢˜æ•°æ®é›†
             - **ImageCoDe**ï¼ˆ17Kï¼‰: è‡ªç”±å½¢å¼å¤šå›¾åƒQA
             - **Multi-VQA**ï¼ˆ5Kï¼‰: è‡ªæ”¶é›†å¤šå›¾åƒQA
          4. **æ—¶é—´ç†è§£**: è§‚å¯Ÿå¤šå¸§ä»¥ç†è§£æ—¶é—´ä¿¡æ¯
             - **VIST**ï¼ˆ7Kï¼‰: ä»å›¾åƒåºåˆ—å™è¿°æ•…äº‹
             - **NExT-QA**ï¼ˆ4Kï¼‰ã€**STAR**ï¼ˆ3Kï¼‰: è§†é¢‘ç†è§£ä»»åŠ¡
        - **å•å›¾åƒæ•°æ®é›†**ï¼ˆ268Kï¼‰: DVQAï¼ˆ200Kï¼‰ã€DocVQAï¼ˆ39Kï¼‰ã€ChartQAï¼ˆ28Kï¼‰ç”¨äºå¹³è¡¡å¤šå›¾åƒå’Œå•å›¾åƒèƒ½åŠ›
        - **æ–°æ•´ç†å­é›†**ï¼ˆ4ä¸ªæ–°æ•°æ®é›†ï¼‰:
          - **LLaVA-665k-multi**: LLaVA-665kçš„å¤šå›¾åƒç‰ˆæœ¬
          - **LRV-multi**: LRVçš„å¤šå›¾åƒç‰ˆæœ¬
          - **Contrast-Caption**: é‡æ–°æ ¼å¼åŒ–æ ‡é¢˜æ•°æ®é›†ç”¨äºå¤šå›¾åƒæ¨ç†
          - **Multi-VQA**: è‡ªæ”¶é›†å¤šå›¾åƒQAæ•°æ®é›†
      - **æ–‡æœ¬-å›¾åƒäº¤é”™æ ¼å¼**:
        - **æ ¼å¼**: "(image {i}: <BOI><image><EOI>)"ï¼Œå…¶ä¸­<BOI>å’Œ<EOI>æ˜¯å›¾åƒåˆ†éš”ç¬¦
        - **è®¾è®¡åŸåˆ™**: (1) æ¸…æ™°æ ‡è®°å›¾åƒä¹‹é—´çš„è¾¹ç•Œï¼Œ(2) è¡¨ç¤ºå›¾åƒçš„åºåˆ—å·
        - **å®ç°**: ä½¿ç”¨<Image>å’Œ</Image>ä½œä¸ºåˆ†éš”ç¬¦
        - **å›¾åƒä¸Šä¸‹æ–‡é•¿åº¦**:
          - **LLaVAæ¶æ„**: æ¯å¼ å›¾åƒ576ä¸ªå›¾åƒä»¤ç‰Œï¼Œæœ€å¤š14å¼ å›¾åƒï¼ˆ8Kä¸Šä¸‹æ–‡ï¼‰
          - **Idefics2æ¶æ„**: æ¯å¼ å›¾åƒ64ä¸ªä»¤ç‰Œï¼Œæœ€å¤š128å¼ å›¾åƒï¼ˆ8Kä¸Šä¸‹æ–‡ï¼‰
      - **å…³é”®æŠ€æœ¯**:
        - **æŒ‡ä»¤å¾®è°ƒèšç„¦**: åœ¨721Ké«˜è´¨é‡æ•°æ®ä¸Šè¿›è¡Œä½æˆæœ¬æŒ‡ä»¤å¾®è°ƒ vs. å¤§è§„æ¨¡é¢„è®­ç»ƒ
        - **å¤šæŠ€èƒ½è¦†ç›–**: ç³»ç»Ÿè¦†ç›–æ‰€æœ‰å››ç§å¤šå›¾åƒæŠ€èƒ½
        - **å­¦æœ¯çº§èµ„æº**: æ— éœ€å¤§è§„æ¨¡è®¡ç®—èµ„æºå³å¯å®ç°å¼ºå¤§æ€§èƒ½
        - **æ ¼å¼æ ‡å‡†åŒ–**: è·¨æ‰€æœ‰æ•°æ®é›†ä¸€è‡´çš„æ–‡æœ¬-å›¾åƒäº¤é”™æ ¼å¼
  - **MANTISæ¨¡å‹å®¶æ—**:
      - **æ¶æ„å˜ä½“**:
        - **Mantis-CLIP**: CLIPç¼–ç å™¨ + LLaMA-3-8Bï¼Œåœ¨CC3Må­é›†ï¼ˆ0.56Mï¼‰ä¸Šé¢„è®­ç»ƒ
        - **Mantis-SigLIP**: SigLIPç¼–ç å™¨ + LLaMA-3-8Bï¼Œåœ¨CC3Må­é›†ï¼ˆ0.56Mï¼‰ä¸Šé¢„è®­ç»ƒ
        - **Mantis-Flamingo**: CLIPç¼–ç å™¨ + MPT-7Bï¼Œä»OpenFlamingoåˆå§‹åŒ–ï¼ˆåœ¨2.4Bæ•°æ®ä¸Šé¢„è®­ç»ƒï¼‰
        - **Mantis-Idefics2**: SigLIPç¼–ç å™¨ + Mistral-7B-v0.1ï¼Œä»Idefics2åˆå§‹åŒ–ï¼ˆåœ¨143Mæ•°æ®ä¸Šé¢„è®­ç»ƒï¼‰
      - **è®­ç»ƒ**: åœ¨MANTIS-INSTRUCTï¼ˆ721Kï¼‰+ 268Kå•å›¾åƒæ•°æ®ä¸Šå¾®è°ƒ
      - **è®­ç»ƒèµ„æº**: 16Ã—A100-40Gè®­ç»ƒ36å°æ—¶
  - **Mantis-EvalåŸºå‡†æµ‹è¯•**:
      - **è§„æ¨¡**: 217ä¸ªå¤šå›¾åƒæ¨ç†ç¤ºä¾‹ï¼Œæ¶µç›–ä¸åŒä¸»é¢˜
      - **è¦†ç›–**: å¤§å°æ„ŸçŸ¥ã€é‡é‡æ¯”è¾ƒç­‰
      - **æ„å»º**: ç”±æ³¨é‡Šè€…ç²¾å¿ƒæ•´ç†ï¼Œå›¾åƒé€šè¿‡Googleæœç´¢è·å–
      - **æ ¼å¼**: åŒ…å«å¤šé¡¹é€‰æ‹©å’Œç®€ç­”é¢˜
  - **æ•°æ®è§„æ¨¡**:
      - **MANTIS-INSTRUCT**: 721Kå¤šå›¾åƒæŒ‡ä»¤å®ä¾‹
        - **æ¯ä¸ªç¤ºä¾‹å¹³å‡å›¾åƒæ•°**: 4.7
        - **æ¯ä¸ªç¤ºä¾‹æœ€å¤§å›¾åƒæ•°**: 50
        - **å¹³å‡è½®æ•°**: 14.4
        - **å¹³å‡æ–‡æœ¬ä»¤ç‰Œé•¿åº¦**: 555
        - **å¹³å‡æ–‡æœ¬+å›¾åƒä»¤ç‰Œé•¿åº¦**: 3,584
      - **å•å›¾åƒæ•°æ®é›†**: 268Kå®ä¾‹ç”¨äºå¹³è¡¡
  - **å®éªŒç»“æœ** - **åœ¨æ‰€æœ‰å¤šå›¾åƒåŸºå‡†æµ‹è¯•ä¸Šè¾¾åˆ°SOTA**:
      - **å¤šå›¾åƒåŸºå‡†æµ‹è¯•**ï¼ˆ5ä¸ªåŸºå‡†æµ‹è¯•ï¼‰:
        - **NLVR2**: Mantis-Idefics2è¾¾åˆ°**89.71**ï¼ˆvs. Idefics2-8B 86.87ï¼Œ+2.84ï¼‰
        - **Q-Bench**: Mantis-Idefics2è¾¾åˆ°**75.20**ï¼ˆvs. Idefics2-8B 57.00ï¼Œ+18.20ï¼‰
        - **Mantis-Eval**: Mantis-SigLIPè¾¾åˆ°**59.45**ï¼ˆvs. Idefics2-8B 48.85ï¼Œ+10.60ï¼‰
        - **BLINK**: Mantis-Idefics2è¾¾åˆ°**49.05**ï¼ˆvs. Idefics2-8B 45.18ï¼Œ+3.87ï¼‰
        - **MVBench**: Mantis-SigLIPè¾¾åˆ°**50.15**ï¼ˆvs. Idefics2-8B 29.68ï¼Œ+20.47ï¼‰
        - **å¹³å‡**: Mantis-SigLIPè¾¾åˆ°**62.7**ï¼ˆvs. Idefics2-8B 53.5ï¼Œ+9.2ï¼‰ï¼ŒMantis-Idefics2è¾¾åˆ°**64.5**ï¼ˆvs. Idefics2-8B 53.5ï¼Œ+11.0ï¼‰
      - **vs. GPT-4V**: Mantis-Idefics2åŒ¹é…GPT-4Væ€§èƒ½ï¼ˆ64.5 vs 64.5å¹³å‡ï¼‰
      - **vs. Idefics2-8B**: å°½ç®¡Idefics2-8Båœ¨140Mäº¤é”™å¤šå›¾åƒæ•°æ®ä¸Šé¢„è®­ç»ƒï¼ˆæ¯”MANTIS-INSTRUCTå¤§200å€ï¼‰ï¼ŒMantiså¹³å‡è¶…è¶ŠIdefics2-8B **11ä¸ªç»å¯¹ç‚¹**
      - **æ³›åŒ–**: ä¿æŒå†…å’Œä¿æŒå¤–ç»“æœåŒæ ·å¼ºå¤§ï¼Œæ˜¾ç¤ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›
      - **å•å›¾åƒæ€§èƒ½**: Mantisä¿æŒå¼ºå¤§çš„å•å›¾åƒæ€§èƒ½ï¼Œä¸CogVLMå’ŒEmu2ç›¸å½“
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´5æœˆ
  - **æœºæ„**: æ»‘é“å¢å¤§å­¦ã€æ¸…åå¤§å­¦ã€Sea AI Lab
  - **å¼€æº**: âœ… [GitHub](https://github.com/tiger-ai-lab/Mantis) - ä»£ç ã€MANTIS-INSTRUCTæ•°æ®é›†ï¼ˆ721Kï¼‰ã€æ¨¡å‹
  - **é‡è¦æ„ä¹‰**:
      - **é¦–ä¸ªå¤šå›¾åƒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†**: MANTIS-INSTRUCTä¸ºæœªæ¥ç ”ç©¶æä¾›é‡è¦åŸºçº¿
      - **å­¦æœ¯çº§èµ„æº**: æ— éœ€å¤§è§„æ¨¡é¢„è®­ç»ƒå³å¯è¾¾åˆ°SOTAï¼Œå±•ç¤ºæŒ‡ä»¤å¾®è°ƒçš„æ•ˆç‡
      - **å¤šæŠ€èƒ½è¦†ç›–**: ç³»ç»Ÿè¦†ç›–å…±æŒ‡ã€æ¯”è¾ƒã€æ¨ç†å’Œæ—¶é—´ç†è§£
      - **æˆæœ¬æ•ˆç›Š**: ä½æˆæœ¬æŒ‡ä»¤å¾®è°ƒï¼ˆ721Kæ•°æ®ï¼‰ä¼˜äºåœ¨200å€æ›´å¤§æ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹
      - **æ³›åŒ–**: åœ¨ä¿æŒå†…å’Œä¿æŒå¤–åŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰å¼ºå¤§æ€§èƒ½
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2406.11833">ğŸ“„ MMDU</a></b><br>
<code>arXiv 2406.11833</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-NeurIPS_2024-red?style=flat-square"/>
</summary>

  - **é‡ç‚¹**: **å¤šè½®å¤šå›¾åƒå¯¹è¯ç†è§£åŸºå‡†æµ‹è¯•å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†** - å…¨é¢çš„åŸºå‡†æµ‹è¯•å’Œå¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°å’Œæ”¹è¿›LVLMåœ¨å¤šè½®å’Œå¤šå›¾åƒå¯¹è¯ä¸­çš„èƒ½åŠ›
  - **æ•°æ®æ„å»ºæ–¹æ³•** - **åŸºäºèšç±»çš„å›¾åƒé€‰æ‹© + GPT-4oç”Ÿæˆ + äººå·¥æ³¨é‡Š**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä½¿ç”¨èšç±»ç®—æ³•ä»å¼€æºWikipediaä¸­æ‰¾åˆ°ç›¸å…³å›¾åƒå’Œæ–‡æœ¬æè¿°ï¼Œé€šè¿‡äººå·¥æ³¨é‡Šè€…å’ŒGPT-4oè¾…åŠ©æ„å»ºé—®ç­”å¯¹
      - **MMDUåŸºå‡†æµ‹è¯•æ„å»º**:
        - **æ•°æ®æ”¶é›†**:
          1. **å›¾åƒå’Œæ–‡æœ¬é€‰æ‹©**:
             - **æ¥æº**: å¼€æºWikipediaæ¡ç›®
             - **æ–¹æ³•**: èšç±»ç®—æ³•è¯†åˆ«ç›¸å…³Wikipediaå®ä½“
             - **è¿‡ç¨‹**: ä½¿ç”¨å¥å­è½¬æ¢å™¨ç¼–ç æ¡ç›®çš„ç›¸å…³æ ‡ç­¾ï¼Œä½¿ç”¨è·å¾—çš„åµŒå…¥å¯¹æ¡ç›®è¿›è¡Œèšç±»
             - **å›¾åƒåŒ¹é…**: ä½¿ç”¨å›¾åƒæ ‡é¢˜åŒ¹é…æ¡ç›®ä»¥è·å¾—é«˜åº¦ç›¸å…³çš„æ¡ç›®å’Œå›¾åƒé›†
             - **é€‰æ‹©**: åœ¨æ¯ä¸ªèšç±»å†…ï¼Œé€‰æ‹©å¤šå¼ å›¾åƒå’Œå…³è”çš„æ–‡æœ¬ä¿¡æ¯ä»¥åˆ›å»ºå›¾åƒ-æ–‡æœ¬å¯¹ç»„åˆï¼ˆèŒƒå›´ä»2åˆ°20å¼ å›¾åƒï¼‰
          2. **é—®ç­”ç”Ÿæˆ**:
             - **GPT-4oç”Ÿæˆ**: ä½¿ç”¨ç²¾å¿ƒè®¾è®¡çš„æç¤ºæŒ‡å¯¼GPT-4oæ ¹æ®å¯ç”¨å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯ç”Ÿæˆç›¸åº”çš„é—®ç­”
             - **å¤šè½®æ„å»º**:
               - é¦–å…ˆä¸ºæ¯å¼ å•å›¾åƒåŠå…¶å…³è”æ–‡æœ¬æ„å»ºå¤šè½®é—®ç­”å¯¹
               - ç„¶åå°†å¤šå¼ å›¾åƒç»„åˆè¾“å…¥GPT-4oä»¥åŸºäºå¤šå¼ å›¾åƒç”Ÿæˆå¤šè½®é—®ç­”å¯¹
               - å°†å¤šå¼ å›¾åƒçš„å¤šè½®é—®ç­”å¯¹ä¸æ¯å¼ å•å›¾åƒçš„é—®ç­”å¯¹ç»“åˆï¼Œåˆ›å»ºåŒ…å«å•å›¾åƒå’Œå¤šå›¾åƒé—®é¢˜çš„å¯¹è¯
             - **æ–‡æœ¬-å›¾åƒäº¤é”™æ ¼å¼**: ä½¿ç”¨<image-1>ã€<image-2>ç­‰æ ‡ç­¾æ¥å¼•ç”¨ä¸åŒçš„å›¾åƒ
          3. **è´¨é‡æ§åˆ¶**:
             - **äººå·¥æ³¨é‡Š**: ä¸“å®¶æ³¨é‡Šè€…ä»”ç»†å®¡æŸ¥ç”Ÿæˆçš„å¯¹è¯
             - **é€‰æ‹©**: ä¸ºåŸºå‡†æµ‹è¯•é€‰æ‹©110ä¸ªé«˜è´¨é‡å¤šè½®å¤šå›¾åƒå¯¹è¯
             - **ç¼–è¾‘**: ä»”ç»†ç¼–è¾‘æ ·æœ¬ä»¥æ¶ˆé™¤GPT-4oå“åº”ä¸­çš„å¹»è§‰å’Œé”™è¯¯
             - **è´¨é‡ä¿è¯**:
               - ç»“åˆè‡ªåŠ¨å’Œæ‰‹åŠ¨ç­›é€‰æ–¹æ³•
               - å¤šè½®æ‰‹åŠ¨å®¡æŸ¥æœºåˆ¶ï¼ˆè‡³å°‘ä¸¤è½®ï¼šå¸¸è§„å®¡æŸ¥è€…çš„åˆæ­¥æ£€æŸ¥ï¼Œä¸“å®¶çš„æ·±å…¥æ£€æŸ¥ï¼‰
               - ä¸“é—¨çš„Web UIç”¨äºå¿«é€Ÿæµè§ˆå’Œä¿®æ”¹æ•°æ®å†…å®¹
        - **MMDU-45Kæ•°æ®é›†æ„å»º**:
          - **ç›¸åŒè¿‡ç¨‹**: ä½¿ç”¨ä¸æ„å»ºMMDUç›¸åŒçš„è¿‡ç¨‹
          - **å·®å¼‚**: éšæœºé‡‡æ ·äººå·¥éªŒè¯è€Œä¸æ˜¯MMDUä¸­ä½¿ç”¨çš„è¯¦å°½äººå·¥è¯„ä¼°
          - **è§„æ¨¡**: 45Ké«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®
      - **å…³é”®æŠ€æœ¯**:
        - **åŸºäºèšç±»çš„é€‰æ‹©**: é€šè¿‡é€‰æ‹©ç›¸å…³å›¾åƒç¡®ä¿é€»è¾‘è¿è´¯æ€§å’Œä¸°å¯Œå†…å®¹
        - **GPT-4oè¾…åŠ©**: åˆ©ç”¨GPT-4oè¿›è¡Œé—®ç­”ç”Ÿæˆï¼ŒåŒæ—¶ä¿æŒäººå·¥ç›‘ç£
        - **å¤šè½®è®¾è®¡**: åœ¨åŒä¸€å¯¹è¯ä¸­æ”¯æŒå•å›¾åƒå’Œå¤šå›¾åƒé—®é¢˜
        - **å¯æ‰©å±•æ ¼å¼**: çµæ´»çš„æ ¼å¼å…è®¸è¿æ¥å¤šä¸ªå¯¹è¯ï¼Œç†è®ºä¸Šæ”¯æŒæ— é™é•¿åº¦
  - **MMDUåŸºå‡†æµ‹è¯•ç‰¹å¾**:
      - **å¤šè½®å’Œå¤šå›¾åƒ**: æœ€å¤š20å¼ å›¾åƒå’Œ27è½®ï¼Œè‡³å°‘æ¯”ä¹‹å‰çš„åŸºå‡†æµ‹è¯•é•¿5å€
      - **é•¿ä¸Šä¸‹æ–‡**: æœ€å¤š18Kå›¾åƒ+æ–‡æœ¬ä»¤ç‰Œï¼Œè¯„ä¼°LVLMå¤„ç†å’Œç†è§£æ‰©å±•ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›
      - **å¼€æ”¾è¯„ä¼°**: é‡‡ç”¨è‡ªç”±å½¢å¼å¤šè½®è¾“å‡ºï¼Œé€šè¿‡GPT-4oä½œä¸ºåˆ¤æ–­è¯„ä¼°LVLMçš„æ€§èƒ½
      - **è¯„ä¼°ç»´åº¦**ï¼ˆ6ä¸ªç»´åº¦ï¼‰:
        1. **åˆ›é€ æ€§**: å“åº”çš„åŸåˆ›æ€§å’Œåˆ›æ–°æ€§
        2. **ä¸°å¯Œæ€§**: ä¿¡æ¯çš„è¯¦ç»†ç¨‹åº¦å’Œæ·±åº¦
        3. **è§†è§‰æ„ŸçŸ¥**: è¯†åˆ«è§†è§‰å…ƒç´ çš„å‡†ç¡®æ€§
        4. **é€»è¾‘è¿è´¯æ€§**: é€»è¾‘ç»“æ„å’Œæµç¨‹
        5. **ç­”æ¡ˆå‡†ç¡®æ€§**: äº‹å®ä¿¡æ¯çš„æ­£ç¡®æ€§
        6. **å›¾åƒå…³ç³»ç†è§£**: ç†è§£å›¾åƒä¹‹é—´çš„å…³ç³»
        - **æ€»ä½“åˆ†æ•°**: å…¨é¢è¯„ä¼°ï¼ˆä»6ä¸ªç»´åº¦èšåˆå¾—å‡ºï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **MMDUåŸºå‡†æµ‹è¯•**: 110ä¸ªé«˜è´¨é‡å¤šè½®å¤šå›¾åƒå¯¹è¯ï¼ŒåŒ…å«è¶…è¿‡1,600ä¸ªé—®é¢˜
        - **æ¯ä¸ªå¯¹è¯çš„å›¾åƒæ•°**: 2åˆ°20å¼ å›¾åƒ
        - **å¹³å‡å›¾åƒå’Œæ–‡æœ¬ä»¤ç‰Œé•¿åº¦**: 8.2Kä»¤ç‰Œ
        - **æœ€å¤§å›¾åƒå’Œæ–‡æœ¬é•¿åº¦**: 18Kä»¤ç‰Œ
        - **å¹³å‡è½®æ•°**: 15è½®é—®ç­”
      - **MMDU-45Kæ•°æ®é›†**: 45Ké«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ•°æ®
        - **å¹³å‡æ–‡æœ¬ä»¤ç‰Œ**: 6.4K
        - **æ¯ä¸ªæ ·æœ¬çš„å›¾åƒæ•°**: 2-20å¼ å›¾åƒ
        - **å¹³å‡15è½®é—®ç­”**
  - **å®éªŒç»“æœ**:
      - **åŸºå‡†æµ‹è¯•è¯„ä¼°**ï¼ˆè¯„ä¼°äº†15ä¸ªLVLMï¼‰:
        - **å¼€æº vs. ä¸“æœ‰å·®è·**: æœ€ä½³å¼€æºæ¨¡å‹å¾—åˆ†42.8%ï¼Œè¿œä½äºä¸“æœ‰GPT-4oçš„70.2%
        - **æ€§èƒ½å·®è·**: ä¸“æœ‰å’Œå¼€æºLVLMä¹‹é—´å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®å¼‚
      - **å¾®è°ƒç»“æœ**ï¼ˆInternLM-XC2ï¼‰:
        - **MMDU**: +14.5%æ”¹è¿›
        - **MMStar**: +1.1%æ”¹è¿›
        - **MathVista**: +1.5%æ”¹è¿›
        - **ChartQA**: +1.2%æ”¹è¿›
      - **æ¨¡å‹æ”¹è¿›**:
        - **æ›´é•¿å¯¹è¯**: åœ¨MMDU-45Kä¸Šå¾®è°ƒç”Ÿæˆæ›´é•¿ã€æ›´å‡†ç¡®çš„å¯¹è¯
        - **å¤šè½®æ€§èƒ½**: åœ¨å¤šè½®ã€å¤šå›¾åƒåœºæ™¯ä¸Šæ˜¾è‘—æ”¹è¿›
        - **æ³›åŒ–**: åœ¨MMDUå’Œç°æœ‰åŸºå‡†æµ‹è¯•ä¸Šéƒ½æœ‰æ”¹è¿›
  - **å‘å¸ƒæ—¶é—´**: NeurIPS 2024ï¼ˆæ•°æ®é›†å’ŒåŸºå‡†æµ‹è¯•è½¨é“ï¼‰
  - **æœºæ„**: ä¸Šæµ·äº¤é€šå¤§å­¦ã€ä¸Šæµ·AIå®éªŒå®¤ã€é¦™æ¸¯ä¸­æ–‡å¤§å­¦ã€CPII under InnoHKã€MThreads, Inc.
  - **å¼€æº**: âœ… [GitHub](https://github.com/Liuziyu77/MMDU) - ä»£ç ã€MMDUåŸºå‡†æµ‹è¯•ï¼ˆ110ä¸ªå¯¹è¯ï¼‰ã€MMDU-45Kæ•°æ®é›†ï¼ˆ45Kæ ·æœ¬ï¼‰
  - **é‡è¦æ„ä¹‰**:
      - **å…¨é¢åŸºå‡†æµ‹è¯•**: é¦–ä¸ªä¸“é—¨ä¸ºå¤šè½®ã€å¤šå›¾åƒå¯¹è¯ç†è§£è®¾è®¡çš„åŸºå‡†æµ‹è¯•
      - **é•¿ä¸Šä¸‹æ–‡è¯„ä¼°**: è¯„ä¼°LVLMå¤„ç†æ‰©å±•ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›ï¼ˆæœ€å¤š18Kä»¤ç‰Œï¼‰
      - **å¼€æ”¾è¯„ä¼°**: é‡‡ç”¨è‡ªç”±å½¢å¼å¤šè½®è¾“å‡ºï¼Œä½¿ç”¨GPT-4oä½œä¸ºåˆ¤æ–­ï¼Œæ¯”ä¼ ç»Ÿå¤šé¡¹é€‰æ‹©æ ¼å¼æ›´çœŸå®
      - **å¯æ‰©å±•æ•°æ®é›†**: MMDU-45Kæä¾›å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®ä»¥æ”¹è¿›å¤šè½®ã€å¤šå›¾åƒèƒ½åŠ›
      - **å¼¥åˆæ€§èƒ½å·®è·**: è¯æ˜åœ¨MMDU-45Kä¸Šå¾®è°ƒæ˜¾è‘—è§£å†³äº†å¼€æºå’Œä¸“æœ‰LVLMä¹‹é—´çš„å·®è·
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2403.09028">ğŸ“„ ChartInstruct</a></b><br>
<code>arXiv 2403.09028</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**Chartç†è§£çš„æŒ‡ä»¤è°ƒä¼˜æ•°æ®** - æ„å»ºå¤§è§„æ¨¡ã€å¤šæ ·åŒ–çš„chartæŒ‡ä»¤æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒé€šç”¨chartç†è§£æ¨¡å‹
  - **æ•°æ®åˆæˆæ–¹æ³•** - **LLMé©±åŠ¨çš„å¤šä»»åŠ¡æŒ‡ä»¤ç”Ÿæˆ**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šåˆ©ç”¨GPT-3.5/GPT-4ç”Ÿæˆè¦†ç›–å¹¿æ³›chartç†è§£ä»»åŠ¡çš„æŒ‡ä»¤æ•°æ®ï¼Œæ”¯æŒinstruction tuning
      - **æ•°æ®æ”¶é›†**ï¼š
        - **Chartè¯­æ–™**ï¼šä»å¤šä¸ªåœ¨çº¿æ¥æºæ”¶é›†çœŸå®å›¾è¡¨ï¼Œæ¶µç›–å¤šæ ·åŒ–è§†è§‰é£æ ¼
          - **UniChartæ•°æ®é›†**ï¼š611K chartsï¼ˆæ¥æºï¼šPew, Statista, OECD, OWIDï¼‰
          - **WebChartsï¼ˆæ–°è´¡çŒ®ï¼‰**ï¼š41K chartsï¼ˆç½‘ç»œçˆ¬å–ï¼Œä½¿ç”¨Gemini Pro Visionæå–æ•°æ®è¡¨ï¼‰
        - **æœ€ç»ˆç”¨äºinstructionç”Ÿæˆ**ï¼š70,882ä¸ªç‹¬ç‰¹charts
      - **æŒ‡ä»¤ç”ŸæˆPipeline**ï¼š
        - **ä»»åŠ¡é€‰æ‹©**ï¼šå®šä¹‰6å¤§ä»»åŠ¡ç±»åˆ«
          1. **Chart Summarization**ï¼šç”Ÿæˆå›¾è¡¨captionï¼Œæ•è·å…³é”®æ´å¯Ÿï¼ˆè¶‹åŠ¿ã€æ¨¡å¼ï¼‰
          2. **Open-ended QA**ï¼šç”Ÿæˆè§£é‡Šæ€§é—®ç­”ï¼ˆéœ€è¦è¯¦ç»†å›ç­”ï¼‰
          3. **Fact Checking**ï¼šç»™å®šclaimï¼Œç”Ÿæˆverdictï¼ˆaccept/refuteï¼‰+ explanation
          4. **Chain-of-Thought (CoT) Reasoning**ï¼š
             - **Variable Dependent**ï¼šä½¿ç”¨å·¥å…·ï¼ˆå—ToolFormerå¯å‘ï¼‰è®¡ç®—ç»Ÿè®¡å€¼
             - **Variable Independent**ï¼šæ£€ç´¢ã€æ¯”è¾ƒã€åŸºç¡€æ•°å­¦åˆ†æ
          5. **Code Generation**ï¼šç”Ÿæˆå¯æ‰§è¡ŒPythonè„šæœ¬å›ç­”æŸ¥è¯¢ï¼ˆå—PALå¯å‘ï¼‰
          6. **Novel Tasks**ï¼šè®©LLMæè®®æ–°ä»»åŠ¡ï¼ˆæœªæ¥å€¼é¢„æµ‹ã€æ¨¡å¼æ£€æµ‹ç­‰ï¼‰
        - **Promptè®¾è®¡**ï¼š
          - æ¯ä¸ªä»»åŠ¡è®¾è®¡ä¸“é—¨çš„promptæ¨¡æ¿
          - è¾“å…¥ï¼šå›¾è¡¨æ•°æ®è¡¨ + å…ƒæ•°æ®ï¼ˆæ ‡é¢˜ï¼‰
          - è¾“å‡ºï¼šæŒ‡ä»¤-å“åº”å¯¹
        - **ç”Ÿæˆç­–ç•¥**ï¼š
          - **GPT-4**ï¼šç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆCoTã€Novel tasksï¼‰
          - **GPT-3.5 Turbo**ï¼šç”¨äºä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡
          - æ¯æ¬¡è°ƒç”¨ç”Ÿæˆå¤šä¸ªæ ·æœ¬ä»¥å¢åŠ å¤šæ ·æ€§å’Œé™ä½æˆæœ¬
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**ï¼š
        - **ä»»åŠ¡å¤šæ ·æ€§**ï¼šè¦†ç›–6å¤§ç±»ã€å¤šä¸ªå­ä»»åŠ¡ï¼Œé¿å…task-specific overfitting
        - **çœŸå®å›¾è¡¨**ï¼šåŸºäºçœŸå®åœ¨çº¿å›¾è¡¨ï¼Œè€Œéåˆæˆæ•°æ®
        - **è‡ªåŠ¨åŒ–æµç¨‹**ï¼šå®Œå…¨è‡ªåŠ¨åŒ–çš„LLMé©±åŠ¨pipelineï¼Œå¯æ‰©å±•
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **ChartInstructæ•°æ®é›†**ï¼š191KæŒ‡ä»¤ï¼Œå¯¹åº”70,882ä¸ªcharts
      - **åˆ†å¸ƒ**ï¼š
        - Chart Summarization: 53,876 (28.24%)
        - Open-ended QA: 42,470 (22.26%)
        - CoT Reasoning: 27,271 (14.3%)
        - Fact Checking: 24,175 (12.67%)
        - Code Generation: 19,572 (10.26%)
        - Novel Tasks: 23,410 (12.27%)
      - **Chartsæ¥æºåˆ†å¸ƒ**ï¼ˆunique chartsæ•°é‡ï¼‰ï¼š
        - WebCharts: 41,742 (58.9%)
        - OECD/OWID: 10,949 (15.4%)
        - Statista: 9,992 (14.1%)
        - PlotQA: 8,199 (11.6%)
      - **Instructionsåˆ†å¸ƒ**ï¼šWebChartsè´¡çŒ®157,190 instructionsï¼Œå æ€»æ•°çš„67.5%
  - **æ¨¡å‹**ï¼šä¸¤ç§ç³»ç»Ÿè®¾è®¡
      1. **End-to-end**ï¼šUniChart vision encoder + LLMï¼ˆLlama2-7B / Flan-T5-XL-3Bï¼‰
      2. **Pipeline**ï¼šChart-to-table model (DEPLOT) â†’ LLM
  - **å®éªŒç»“æœ** - **4ä¸ªbenchmarkä¸Šçš„SOTA**ï¼š
      - **ChartQA**ï¼šè¶…è¶Šä¹‹å‰SOTA
      - **Chart2Text**ï¼šsummarizationä»»åŠ¡SOTA
      - **OpenCQA**ï¼šopen-ended QA SOTA
      - **ChartFC**ï¼šfact-checking SOTA
      - **Human evaluation**ï¼šåœ¨çœŸå®chartç†è§£åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²
  - **æ•°æ®è´¨é‡**ï¼š
      - **ä¸“å®¶è¯„ä¼°**ï¼š100ä¸ªæ ·æœ¬äººå·¥æ ‡æ³¨
        - 87%çš„æŒ‡ä»¤æè¿°æœ‰æ•ˆä»»åŠ¡
        - 86%çš„è¾“å…¥ä¸ä»»åŠ¡æè¿°åŒ¹é…
        - 61%çš„è¾“å‡ºå®Œå…¨æ­£ç¡®ï¼Œ8%éƒ¨åˆ†æ­£ç¡®
      - **å¤šæ ·æ€§**ï¼šåŠ¨è¯-åè¯å¯¹åˆ†ææ˜¾ç¤ºå¹¿æ³›çš„ç†è§£å’Œæ¨ç†ä»»åŠ¡
  - **å‘å¸ƒæ—¶é—´**ï¼šarXiv 2024å¹´3æœˆ
  - **æœºæ„**ï¼šYork University (Canada), Qatar Computing Research Institute, Salesforce Research, NTU Singapore
  - **ä½œè€…**ï¼šAhmed Masry, Mehrad Shahmohammadi, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty
  - **å¼€æº**ï¼šâœ… [ä»£ç å’Œæ•°æ®](https://github.com/vis-nlp/ChartInstruct)
  - **é‡è¦æ„ä¹‰**ï¼š
      - **é¦–ä¸ªå¤§è§„æ¨¡chartæŒ‡ä»¤æ•°æ®é›†**ï¼šä¸ºcharté¢†åŸŸinstruction tuningå¥ å®šåŸºç¡€
      - **ä»»åŠ¡å…¨é¢æ€§**ï¼šè¦†ç›–chartç†è§£çš„å¤šä¸ªæ–¹é¢ï¼Œé¿å…narrow task focus
      - **çœŸå®æ•°æ®**ï¼šåŸºäºçœŸå®åœ¨çº¿å›¾è¡¨ï¼Œæ›´æ¥è¿‘å®é™…åº”ç”¨åœºæ™¯
      - **å¼€æ”¾è´¡çŒ®**ï¼šå®Œå…¨å¼€æºæ•°æ®ã€ä»£ç ï¼Œæ¨åŠ¨chartç†è§£ç ”ç©¶
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2412.05243">ğŸ“„ CompCap</a></b><br>
<code>arXiv 2412.05243</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**Composite Imagesçš„Captionç”Ÿæˆ** - ä¸ºåˆæˆå›¾åƒï¼ˆæ‹¼è´´ã€å›¾è¡¨ã€è¡¨æ ¼ã€ä»£ç ã€å›¾ç¤ºç­‰ï¼‰ç”Ÿæˆé«˜è´¨é‡captions
  - **é—®é¢˜èƒŒæ™¯**ï¼š
      - **Composite Images (CI)**ï¼šåˆæˆè§†è§‰å†…å®¹ï¼Œç”±å¤šç§å…ƒç´ ç»„åˆï¼ˆç…§ç‰‡ã€æ–‡æœ¬ã€å›¾å½¢ç­‰ï¼‰
      - **ç°çŠ¶**ï¼šç°æœ‰MLLMè®­ç»ƒæ•°æ®ä¸»è¦å…³æ³¨è‡ªç„¶å›¾åƒ(NI) captionsï¼ŒCI captionsç¨€ç¼º
      - **å½±å“**ï¼šMLLMsåœ¨CIä¸Šè¡¨ç°å·®ï¼Œcaptioningå’ŒVQAå‡†ç¡®ç‡æ˜æ˜¾ä½äºNI
  - **æ•°æ®åˆæˆæ–¹æ³•** - **CompCapæ¡†æ¶ï¼šMetadataé©±åŠ¨çš„CI-captionåˆæˆ**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šåˆ©ç”¨metadataï¼ˆå›¾åƒ-captionå¯¹ã€å¸ƒå±€ã€è¡¨æ ¼æ•°æ®ã€æ–‡æœ¬ï¼‰+ LLMs + è‡ªåŠ¨åŒ–å·¥å…·ï¼ŒåˆæˆCIåŠå…¶è¯¦ç»†captions
      - **CompCapæ¡†æ¶ï¼ˆé€šç”¨ï¼‰**ï¼š
        - **è¾“å…¥**ï¼šMetadataï¼ˆåŸå§‹æ•°æ® + é…ç½®/å®šåˆ¶ï¼‰
        - **å›¾åƒåˆæˆ**ï¼šä½¿ç”¨å„ç§å·¥å…·ï¼ˆæ¸²æŸ“åº“ã€ä»£ç ï¼‰åŸºäºmetadataç”ŸæˆCI
        - **Captionç”Ÿæˆ**ï¼šLLMåŸºäºmetadataç”Ÿæˆå‡†ç¡®ã€è¯¦ç»†çš„caption
        - **çµæ´»æ€§**ï¼šå¯ä¸ºä¸åŒCIç±»å‹å®ç°å®šåˆ¶åŒ–pipeline
      - **6ç§CIç±»å‹çš„å®ç°**ï¼š
        1. **Collageï¼ˆæ‹¼è´´ï¼‰**ï¼š
           - **åŸå§‹æ•°æ®**ï¼šå›¾åƒ-captionå¯¹æ•°æ®é›†
           - **é…ç½®**ï¼šéšæœºç”Ÿæˆå¸ƒå±€ï¼ˆè¡Œåˆ—ç»“æ„ï¼‰
           - **å›¾åƒåˆæˆ**ï¼šæ ¹æ®å¸ƒå±€æ’åˆ—å›¾åƒ
           - **Captionç”Ÿæˆ**ï¼šLLMåŸºäºå•ä¸ªå›¾åƒcaptions + å¸ƒå±€ä¿¡æ¯ç”Ÿæˆæ•´ä½“caption
           - **æ£€ç´¢ç­–ç•¥**ï¼šéšæœºæ£€ç´¢ã€ç›¸ä¼¼åº¦æ£€ç´¢ã€å®ä½“æ£€ç´¢ï¼ˆ3ç§ï¼‰
        2. **Image-Text**ï¼š
           - åœ¨å›¾åƒä¸Šå åŠ æ–‡æœ¬
           - LLMç”Ÿæˆæè¿°å›¾åƒå†…å®¹å’Œæ–‡æœ¬çš„caption
        3. **Chartï¼ˆå›¾è¡¨ï¼‰**ï¼š
           - **åŸå§‹æ•°æ®**ï¼šè¡¨æ ¼æ•°æ®
           - **å›¾åƒåˆæˆ**ï¼šä½¿ç”¨Matplotlib/Plotlyæ¸²æŸ“å›¾è¡¨
           - **Captionç”Ÿæˆ**ï¼šLLMåŸºäºè¡¨æ ¼æ•°æ®ç”Ÿæˆå›¾è¡¨æè¿°ï¼ˆæ•°æ®åˆ†æã€è¶‹åŠ¿ï¼‰
        4. **Diagramï¼ˆå›¾ç¤ºï¼‰**ï¼š
           - ä½¿ç”¨Mermaidç­‰å·¥å…·ç”Ÿæˆæµç¨‹å›¾ã€æ¶æ„å›¾
        5. **Codeï¼ˆä»£ç ï¼‰**ï¼š
           - **åŸå§‹æ•°æ®**ï¼šä»£ç ç‰‡æ®µ
           - **å›¾åƒåˆæˆ**ï¼šä»£ç æ¸²æŸ“ä¸ºå›¾åƒï¼ˆsyntax highlightingï¼‰
           - **Captionç”Ÿæˆ**ï¼šæè¿°ä»£ç åŠŸèƒ½ã€ç»“æ„
        6. **Tableï¼ˆè¡¨æ ¼ï¼‰**ï¼š
           - è¡¨æ ¼æ•°æ®æ¸²æŸ“ä¸ºå›¾åƒ
           - LLMç”Ÿæˆè¡¨æ ¼å†…å®¹æè¿°
      - **Captionè´¨é‡æ ‡å‡†**ï¼š
        - **Accuracy**ï¼šå¿ å®åæ˜ å›¾åƒå†…å®¹ï¼Œæ— è¯¯å¯¼ä¿¡æ¯
        - **Detailedness**ï¼šæä¾›å…·ä½“æ´å¯Ÿï¼Œè¶…è¶ŠåŸºç¡€æè¿°
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**ï¼š
        - **Metadataé©±åŠ¨**ï¼šç¡®ä¿captionå‡†ç¡®æ€§ï¼ˆåŸºäºç»“æ„åŒ–æ•°æ®è€Œéè§†è§‰æ¨æµ‹ï¼‰
        - **æ¨¡å—åŒ–**ï¼šæ˜“äºæ‰©å±•åˆ°æ–°çš„CIç±»å‹
        - **å¯æ‰©å±•**ï¼šåˆ©ç”¨ä¸°å¯Œçš„åŸå§‹æ•°æ®ï¼ˆå›¾åƒæ•°æ®é›†ã€è¡¨æ ¼ç­‰ï¼‰
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **CompCap-118K**ï¼š118K CI-caption pairs
      - **ç»„æˆ**ï¼š
        - Collage: 42.3%
        - Image-Text: 31.4%
        - Chart: 18.7%
        - Table: 3.4%
        - Diagram: 2.5%
        - Code: 1.7%
  - **å®éªŒç»“æœ** - **CIç†è§£åŸºå‡†ä¸Šçš„æ˜¾è‘—æå‡**ï¼š
      - **è®­ç»ƒ**ï¼šåœ¨xGen-MM-inst.-4Bã€LLaVA-NeXT-Vicuna-7B/13Bä¸ŠSFT
      - **11ä¸ªbenchmarkå¹³å‡æå‡**ï¼š
        - xGen-MM-4B: +1.7%
        - LLaVA-NeXT-7B: +2.0%
        - LLaVA-NeXT-13B: +2.9%
      - **CI-specific benchmarkæ˜¾è‘—æå‡**ï¼š
        - ChartQA: +8.0% (LLaVA-13B)
        - DocVQA: +6.2%
        - InfoVQA: +4.5%
        - TextVQA: +3.8%
      - **NI benchmarkä¿æŒæ€§èƒ½**ï¼šåœ¨è‡ªç„¶å›¾åƒä»»åŠ¡ä¸Šæ— é€€åŒ–
  - **æ¶ˆèç ”ç©¶**ï¼š
      - **Caption vs VQAæ•°æ®**ï¼šCaptionæ•°æ®å¯¹CIç†è§£æ›´æœ‰æ•ˆ
      - **æ•°æ®é‡**ï¼šæ€§èƒ½éšCompCapæ•°æ®é‡å¢åŠ è€Œæå‡
      - **CIç±»å‹**ï¼šChartå’ŒImage-Textç±»å‹è´¡çŒ®æœ€å¤§
  - **å‘å¸ƒæ—¶é—´**ï¼šarXiv 2024å¹´12æœˆ
  - **æœºæ„**ï¼šMeta, Tufts University, Georgia Tech
  - **ä½œè€…**ï¼šXiaohui Chen, Satya Narayan Shukla, Mahmoud Azabç­‰
  - **å¼€æº**ï¼šå¾…ç¡®è®¤
  - **é‡è¦æ„ä¹‰**ï¼š
      - **å¡«è¡¥CIæ•°æ®ç©ºç™½**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§åœ°ä¸ºCIç”Ÿæˆé«˜è´¨é‡captions
      - **é€šç”¨æ¡†æ¶**ï¼šCompCapæ¡†æ¶å¯åº”ç”¨äºå¤šç§CIç±»å‹
      - **å®ç”¨å½±å“**ï¼šæ˜¾è‘—æå‡MLLMså¯¹çœŸå®ä¸–ç•Œåˆæˆå›¾åƒçš„ç†è§£èƒ½åŠ›
      - **æ•°æ®æ•ˆç‡**ï¼š11.8ä¸‡æ•°æ®å³å¯å¸¦æ¥æ˜¾è‘—æå‡
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.18558">ğŸ“„ Infinity-MM</a></b><br>
<code>arXiv 2410.18558</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**å¤§è§„æ¨¡å¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®æ„å»º** - æ”¶é›†ã€æ•´åˆå’Œåˆæˆ40M+å¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®ï¼ŒåŒæ—¶æå‡ºåŸºäºtagging systemçš„åˆæˆæ–¹æ³•
  - **æ ¸å¿ƒè´¡çŒ®**ï¼šæ•°æ®è§„æ¨¡ + åˆæˆæ–¹æ³•åˆ›æ–°
      - **æ•°æ®è§„æ¨¡**ï¼š44.8Må¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®ï¼ˆå¼€æºæœ€å¤§è§„æ¨¡ä¹‹ä¸€ï¼‰
      - **åˆæˆæ–¹æ³•**ï¼šåŸºäºtagging systemçš„æ•°æ®åˆæˆï¼Œæ”¯æŒæŒç»­æ‰©å±•
  - **æ•°æ®æ„å»ºæ–¹æ³•**ï¼š
      - **é˜¶æ®µ1ï¼šæ•°æ®æ”¶é›†**ï¼š
        - **ç»Ÿä¸€é¢„å¤„ç†**ï¼šæ”¶é›†å¯ç”¨çš„å¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®é›†ï¼Œè¿›è¡Œæ ¼å¼ç»Ÿä¸€
        - **è´¨é‡è¿‡æ»¤**ï¼šå»é‡ã€è´¨é‡æ£€æŸ¥
        - **æ¥æº**ï¼šæ•´åˆå¤šä¸ªå…¬å¼€æ•°æ®é›†ï¼ˆLLaVAç³»åˆ—ã€ShareGPT4Vã€Cambrianç­‰ï¼‰
      - **é˜¶æ®µ2ï¼šæ•°æ®åˆæˆï¼ˆåˆ›æ–°ç‚¹ï¼‰**ï¼š
        - **Tagging Systemè®¾è®¡**ï¼š
          - **Image Tagging**ï¼šä½¿ç”¨RAM++æ¨¡å‹æå–å›¾åƒtagsï¼ˆå¯¹è±¡ã€åŠ¨ä½œã€åœºæ™¯ï¼‰
          - **Instruction Tagging**ï¼šè®¾è®¡ä¸‰å±‚æŒ‡ä»¤tagç³»ç»Ÿ
            - **ä¸€å±‚**ï¼š6å¤§ç±»ï¼ˆCoarse Perception, Fine-grained Perception-single, Fine-grained Perception-cross, Relation Reasoning, Attribute Reasoning, Logic Reasoningï¼‰
            - **äºŒå±‚**ï¼šç»†åŒ–ä»»åŠ¡ç‰¹å¾
            - **ä¸‰å±‚**ï¼šåŸºäºå…·ä½“ä»»åŠ¡éœ€æ±‚çš„è¯¦ç»†åˆ†ç±»ï¼Œæ€»è®¡199ä¸ªsub-tasks
        - **Image-Instruction Mapping**ï¼š
          - ç»Ÿè®¡seed dataä¸­image tagsä¸instruction tagsçš„å…±ç°é¢‘ç‡
          - è®¡ç®—TF-IDFå€¼ï¼Œå»ºç«‹image tag â†’ instruction typeçš„æ˜ å°„
          - **ä½œç”¨**ï¼šæŒ‡å¯¼æ–°å›¾åƒåº”è¯¥ç”Ÿæˆä»€ä¹ˆç±»å‹çš„æŒ‡ä»¤
        - **Instruction Synthesis Pipeline**ï¼š
          1. **Question Generation**ï¼š
             - è¾“å…¥ï¼šå›¾åƒ + ç›®æ ‡instruction type + few-shot examples
             - æ¨¡å‹ï¼šMiniCPM-V2.6ï¼ˆå¼€æºVLMï¼‰
             - è¾“å‡ºï¼šç¬¦åˆç›®æ ‡typeçš„é—®é¢˜
          2. **Answer Generation**ï¼š
             - ä½¿ç”¨ä¸åŒpromptç”Ÿæˆå¤šæ ·åŒ–ç­”æ¡ˆæ ¼å¼
             - ç¡®ä¿ç­”æ¡ˆå‡†ç¡®æ€§å’Œæ ¼å¼å¤šæ ·æ€§
          3. **Quality Filtering**ï¼š
             - é‡æ–°è¾“å…¥å›¾åƒ+é—®é¢˜åˆ°VLMï¼Œè¯„ä¼°ç›¸å…³æ€§
             - è¿‡æ»¤ä½è´¨é‡é—®é¢˜
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**ï¼š
        - **Tagging System**ï¼šç³»ç»ŸåŒ–çš„æŒ‡ä»¤åˆ†ç±»ï¼Œç¡®ä¿æ•°æ®å¤šæ ·æ€§
        - **Image-Instructionå¯¹åº”**ï¼šè‡ªåŠ¨è¯†åˆ«å“ªç±»å›¾åƒé€‚åˆå“ªç±»æŒ‡ä»¤
        - **å¼€æºVLMåˆæˆ**ï¼šä½¿ç”¨MiniCPM-V2.6è€ŒéGPT-4ï¼Œæˆæœ¬ä½ä¸”å¯å¤ç°
        - **æŒç»­æ‰©å±•**ï¼šæ¡†æ¶æ”¯æŒæŒç»­æ·»åŠ æ–°æ•°æ®
  - **æ•°æ®è§„æ¨¡**ï¼š
      - **Infinity-MM**ï¼š44.8M samples
      - **ç»„æˆ**ï¼ˆæŒ‰æ•°æ®ç±»åˆ«ï¼‰ï¼š
        - **å›¾åƒ-æ–‡æœ¬æè¿°æ•°æ®**ï¼š10M
        - **ç»¼åˆè§†è§‰æŒ‡ä»¤æ•°æ®**ï¼š25.8M
          - General Instruction: 7.1M
          - OCR Data: 2.6M
          - Doc/Chart/Screen: 5.8M
          - Math/Reasoning: 1.3M
          - Text Instruction: 9M
        - **ç²¾é€‰è§†è§‰æŒ‡ä»¤æ•°æ®**ï¼š6M
          - General Instruction: 1.3M
          - OCR Data: 0.3M
          - Doc/Chart/Screen: 1.9M
          - Math/Reasoning: 0.7M
          - Text Instruction: 1.8M
        - **GPT4 & åˆæˆæ•°æ®**ï¼š3M
          - General Instruction: 1M
          - OCR Data: 0.5M
          - Doc/Chart/Screen: 0.1M
          - Math/Reasoning: 0.3M
          - Text Instruction: 0.3M
          - æ–°åˆæˆæ•°æ®ï¼ˆä½¿ç”¨å¼€æºVLMï¼‰ï¼š0.8M
  - **æ¨¡å‹**ï¼š**Aquila-VL-2B**
      - **æ¶æ„**ï¼š2B parameter VLM
      - **è®­ç»ƒ**ï¼šåŸºäºInfinity-MMè®­ç»ƒ
  - **å®éªŒç»“æœ** - **2Bæ¨¡å‹SOTA**ï¼š
      - **å¹³å‡å¾—åˆ†**ï¼šåœ¨å¤šä¸ªbenchmarkä¸Šè¶…è¶ŠåŒè§„æ¨¡æ¨¡å‹
      - **ä¼˜äºå…¶ä»–å¼€æºæ•°æ®è®­ç»ƒçš„æ¨¡å‹**ï¼š
        - è¶…è¶ŠOneVision-SIè®­ç»ƒçš„æ¨¡å‹
        - è¶…è¶Šéƒ¨åˆ†é—­æºæ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼ˆè§Figure 1ï¼‰
      - **å…³é”®å‘ç°**ï¼šå¤§è§„æ¨¡é«˜è´¨é‡æ•°æ® + åˆç†æ··åˆæ¯”ä¾‹ = SOTAæ€§èƒ½
  - **æ¶ˆèç ”ç©¶**ï¼š
      - **æ•°æ®è§„æ¨¡**ï¼šæ€§èƒ½éšæ•°æ®é‡å¢åŠ è€Œæå‡
      - **æ•°æ®ç±»å‹æ··åˆ**ï¼šä¸åŒä»»åŠ¡ç±»å‹çš„æœ€ä¼˜æ··åˆæ¯”ä¾‹
      - **Tagging System**ï¼šéªŒè¯image-instruction mappingçš„æœ‰æ•ˆæ€§
  - **å‘å¸ƒæ—¶é—´**ï¼šarXiv 2024å¹´10æœˆï¼ˆv2: 2025å¹´1æœˆï¼‰
  - **æœºæ„**ï¼šBAAI (åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢), BJTU, BUPT, ICT/CAS, HKUST(GZ), PKU, DLUT
  - **ä½œè€…**ï¼šShuhao Gu, Jialing Zhang, Siyuan Zhou, Kevin Yuç­‰ï¼ˆå¤§å›¢é˜Ÿï¼‰
  - **å¼€æº**ï¼šâœ… [æ•°æ®é›†](https://huggingface.co/datasets/BAAI/Infinity-MM)
  - **é‡è¦æ„ä¹‰**ï¼š
      - **è§„æ¨¡çªç ´**ï¼š44.8Mæ ·æœ¬ï¼Œå¼€æºæ•°æ®ä¸­è§„æ¨¡æœ€å¤§ä¹‹ä¸€
      - **åˆæˆæ–¹æ³•åˆ›æ–°**ï¼šTagging systemæä¾›ç³»ç»ŸåŒ–çš„æ•°æ®åˆæˆæŒ‡å¯¼
      - **å¼€æºVLMåˆæˆ**ï¼šé¦–æ¬¡ç”¨å¼€æºVLMè¿›è¡Œå¤§è§„æ¨¡é«˜è´¨é‡åˆæˆ
      - **æŒç»­æ‰©å±•**ï¼šæ¡†æ¶æ”¯æŒæŒç»­æ•°æ®æ‰©å±•ï¼Œè€Œéä¸€æ¬¡æ€§æ•°æ®é›†
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=ShareGPT4V">ğŸ“„ ShareGPT4V</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Section 3.1):
      - Uses **GPT-4V** to generate high-quality captions for 100K images
      - Prompt design: Requires detailed descriptions (3-5 times more detailed than original captions)
      - Image sources: Curated images from COCO, SAM, LAION, etc.
  - **Data Scale**: 100K high-quality captions
  - **Open Source**: âœ… [Dataset](https://huggingface.co/datasets/Lin-Chen/ShareGPT4V) | [Code](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=SVIT">ğŸ“„ SVIT</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Section 3.2):
      - Uses **GPT-4** to generate large-scale visual instruction data
      - 4.2M dialogues + 1.6M complex reasoning
      - Based on captions from multiple datasets (COCO, VG, CC3M, etc.)
  - **Data Scale**: 5.8M instruction data
  - **Open Source**: âœ… [Dataset](https://huggingface.co/datasets/BAAI/SVIT)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=CapsFusion">ğŸ“„ CapsFusion</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Section 3):
      - **Fuses outputs from multiple captioning models** (BLIP-2, CoCa, GPT-4V, etc.)
      - Uses weighted fusion strategy, combining strengths of different models
      - Re-generates captions for DataComp-1B
  - **Data Scale**: Billion-scale recaptioning
  - **Open Source**: âœ… [Code](https://github.com/baaivision/CapsFusion)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Image%20Textualization">ğŸ“„ Image Textualization</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Automatic Framework for Detailed Image Descriptions**:
      - **Core Innovation**: Maximally converts visual information into text by combining **MLLM understanding** with **vision expert perception**
      - **Three-Phase Pipeline**:
        - **Phase 1 - Holistic Textualization**:
          - Leverage MLLM to create **Reference Description**
          - Provides basic structure for both visual information and linguistic expression
          - Contains the "skeleton" despite lacking details and containing hallucinations
        - **Phase 2 - Visual Detail Textualization**:
          - Use vision expert models (object detection, dense captioning, instance segmentation) to extract **fine-grained object-level information**
          - Extract multiple details from image-side (trained with high-resolution images and object-level annotations)
          - Identify and filter hallucinations in Reference Description
          - Convert perception results into text format
        - **Phase 3 - Textualized Recaptioning**:
          - Integrate visual details with reference description using LLM
          - Produce final high-quality description that is both rich in details and free from hallucinations
      - **Key Advantages**:
        - Addresses MLLM weaknesses: visual hallucination problem and lack of fine-grained details
        - Vision experts provide precise perception (high-res training, object-level annotations)
        - MLLMs provide holistic understanding capabilities
  - **Data Scale**: Creates image description dataset (scale varies by application)
  - **Experimental Results**:
      - LLaVA-7B trained on IT-curated descriptions generates **richer image descriptions**
      - Substantially increases output length and detail with **less hallucination**
      - Comprehensive evaluation on multiple benchmarks verifies description quality
  - **Publication**: arXiv June 2024
  - **Institution**: HKUST, Wuhan University, Zhejiang University, UIUC
  - **Open Source**: âœ… [Code](https://github.com/sterzhang/image-textualization/) | [Dataset](https://huggingface.co/datasets/Sterzhang/image-textualization/)
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2406.08478">ğŸ“„ Recap-DataComp-1B</a></b><br>
<code>arXiv 2406.08478</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Scale-1B-orange?style=flat-square"/>
</summary>

  - **èšç„¦**: **LLaMA-3é©±åŠ¨çš„åäº¿çº§å›¾åƒé‡æ–°æ ‡æ³¨** - ä½¿ç”¨LLaMA-3-powered LLaVAå¯¹DataComp-1Bï¼ˆ1.3Bå›¾åƒï¼‰è¿›è¡Œå…¨é‡é‡æ–°æ ‡æ³¨ï¼Œç”Ÿæˆè¯¦ç»†ã€å¯¹é½çš„caption
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è®­ç»ƒCaptioner + å¤§è§„æ¨¡Recaptioning**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªåœ¨**åäº¿çº§è§„æ¨¡**ä¸Šä½¿ç”¨å¼€æºLLaMA-3è¿›è¡Œé«˜è´¨é‡é‡æ–°æ ‡æ³¨çš„å·¥ä½œï¼Œå¡«è¡¥ç¤¾åŒºç¼ºå£
      - **Stage 1: è®­ç»ƒé«˜æ€§èƒ½Captioner**:
        - **æ¨¡å‹æ¶æ„**: LLaVA-1.5æ¡†æ¶ + **LLaMA-3-8B**ï¼ˆæ›¿ä»£åŸ7B/13Bï¼‰+ CLIP ViT-L/14ï¼ˆå†»ç»“ï¼‰
        - **è®­ç»ƒæµç¨‹**ï¼ˆ2é˜¶æ®µï¼‰:
          1. **é¢„è®­ç»ƒé˜¶æ®µ**: 558Kå›¾æ–‡å¯¹ï¼ˆLAION/CC/SBUï¼‰è®­ç»ƒ2å±‚MLP projection
          2. **æŒ‡ä»¤å¾®è°ƒé˜¶æ®µ**: 665K instructionæ•°æ®ï¼ˆLLaVA-1.5ï¼‰+ **HQ-Editæ•°æ®é›†**å¾®è°ƒMLPå’ŒLLM
        - **æ¨¡å‹æ€§èƒ½**:
          - MMMU: 45.2ï¼ˆvs. LLaVA-1.5-7Bçš„33.6ï¼Œ+11.6ï¼‰
          - MM-Vet: 37.8ï¼ˆvs. LLaVA-1.5-7Bçš„33.9ï¼Œ+3.9ï¼‰
          - è¶…è¶ŠLLaVA-1.5-13Bï¼Œå±•ç°å¼ºå¤§è§†è§‰ç†è§£èƒ½åŠ›
      - **Stage 2: å¤§è§„æ¨¡Recaptioning**:
        - **æ•°æ®æº**: DataComp-1Bï¼ˆ~1.3B web-crawledå›¾æ–‡å¯¹ï¼Œå·²ç»è¿‡å®‰å…¨æ£€æŸ¥ã€å»é‡ã€CLIPè¿‡æ»¤ï¼‰
        - **ç”ŸæˆPrompt**: "Please generate a detailed caption of this image. Please be as descriptive as possible."
        - **ç”Ÿæˆç­–ç•¥**: è´ªå©ªè§£ç ï¼Œæœ€å¤§128 tokensï¼Œè‡ªå›å½’ç”Ÿæˆ
        - **è¾“å‡º**: **Recap-DataComp-1B**ï¼ˆ1.3Bé‡æ–°æ ‡æ³¨çš„å›¾æ–‡å¯¹ï¼‰
      - **è´¨é‡åˆ†æ**:
        - **é•¿åº¦**: å¹³å‡49.43 tokensï¼ˆvs. åŸå§‹10.22ï¼Œ+4.8xï¼‰
        - **è¯æ±‡ä¸°å¯Œåº¦**: è¦†ç›–82.86%çš„è¯æ±‡ï¼Œæ›´å¤šæ ·çš„åè¯å’Œå½¢å®¹è¯
        - **è¯­ä¹‰å¯¹é½**:
          - **LongCLIP Score**: 89.91ï¼ˆvs. åŸå§‹10.09ï¼Œ**çº¦9å€æå‡**ï¼‰
          - æ ‡å‡†CLIP Score: 49.57 vs. 50.43ï¼ˆç›¸å½“ï¼Œå› CLIPè®­ç»ƒäºçŸ­captionï¼‰
        - **äººå·¥è´¨é‡è¯„ä¼°ï¼ˆGPT-4Vè¯„åˆ†ï¼‰**:
          - å¹³å‡è¯„åˆ†: 4.14/5ï¼ˆvs. åŸå§‹3.71ï¼Œ+0.43ï¼‰
          - è¯„ä¼°ç»´åº¦ï¼šæµç•…æ€§ã€å‡†ç¡®æ€§ã€å¯¹é½åº¦
  - **å®éªŒç»“æœ** - **CLIPå’ŒDiTæ¨¡å‹æ˜¾è‘—æå‡**:
      - **CLIPæ¨¡å‹**ï¼ˆæ··åˆæ¯”ä¾‹p=0.8ï¼Œ80%åŸå§‹+20%é‡æ ‡æ³¨ï¼‰:
        - **é›¶æ ·æœ¬æ£€ç´¢**ï¼ˆCOCO Iâ†’Tï¼‰: 61.5%ï¼ˆvs. åŸå§‹57.3%ï¼Œ+4.2%ï¼‰
        - **é›¶æ ·æœ¬æ£€ç´¢**ï¼ˆFlickr30K Tâ†’Iï¼‰: 66.9%ï¼ˆvs. åŸå§‹63.0%ï¼Œ+3.9%ï¼‰
        - **Urban-1Ké•¿æ–‡æœ¬æ£€ç´¢**: 85.0% Iâ†’Tï¼ˆvs. åŸå§‹53.2%ï¼Œ**+31.8%**ï¼‰
        - **VG-Attribution**: 66.4%ï¼ˆvs. åŸå§‹57.1%ï¼Œ+9.3%ï¼‰
      - **Text-to-Image DiTæ¨¡å‹**ï¼ˆæ··åˆæ¯”ä¾‹p=0.0ï¼Œ100%é‡æ ‡æ³¨ï¼‰:
        - **FID**: 27.8ï¼ˆvs. åŸå§‹36.2ï¼Œ**-8.4**ï¼‰
        - **CLIP Score**: 32.5%ï¼ˆvs. åŸå§‹29.3%ï¼Œ+3.2%ï¼‰
        - **Recap-CLIP Score**: 28.3%ï¼ˆvs. åŸå§‹19.9%ï¼Œ+8.4%ï¼‰
        - **GPT-4V Score**: 2.53ï¼ˆvs. åŸå§‹1.40ï¼Œ+1.1ï¼‰
      - **å…³é”®å‘ç°**:
        - **æ··åˆç­–ç•¥æœ€ä¼˜**: åŸå§‹+é‡æ ‡æ³¨æ··åˆè®­ç»ƒæ•ˆæœæœ€ä½³ï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
        - **æ›´å¤§æ–‡æœ¬ç¼–ç å™¨**: é…åˆé‡æ ‡æ³¨æ•°æ®ï¼ŒCLIPæ–‡æœ¬ç¼–ç å™¨æ‰©å¤§å¯è¿›ä¸€æ­¥æå‡æ€§èƒ½
        - **é•¿æ–‡æœ¬ç†è§£**: é‡æ ‡æ³¨æ˜¾è‘—æå‡CLIPå¯¹é•¿ã€å¤æ‚æ–‡æœ¬çš„ç†è§£èƒ½åŠ›
  - **æ•°æ®è§„æ¨¡**:
      - **Recap-DataComp-1B**: 1.3Bé‡æ–°æ ‡æ³¨çš„å›¾æ–‡å¯¹
      - **å¹³å‡captioné•¿åº¦**: 49.43 tokensï¼ˆvs. åŸå§‹10.22ï¼‰
  - **å¼€æº**: âœ… [é¡¹ç›®é¡µé¢](https://www.haqtu.me/Recap-Datacomp-1B/)
  - **æœºæ„**: UC Santa Cruz + University of Edinburgh + JHU + Adobe + UT Austin
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´6æœˆ
  - **é‡è¦æ„ä¹‰**:
      - **å¼€æºåäº¿çº§é‡æ ‡æ³¨**: é¦–ä¸ªå¼€æºçš„åäº¿çº§é«˜è´¨é‡é‡æ ‡æ³¨æ•°æ®é›†ï¼Œé™ä½ç¤¾åŒºé—¨æ§›
      - **LLaMA-3åº”ç”¨**: å±•ç¤ºå¼€æºLLMï¼ˆLLaMA-3ï¼‰å¯è¾¾GPT-4Vçº§åˆ«çš„æ ‡æ³¨è´¨é‡
      - **è·¨ä»»åŠ¡æ³›åŒ–**: åŒæ—¶æå‡åˆ¤åˆ«å¼ï¼ˆCLIPï¼‰å’Œç”Ÿæˆå¼ï¼ˆDiTï¼‰æ¨¡å‹æ€§èƒ½
      - **é•¿æ–‡æœ¬ç†è§£**: è¯æ˜è¯¦ç»†captionå¯¹é•¿æ–‡æœ¬æ£€ç´¢å’Œå±æ€§ç†è§£çš„å…³é”®ä½œç”¨
      - **æ··åˆç­–ç•¥å¯å‘**: ä¸ºç¤¾åŒºæä¾›åŸå§‹+åˆæˆæ•°æ®æ··åˆè®­ç»ƒçš„æœ€ä½³å®è·µ
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2504.13123">ğŸ“„ Hunyuan-Recap100M</a></b><br>
<code>arXiv 2504.13123</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Scale-100M-orange?style=flat-square"/>
</summary>

  - **èšç„¦**: **ä½å¹»è§‰ã€çŸ¥è¯†å¯†é›†å‹åˆæˆcaption** - è…¾è®¯æ··å…ƒå›¢é˜Ÿæå‡ºçš„100Mçº§ä½å¹»è§‰captionç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡è¿ç»­DPOå’ŒçŸ¥è¯†å¢å¼ºå®ç°é«˜è´¨é‡é‡æ–°æ ‡æ³¨
  - **æ•°æ®åˆæˆæ–¹æ³•** - **çŸ¥è¯†å¢å¼ºSFT + è¿ç»­DPO**:
      - **æ ¸å¿ƒåˆ›æ–°**: è§£å†³ä¸¤å¤§ç—›ç‚¹ï¼š1ï¼‰é™ä½å¹»è§‰ï¼ˆéå¹»è§‰ç‡ä»48.3%æå‡è‡³77.9%ï¼‰ï¼›2ï¼‰æå‡çŸ¥è¯†å¯†åº¦ï¼ˆæ•´åˆå®ä½“ã€å±æ€§ç­‰å¤–éƒ¨çŸ¥è¯†ï¼‰
      - **Stage 1: çŸ¥è¯†å¢å¼ºSFT**:
        - **æ•°æ®ç”Ÿæˆ**ï¼ˆGPT-4o + äººå·¥å®¡æ ¸ï¼‰:
          - **æ•°æ®æº**: CC3Mã€CC12Mã€DataCompã€Wukongã€Wikipediaï¼ˆé‡‡æ ·åˆå§‹å›¾æ–‡å¯¹ï¼‰
          - **GPT-4o Promptè®¾è®¡**ï¼ˆä¸‰æ­¥æ³•ï¼‰:
            1. å‡†ç¡®å…·ä½“æè¿°å›¾åƒå†…å®¹ï¼ˆ>50è¯ï¼‰ï¼Œé¿å…ä¸»è§‚è¯„è®º
            2. **çŸ¥è¯†æ³¨å…¥**: å‚è€ƒalt-text/metadataï¼Œæå–å¹¶æ•´åˆç‰¹å®šå®ä½“åã€IPåã€åœ°åç­‰å…³é”®ä¿¡æ¯ï¼ˆå¦‚"åŸƒè²å°”é“å¡”"è€Œé"é‡‘å±å¡”"ï¼‰
            3. è§£é‡Šä¿®æ”¹åŸå› 
          - **äººå·¥åå¤„ç†**: çº æ­£æ˜æ˜¾é”™è¯¯ã€ç¡®è®¤å…³é”®ä¿¡æ¯åŒ…å«ã€è¿‡æ»¤å™ªå£°
          - **æ•°æ®è§„æ¨¡**: 43,408æ¡é«˜è´¨é‡æ ‡æ³¨æ•°æ®
        - **æ¨¡å‹è®­ç»ƒ**: Qwen2-VL-7Bï¼ˆåŸºåº§ï¼‰ + LoRAå¾®è°ƒ
          - å­¦ä¹ ç‡: 1e-5ï¼Œæ‰¹å¤§å°: 128ï¼Œè®­ç»ƒ10 epochs
          - è¾“å‡º: **Recaption-SFTæ¨¡å‹**
      - **Stage 2: è¿ç»­DPOï¼ˆContinuous DPO, CDPOï¼‰**:
        - **æ ‡å‡†DPOé—®é¢˜**: åœ¨captionä»»åŠ¡ä¸­ï¼ŒDPOæ€§èƒ½åœ¨æ•°æ®è§„æ¨¡è¾¾åˆ°ä¸€å®šç¨‹åº¦åplateauï¼ˆåœæ»ï¼‰
        - **CDPOè§£å†³æ–¹æ¡ˆ**ï¼ˆå…³é”®åˆ›æ–°ï¼‰:
          - **è¿­ä»£æ›´æ–°reference model**: å½“DPOæ€§èƒ½é¥±å’Œæ—¶ï¼Œç”¨å½“å‰policy modelæ›´æ–°reference model
          - **é‡æ–°é‡‡æ ·preference data**: ä½¿ç”¨æ›´æ–°åçš„modelé‡æ–°ç”Ÿæˆpreferred/dispreferred pairs
          - **é•¿åº¦å¹³è¡¡**: å¯¹preference pairsè¿›è¡Œé•¿åº¦å¹³è¡¡é‡‡æ ·ï¼Œé˜²æ­¢length bias
        - **åˆå§‹DPOé˜¶æ®µ**:
          - é‡‡æ ·300Kå›¾æ–‡å¯¹ â†’ SFTæ¨¡å‹æ¨ç†ï¼ˆ8æ¬¡å¹¶è¡Œï¼Œé‡‡æ ·å‚æ•°ï¼štop-p=1.0, top-k=20, temp=1.0ï¼‰
          - ä½¿ç”¨å†…éƒ¨Criticæ¨¡å‹é€‰æ‹©best/worstè¾“å‡ºæ„å»ºpreference pairs
          - é•¿åº¦å¹³è¡¡åä¿ç•™218Ké«˜è´¨é‡pairs
          - è®­ç»ƒåˆå§‹DPOæ¨¡å‹ï¼ˆä½œä¸ºreferenceï¼‰
        - **CDPOé˜¶æ®µ**:
          - é‡‡æ ·200Kæ–°å›¾æ–‡å¯¹ â†’ ç”¨åˆå§‹DPOæ¨¡å‹ç”Ÿæˆæ–°preference data
          - é•¿åº¦å¹³è¡¡åä¿ç•™139K pairs
          - ç»§ç»­è®­ç»ƒï¼ˆ1 epochï¼Œå­¦ä¹ ç‡5e-6ï¼‰
        - **æ•ˆæœ**:
          - éå¹»è§‰ç‡: 48.33%ï¼ˆQwen2-VL-7Bï¼‰ â†’ 77.86%ï¼ˆCDPOï¼‰
          - ä½å¹»è§‰ç‡: 87.87% â†’ 98.08%
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **çŸ¥è¯†å¯†é›†**: æ•´åˆalt-textä¸­çš„å®ä½“åã€ä¸“æœ‰åè¯ï¼ˆå¦‚"è‰é…¸ C2H2O4"ï¼‰
        - **ä½å¹»è§‰**: CDPOçªç ´DPO plateauï¼ŒæŒç»­é™ä½å¹»è§‰
        - **ç»†èŠ‚ä¸°å¯Œ**: å¹³å‡8.1ä¸ªè§†è§‰ç»†èŠ‚/captionï¼ˆvs. Recap-DataComp-1Bçš„6.64ï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **Hunyuan-Recap100M**: 100Mé‡æ–°æ ‡æ³¨çš„å›¾æ–‡å¯¹
      - **å¹³å‡captioné•¿åº¦**: 103.15 tokensï¼ˆvs. Recap-DataComp-1Bçš„72.60ï¼‰
      - **å¹³å‡ç»†èŠ‚æ•°**: 8.1ä¸ªè§†è§‰ç»†èŠ‚
      - **éå¹»è§‰ç‡**: 77.9%ï¼ˆvs. Recap-DataComp-1Bçš„29.7%ï¼‰
      - **å¹»è§‰ç‡**: 4.2%ï¼ˆvs. Recap-DataComp-1Bçš„24.9%ï¼‰
  - **å®éªŒç»“æœ** - **VLMå’ŒT2Iæ¨¡å‹å…¨é¢æå‡**:
      - **VLMé¢„è®­ç»ƒ**ï¼ˆLLaVAæ¶æ„ï¼šSigLIP + Hunyuan-7Bï¼‰:
        - **15ä¸ªVLä»»åŠ¡**: å¹³å‡æå‡è‡³59.35%ï¼ˆvs. alt-text 53.12%ï¼Œ**+6.2%**ï¼‰
        - **20ä¸ªè®¤çŸ¥åŸŸ**: å¹³å‡å‡†ç¡®ç‡53.67%ï¼ˆvs. alt-text 36.33%ï¼Œ**+17.3%**ï¼‰
        - **å¹»è§‰ä»»åŠ¡**: HallusionBenchéå¹»è§‰ç‡73.87%ï¼ˆvs. alt-text 68.38%ï¼Œ+5.5%ï¼‰
        - **ç»†ç²’åº¦æ„ŸçŸ¥**: åœ¨åŠ¨ç‰©ã€æ¤ç‰©ã€åœ°æ ‡ç­‰20ç±»è§†è§‰å¯¹è±¡è¯†åˆ«ä¸Šæ˜¾è‘—æå‡
      - **T2Iç”Ÿæˆ**ï¼ˆHunyuan-DiTå¾®è°ƒï¼Œ2Mæ•°æ®LoRAï¼‰:
        - **å†…éƒ¨æ„ŸçŸ¥æµ‹è¯•é›†**: FIDä»62.38é™è‡³45.33ï¼ˆ**-17.1**ï¼‰ï¼ŒCLIP Scoreä»0.323æå‡è‡³0.357
        - **MSCOCOæµ‹è¯•é›†**: FIDä»28.79é™è‡³15.46ï¼ˆ**-13.3**ï¼‰ï¼ŒCLIP Scoreä»0.307æå‡è‡³0.313
      - **è®­ç»ƒæ•ˆç‡**: 20M Hunyuan-Recap100Mæ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼Œåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šè¶…è¶Šå…¶ä»–100M scaleæ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹
  - **è´¨é‡è¯„ä¼°**ï¼ˆåŸºäºGPT-4oçš„CIEMæ–¹æ³•ï¼‰:
      - **vs. Capfusion-120M**: ç»†èŠ‚æ•°+267%ï¼Œé•¿åº¦+3.5xï¼Œå¹»è§‰ç‡-8.6%
      - **vs. Recap-DataComp-1B**: éå¹»è§‰ç‡+43.6%ï¼Œå¹»è§‰ç‡-19.3%
  - **å¼€æº**: âœ… æ‰¿è¯ºå‘å¸ƒHunyuan-Recap100Mæ•°æ®é›†
  - **æœºæ„**: Hunyuan Team, Tencentï¼ˆè…¾è®¯æ··å…ƒå›¢é˜Ÿï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´5æœˆ
  - **é‡è¦æ„ä¹‰**:
      - **ä½å¹»è§‰çªç ´**: é¦–ä¸ªç³»ç»Ÿæ€§è§£å†³captionå¹»è§‰é—®é¢˜çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆéå¹»è§‰ç‡77.9%ï¼‰
      - **CDPOæ–¹æ³•è®º**: æå‡ºè¿ç»­DPOï¼Œçªç ´æ ‡å‡†DPOçš„plateaué™åˆ¶
      - **çŸ¥è¯†å¯†é›†**: åˆ›æ–°æ€§åœ°æ•´åˆå¤–éƒ¨çŸ¥è¯†ï¼ˆå®ä½“ã€å±æ€§ï¼‰åˆ°captionä¸­
      - **è·¨ä»»åŠ¡éªŒè¯**: åŒæ—¶åœ¨VLMé¢„è®­ç»ƒå’ŒT2Iç”Ÿæˆä¸Šå–å¾—æ˜¾è‘—æå‡
      - **å·¥ä¸šçº§è§„æ¨¡**: 100Mæ•°æ®è§„æ¨¡ï¼Œå±•ç¤ºå·¥ä¸šç•Œåœ¨åˆæˆæ•°æ®ä¸Šçš„æ¢ç´¢
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2507.18616">ğŸ“„ SynC</a></b><br>
<code>arXiv 2507.18616</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
</summary>

  - **èšç„¦**: **åˆæˆæ•°æ®refinement foré›¶æ ·æœ¬å›¾åƒæ ‡æ³¨** - é€šè¿‡one-to-many mappingé‡æ–°é…å¯¹captionåˆ°æœ€è¯­ä¹‰å¯¹é½çš„åˆæˆå›¾åƒ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **One-to-many Mapping + Cycle-Consistencyå¯¹é½è¯„åˆ†**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä¸åŒäºä¼ ç»Ÿpruningæˆ–é‡æ–°ç”Ÿæˆï¼ŒSynCä¸“æ³¨äº**é‡æ–°åˆ†é…captionåˆ°é¢„ç”Ÿæˆå›¾åƒæ± ä¸­æœ€ä½³åŒ¹é…çš„å›¾åƒ**
      - **é—®é¢˜å®šä¹‰**:
        - **ä¼ ç»Ÿone-to-one**: ğ‘†_One(C_i) = {I_i^syn}ï¼ˆæ¯ä¸ªcaptionåªå¯¹åº”ç›´æ¥ç”Ÿæˆçš„å›¾åƒï¼‰
        - **æŒ‘æˆ˜**: T2Iæ¨¡å‹å¸¸ç”Ÿæˆè¯­ä¹‰misalignmentå›¾åƒï¼ˆç¼ºå¤±å¯¹è±¡ã€é”™è¯¯å±æ€§ï¼‰ï¼Œä½†captionæœ¬èº«æ˜¯well-formedçš„
        - **ä¸Webæ•°æ®pruningçš„å·®å¼‚**: Webæ•°æ®æ˜¯"noisy text + clean image"ï¼Œåˆæˆæ•°æ®æ˜¯"clean caption + noisy image"
      - **One-to-many Selection Strategy (ğ‘†_T2I)**:
        - **è¾“å…¥**: Caption C_iï¼Œé¢„ç”Ÿæˆåˆæˆå›¾åƒæ± I^syn
        - **T2I Retrieval**: ä½¿ç”¨VLMï¼ˆSigLIP ViT-B/16ï¼‰çš„æ–‡æœ¬ç¼–ç å™¨E_Tå’Œå›¾åƒç¼–ç å™¨E_I
        - **æ£€ç´¢top-Kå€™é€‰**: ğ‘…_i = Top-K_j { âŸ¨E_I(I_j^syn), E_T(C_i)âŸ© }ï¼ˆK=15ï¼‰
        - **è¾“å‡º**: å€™é€‰é›† {I_r^syn}_râˆˆR_iï¼Œè€Œéä»…I_i^syn
        - **ä¼˜åŠ¿**: å…è®¸captionä»æ•´ä¸ªå›¾åƒæ± ä¸­æ‰¾åˆ°æ›´å¥½åŒ¹é…ï¼Œè€Œéä¸¢å¼ƒmisaligned pairs
      - **Cycle-Consistency Alignment Scoring (ğ‘“_ret)**:
        - **æ ‡å‡†CLIP Scoreå±€é™**: å…¨å±€å¯¹é½ä¼˜å…ˆï¼Œå¿½ç•¥ç»†ç²’åº¦ç»†èŠ‚å’Œç»„åˆç†è§£
        - **Cycle-Consistencyçµæ„Ÿ**: T2Iæ£€ç´¢ï¼ˆé€‰æ‹©ï¼‰ + I2Tæ£€ç´¢ï¼ˆè¯„åˆ†ï¼‰
        - **I2T Retrieval Scoring**:
          1. å¯¹å€™é€‰å›¾åƒI^synæ‰§è¡ŒI2Tæ£€ç´¢ï¼Œä»caption corpus Cä¸­æ£€ç´¢top-K_rç›¸ä¼¼captions
          2. ä½¿ç”¨SBERTï¼ˆSentence Transformerï¼‰è®¡ç®—æ£€ç´¢åˆ°çš„captionsä¸åŸå§‹caption Cçš„æ–‡æœ¬ç›¸ä¼¼åº¦
          3. åˆ†æ•°: ğ‘“_ret(I^syn, C) = max_râˆˆRÌ‚(I^syn) âŸ¨E_S(C_r), E_S(C)âŸ©
        - **æ ¸å¿ƒé€»è¾‘**: å¦‚æœI^synçœŸæ­£å¯¹é½Cï¼Œé‚£ä¹ˆä»I^synæ£€ç´¢å›çš„captionsåº”ä¸Cè¯­ä¹‰ç›¸ä¼¼
        - **æœ€ç»ˆé€‰æ‹©**: I_i^*syn = argmax_{I^synâˆˆS(C_i)} f_ret(I^syn, C_i)
      - **Filtering**: æŒ‰alignment scoreæ’åºï¼Œä¿ç•™top Ï„% pairsï¼ˆÏ„âˆˆ[0,1]ï¼‰
  - **å®éªŒè®¾ç½®**:
      - **åŸºçº¿æ¨¡å‹**: PCM-Netï¼ˆECCV 2024ï¼‰
      - **T2Iæ¨¡å‹**: Stable Diffusion v1.4ï¼ˆ512Ã—512ï¼Œ20 sampling stepsï¼‰
      - **æ£€ç´¢VLM**: SigLIP ViT-B/16@256
      - **æ–‡æœ¬ç¼–ç å™¨**: SBERTï¼ˆunimodal text similarityï¼‰
      - **æ•°æ®æº**: CC3Mã€SS1Mç”Ÿæˆ200Kåˆæˆpairs
  - **å®éªŒç»“æœ** - **é›¶æ ·æœ¬captioningæ˜¾è‘—æå‡**:
      - **COCO Captioning**ï¼ˆViT-B/32ï¼‰:
        - BLEU@4: 31.5 â†’ 33.6 (+2.1)
        - CIDEr: 103.8 â†’ 112.0 (+8.2)
        - SPICE: 19.7 â†’ 20.5 (+0.8)
      - **COCO Captioning**ï¼ˆViT-L/14ï¼‰:
        - BLEU@4: 33.6 â†’ 35.2 (+1.6)
        - CIDEr: 113.6 â†’ 119.8 (+6.2)
        - SPICE: 20.8 â†’ 21.9 (+1.1)
      - **Flickr30k**ï¼ˆViT-L/14ï¼‰:
        - BLEU@4: 28.5 â†’ 29.6 (+1.1)
        - CIDEr: 69.5 â†’ 75.6 (+6.1)
      - **Cross-domain**: COCOâ†’Flickr30kæå‡CIDEr +4.8ï¼ŒFlickr30kâ†’COCOæå‡+5.5
      - **NoCaps** (out-of-domain): Entire CIDEr 70.5 â†’ 72.7 (+2.2)
      - **ä¸€è‡´æ€§**: åœ¨æ‰€æœ‰è®¾ç½®ï¼ˆin-domain, cross-domain, out-of-domainï¼‰ä¸ŠæŒç»­æå‡
  - **æ¶ˆèç ”ç©¶**:
      - **vs. ä¼ ç»Ÿpruningæ–¹æ³•**: SynCè¶…è¶ŠåŸºäºVLMçš„pruningæ–¹æ³•ï¼ˆé¿å…è®¡ç®—å¼€é”€å’Œå…¬å¹³æ€§é—®é¢˜ï¼‰
      - **Kå€¼å½±å“**: K=15è¾¾åˆ°æœ€ä½³å¹³è¡¡
      - **Ï„å€¼**: ä¿ç•™top 80-90% pairsæ•ˆæœæœ€ä¼˜
  - **å¼€æº**: âœ… [GitHub](https://github.com/boreng0817/SynC)
  - **æœºæ„**: Hanyang University + CJ Group
  - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´7æœˆ
  - **é‡è¦æ„ä¹‰**:
      - **é’ˆå¯¹åˆæˆæ•°æ®ç‰¹æ€§**: é¦–ä¸ªä¸“é—¨ä¸º"clean caption + noisy image"è®¾è®¡çš„refinementæ–¹æ³•
      - **æ— éœ€é‡æ–°ç”Ÿæˆ**: é‡ç”¨é¢„ç”Ÿæˆå›¾åƒæ± ï¼Œé™ä½è®¡ç®—æˆæœ¬
      - **Cycle-Consistency**: åŒå‘æ£€ç´¢ä¿è¯ç»†ç²’åº¦å¯¹é½
      - **æ³›åŒ–æ€§å¼º**: è·¨åŸŸã€è·¨æ¨¡å‹ä¸€è‡´æå‡
      - **å®ç”¨æ€§**: ç®€å•æœ‰æ•ˆï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰ZIC pipeline
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2510.27164">ğŸ“„ High-Res Captioning</a></b><br>
<code>arXiv 2510.27164</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
</summary>

  - **èšç„¦**ï¼š**é«˜åˆ†è¾¨ç‡å›¾åƒç²¾ç¡®è¯¦ç»†captionç”Ÿæˆ** - Training-free pipelineï¼Œæ•´åˆVLM+LLM+å¯¹è±¡æ£€æµ‹ç³»ç»Ÿï¼Œè§£å†³VLMä½åˆ†è¾¨ç‡é¢„è®­ç»ƒå¯¼è‡´çš„ç»†èŠ‚ä¸¢å¤±
  - **æ•°æ®åˆæˆæ–¹æ³•** - **äº”é˜¶æ®µCaption Refinement Pipeline**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé€šè¿‡"äººç±»è§†è§‰zoom-in"æœºåˆ¶å’Œå¯¹è±¡æ£€æµ‹éªŒè¯ï¼Œç”Ÿæˆæ›´è¯¦ç»†ã€æ›´å¯é çš„é«˜åˆ†è¾¨ç‡å›¾åƒcaptionï¼ŒåŒæ—¶é™ä½å¹»è§‰
      - **Stage 1ï¼šåˆå§‹Captionç”Ÿæˆ**ï¼š
        - **VLMç”Ÿæˆ**ï¼šä½¿ç”¨VLMï¼ˆInstructBLIP/LLaVA-v1.5/Qwen2-VLï¼‰ç”Ÿæˆåˆå§‹caption
        - **Prompt**ï¼š "Describe this image in detail."
        - **é—®é¢˜**ï¼šVLMé€šå¸¸åœ¨ä½åˆ†è¾¨ç‡é¢„è®­ç»ƒï¼ˆ224Ã—224æˆ–336Ã—336ï¼‰ï¼Œé«˜åˆ†è¾¨ç‡å›¾åƒé™é‡‡æ ·ä¸¢å¤±ç»†èŠ‚
        - **LLMæå–å…³é”®å¯¹è±¡**ï¼šä½¿ç”¨GPT-4oä»åˆå§‹captionä¸­æå–å…³é”®å¯¹è±¡åˆ—è¡¨
      - **Stage 2ï¼šè¯†åˆ«æ½œåœ¨å…±ç°å¯¹è±¡**ï¼š
        - **LLMæ¨ç†**ï¼šåŸºäºå…³é”®å¯¹è±¡ï¼ŒLLMåˆ©ç”¨ä¸–ç•ŒçŸ¥è¯†æ¨æ–­å¯èƒ½å…±åŒå‡ºç°ä½†è¢«é—æ¼çš„å¯¹è±¡
        - **ç¤ºä¾‹**ï¼šè‹¥å…³é”®å¯¹è±¡æ˜¯"table, chair"ï¼ŒLLMæ¨æ–­å¯èƒ½å­˜åœ¨"lamp, books, cup"
        - **è¾“å‡º**ï¼šæ‰©å±•å€™é€‰å¯¹è±¡åˆ—è¡¨ï¼ˆåŸå§‹+æ–°æè®®ï¼‰
      - **Stage 3ï¼šå¯¹è±¡å­˜åœ¨æ€§éªŒè¯**ï¼š
        - **ä¸‰æ£€æµ‹å™¨Ensemble**ï¼šGroundingDINO + YOLO-World + OWLv2
        - **éªŒè¯ç­–ç•¥**ï¼š
          - å¯¹è±¡è¢«æ£€æµ‹ï¼šä¸‰ä¸ªæ£€æµ‹å™¨æ€»ç½®ä¿¡åº¦â‰¥0.5ï¼ˆIoUâ‰¥0.7è§†ä¸ºåŒä¸€å¯¹è±¡ï¼‰
          - å¯¹è±¡æœªæ£€æµ‹ï¼šä»»ä½•æ£€æµ‹å™¨éƒ½æœªæ£€æµ‹åˆ° â†’ ä»åˆå§‹captionä¸­ç§»é™¤ï¼ˆé™ä½å¹»è§‰ï¼‰
        - **è¾“å‡º**ï¼šéªŒè¯å¯¹è±¡åˆ—è¡¨ + è¾¹ç•Œæ¡†åæ ‡
      - **Stage 4ï¼šæ–°å¯¹è±¡è¯¦ç»†Captioningï¼ˆZoom-inæœºåˆ¶ï¼‰**ï¼š
        - **è£å‰ªè¾¹ç•Œæ¡†**ï¼šä¸ºæ–°æ£€æµ‹ä½†åˆå§‹captionæœªæåŠçš„å¯¹è±¡è£å‰ªå›¾åƒåŒºåŸŸ
        - **é‡æ–°Captioning**ï¼šå°†è£å‰ªå›¾åƒè¾“å…¥VLMï¼Œç”Ÿæˆè¯¦ç»†å¯¹è±¡æè¿°
        - **æ¨¡æ‹Ÿäººç±»è§†è§‰**ï¼šç±»ä¼¼äººç±»æ”¾å¤§è§‚å¯Ÿé«˜åˆ†è¾¨ç‡å›¾åƒç»†èŠ‚çš„è¿‡ç¨‹
        - **æ•ˆç‡ä¼˜åŒ–**ï¼šä»…å¯¹åˆå§‹captionç¼ºå¤±çš„å¯¹è±¡æ‰§è¡Œï¼Œå·²æè¿°å¯¹è±¡å‡å®šè¶³å¤Ÿè¯¦ç»†
      - **Stage 5ï¼šæœ€ç»ˆCaptioné‡æ–°æªè¾**ï¼š
        - **GPT-4oæ•´åˆ**ï¼šç»“åˆåˆå§‹caption + éªŒè¯å¯¹è±¡åˆ—è¡¨+åæ ‡ + æ–°è¯¦ç»†æè¿°
        - **åŒé‡ç›®æ ‡**ï¼š
          1. **ç§»é™¤å¹»è§‰**ï¼šåˆ é™¤æœªæ£€æµ‹å¯¹è±¡çš„å¼•ç”¨
          2. **æ·»åŠ æ–°ä¿¡æ¯**ï¼šæ•´åˆæ–°æ£€æµ‹å¯¹è±¡çš„è¯¦ç»†æè¿°å’Œç©ºé—´ä¸Šä¸‹æ–‡
        - **ç©ºé—´ä¸Šä¸‹æ–‡**ï¼šä½¿ç”¨ç›¸å¯¹ä½ç½®ï¼ˆ"on the left", "in the foreground", "near the center"ï¼‰
        - **æ ¼å¼**ï¼š{label}: {caption} at coordinates (x_min, y_min, x_max, y_max)
        - **è‡ªç„¶æµç•…**ï¼šæ•´ä½“é‡æ–°æªè¾è€Œéç®€å•æ‹¼æ¥ï¼Œä¿æŒè¯­ä¹‰è¿è´¯æ€§
  - **å®éªŒè®¾ç½®**ï¼š
      - **VLMs**ï¼šInstructBLIPï¼ˆ224Ã—224ï¼‰ã€LLaVA-v1.5ï¼ˆ336Ã—336ï¼‰ã€Qwen2-VLï¼ˆåŠ¨æ€åˆ†è¾¨ç‡ï¼‰
      - **LLM**ï¼šGPT-4oï¼ˆæå–ã€æ¨ç†ã€é‡æ–°æªè¾ï¼‰
      - **æ£€æµ‹å™¨**ï¼šGroundingDINO, YOLO-World, OWLv2ï¼ˆå¼€æ”¾è¯æ±‡ï¼‰
      - **è¯„ä¼°æ¨¡å‹**ï¼šLLaMA-3.2-Vision-Instructï¼ˆ1120Ã—1120ï¼Œreference-freeè¯„ä¼°ï¼‰
      - **æ•°æ®é›†**ï¼šObjects365ä¸­ç­›é€‰çš„266å¼ 4Kå›¾åƒï¼ˆ3840Ã—2160ï¼‰ï¼Œæ ‡å‡†ï¼šâ‰¥15ç±»å¯¹è±¡ã€â‰¥10å°å¯¹è±¡ã€â‰¥5äºº
  - **å®éªŒç»“æœ** - **Captionè´¨é‡ä¸å¹»è§‰åŒé‡æå‡**ï¼š
      - **Pairwiseæ¯”è¾ƒï¼ˆWinning Rateï¼‰**ï¼š
        - InstructBLIP: ~55% winning rateï¼ˆvs. åˆå§‹captionï¼‰
        - LLaVA-v1.5: ~58% winning rate
        - Qwen2-VL: ~52% winning rateï¼ˆå·²è¾ƒå¼ºä½†ä»æœ‰æå‡ï¼‰
      - **å®šé‡è¯„åˆ†ï¼ˆ0-1èŒƒå›´ï¼Œ5æ¬¡å®éªŒå¹³å‡ï¼‰**ï¼š
        - InstructBLIP: 0.6344 â†’ 0.6952 (**+9.59%**)
        - LLaVA-v1.5: 0.6785 â†’ 0.7304 (**+7.66%**)
        - Qwen2-VL: 0.8260 â†’ 0.8398 (**+1.68%**ï¼ŒåŠ¨æ€åˆ†è¾¨ç‡å·²è¾ƒrobustï¼‰
      - **POPEå¹»è§‰åŸºå‡†ï¼ˆAccuracy/Precision/Recall/F1ï¼Œå¹³å‡æå‡ï¼‰**ï¼š
        - **Randomé‡‡æ ·**ï¼š
          - InstructBLIP: Acc +4.87%, Prec +24.16%, Recall +50.15%, F1 **+45.10%**
          - LLaVA-v1.5: Acc +5.30%, Prec +22.23%, Recall +24.31%, F1 +23.88%
          - Qwen2-VL: Acc +2.62%, Prec +13.70%, Recall +24.90%, F1 +22.97%
        - **Popularé‡‡æ ·**ï¼š
          - InstructBLIP: F1 +28.71%, LLaVA-v1.5: F1 +20.32%, Qwen2-VL: F1 +23.84%
        - **Adversarialé‡‡æ ·**ï¼š
          - InstructBLIP: F1 +28.85%, LLaVA-v1.5: F1 +20.59%, Qwen2-VL: F1 **+29.44%**
      - **ä¸€è‡´æ€§**ï¼šå¯¹é¢„è®­ç»ƒåˆ†è¾¨ç‡è¾ƒä½çš„VLMæå‡æ›´æ˜¾è‘—ï¼Œè¯æ˜æ–¹æ³•é’ˆå¯¹"resolution curse"çš„æœ‰æ•ˆæ€§
  - **å¼€æº**ï¼šâœ… ï¼ˆè®ºæ–‡æ‰¿è¯ºå‘å¸ƒä»£ç å’Œpromptsï¼‰
  - **æœºæ„**ï¼šUniversity of Seoul + POSTECH + Yonsei University
  - **å‘å¸ƒæ—¶é—´**ï¼šarXiv 2025å¹´10æœˆ
  - **é‡è¦æ„ä¹‰**ï¼š
      - **æ— éœ€é‡æ–°è®­ç»ƒ**ï¼šTraining-free pipelineï¼Œé€‚ç”¨äºä»»ä½•VLM
      - **äººç±»è§†è§‰æ¨¡æ‹Ÿ**ï¼šZoom-inæœºåˆ¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¨¡æ‹Ÿäººç±»è§‚å¯Ÿé«˜åˆ†è¾¨ç‡å›¾åƒçš„è¿‡ç¨‹
      - **åŒé‡ä¼˜åŒ–**ï¼šåŒæ—¶æå‡captionè¯¦ç»†åº¦ï¼ˆæ–°å¯¹è±¡ï¼‰å’Œå‡†ç¡®æ€§ï¼ˆç§»é™¤å¹»è§‰ï¼‰
      - **Ensembleæ£€æµ‹**ï¼šä¸‰æ£€æµ‹å™¨ensembleé™ä½å•æ¨¡å‹åå·®ï¼Œæå‡éªŒè¯å¯é æ€§
      - **é«˜åˆ†è¾¨ç‡é’ˆå¯¹æ€§**ï¼šæ˜ç¡®è§£å†³VLMåœ¨4K/é«˜åˆ†è¾¨ç‡å›¾åƒä¸Šçš„æ€§èƒ½é€€åŒ–é—®é¢˜
      - **å·¥ä½œæµé€šç”¨**ï¼šå¯æ‰©å±•è‡³å¤šæ¨¡æ€æ£€ç´¢ã€T2Iç”Ÿæˆã€VQAç­‰ä¸‹æ¸¸ä»»åŠ¡
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=LLaVAR">ğŸ“„ LLaVAR</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Section 3.2):
      - Targets text-rich images (documents, posters, charts, etc.)
      - Uses **GPT-4** to generate instruction Q&A pairs based on OCR results
      - Generates "understanding + reasoning" type questions (not just reading text)
  - **Data Scale**: 422K instruction data
  - **Open Source**: âœ… [Code](https://github.com/SALT-NLP/LLaVAR)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=ALLaVA">ğŸ“„ ALLaVA</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Abstract explicitly describes):
      - **Captioning-then-QA paradigm**: Two-stage data generation
      - Uses **GPT-4V** to generate two types of data:
        a) **Fine-grained image annotations** for vision-language alignment
        b) **Complex reasoning visual QA pairs** for visual instruction fine-tuning
      - Complete data generation pipeline, utilizing powerful proprietary models to synthesize high-quality data
  - **Data Scale**: 1.3M samples
  - **Experimental Results**: Achieves competitive performance among 4B models, even on par with 7B/13B models on various benchmarks
  - **Open Source**: âœ… Dataset open-sourced (mentioned in paper)
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=COGS">ğŸ“„ COGS</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Abstract explicitly describes):
      - **Composition-Grounded Instruction Synthesis**
      - Starts from **small set of seed questions**, generates large-scale data through decomposition-recomposition:
        a) **Decompose**: Breaks seed questions into primitive perception and reasoning factors
        b) **Recompose**: Systematically recombines factors with new images
        c) **Generate**: Creates large collections of synthetic Q&A pairs, each paired with subquestions and intermediate answers
      - Supports reinforcement learning with factor-level process rewards
  - **Application Domains**: Charts, webpages, rendered documents, and other artificial image domains
  - **Experimental Results**: Substantial improvements on unseen questions, largest gains on reasoning-heavy and compositional questions, good transfer across datasets
  - **Publication**: arXiv October 2025
  - **Institution**: MIT, IBM Research, etc.
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2402.12226">ğŸ“„ AnyGPT</a></b><br>
<code>arXiv 2402.12226</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-å¤æ—¦å¤§å­¦-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **Any-to-Anyå¤šæ¨¡æ€å¯¹è¯æ•°æ®åˆæˆ** - ä½¿ç”¨ç”Ÿæˆæ¨¡å‹åˆ›å»ºå¤§è§„æ¨¡ä»»æ„æ¨¡æ€åˆ°ä»»æ„æ¨¡æ€ï¼ˆæ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒã€éŸ³ä¹ï¼‰çš„å¤šè½®å¯¹è¯æ•°æ®é›†
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ä¸¤é˜¶æ®µGPT-4å¼•å¯¼ + å¤šæ¨¡æ€ç”ŸæˆPipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªå¤§è§„æ¨¡any-to-anyå¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®é›†ï¼Œä½¿ç”¨ç¦»æ•£è¡¨ç¤ºç»Ÿä¸€å¤„ç†å¤šç§æ¨¡æ€ï¼Œé€šè¿‡ç”Ÿæˆæ¨¡å‹è‡ªåŠ¨æ„å»ºäº¤ç»‡å¤šæ¨¡æ€å…ƒç´ çš„å¯¹è¯
      - **é—®é¢˜è¯†åˆ«**:
        - ç¼ºä¹å¤§è§„æ¨¡å¤šæ¨¡æ€äº¤ç»‡æŒ‡ä»¤è·Ÿéšæ•°æ®
        - ç°æœ‰æ•°æ®é›†æ¨¡æ€ç»„åˆæœ‰é™ï¼ˆé€šå¸¸åªæœ‰å›¾åƒ+æ–‡æœ¬ï¼‰
        - ç¼ºå°‘éŸ³é¢‘æ¨¡æ€ï¼ˆè¯­éŸ³ã€éŸ³ä¹ï¼‰çš„å¤šæ¨¡æ€å¯¹è¯æ•°æ®
      - **ä¸¤é˜¶æ®µæ•°æ®æ„å»ºPipelineï¼ˆAnyInstruct-108kï¼‰**:
        1. **æ–‡æœ¬å¯¹è¯ç”Ÿæˆé˜¶æ®µï¼ˆStage 1ï¼‰**:
           - **è¯é¢˜æ± æ„å»º**:
             - å‡†å¤‡100ä¸ªå…ƒè¯é¢˜ï¼ˆmeta topicsï¼‰
             - ä½¿ç”¨GPT-4å¯¹æ¯ä¸ªå…ƒè¯é¢˜ç”Ÿæˆ200ä¸ªå…·ä½“è¯é¢˜ï¼ˆ4è½®brainstormingï¼‰
             - æ€»å…±20,000ä¸ªè¯é¢˜æ¶µç›–å¤šä¸ªé¢†åŸŸ
           - **åœºæ™¯æ„å»º**:
             - åŸºäºè¯é¢˜ï¼ŒGPT-4ç”Ÿæˆå¯¹è¯åœºæ™¯æè¿°
             - åœºæ™¯è¦æ±‚ï¼šç”¨æˆ·ä¸èŠå¤©æœºå™¨äººä¹‹é—´çš„éå­¦æœ¯å¯¹è¯
             - å¯¹è¯ä¸­å¯ä»¥ä½¿ç”¨å›¾åƒæˆ–éŸ³ä¹ä¼ è¾¾ä¿¡æ¯ï¼ˆä¸åŒ…æ‹¬è§†é¢‘ï¼‰
             - å›¾åƒä¸èƒ½æ˜¯å›¾è¡¨æˆ–åä½œï¼ˆé¿å…ç‰ˆæƒé—®é¢˜ï¼‰
           - **å¯¹è¯ç”Ÿæˆ**:
             - ä½¿ç”¨GPT-4åŸºäºåœºæ™¯ç”Ÿæˆå¤šè½®å¯¹è¯æ–‡æœ¬
             - å¯¹è¯æ ¼å¼ï¼šç”¨æˆ·å’ŒAnyGPTäº¤æ›¿å‘è¨€
             - å¤šæ¨¡æ€å…ƒç´ ä»¥æ–‡æœ¬æè¿°å½¢å¼åµŒå…¥ï¼š`[image: description]`, `[music: description]`
             - çº¦æŸæ¡ä»¶ï¼š
               - æ¯ä¸ªutterance 5-15ä¸ªè¯ï¼Œç®€æ´æ˜äº†
               - ç”¨æˆ·utteranceå¿…é¡»æ˜¯é—®é¢˜æˆ–æŒ‡ä»¤
               - å¯¹è¯ä¿æŒ2-3è½®
               - æ¯ä¸ªå¯¹è¯åŒ…å«1ä¸ªéŸ³ä¹ï¼Œæœ€å¤š2ä¸ªå›¾åƒ
             - éŸ³ä¹æè¿°è¦æ±‚ï¼šèšç„¦æµæ´¾ã€é£æ ¼ã€ä¹å™¨ï¼Œé¿å…æåŠå…·ä½“æ›²ç›®
        2. **æ–‡æœ¬åˆ°å¤šæ¨¡æ€è½¬æ¢é˜¶æ®µï¼ˆStage 2ï¼‰**:
           - **å›¾åƒåˆæˆ**:
             - æ¨¡å‹ï¼š**Stable Diffusion XL (SDXL)**
             - è¾“å…¥ï¼šå¯¹è¯ä¸­çš„å›¾åƒæè¿°æ–‡æœ¬`[image: description]`
             - è¾“å‡ºï¼šé«˜è´¨é‡åˆæˆå›¾åƒ
             - æ›¿æ¢å¯¹è¯ä¸­çš„æ–‡æœ¬æè¿°ä¸ºå®é™…å›¾åƒ
           - **éŸ³ä¹åˆæˆ**:
             - æ¨¡å‹ï¼š**MusicGen**
             - è¾“å…¥ï¼šå¯¹è¯ä¸­çš„éŸ³ä¹æè¿°æ–‡æœ¬`[music: description]`
             - è¾“å‡ºï¼š5ç§’éŸ³é¢‘ç‰‡æ®µ
             - æ›¿æ¢å¯¹è¯ä¸­çš„æ–‡æœ¬æè¿°ä¸ºå®é™…éŸ³ä¹
           - **è¯­éŸ³åˆæˆ**:
             - æ¨¡å‹ï¼š**Azure Text-to-Speech API (Microsoft)**
             - è¾“å…¥ï¼šç”¨æˆ·æŒ‡ä»¤å’Œæ¨¡å‹çš„æ–‡æœ¬å›å¤
             - è¾“å‡ºï¼šè‡ªç„¶è¯­éŸ³
             - ä¸ºå¯¹è¯æ·»åŠ è¯­éŸ³æ¨¡æ€
           - **è´¨é‡è¿‡æ»¤**:
             - è¿‡æ»¤ä½è´¨é‡ç”Ÿæˆç»“æœ
             - ç¡®ä¿å›¾åƒ-æ–‡æœ¬å¯¹é½ã€éŸ³ä¹-æè¿°åŒ¹é…
        3. **é¢å¤–è¯­éŸ³å¯¹è¯å¢å¼º**:
           - ä»ç°æœ‰çº¯æ–‡æœ¬æŒ‡ä»¤æ•°æ®é›†ä¸­æå–é€‚åˆå£è¯­å™è¿°çš„å¯¹è¯
           - ä½¿ç”¨TTSæ¨¡å‹è½¬æ¢ä¸º100Kè¯­éŸ³å¯¹è¯
           - å¢å¼ºè¯­éŸ³æ¨¡æ€æ•°æ®è§„æ¨¡
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å®Œå…¨åˆæˆ**: æ‰€æœ‰è§†è§‰å’ŒéŸ³é¢‘å†…å®¹å‡ç”±ç”Ÿæˆæ¨¡å‹åˆ›å»ºï¼Œæ— éœ€äººå·¥æ ‡æ³¨
        - **æ¨¡æ€å¤šæ ·æ€§**: åŒæ—¶åŒ…å«æ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³ã€éŸ³ä¹å››ç§æ¨¡æ€
        - **ä»»æ„ç»„åˆ**: æ”¯æŒä»»æ„æ¨¡æ€è¾“å…¥åˆ°ä»»æ„æ¨¡æ€è¾“å‡ºçš„å¯¹è¯
        - **è‡ªåŠ¨åŒ–**: GPT-4å¼•å¯¼çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ç”Ÿæˆæµç¨‹
        - **å¯æ‰©å±•æ€§**: è¯é¢˜æ± å’Œåœºæ™¯å¯çµæ´»æ‰©å±•ï¼Œç”Ÿæˆæ¨¡å‹å¯æ›¿æ¢
  - **AnyInstruct-108kæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 108Kå¤šè½®å¤šæ¨¡æ€å¯¹è¯
      - **å¤šæ¨¡æ€å…ƒç´ ç»Ÿè®¡**:
        - å›¾åƒï¼š205Kå¼ åˆæˆå›¾åƒ
        - è¯­éŸ³ï¼š503Kè¯­éŸ³å½•éŸ³
        - éŸ³ä¹ï¼š113KéŸ³ä¹ç‰‡æ®µ
      - **å¯¹è¯ç‰¹ç‚¹**:
        - å¤šè½®äº¤äº’ï¼ˆ2-3è½®ï¼‰
        - äº¤ç»‡å¤šç§æ¨¡æ€ï¼ˆæ–‡æœ¬+å›¾åƒ+è¯­éŸ³+éŸ³ä¹ï¼‰
        - ä»»æ„æ¨¡æ€ç»„åˆï¼ˆå¦‚ï¼šè¯­éŸ³æŒ‡ä»¤+å›¾åƒ â†’ æ–‡æœ¬+éŸ³ä¹+è¯­éŸ³å›å¤ï¼‰
      - **è¯é¢˜è¦†ç›–**: æ¶µç›–æ¸¸æˆã€ç¯å¢ƒã€è‰ºæœ¯ã€ç§‘æŠ€ã€ç”Ÿæ´»ç­‰å¤šä¸ªé¢†åŸŸ
  - **AnyGPTæ¨¡å‹**:
      - **æ¶æ„**:
        - åŸºç¡€ï¼šLLaMA-2 7B
        - å¤šæ¨¡æ€Tokenizersï¼šSEEDï¼ˆå›¾åƒï¼‰ã€SpeechTokenizerï¼ˆè¯­éŸ³ï¼‰ã€MusicTokenizerï¼ˆéŸ³ä¹ï¼‰
        - ç»Ÿä¸€è¯æ±‡è¡¨ï¼šå°†æ‰€æœ‰æ¨¡æ€è½¬æ¢ä¸ºç¦»æ•£tokens
      - **è®­ç»ƒ**:
        - é¢„è®­ç»ƒï¼šå¤šæ¨¡æ€å¯¹é½ï¼ˆå›¾åƒ-æ–‡æœ¬ã€è¯­éŸ³-æ–‡æœ¬ã€éŸ³ä¹-æ–‡æœ¬ï¼‰
        - æŒ‡ä»¤å¾®è°ƒï¼šåœ¨AnyInstruct-108kä¸Šå¾®è°ƒ
      - **èƒ½åŠ›**: ä»»æ„æ¨¡æ€è¾“å…¥åˆ°ä»»æ„æ¨¡æ€è¾“å‡ºçš„å¯¹è¯ç”Ÿæˆ
  - **å®éªŒç»“æœ** - **é›¶æ ·æœ¬æ€§èƒ½æ¥è¿‘ä¸“ç”¨æ¨¡å‹**:
      - **å›¾åƒç†è§£**:
        - MS-COCO Captioning: CIDEr **82.3**ï¼ˆæ¥è¿‘Flamingo-9Bçš„79.4ï¼‰
      - **å›¾åƒç”Ÿæˆ**:
        - MS-COCO Text-to-Image: CLIPScore **0.65**ï¼ˆä¸SEED-LLaMAç›¸å½“ï¼‰
      - **è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰**:
        - LibriSpeech: WER **8.5**ï¼ˆæ¥è¿‘äººç±»æ°´å¹³5.8ï¼Œä¸“ç”¨æ¨¡å‹2.7ï¼‰
      - **è¯­éŸ³åˆæˆï¼ˆTTSï¼‰**:
        - VCTK: WER **8.5**, Speaker Similarity **0.77**
      - **éŸ³ä¹ç†è§£ä¸ç”Ÿæˆ**:
        - MusicCaps: CLAPScore **0.11**ï¼ˆéŸ³ä¹ç†è§£ï¼‰ã€**0.14**ï¼ˆéŸ³ä¹ç”Ÿæˆï¼‰
      - **Any-to-Anyå¯¹è¯**: æˆåŠŸå¤„ç†ä»»æ„æ¨¡æ€ç»„åˆçš„è¾“å…¥å’Œè¾“å‡ºï¼Œå±•ç¤ºæµç•…çš„å¤šæ¨¡æ€äº¤äº’èƒ½åŠ›
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - ç¦»æ•£è¡¨ç¤ºèƒ½æœ‰æ•ˆç»Ÿä¸€å¤šç§æ¨¡æ€
      - å¤šæ¨¡æ€é¢„è®­ç»ƒå¯¹é½è‡³å…³é‡è¦
      - AnyInstruct-108kæ˜¾è‘—æå‡any-to-anyå¯¹è¯èƒ½åŠ›
  - **æœºæ„**: å¤æ—¦å¤§å­¦ã€Multimodal Art Projection Research Communityã€ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤
  - **ä½œè€…**: Jun Zhan, Junqi Dai, Jiasheng Ye, Yunhua Zhou, Dong Zhang, Zhigeng Liu, Xin Zhang, Ruibin Yuan, Ge Zhang, Linyang Li, Hang Yan, Jie Fu, Tao Gui, Tianxiang Sun, Yu-Gang Jiang, Xipeng Qiu
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´2æœˆï¼ˆv5ï¼‰
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2402.12226](https://arxiv.org/abs/2402.12226)
  - **å¼€æº**: âœ… [é¡¹ç›®ä¸»é¡µ](https://junzhan2000.github.io/AnyGPT.github.io/)
  - **æ„ä¹‰**:
      - **æ•°æ®è´¡çŒ®**: é¦–ä¸ªå¤§è§„æ¨¡any-to-anyå¤šæ¨¡æ€æŒ‡ä»¤æ•°æ®é›†ï¼Œå¡«è¡¥éŸ³é¢‘æ¨¡æ€å¯¹è¯æ•°æ®ç©ºç™½
      - **ç”Ÿæˆå¼æ–¹æ³•**: ä½¿ç”¨ç”Ÿæˆæ¨¡å‹åˆ›å»ºå®Œå…¨åˆæˆçš„å¤šæ¨¡æ€å¯¹è¯æ•°æ®ï¼Œé¿å…éšç§å’Œç‰ˆæƒé—®é¢˜
      - **æ¨¡æ€ç»Ÿä¸€**: è¯æ˜ç¦»æ•£è¡¨ç¤ºå¯ä»¥æœ‰æ•ˆç»Ÿä¸€å¤šç§æ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³ã€éŸ³ä¹ï¼‰
      - **å¯æ‰©å±•æ€§**: ä¸¤é˜¶æ®µpipelineå¯è½»æ¾æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€æˆ–æ›´å¤§è§„æ¨¡
      - **é›¶æ ·æœ¬èƒ½åŠ›**: è¯æ˜åœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å¯ä»¥è·å¾—æ¥è¿‘ä¸“ç”¨æ¨¡å‹çš„é›¶æ ·æœ¬æ€§èƒ½
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2403.03194">ğŸ“„ MAGID</a></b><br>
<code>arXiv 2403.03194</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤šæ¨¡æ€å¯¹è¯æ•°æ®è‡ªåŠ¨ç”Ÿæˆ** - å°†text-onlyå¯¹è¯è‡ªåŠ¨å¢å¼ºä¸ºå¤šæ¨¡æ€å¯¹è¯ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰
  - **é—®é¢˜èƒŒæ™¯**:
      - **ç°æœ‰æ–¹æ³•å±€é™**: æ£€ç´¢å¼æ–¹æ³•ï¼ˆä»å›ºå®šå›¾åƒåº“æ£€ç´¢ï¼‰å¯¼è‡´å›¾åƒå¤šæ ·æ€§å—é™ã€åŒ¹é…åº¦ä½
      - **æ•°æ®ç¨€ç¼º**: å¤šæ¨¡æ€å¯¹è¯æ•°æ®éš¾ä»¥è·å–ï¼Œéšç§å’Œè´¨é‡é—®é¢˜ä¸¥é‡
      - **å•å›¾é™åˆ¶**: ç°æœ‰æ•°æ®é›†é€šå¸¸æ¯å¯¹è¯åªæœ‰ä¸€å¼ å›¾åƒ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ç”Ÿæˆå¼å¤šæ¨¡æ€å¯¹è¯Pipeline + è´¨é‡ä¿è¯æ¨¡å—**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä»text-onlyå¯¹è¯å‡ºå‘ï¼Œä½¿ç”¨LLMè¯†åˆ«éœ€è¦å›¾åƒçš„utterancesï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œé…åˆåé¦ˆå¾ªç¯ç¡®ä¿è´¨é‡
      - **ä¸‰å¤§æ ¸å¿ƒæ¨¡å—**:
        1. **LLM-based Scannerï¼ˆæ‰«æå™¨ï¼‰**:
           - **ä»»åŠ¡**: è¯†åˆ«å¯¹è¯ä¸­éœ€è¦å›¾åƒçš„utterancesï¼Œå¹¶ç”Ÿæˆå›¾åƒæè¿°
           - **è¾“å…¥**: Text-onlyå¯¹è¯
           - **è¾“å‡º**: é€‰å®šçš„utterances + å¯¹åº”çš„å›¾åƒæè¿°
           - **Promptå·¥ç¨‹**: æµ‹è¯•ä¸‰ç§ç­–ç•¥
             - **Zero-shot**: ä»…æä¾›æ ¼å¼å’Œé—®é¢˜æè¿°
             - **Few-shot**: æä¾›è¾“å…¥-è¾“å‡ºç¤ºä¾‹
             - **Chain-of-Thought (CoT)**: æä¾›æ¨ç†æ­¥éª¤ï¼ˆæœ€ä¼˜é€‰æ‹©ï¼‰
           - **è¾“å‡ºæ ¼å¼æ§åˆ¶**: ä½¿ç”¨HTML-likeæ ‡ç­¾ï¼ˆ`<result>` å’Œ `<reason>`ï¼‰ç»“æ„åŒ–è¾“å‡º
           - **å…³é”®**: CoTæä¾›å¯è°ƒè¯•çš„æ¨ç†è·¯å¾„ï¼Œé¿å…ä¸Šä¸‹æ–‡ä¸ä¸€è‡´ï¼ˆå¦‚"give it a look"ç”Ÿæˆæ— æ„ä¹‰å›¾åƒï¼‰
        2. **Diffusion-based Image Generatorï¼ˆå›¾åƒç”Ÿæˆå™¨ï¼‰**:
           - **æ¨¡å‹é€‰æ‹©**: Stable Diffusion XL 1.0ï¼ˆSDXLï¼‰
           - **ä¼˜åŠ¿**: åœ¨æ•°åäº¿å›¾åƒä¸Šè®­ç»ƒï¼Œç”Ÿæˆå¤šæ ·åŒ–ã€é«˜è´¨é‡å›¾åƒ
           - **è¾“å…¥**: LLMç”Ÿæˆçš„å›¾åƒæè¿°
           - **è¾“å‡º**: åˆæˆå›¾åƒ
           - **å…³é”®**: è¶…è¶Šæ£€ç´¢å¼æ–¹æ³•çš„å¤šæ ·æ€§ç“¶é¢ˆ
        3. **Quality Assurance Moduleï¼ˆè´¨é‡ä¿è¯æ¨¡å—ï¼‰**:
           - **ä¸‰å¤§è¯„ä¼°ç»´åº¦**:
             a) **Image-Text Matchingï¼ˆå›¾æ–‡åŒ¹é…ï¼‰**:
                - ä½¿ç”¨CLIP scoreéªŒè¯å›¾åƒä¸utteranceçš„åŒ¹é…åº¦
                - ä½åˆ†è§¦å‘é‡æ–°ç”Ÿæˆï¼ˆæœ€å¤š2æ¬¡ï¼‰
             b) **Image Qualityï¼ˆå›¾åƒè´¨é‡ï¼‰**:
                - ä½¿ç”¨aesthetic scoreï¼ˆåŸºäºCLIP embedding + MLPï¼‰
                - æ£€æµ‹æ‰©æ•£æ¨¡å‹artifacts
                - é˜ˆå€¼ï¼š0.51ï¼ˆæœ‰æ•ˆæ£€æµ‹å¤§éƒ¨åˆ†artifactsï¼‰
             c) **Image Safetyï¼ˆå›¾åƒå®‰å…¨ï¼‰**:
                - NSFWå†…å®¹æ£€æµ‹
                - æ•°æ®é›†ä¸­æå°‘å‘ç°ä¸å®‰å…¨å›¾åƒï¼ŒéªŒè¯pipelineå¯é æ€§
           - **åé¦ˆå¾ªç¯**: è‹¥å›¾åƒä¸æ»¡è¶³æ ‡å‡†ï¼Œå›åˆ°LLMé‡æ–°ç”Ÿæˆå›¾åƒæè¿°
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç”Ÿæˆå¼è€Œéæ£€ç´¢å¼**: å›¾åƒå¤šæ ·æ€§ä¸å—é™äºå›¾åƒåº“å¤§å°
        - **è‡ªåŠ¨åŒ–**: å®Œå…¨è‡ªåŠ¨åŒ–pipelineï¼Œæ— éœ€äººå·¥æ ‡æ³¨
        - **è´¨é‡ä¿è¯**: å¤šç»´åº¦è´¨é‡æ§åˆ¶ç¡®ä¿æ•°æ®å¯ç”¨æ€§
        - **å¤šå›¾åƒæ”¯æŒ**: ä¸é™åˆ¶æ¯å¯¹è¯åªæœ‰ä¸€å¼ å›¾åƒ
        - **éšç§å‹å¥½**: ä¸ä¾èµ–çœŸå®ç”¨æˆ·æ•°æ®
  - **æ•°æ®è§„æ¨¡**:
      - **MAGIDæ•°æ®é›†**: Medium-sized datasetï¼ˆè®ºæ–‡ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼‰
      - **æ¥æº**: Text-onlyå¯¹è¯æ•°æ®é›†ï¼ˆå¦‚DailyDialogç­‰ï¼‰
  - **å®éªŒç»“æœ** - **è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°**:
      - **å®šé‡è¯„ä¼°**:
        - åœ¨3ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šä¸SOTA baselineså¯¹æ¯”
        - ä½¿ç”¨è‡ªåŠ¨æŒ‡æ ‡ï¼ˆCLIP scoreã€FIDç­‰ï¼‰
      - **äººå·¥è¯„ä¼°**:
        - MAGIDæ˜¾è‘—ä¼˜äºæ£€ç´¢å¼baselineï¼ˆç‰¹åˆ«æ˜¯å›¾åƒåº“å°æ—¶ï¼‰
        - å›¾åƒ-å¯¹è¯ä¸€è‡´æ€§è¯„åˆ†é«˜
        - å›¾åƒè´¨é‡å’Œå¤šæ ·æ€§è·å¾—é«˜åˆ†
      - **æ¶ˆèç ”ç©¶**:
        - CoT promptingä¼˜äºzero-shotå’Œfew-shot
        - è´¨é‡ä¿è¯æ¨¡å—å¯¹æœ€ç»ˆæ•°æ®è´¨é‡è‡³å…³é‡è¦
        - åé¦ˆå¾ªç¯æœ‰æ•ˆæå‡å›¾åƒ-æ–‡æœ¬å¯¹é½
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´3æœˆ
  - **æœºæ„**: AWS AI Labs, University of Waterloo
  - **ä½œè€…**: Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Guptaç­‰
  - **å¼€æº**: âœ… [ä»£ç ](https://github.com/amazon-science/MAGID)
  - **é‡è¦æ„ä¹‰**:
      - **èŒƒå¼è½¬å˜**: ä»æ£€ç´¢å¼åˆ°ç”Ÿæˆå¼å¤šæ¨¡æ€å¯¹è¯æ•°æ®æ„å»º
      - **è´¨é‡ä¿è¯è®¾è®¡**: å¤šç»´åº¦è´¨é‡æ§åˆ¶+åé¦ˆå¾ªç¯çš„ç³»ç»ŸåŒ–è®¾è®¡
      - **è§£å†³å®é™…æŒ‘æˆ˜**: åº”å¯¹éšç§ã€å¤šæ ·æ€§ã€è´¨é‡ä¸‰å¤§æŒ‘æˆ˜
      - **å¯æ‰©å±•æ€§**: è‡ªåŠ¨åŒ–pipelineæ˜“äºæ‰©å±•åˆ°å¤§è§„æ¨¡
      - **å¤šå›¾åƒå¯¹è¯**: æ”¯æŒper conversationå¤šå¼ å›¾åƒï¼Œæ›´è´´è¿‘çœŸå®åœºæ™¯
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2412.14475">ğŸ“„ MegaPairs</a></b><br>
<code>arXiv 2412.14475</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **é€šç”¨å¤šæ¨¡æ€æ£€ç´¢å™¨çš„å¤§è§„æ¨¡æ•°æ®åˆæˆ** - åˆ©ç”¨å¼‚æ„KNNä¸‰å…ƒç»„å’Œå¼€æ”¾æŒ‡ä»¤ç”Ÿæˆå®ç°å¯æ‰©å±•çš„å¤šæ¨¡æ€æ£€ç´¢è®­ç»ƒæ•°æ®æ„å»º
  - **æ•°æ®åˆæˆæ–¹æ³•** - **å¼‚æ„ç›¸ä¼¼æ€§æŒ–æ˜ + MLLM/LLMæ ‡æ³¨Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: ä½¿ç”¨**å¤šç§ç›¸ä¼¼æ€§æ¨¡å‹**ä»å¼€æ”¾åŸŸå›¾åƒè¯­æ–™ä¸­æŒ–æ˜å¤šæ ·åŒ–å›¾åƒå¯¹ï¼Œé…åˆMLLM/LLMç”Ÿæˆå¼€æ”¾å¼æ£€ç´¢æŒ‡ä»¤
      - **ä¸¤é˜¶æ®µPipeline**:
        1. **å¼‚æ„å›¾åƒå¯¹æŒ–æ˜**ï¼ˆå¤šæ ·æ€§å…³é”®ï¼‰:
           - **ä¸‰ç±»ç›¸ä¼¼æ€§æ¨¡å‹å¹¶è¡Œæ£€ç´¢**:
             - a) **è§†è§‰-è¯­ä¹‰ç›¸å…³æ€§**ï¼ˆEVA-CLIPå›¾åƒç¼–ç å™¨ï¼‰: æ•è·è¯­ä¹‰ç›¸å…³æ€§ï¼Œå¿½ç•¥è§†è§‰ç›¸ä¼¼æ€§ï¼ˆå¦‚åŒä¸€æ±½è½¦çš„ä¸åŒè§†è§’ï¼‰
             - b) **è§†è§‰-æ¨¡å¼ç›¸å…³æ€§**ï¼ˆDINOv2ï¼‰: æ•è·è§†è§‰ç›¸ä¼¼æ€§ï¼Œå¿½ç•¥è¯­ä¹‰ç›¸å…³æ€§ï¼ˆå¦‚ç›¸ä¼¼èƒŒæ™¯ä¸­çš„ä¸åŒæ±½è½¦ï¼‰
             - c) **Captionç›¸å…³æ€§**ï¼ˆEVA-CLIPæ–‡æœ¬ç¼–ç å™¨ï¼‰: åŸºäºå›¾åƒé…å¯¹captionçš„æ–‡æœ¬ç›¸ä¼¼æ€§
           - **ç›¸ä¼¼åº¦è¿‡æ»¤**: ä¿ç•™åˆ†æ•°åœ¨(0.8, 0.96)åŒºé—´çš„å›¾åƒå¯¹ï¼Œæ¶ˆé™¤å¼±å…³è”å’Œè¿‘é‡å¤
           - **ç¡¬è´Ÿæ ·æœ¬**: ä»æ£€ç´¢é›†åˆä¸­è‡ªåŠ¨å¼•å…¥ç¡¬è´Ÿæ ·æœ¬ï¼ˆå…¶ä»–æ£€ç´¢åˆ°çš„éç›®æ ‡å›¾åƒï¼‰
           - **è§„æ¨¡**: ä»RecapDataComp-1Bçš„2000ä¸‡å›¾åƒå­é›†ä¸­æŒ–æ˜å…³ç³»
        2. **å¼€æ”¾å¼æŒ‡ä»¤ç”Ÿæˆ**ï¼ˆåŸºäºMLLM/LLMï¼‰:
           - **å…³ç³»æè¿°ç”Ÿæˆ**ï¼ˆInternVL2-26Bï¼‰:
             - è¾“å…¥å›¾åƒå¯¹(Iq, Iti)
             - MLLMç”Ÿæˆè¯¦ç»†æè¿°Diï¼Œè¯´æ˜ä¸¤å›¾åƒçš„å…±åŒæ¦‚å¿µå’Œå·®å¼‚
             - æ•è·è§†è§‰å’Œè¯­ä¹‰å…³ç³»
           - **æŒ‡ä»¤åˆæˆ**ï¼ˆLLaMA3-8Bï¼‰:
             - LLMåŸºäºæè¿°Diç”Ÿæˆå¤šæ ·åŒ–æ–‡æœ¬æŒ‡ä»¤Tqâ†’ti
             - æ¯ä¸ªå›¾åƒå¯¹ç”Ÿæˆè‡³å°‘3æ¡ä¸åŒæŒ‡ä»¤
             - æŒ‡ä»¤è®¾è®¡ä¸ºå¼€æ”¾å¼æœç´¢æŸ¥è¯¢ï¼ˆå¦‚"æ˜¾ç¤ºæ±½è½¦å†…éƒ¨"ï¼‰
           - **æœ€ç»ˆä¸‰å…ƒç»„**: (Iq, Tqâ†’ti, Iti) + 5ä¸ªç¡¬è´Ÿæ ·æœ¬
      - **å…³é”®ä¼˜åŠ¿**:
        - **å¯æ‰©å±•æ€§**: åˆ©ç”¨é€šç”¨å›¾åƒè¯­æ–™ï¼ˆä¸ä¾èµ–å¤šå›¾åƒç½‘é¡µï¼‰ï¼Œè§„æ¨¡æ— é™æ‰©å±•
        - **è´¨é‡ä¿è¯**: ç›¸ä¼¼åº¦è¿‡æ»¤ + MLLM/LLMæ ‡æ³¨ç¡®ä¿é«˜è´¨é‡
        - **å¤šæ ·æ€§**: ä¸‰ç±»å¼‚æ„ç›¸ä¼¼æ€§å¼•å…¥ä¸åŒç±»å‹çš„å›¾åƒå…³ç³»
        - **ä½æˆæœ¬**: ä½¿ç”¨å¼€æºMLLM/LLMï¼ˆInternVL2-26B, LLaMA3-8Bï¼‰
  - **æ•°æ®è§„æ¨¡**:
      - **MegaPairs**: 2623.5ä¸‡å›¾åƒå¯¹
      - **æºè¯­æ–™**: RecapDataComp-1Bçš„2000ä¸‡å›¾åƒå­é›†
      - **æŒ‡ä»¤å¤šæ ·æ€§**: æ¯å¯¹è‡³å°‘3æ¡æŒ‡ä»¤
      - **ç¡¬è´Ÿæ ·æœ¬**: æ¯ä¸ªæŸ¥è¯¢5ä¸ªç¡¬è´Ÿæ ·æœ¬
  - **æ¨¡å‹**: **MMRetç³»åˆ—** - åŸºäºMegaPairsè®­ç»ƒçš„é€šç”¨å¤šæ¨¡æ€æ£€ç´¢å™¨
      - **MMRet-Base**: CLIP-Bæ¶æ„ï¼ˆ149Må‚æ•°ï¼‰
      - **MMRet-Large**: CLIP-Læ¶æ„ï¼ˆ428Må‚æ•°ï¼‰
      - **MMRet-MLLM**: LLaVA-1.6 Mistral 7Bæ¶æ„ï¼ˆ7.57Bå‚æ•°ï¼‰
  - **å®éªŒç»“æœ** - **SOTAé›¶æ ·æœ¬æ€§èƒ½**:
      - **ç»„åˆå›¾åƒæ£€ç´¢ï¼ˆCIRï¼‰åŸºå‡†**ï¼ˆ4ä¸ªä¸»æµåŸºå‡†ï¼‰:
        - **CIRCO**ï¼ˆä¸»åŸºå‡†ï¼‰:
          - MMRet-MLLM: **42.2% mAP@5**ï¼ˆè¶…è¶Šä¹‹å‰SOTA CoCa-based MagicLens-Lçš„34.1%ï¼Œ**+8.1%**ï¼‰
          - MMRet-Large: **39.2% mAP@5**ï¼ˆCLIP-Lè§„æ¨¡SOTAï¼‰
          - MMRet-Base: **34.3% mAP@5**ï¼ˆè¶…è¶Šå¤§å¤šæ•°æ›´å¤§æ¨¡å‹ï¼‰
        - **CIRRæµ‹è¯•é›†**:
          - MMRet-MLLM: **46.7% R@1, 75.4% Rs@1**ï¼ˆè¶…è¶ŠSOTA **+7.4% R@1, +4.5% Rs@1**ï¼‰
          - MMRet-Large: **38.0% R@1**ï¼ˆCLIP-Lè§„æ¨¡SOTAï¼‰
        - **FashionIQ**: MMRet-MLLM **35.6% R@10**
        - **GeneCIS**: MMRet-MLLM **21.1% Rs@1**ï¼ˆè¶…è¶ŠSOTA **+3.7%**ï¼‰
      - **MMEBåŸºå‡†**ï¼ˆ36ä¸ªæ•°æ®é›†ï¼Œ4ç±»å…ƒä»»åŠ¡ï¼‰:
        - **é›¶æ ·æœ¬æ€»åˆ†**: MMRet-MLLM **44.0%**ï¼ˆSOTAï¼Œè¶…è¶ŠUniIRçš„42.8%ï¼‰
        - **åˆ†ç±»ä»»åŠ¡**: 47.2%
        - **VQAä»»åŠ¡**: 18.4%
        - **æ£€ç´¢ä»»åŠ¡**: 56.5%ï¼ˆæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼‰
        - **è§†è§‰å®šä½**: 62.2%
      - **ç›‘ç£å¾®è°ƒæ€§èƒ½**ï¼ˆMMEBï¼‰:
        - **æ€»åˆ†**: **64.1%**ï¼ˆè¶…è¶ŠVLM2Vec Phi-3.5-Vçš„60.1%ï¼‰
        - **INDæ•°æ®é›†**: 68.0%
        - **OODæ•°æ®é›†**: 59.1%ï¼ˆå¼ºæ³›åŒ–èƒ½åŠ›ï¼Œè¶…è¶ŠVLM2Vec LLaVA-1.6 **+7.1%**ï¼‰
  - **æ•°æ®è´¨é‡éªŒè¯**:
      - **æ•°æ®æ•ˆç‡**: ä»…**50ä¸‡MegaPairsæ ·æœ¬**å³è¶…è¶ŠMagicLensåœ¨**3670ä¸‡æ•°æ®**ä¸Šçš„è®­ç»ƒç»“æœï¼ˆ**æ•°æ®é‡1/70**ï¼‰
      - **å¯æ‰©å±•æ€§**: æ€§èƒ½éšæ•°æ®è§„æ¨¡æŒç»­æå‡ï¼ˆä»128Kåˆ°26Mï¼‰
      - **å¼‚æ„ç­–ç•¥æ•ˆæœ**: åŒæ—¶ä½¿ç”¨ä¸‰ç±»ç›¸ä¼¼æ€§ä¼˜äºå•ä¸€ç­–ç•¥ï¼ˆæ¶ˆèç ”ç©¶éªŒè¯ï¼‰
      - **ç¡¬è´Ÿæ ·æœ¬é‡è¦æ€§**: åŒ…å«ç¡¬è´Ÿæ ·æœ¬æ˜¾è‘—æå‡æ€§èƒ½ï¼ˆ+5-10%è·¨åŸºå‡†ï¼‰
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´12æœˆ
  - **æœºæ„**: åŒ—äº¬é‚®ç”µå¤§å­¦ã€åŒ—äº¬æ™ºæºäººå·¥æ™ºèƒ½ç ”ç©¶é™¢ã€ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ã€ä¸Šæµ·äº¤é€šå¤§å­¦ã€é¦™æ¸¯ç†å·¥å¤§å­¦
  - **ä½œè€…**: Junjie Zhou, Zheng Liu, Ze Liu, Shitao Xiaoç­‰
  - **å¼€æº**: âœ… **å®Œå…¨å¼€æº** - æ•°æ®é›†ã€æ¨¡å‹ã€æ•°æ®åˆæˆpipelineå‡å°†å…¬å¼€
  - **é‡è¦æ„ä¹‰**:
      - **çªç ´æ•°æ®ç“¶é¢ˆ**: é¦–æ¬¡å®ç°ä»é€šç”¨å›¾åƒè¯­æ–™å¤§è§„æ¨¡åˆæˆå¤šæ¨¡æ€æ£€ç´¢æ•°æ®
      - **è´¨é‡ä¼˜äºè§„æ¨¡**: è¯æ˜é«˜è´¨é‡åˆæˆæ•°æ®æ¯”å¤§è§„æ¨¡ä½è´¨é‡æ•°æ®æ›´æœ‰æ•ˆ
      - **å¼‚æ„ç›¸ä¼¼æ€§åˆ›æ–°**: å¤šç±»å‹ç›¸ä¼¼æ€§æŒ–æ˜å¼•å…¥å¤šæ ·åŒ–å›¾åƒå…³ç³»
      - **å¼€æºç”Ÿæ€è´¡çŒ®**: å®Œæ•´å¼€æºæ•°æ®ã€æ¨¡å‹ã€pipelineï¼Œæ¨åŠ¨é¢†åŸŸå‘å±•
      - **é€šç”¨æ£€ç´¢èƒ½åŠ›**: åœ¨CIRå’Œå¹¿æ³›å¤šæ¨¡æ€ä»»åŠ¡ä¸Šå‡è¾¾åˆ°SOTA
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2410.11963">ğŸ“„ CtrlSynth</a></b><br>
<code>arXiv 2410.11963</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¯æ§å›¾åƒ-æ–‡æœ¬åˆæˆç®¡é“** - é€šè¿‡è§†è§‰æ ‡ç­¾çš„åˆ†è§£-é‡ç»„å®ç°ç»†ç²’åº¦æ§åˆ¶çš„å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **åˆ†è§£-é‡ç»„èŒƒå¼çš„å¯æ§æ•°æ®åˆæˆ**:
      - **æ ¸å¿ƒåˆ›æ–°**: å°†å›¾åƒè¯­ä¹‰åˆ†è§£ä¸ºåŸºæœ¬å…ƒç´ ï¼ˆå¯¹è±¡ã€å±æ€§ã€å…³ç³»ï¼‰ï¼Œé€šè¿‡ç”¨æˆ·å®šä¹‰çš„æ§åˆ¶ç­–ç•¥æ“ä½œï¼Œå†é‡ç»„ç”Ÿæˆåˆæˆæ•°æ®
      - **ä¸‰å¤§æ ¸å¿ƒç»„ä»¶**:
        1. **è§†è§‰æ ‡è®°æ¨¡å‹ï¼ˆVTMï¼‰**:
           - æå–å›¾åƒçš„åŸºæœ¬è§†è§‰å…ƒç´ ï¼ˆ**è§†è§‰æ ‡ç­¾**ï¼‰
           - **å¯¹è±¡å’Œå±æ€§**: ä½¿ç”¨å¤šæ ‡ç­¾åˆ†ç±»å™¨ï¼ˆCatLIP-Hugeï¼‰+ é¡¶çº§20ç±»sigmoidé¢„æµ‹
           - **å…³ç³»**: ä½¿ç”¨å¤šæ¨¡æ€æ ‡æ³¨æ¨¡å‹ï¼ˆFlorence-largeï¼‰ç”Ÿæˆè¯¦ç»†æè¿° + LLMï¼ˆQwen2-7Bï¼‰æå–å…³ç³»
           - **æ··åˆæ–¹æ³•**: ç»“åˆCatLIPçš„å¯¹è±¡/å±æ€§é¢„æµ‹ä¸Florence+LLMçš„å…³ç³»æå–ï¼Œå½¢æˆå…¨é¢çš„è§†è§‰æ ‡ç­¾é›†
        2. **æ–‡æœ¬æ§åˆ¶å™¨**:
           - æ¥å—è§†è§‰æ ‡ç­¾ + ç”¨æˆ·ç­–ç•¥ + å¯é€‰åŸå§‹æ–‡æœ¬
           - ç”Ÿæˆæ–‡æœ¬åˆæˆæŒ‡ä»¤å¼•å¯¼LLM
           - **ä¸‰ç±»é¢„å®šä¹‰ç­–ç•¥**:
             - a) **ç¼–è¾‘è§†è§‰æ ‡ç­¾**ï¼ˆåˆ é™¤ã€æ·»åŠ ã€æ›¿æ¢ï¼‰å®ç°ç»†ç²’åº¦å†…å®¹æ§åˆ¶
             - b) **çº¦æŸè¯­ä¹‰å«ä¹‰**æ”¹è¿›å™ªå£°æ ‡æ³¨çš„å¿ å®åº¦
             - c) **é£æ ¼åŒ–è¾“å‡º**ï¼ˆå¦‚JSONæ ¼å¼ï¼‰æå‡ä¸‹æ¸¸å¯ç”¨æ€§
           - **10ä¸ªæ–‡æœ¬æ§åˆ¶ç­–ç•¥**ç”¨äºcaptionåˆæˆï¼ˆè¯¦è§è®ºæ–‡é™„å½•A.1ï¼‰
        3. **å›¾åƒæ§åˆ¶å™¨**:
           - æ¥å—æ–‡æœ¬æç¤º + ç”¨æˆ·ç­–ç•¥
           - è¾“å‡ºå›¾åƒåˆæˆæŒ‡ä»¤å¼•å¯¼æ‰©æ•£æ¨¡å‹
           - **ä¸¤ç±»ç­–ç•¥**:
             - æ ‡ç­¾æƒé‡è°ƒæ•´ï¼ˆçªå‡ºç‰¹å®šå¯¹è±¡/å±æ€§ï¼‰
             - é£æ ¼æç¤ºï¼ˆç”µå½±æ„Ÿã€çœŸå®æ„Ÿã€è‰ºæœ¯é£æ ¼ï¼‰
      - **çµæ´»çš„åˆæˆè·¯å¾„**ï¼ˆæ”¯æŒ4æ¡ä¸»è¦è·¯å¾„ï¼‰:
        - **SP(1) å›¾åƒâ†’æ–‡æœ¬**: åŸå§‹å›¾åƒ â†’ VTM â†’ è§†è§‰æ ‡ç­¾ â†’ æ–‡æœ¬æ§åˆ¶å™¨ â†’ LLM â†’ åˆæˆæ–‡æœ¬
        - **SP(2) å›¾åƒ+åŸå§‹æ–‡æœ¬â†’æ”¹è¿›æ–‡æœ¬**: åŒ…å«åŸå§‹æ ‡æ³¨ä½œä¸ºçº¦æŸï¼Œç”Ÿæˆå¿ å®çš„æ”¹è¿›æ–‡æœ¬
        - **SP(3) å›¾åƒâ†’æ–‡æœ¬+å›¾åƒ**: ç”Ÿæˆæ–‡æœ¬ â†’ å›¾åƒæ§åˆ¶å™¨ â†’ æ‰©æ•£æ¨¡å‹ â†’ åˆæˆå›¾åƒ+æ–‡æœ¬å¯¹
        - **SP(4) æ–‡æœ¬â†’å›¾åƒ**: åŸå§‹æ–‡æœ¬ â†’ å›¾åƒæ§åˆ¶å™¨ â†’ æ‰©æ•£æ¨¡å‹ â†’ åˆæˆå›¾åƒ
      - **é—­ç¯è‡ªè¿‡æ»¤æœºåˆ¶**:
        - **è´¨é‡éªŒè¯**: æ£€æŸ¥åˆæˆæ–‡æœ¬æ˜¯å¦åŒ…å«è‡³å°‘æ¯”ä¾‹pfçš„è§†è§‰æ ‡ç­¾ï¼ˆé»˜è®¤20%ï¼‰
        - **å›¾åƒéªŒè¯**: åˆæˆå›¾åƒé€šè¿‡VTMå†æ¬¡æå–æ ‡ç­¾ï¼ŒéªŒè¯ä¸æºæ–‡æœ¬çš„å¯¹é½
        - **ä¼˜åŠ¿**: æ— éœ€æ‰‹å·¥è§„åˆ™å³å¯è‡ªåŠ¨è¿‡æ»¤ä½è´¨é‡æ ·æœ¬
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç»†ç²’åº¦å¯æ§æ€§**: é€šè¿‡æ ‡ç­¾çº§æ“ä½œå®ç°ç²¾ç¡®æ•°æ®åˆæˆ
        - **æ— è®­ç»ƒ**: å®Œå…¨åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆLLMã€æ‰©æ•£æ¨¡å‹ï¼‰ï¼Œæ— éœ€é¢å¤–è®­ç»ƒ
        - **æ¨¡å—åŒ–**: å¯è½»æ¾æ›¿æ¢LLMã€æ‰©æ•£æ¨¡å‹æˆ–VTMç»„ä»¶
        - **é—­ç¯è®¾è®¡**: è‡ªåŠ¨è´¨é‡éªŒè¯å’Œè¿‡æ»¤èƒ½åŠ›
  - **æ•°æ®è§„æ¨¡**:
      - **CC3Måˆæˆæ•°æ®**:
        - CtrlSynth-cap: 260ä¸‡captionsï¼ˆä»280ä¸‡åŸå§‹æ•°æ®è¿‡æ»¤ï¼‰
        - CtrlSynth-img: 240ä¸‡å›¾åƒ
        - CtrlSynth-mix: 510ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹ï¼ˆæ··åˆcap+capimgï¼‰
      - **CC12Måˆæˆæ•°æ®**:
        - CtrlSynth-cap: 1020ä¸‡captionsï¼ˆä»1130ä¸‡åŸå§‹æ•°æ®ï¼‰
        - CtrlSynth-img: 950ä¸‡å›¾åƒ
        - CtrlSynth-mix: 1970ä¸‡å›¾åƒ-æ–‡æœ¬å¯¹
  - **å®éªŒç»“æœ** - **åœ¨CLIPé¢„è®­ç»ƒä¸Šçš„å…¨é¢è¯„ä¼°**:
      - **é›¶æ ·æœ¬åˆ†ç±»**ï¼ˆ31ä¸ªæ•°æ®é›†ï¼‰:
        - CC3Mè®­ç»ƒ: å¹³å‡å‡†ç¡®ç‡ä»19.4%æå‡è‡³**27.1%ï¼ˆ+7.7%ï¼‰**
        - CC12Mè®­ç»ƒ: ä»33.9%æå‡è‡³**36.6%ï¼ˆ+2.5%ï¼‰**
        - ImageNetå˜ä½“: ä»11.3%æå‡è‡³**20.7%ï¼ˆ+9.4%ï¼‰** [CC3M]
      - **å›¾åƒ-æ–‡æœ¬æ£€ç´¢**ï¼ˆCOCOã€Flickr30kï¼‰:
        - CC3Mè®­ç»ƒ: recall@1ä»13.7%æå‡è‡³**37.1%ï¼ˆ+23.4%ï¼‰**
        - Flickr I2T: ä»21.3%æå‡è‡³**57.3%ï¼ˆ+36%ï¼‰**
        - CC12Mè®­ç»ƒ: recall@1ä»45.4%æå‡è‡³**54.4%ï¼ˆ+9.0%ï¼‰**
      - **ç»„åˆæ¨ç†**ï¼ˆSugarCrepeåŸºå‡†ï¼‰:
        - CC3Mè®­ç»ƒ: ä»64.0%æå‡è‡³**68.5%ï¼ˆ+4.5%ï¼‰**
        - CC12Mè®­ç»ƒ: ä»72.3%æå‡è‡³**75.3%ï¼ˆ+3.0%ï¼‰**
        - **çªå‡ºæå‡**: REPLACEå…³ç³» +4.3%ï¼ŒSWAPå±æ€§ +14.8%
      - **é•¿å°¾ä»»åŠ¡æ€§èƒ½**:
        - **ImageNet-LT**: å°¾ç±»å‡†ç¡®ç‡+21.3%ï¼Œæ•´ä½“+5.4%
        - **Places-LT**: å°¾ç±»å‡†ç¡®ç‡+16.2%ï¼Œæ•´ä½“+3.7%
      - **ä¸å…ˆå‰å·¥ä½œå¯¹æ¯”**:
        - è¶…è¶Š**VeCLIP**: åœ¨VTABä¸Šå¹³å‡+4.8%ï¼ŒImageNet 1Kä¸Š+7.9%
        - è¶…è¶Š**LaCLIP**: åœ¨15ä¸ªæ•°æ®é›†ä¸Šå¹³å‡+3.4%ï¼ŒImageNet 1Kä¸Š+2.3%
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - **è§†è§‰å…³ç³»çš„é‡è¦æ€§**: åŒ…å«å…³ç³»æ ‡ç­¾æ¯”ä»…å¯¹è±¡/å±æ€§æå‡4%ç»„åˆæ¨ç†æ€§èƒ½
      - **æ··åˆLLMæ•ˆæœ**: Mistral-NeMoä¼˜äºQwen2-7Bï¼ˆ+3% SugarCrepeï¼‰
      - **è¿‡æ»¤é˜ˆå€¼**: 20%è¾¾åˆ°æœ€ä½³æ€§èƒ½å¹³è¡¡ï¼ˆ10%-30%èŒƒå›´å†…ç¨³å®šï¼‰
      - **æ··åˆæ¯”ä¾‹**: 50%åˆæˆæ•°æ®è¾¾åˆ°æœ€ä½³å¢ç›Šï¼Œæ›´é«˜æ¯”ä¾‹æ”¶ç›Šé€’å‡
      - **æ•°æ®æ•ˆç‡**: åˆæˆæ•°æ®ä½¿CLIPè®­ç»ƒæ•ˆç‡æå‡40%ï¼ˆè¾¾åˆ°20%å‡†ç¡®ç‡æ‰€éœ€è¿­ä»£æ•°ï¼‰
  - **åˆæˆè´¨é‡åˆ†æ**:
      - **æ–‡æœ¬é•¿åº¦**: åˆæˆcaptionå¹³å‡60è¯ vs åŸå§‹8è¯
      - **ä¿¡æ¯å¯†åº¦**: åŒ…å«æ›´ä¸°å¯Œçš„è§†è§‰ç»†èŠ‚å’Œå…³ç³»æè¿°
      - **å¤šæ ·æ€§**: é€šè¿‡æ§åˆ¶ç­–ç•¥ç”Ÿæˆå¤šæ ·åŒ–è¡¨è¿°
  - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´10æœˆ
  - **æœºæ„**: Appleã€Meta
  - **ä½œè€…**: Qingqing Cao, Mahyar Najibi, Sachin Mehta
  - **å¼€æº**: âš ï¸ è®ºæ–‡æœªæ˜ç¡®æåŠæ•°æ®é›†/ä»£ç å¼€æºçŠ¶æ€
  - **é‡è¦æ„ä¹‰**:
      - **é¦–ä¸ªå¯æ§å›¾æ–‡åˆæˆç³»ç»Ÿ**: æä¾›ç»†ç²’åº¦æ§åˆ¶è€Œéé»‘ç›’ç”Ÿæˆ
      - **åˆ†è§£-é‡ç»„èŒƒå¼**: åˆ›æ–°çš„è§†è§‰è¯­ä¹‰æ“ä½œæ–¹æ³•
      - **é—­ç¯è‡ªéªŒè¯**: æ— éœ€äººå·¥è®¾è®¡è¿‡æ»¤è§„åˆ™
      - **è·¨ä»»åŠ¡æ³›åŒ–**: åœ¨åˆ†ç±»ã€æ£€ç´¢ã€ç»„åˆæ¨ç†ã€é•¿å°¾ä»»åŠ¡ä¸Šå…¨é¢æå‡
      - **æ•°æ®æ•ˆç‡**: è¯æ˜åˆæˆæ•°æ®çš„æ ·æœ¬æ•ˆç‡ä¼˜äºçº¯çœŸå®æ•°æ®æ‰©å±•
  
  #### ğŸ› ï¸ å·¥å…·è¾…åŠ©æ ‡æ³¨ç”Ÿæˆï¼ˆç”¨äºæ•°æ®åˆæˆï¼‰
  
  > ä»¥ä¸‹å·¥å…·å¸¸ç”¨äºæ•°æ®åˆæˆpipeline
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2405.02793">ğŸ“„ ImageInWords</a></b><br>
<code>arXiv 2405.02793</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ECCV_2024-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **è¶…è¯¦ç»†å›¾åƒæè¿°ç”Ÿæˆ** - Human-in-the-loopæ¡†æ¶ï¼Œç»“åˆVLMç§å­ç”Ÿæˆå’Œé¡ºåºäººå·¥å¢å¼ºï¼Œç”Ÿæˆé«˜è´¨é‡hyper-detailedå›¾åƒæè¿°
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ç§å­æ ‡æ³¨ + é¡ºåºå¢å¼º + ä¸»åŠ¨å­¦ä¹ **:
      - **æ ¸å¿ƒåˆ›æ–°**: ç»“åˆVLMç”Ÿæˆçš„**ç§å­å…ƒæ•°æ®**ä¸**äººå·¥æ ‡æ³¨è€…çš„ä¸å¯æ›¿ä»£è´¨é‡**ï¼Œé€šè¿‡é¡ºåºè¿­ä»£å’Œä¸»åŠ¨å­¦ä¹ å¾ªç¯ç”Ÿæˆè¶…è¯¦ç»†å›¾åƒæè¿°
      - **ä¸¤ä»»åŠ¡æ¡†æ¶**:
        1. **Task 1: å¯¹è±¡çº§æè¿°**ï¼ˆç»†ç²’åº¦æ ‡æ³¨ï¼‰:
           - **è¾“å…¥**: å›¾åƒ + å¯¹è±¡æ£€æµ‹(OD)æ¨¡å‹ç”Ÿæˆçš„(label, bbox)
           - **VLMç§å­ç”Ÿæˆ**: ä½¿ç”¨PaLI-35Bä¸ºæ¯ä¸ªbboxç”Ÿæˆå¯¹è±¡çº§caption
           - **äººå·¥å¢å¼º**: ä¼—åŒ…å·¥ä½œè€…ä¿®æ­£ã€æ·»åŠ ã€åˆ é™¤ã€åˆå¹¶å¯¹è±¡æ ‡æ³¨
           - **è¾“å‡º**: (label, bbox, è¯¦ç»†å¯¹è±¡æè¿°)ä¸‰å…ƒç»„ï¼Œæ¶µç›–æ‰€æœ‰æ˜¾è‘—å¯¹è±¡
        2. **Task 2: å›¾åƒçº§æè¿°**ï¼ˆå…¨å±€æè¿°ï¼‰:
           - **è¾“å…¥**: Task 1çš„å¯¹è±¡æè¿° + VLMç”Ÿæˆçš„å…¨å±€ç§å­caption + å¯é€‰é¢†åŸŸç‰¹å®šå…ƒæ•°æ®ï¼ˆå¦‚è‰ºæœ¯é£æ ¼ï¼‰
           - **é¡ºåºå¢å¼º**: å¤šä¸ªä¼—åŒ…å·¥ä½œè€…ä¾æ¬¡å¢å¼ºå’Œæ”¹è¿›æè¿°ï¼ˆé€šå¸¸3è½®ï¼‰
           - **ä¸»åŠ¨å­¦ä¹ **: æ¯æ”¶é›†1Kæ ·æœ¬åï¼Œä½¿ç”¨æ–°æ•°æ®é‡æ–°å¾®è°ƒPaLI-35Bï¼Œæ”¹è¿›ç§å­è´¨é‡
           - **è¾“å‡º**: 217.2 tokenså¹³å‡é•¿åº¦çš„hyper-detailedæè¿°
      - **é¡ºåºå¢å¼ºä¼˜åŠ¿**ï¼ˆFig. 2ï¼‰:
        - **æ•ˆç‡æå‡**: 3ä¸ªæ ‡æ³¨è€…é¡ºåºå·¥ä½œ vs å¹¶è¡Œå·¥ä½œ
          - **Tokenå¢é•¿**: +20% token countï¼ˆä»170â†’204è¯ï¼‰
          - **æ—¶é—´èŠ‚çœ**: -30% æ—¶é—´ï¼ˆä»800ç§’â†’560ç§’/æ ‡æ³¨è€…ï¼‰
          - **è´¨é‡æå‡**: Jaccardç›¸ä¼¼åº¦ä»0.2æå‡è‡³0.65ï¼ˆround 1-2 â†’ round 2-3ï¼‰
        - **éšå¼å­¦ä¹ å¾ªç¯**: æ ‡æ³¨è€…äº’ç›¸å­¦ä¹ ï¼Œä¸ªä½“è´¨é‡æŒç»­æå‡
      - **ä¸»åŠ¨å­¦ä¹ å¾ªç¯**:
        - **åˆå§‹PaLI**: å¹³å‡ç”Ÿæˆ15è¯caption
        - **3Kæ ·æœ¬å**: æå‡è‡³150+è¯caption
        - **å…³é”®ä½œç”¨**: æ˜¾è‘—é™ä½äººå·¥æ ‡æ³¨è´Ÿæ‹…
      - **æ ‡æ³¨æŒ‡å—**ï¼ˆè¯¦è§è®ºæ–‡Appendix Aï¼‰:
        - **TLDRåŸåˆ™**: é¦–å¥å¿…é¡»æ˜¯æŠ¥çº¸é£æ ¼çš„ç®€æ´æ€»ç»“
        - **æ˜¾è‘—æ€§é¡ºåº**: æŒ‰å¯¹è±¡æ˜¾è‘—æ€§é¡ºåºæè¿°ï¼Œè€Œééšæœºé¡ºåº
        - **è§†è§‰å‡†ç¡®**: ä»…åŒ…å«è§†è§‰å¯æ¨æ–­çš„ç»†èŠ‚ï¼Œé¿å…çŒœæµ‹
        - **å…¨é¢è¦†ç›–**: åŒ…æ‹¬è®¾ç½®ã€èƒŒæ™¯ã€é£æ ¼ã€ç›¸æœºè§’åº¦ã€æ•´ä½“æ„å›¾ã€æ¸²æŸ“æ–‡æœ¬
        - **ç‰¹åˆ«å…³æ³¨**: äººç‰©ã€æœé¥°ã€è‰ºæœ¯ä½œå“ã€åœ°ç‚¹ç‰¹å®šå±æ€§ã€ç‹¬ç‰¹å±æ€§
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç§å­æ ‡æ³¨**: æ˜¾è‘—é™ä½ä»é›¶å¼€å§‹çš„æ ‡æ³¨æˆæœ¬å’Œæ—¶é—´
        - **é¡ºåºå¢å¼º**: æ¯”å¹¶è¡Œæ ‡æ³¨æ›´é«˜æ•ˆï¼ŒåŒæ—¶äº§ç”Ÿå•ä¸€é«˜è´¨é‡è¾“å‡º
        - **ä¸»åŠ¨å­¦ä¹ **: æŒç»­æ”¹è¿›VLMç§å­è´¨é‡ï¼Œå‡å°‘äººå·¥è´Ÿæ‹…
        - **è´¨é‡ä¿è¯**: å¤šè½®è¿­ä»£ + n-gram Jaccardç›¸ä¼¼åº¦ç›‘æ§ç¡®ä¿æ”¶æ•›
  - **æ•°æ®è§„æ¨¡**:
      - **IIWæ•°æ®é›†**: 9,018å¼ å›¾åƒï¼ˆè®­ç»ƒ: 8,573ï¼Œæµ‹è¯•: 445ï¼‰
      - **å¹³å‡ç»Ÿè®¡**:
        - **Tokens**: 217.2 (vs DOCCI 135.7, DCI 148.0)
        - **Sentences**: 9.8
        - **Nouns**: 52.5 (vs DOCCI 34.0, DCI 35.3)
        - **Adjectives**: 28.0 (vs DOCCI 16.6, DCI 16.3)
        - **Verbs**: 19.1 (vs DOCCI 9.6, DCI 10.5)
      - **å›¾åƒæ¥æº**: WebLI-likeæ•°æ®é›†é‡‡æ ·
      - **æ ‡æ³¨æ± **: 20+é¢†åŸŸä¸“å®¶ï¼ˆåˆ›æ„å†™ä½œã€è‰ºæœ¯ã€å†å²ã€æ‘„å½±èƒŒæ™¯ï¼‰
  - **å®éªŒç»“æœ** - **äººå·¥SxSè¯„ä¼°ä¼˜åŠ¿æ˜¾è‘—**:
      - **IIWäººå·¥æ ‡æ³¨ vs å…ˆå‰æ•°æ®é›†**ï¼ˆTable 2ï¼‰:
        - **vs DCIï¼ˆ112æµ‹è¯•æ ·æœ¬ï¼‰**:
          - Comprehensivenessï¼ˆå…¨é¢æ€§ï¼‰: +61%
          - Specificityï¼ˆå…·ä½“æ€§ï¼‰: +80%
          - Hallucinationsï¼ˆæ›´å°‘å¹»è§‰ï¼‰: -42%
          - TLDRè´¨é‡: +91%
          - Human-Likenessï¼ˆç±»äººæ€§ï¼‰: +82%
        - **vs DOCCIï¼ˆ100æµ‹è¯•æ ·æœ¬ï¼‰**:
          - Comprehensiveness: +42%
          - Specificity: +82%
          - Hallucinations: -35%
          - TLDRè´¨é‡: +79%
          - Human-Likeness: +68%
        - **å¹³å‡æå‡**: +66%ï¼ˆ5é¡¹æŒ‡æ ‡å¹³å‡ï¼Œä¸¤æ•°æ®é›†å¹³å‡ï¼‰
      - **IIWäººå·¥æ ‡æ³¨ vs GPT-4V**ï¼ˆTable 3å³ä¾§ï¼‰:
        - **100æ ·æœ¬å¯¹æ¯”**:
          - Comprehensiveness: +35%
          - Specificity: +53%
          - Hallucinations: -59%
          - TLDRè´¨é‡: +70%
          - Human-Likeness: +21%
        - **å¹³å‡æå‡**: +48%
      - **IIWæ¨¡å‹ï¼ˆå¾®è°ƒPaLI-35Bï¼‰vs å…¶ä»–æ•°æ®é›†å¾®è°ƒæ¨¡å‹**ï¼ˆTable 3å·¦ä¾§ï¼‰:
        - **vs DCIæ¨¡å‹**: +42% Comprehensiveness, +54% Specificity, +51% TLDR
        - **vs DOCCIæ¨¡å‹**: +4% Comprehensiveness, +37% Specificity, +57% TLDR
        - **å¹³å‡æå‡**: +31%ï¼ˆ5é¡¹æŒ‡æ ‡å¹³å‡ï¼Œä¸¤æ•°æ®é›†å¹³å‡ï¼‰
  - **ä¸‹æ¸¸åº”ç”¨è¯„ä¼°**:
      - **Text-to-Imageé‡å»º**ï¼ˆTable 4, 240å¼ LocNarå›¾åƒï¼‰:
        - ä½¿ç”¨Imagenæ¨¡å‹ï¼ŒæŒ‰å¥å­ç´¯ç§¯è¾“å…¥ï¼ˆS1, S1-2, S1-3...ï¼‰
        - **Mean Rank**: IIW 1.63 vs DOCCI 1.74 vs DCI 2.05ï¼ˆ**ç¬¬1å**ï¼‰
        - **CLIPç›¸ä¼¼åº¦**: IIW 0.861 vs DOCCI 0.853 vs DCI 0.844ï¼ˆ**æœ€é«˜**ï¼‰
        - **å…³é”®å‘ç°**: å³ä½¿ä»…ç”¨ç¬¬1å¥ï¼ŒIIWä¹Ÿä¼˜äºå…¶ä»–æ•°æ®é›†
      - **ç»„åˆæ¨ç†**ï¼ˆTable 5ï¼ŒLLM-onlyè®¾ç½®ï¼‰:
        - ä½¿ç”¨IIWæè¿°æ›¿æ¢ARO/SVO-Probes/Winogroundä¸­çš„å›¾åƒï¼ŒLLMåˆ¤æ–­
        - **ARO VG-Attribution**: 90.37%ï¼ˆvs InstructBLIP 83.99%, LLaVA 84.80%, **+6%**ï¼‰
        - **ARO VG-Relation**: 66.19%ï¼ˆvs InstructBLIP 62.73%, LLaVA 63.71%, **+2-3%**ï¼‰
        - **Winoground**: 69.38%ï¼ˆvs InstructBLIP 65.25%, LLaVA 63.38%, **+4-6%**ï¼‰
  - **IIW-EvalåŸºå‡†**ï¼ˆTable 6ï¼‰:
      - **2,612å¼ å›¾åƒ** + **1,899ä¸ªå¯¹è±¡çº§æ ‡æ³¨** + **2,712ä¸ªå›¾åƒçº§æ ‡æ³¨**
      - **412ä¸ªäººå·¥SxSæ ‡ç­¾**ï¼ˆIIW vs DCI, IIW vs DOCCIï¼‰
      - **IIW-400**ï¼ˆ400å¼ æ–°è¯„ä¼°é›†ï¼‰+ DCIæµ‹è¯•é›†ï¼ˆ112ï¼‰+ DOCCIæµ‹è¯•é›†ï¼ˆ100ï¼‰
      - **æ¨¡å‹enrichedæ•°æ®é›†**: LocNarï¼ˆ1,000ï¼‰+ XM3600ï¼ˆ1,000ï¼‰ä½¿ç”¨IIWæ¨¡å‹é‡æ–°æ ‡æ³¨
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - **ç§å­æ ‡æ³¨é‡è¦æ€§**ï¼ˆTable 7ï¼‰: æœ‰ç§å­ vs æ— ç§å­ = +54% Comprehensiveness, +48% Specificity
      - **IIWäººå·¥ vs IIWæ¨¡å‹**ï¼ˆTable 8ï¼Œ100æ ·æœ¬ï¼‰: äººå·¥ä»æ˜¾è‘—æ›´ä¼˜ï¼ˆ+78% Compr., +91% Spec.ï¼‰
      - **é¡ºåºè½®æ•°**: 3è½®è¾¾åˆ°0.8ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œåç»­è½®æ•°æ”¶ç›Šé€’å‡
  - **å‘å¸ƒæ—¶é—´**: ECCV 2024 | arXiv 2024å¹´5æœˆï¼ˆv2: 2024å¹´10æœˆï¼‰
  - **æœºæ„**: Google DeepMind, Google Research, University of Washington
  - **ä½œè€…**: Roopal Garg, Andrea Burns, Burcu Karagol Ayan, Yonatan Bittonç­‰
  - **å¼€æº**: âœ… **å®Œå…¨å¼€æº** - IIW-EvalåŸºå‡†ï¼ˆ2.6Kå›¾åƒï¼‰ã€äººå·¥SxSæ ‡ç­¾ã€æ¨¡å‹enriched LocNar+XM3600æ•°æ®
  - **é¡¹ç›®é¡µé¢**: [github.com/google/imageinwords](https://github.com/google/imageinwords)
  - **é‡è¦æ„ä¹‰**:
      - **å¼€åˆ›æ€§äººæœºåä½œ**: é¦–ä¸ªç³»ç»Ÿæ€§åœ°å°†VLMç§å­ä¸äººå·¥ç²¾ç‚¼ç»“åˆçš„hyper-detailedæè¿°ç”Ÿæˆæ¡†æ¶
      - **é¡ºåºå¢å¼ºçªç ´**: è¯æ˜é¡ºåºæ ‡æ³¨ä¼˜äºå¹¶è¡Œæ ‡æ³¨ï¼ˆæ•ˆç‡+è´¨é‡åŒèµ¢ï¼‰
      - **ä¸»åŠ¨å­¦ä¹ å¾ªç¯**: å±•ç¤ºæ•°æ®æ”¶é›†ä¸æ¨¡å‹æ”¹è¿›çš„è‰¯æ€§å¾ªç¯
      - **TLDRè®¾è®¡**: å¼•å…¥æŠ¥çº¸é£æ ¼é¦–å¥æ€»ç»“ï¼Œä¸ºé•¿æè¿°æ•°æ®æ ‘ç«‹èŒƒå¼
      - **å…¨é¢åŸºå‡†**: IIW-Evalæä¾›å¤šç»´åº¦è´¨é‡è¯„ä¼°ï¼Œæ¨åŠ¨æè¿°ç”Ÿæˆç ”ç©¶
      - **ä¸‹æ¸¸éªŒè¯**: T2Ié‡å»ºå’Œç»„åˆæ¨ç†éªŒè¯æè¿°è´¨é‡çš„å®ç”¨ä»·å€¼
      - **è´¨é‡æ ‡æ†**: åœ¨æè¿°å…¨é¢æ€§ã€å…·ä½“æ€§ã€æ— å¹»è§‰æ€§ä¸Šå»ºç«‹æ–°SOTA
  

</details>
<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=SpaRE">ğŸ“„ SpaRE</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Synthetic Spatial QA Generation from Hyper-Detailed Captions**:
      - **Core Innovation**: Leverages untapped potential of hyper-detailed image captions to generate synthetic spatial reasoning question-answer pairs
      - **Data Sources**: DOCCI (15Kâ†’10K filtered), Localized Narratives (849Kâ†’232K filtered), PixMo-Cap (717Kâ†’214K filtered)
      - **LLM-Based Extraction**: Uses Qwen2.5-3B-Instruct to extract spatial relationships from detailed descriptions and formulate diverse QA pairs
      - **Data Scale**: 455K samples containing 3.4M spatial reasoning QA pairs covering 66+ spatial relations
      - **Quality Assurance Pipeline**: 5-step automated filtering (deduplication, reference check, answer-description consistency, image-question consistency, spatial relation verification)
  - **Key Technical Components**:
      - **Spatial Relation Analysis**: Quantifies data scarcity - top 17% of relations account for 90% of samples in existing VL datasets
      - **Multi-Stage Filtering**: Pre-filtering (~65% reduction) â†’ QA generation â†’ post-generation quality verification
      - **Domain Coverage**: Positions/directions, relative distances, orientations/angles, foreground/background layers, boundaries/edges, shadows/reflections, overlapping/layering, scale/size comparisons
      - **Hallucination Mitigation**: Aggressive filtering strategy reduces relation/object hallucination to ~4%/3% respectively
  - **Experimental Results**:
      - **Spatial Reasoning Benchmarks**: VSR 70.3â†’85.4% (+15.1%), What's Up A 44.6â†’100.0% (+55.4%), What's Up B 79.1â†’100.0% (+20.9%), 3DSRBench 46.5â†’57.5% (+11.0%), RealWorldQA 58.6â†’68.8% (+10.2%)
      - **Peak Performance**: Up to 49% improvement on What's Up benchmark (most significant spatial reasoning gains reported in literature)
      - **General VL Performance**: Maintains strong performance on MMMU (51.0%), MMBench (78.6%), HallusionBench (56.3%), TextVQA (80.5%), MME (1661.4-642.3-145.5-156.3-127.5)
      - **Cross-Architecture Validation**: Effective on both Qwen2VL-2B/7B and demonstrates superior performance vs. caption-only training (Molmo-7B-D baseline)
  - **Error Analysis & Limitations**:
      - **Frame of Reference Challenge**: Struggles with empathetic spatial reasoning (adopting others' perspectives) - consistent with prior VLM limitations
      - **3DSRBench Performance**: Relatively weaker on 3D spatial reasoning due to egocentric bias inherited from source datasets
      - **Qualitative Improvements**: Correctly handles complex perspective-dependent questions (e.g., "is the table on the left or right of me?" from person's vs. viewer's perspective)
  - **Cost Efficiency**:
      - **Data Construction**: Significantly more efficient than manual curation methods
      - **Synthetic vs. Natural**: Outperforms direct caption training approaches while providing targeted spatial knowledge
      - **Filtering Strategy**: Balances quality vs. quantity through multi-stage automated verification
  - **Open Source**: âœ… Code and dataset promised to be released
  - **Significance**:
      - **Data Scarcity Solution**: Addresses critical gap in spatial reasoning data through systematic synthesis from rich descriptions
      - **Systematic Analysis**: First comprehensive quantification of spatial relations distribution in major VL datasets
      - **Practical Impact**: Enables applications in robotics, navigation, AR/VR requiring precise spatial understanding
      - **Methodology Transfer**: Demonstrates effective pipeline for extracting task-specific knowledge from hyper-detailed captions
  
  #### ğŸ”„ æŒç»­å­¦ä¹ ä¸ç¾éš¾æ€§é—å¿˜ç¼“è§£
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2503.04229">ğŸ“„ GIFT</a></b><br>
<code>arXiv 2503.04229</code>
</summary>

  - **æ•°æ®åˆæˆæ–¹æ³•** - **åŸºäºStable Diffusionçš„VLMæŒç»­å­¦ä¹ åˆæˆæ•°æ®**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–ä¸ªä½¿ç”¨æ‰©æ•£ç”Ÿæˆåˆæˆæ•°æ®ç¼“è§£è§†è§‰-è¯­è¨€æ¨¡å‹æŒç»­å¾®è°ƒä¸­ç¾éš¾æ€§é—å¿˜çš„æ¡†æ¶
      - **åŒé‡é—å¿˜æŒ‘æˆ˜**ï¼šè§£å†³ä¸‹æ¸¸ä»»åŠ¡é—å¿˜å’ŒVLMé¢„è®­ç»ƒçŸ¥è¯†é€€åŒ– - ç‹¬ç‰¹çš„å¤šæ¨¡æ€CLæŒ‘æˆ˜
      - **åˆæˆæ•°æ®é‡å»º**ï¼šä½¿ç”¨Stable Diffusioné‡å»ºé¢„è®­ç»ƒè¿‘ä¼¼ï¼ˆImageNetç±»åˆ«åç§°ï¼‰å’Œå†å²ä¸‹æ¸¸ä»»åŠ¡æ•°æ®ï¼Œæ— å­˜å‚¨/éšç§é—®é¢˜
      - **æ•°æ®è§„æ¨¡**ï¼šæ¯ä»»åŠ¡1Kåˆæˆå›¾åƒå®ç°ä¼˜äº100KçœŸå®ImageNetå›¾åƒçš„æ€§èƒ½ï¼Œå±•ç¤ºåˆæˆæ•°æ®æ•ˆç‡
  - **å…³é”®æŠ€æœ¯ç»„ä»¶**ï¼š
      - **ç±»ç¼“å†²æ± ç­–ç•¥**ï¼šç»´æŠ¤P = âˆªC_iå­˜å‚¨æ‰€æœ‰é‡åˆ°çš„ç±»åˆ«åç§°ï¼›ä»å¤šæ ·åŒ–æ± ä¸­é‡‡æ ·ç”Ÿæˆè¿‘ä¼¼é¢„è®­ç»ƒ+ä¸‹æ¸¸æ•°æ®
      - **å¯¹æ¯”è’¸é¦æŸå¤±**ï¼šåœ¨åˆæˆå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šä½¿ç”¨ä¸CLIPé¢„è®­ç»ƒä¸€è‡´çš„å›¾åƒ-æ–‡æœ¬åŒ¹é…ç›®æ ‡å°†å½“å‰æ¨¡å‹Î¸_tä¸ä¹‹å‰æ¨¡å‹Î¸_{t-1}å¯¹é½
      - **å›¾åƒ-æ–‡æœ¬å¯¹é½çº¦æŸ**ï¼šé€šè¿‡åœ¨èº«ä»½çŸ©é˜µå’Œå¯¹æ¯”ç›¸ä¼¼åº¦çŸ©é˜µé—´å¼ºåˆ¶KLæ•£åº¦ä½œä¸ºç¡¬ç›®æ ‡çº æ­£æ•™å¸ˆæ¨¡å‹é”™è¯¯
      - **è‡ªé€‚åº”æƒé‡æ•´åˆ(AWC)**ï¼šè®­ç»ƒæœŸé—´ä»åˆæˆæ•°æ®åŠ¨æ€Fisherä¿¡æ¯è®¡ç®—ï¼ˆéEWCçš„é™æ€ï¼‰ï¼Œå®ç°å®æ—¶å‚æ•°é‡è¦æ€§è°ƒæ•´
  - **å®éªŒæ¡†æ¶**ï¼š
      - **MTILåŸºå‡†**ï¼š11ä¸ªæ•°æ®é›†ï¼ˆAircraft, Caltech101, CIFAR100, DTD, EuroSAT, Flowers, Food, MNIST, OxfordPet, StanfordCars, SUN397ï¼‰ï¼Œè·¨å¤šæ ·åŒ–é¢†åŸŸ1,201ç±»
      - **ä¸¤ç§ä»»åŠ¡é¡ºåº**ï¼šå­—æ¯é¡ºåºï¼ˆOrder Iï¼‰å’Œéšæœºï¼ˆOrder IIï¼‰å®‰æ’å¼•å…¥ä¸åŒé¢†åŸŸåç§»æŒ‘æˆ˜
      - **ç»¼åˆæŒ‡æ ‡**ï¼šTransferï¼ˆé›¶æ ·æœ¬èƒ½åŠ›ä¿æŒï¼‰ï¼ŒLastï¼ˆä¸‹æ¸¸ä»»åŠ¡ä¿æŒï¼‰ï¼ŒAvg.ï¼ˆç¨³å®šæ€§-å¯å¡‘æ€§å¹³è¡¡ï¼‰
  - **å®éªŒç»“æœ**ï¼š
      - **MTIL Order I**ï¼šTransfer 69.3% (+8.3% vs l2åŸºçº¿)ï¼ŒAvg. 77.3% (+14.6%)ï¼ŒLast 86.0% (+10.1%) - æ‰€æœ‰æŒ‡æ ‡è¾¾åˆ°æ–°SOTA
      - **MTIL Order II**ï¼šTransfer 65.9% (+5.3%)ï¼ŒAvg. 75.7% (+6.9%)ï¼ŒLast 85.3% (+8.1%) - åœ¨é«˜é¢†åŸŸåç§»ä¸‹ä¿æŒå¼ºæ€§èƒ½
      - **CILåŸºå‡†**ï¼šCIFAR100ï¼ˆ10/20/50æ­¥ï¼‰å’ŒTinyImageNetï¼ˆ5/10/20æ­¥ï¼‰ - ç›¸æ¯”ä¼ ç»ŸCLæ–¹æ³•ä¸€è‡´æ”¹è¿›
      - **åˆæˆvsçœŸå®æ•°æ®**ï¼š1Kåˆæˆå›¾åƒåœ¨Avg./LastæŒ‡æ ‡ä¸Šè¶…è¶Š1KçœŸå®ImageNetå›¾åƒï¼ŒåŒæ—¶ä¿æŒå¯æ¯”çš„Transferåˆ†æ•°
  - **æ¶ˆèç ”ç©¶**ï¼š
      - **å¯¹æ¯”>å…¶ä»–æŸå¤±**ï¼šå¯¹æ¯”è’¸é¦ï¼ˆ85.0% Lastï¼‰>> ç‰¹å¾è·ç¦»ï¼ˆ80.5%ï¼‰> ä»…å›¾åƒï¼ˆ84.1%ï¼‰> ä»…æ–‡æœ¬ï¼ˆ81.8%ï¼‰
      - **æ•™å¸ˆæ¨¡å‹é€‰æ‹©**ï¼šæœ€åCLIPæ¨¡å‹æœ€ä¼˜ vs åˆå§‹CLIPï¼ˆæ›´é«˜Transferä½†æ›´ä½Lastï¼‰vs WiSEæ’å€¼ï¼ˆæ¬¡ä¼˜å¹³è¡¡ï¼‰
      - **ITAè§„æ¨¡åˆ†æ**ï¼šÎ²=0.25æä¾›æœ€ä¼˜è½¯-ç¡¬ç›®æ ‡å¹³è¡¡ï¼›æ›´é«˜Î²å¯¼è‡´åˆæˆæ•°æ®è¿‡æ‹Ÿåˆ
      - **AWC vs EWC**ï¼šè‡ªé€‚åº”Fisherä¿¡æ¯ï¼ˆ86.0% Lastï¼‰æ˜¾è‘—ä¼˜äºé™æ€EWCå˜ä½“ï¼ˆâ‰¤86.2%ç”¨256æ ·æœ¬ï¼‰
  - **åˆæˆæ•°æ®åˆ†æ**ï¼š
      - **ç”Ÿæˆè´¨é‡**ï¼šè·¨é¢†åŸŸé«˜è´¨é‡å¤šæ ·åŒ–å›¾åƒï¼›50â†’25å»å™ªæ­¥éª¤æœ€å°æ€§èƒ½å½±å“ï¼ˆå¿«é€Ÿç”Ÿæˆï¼‰
      - **å¼•å¯¼è§„æ¨¡é²æ£’æ€§**ï¼šCFGè§„æ¨¡ï¼ˆ4.5-10.5ï¼‰é—´ä¸€è‡´æ€§èƒ½ï¼Œç”±äºå…³æ³¨ç±»é—´å¤šæ ·æ€§è¶…è¿‡ç±»å†…å˜åŒ–
      - **é¢†åŸŸç‰¹å®šå½±å“**ï¼šæ¶ˆé™¤ç‰¹å®šä»»åŠ¡åˆæˆæ•°æ®ï¼ˆAircraft, StanfordCarsï¼‰æ˜¾è‘—åŠ å‰§è¿™äº›ä»»åŠ¡çš„é—å¿˜
      - **åˆ†å¸ƒè¦†ç›–**ï¼šåˆæˆé¢„è®­ç»ƒæ•°æ®ï¼ˆImageNetç±»ï¼‰+ä¸‹æ¸¸ç±»æä¾›å…¨é¢ç‰¹å¾ç©ºé—´é”šå®š
  - **è®¡ç®—æ•ˆç‡**ï¼š
      - **æ— å­˜å‚¨**ï¼šæ¯ä»»åŠ¡åä¸¢å¼ƒç”Ÿæˆå›¾åƒï¼›ä¸‹ä¸€ä»»åŠ¡å‰é‡æ–°ç”Ÿæˆç¡®ä¿å¤šæ ·æ€§
      - **éšç§ä¿æŠ¤**ï¼šæ— éœ€å†å²æ•°æ®å­˜å‚¨ï¼›åˆæˆé‡å»ºæ¶ˆé™¤éšç§æ‹…å¿§
      - **æˆæœ¬æ•ˆç›Š**ï¼šæ¯ä»»åŠ¡1Kå›¾åƒé€šè¿‡Stable Diffusion vs å­˜å‚¨/è®¿é—®å¤§è§„æ¨¡çœŸå®æ•°æ®é›†
  - **æœºæ„**ï¼šæ­¦æ±‰å¤§å­¦ã€ä¸­ç§‘é™¢ã€æ­¦æ±‰AIç ”ç©¶
  - **ä½œè€…**ï¼šå´æ–Œã€å¸ˆæ­¦è½©ã€ç‹é‡‘æ¡¥ã€å¶èŒ«
  - **å¼€æº**ï¼šâœ… [ä»£ç ](https://github.com/Luo-Jiaming/GIFT_CL)
  - **æ„ä¹‰**ï¼š
      - **å¤šæ¨¡æ€CLçªç ´**ï¼šé¦–æ¬¡æˆåŠŸå°†æ‰©æ•£ç”Ÿæˆåˆæˆæ•°æ®åº”ç”¨äºVLMæŒç»­å­¦ä¹ 
      - **åŒé‡çŸ¥è¯†ä¿æŒ**ï¼šåŒæ—¶ç»´æŠ¤é¢„è®­ç»ƒæ³›åŒ–å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ - å®é™…VLMéƒ¨ç½²çš„å…³é”®
      - **åˆæˆæ•°æ®èŒƒå¼**ï¼šå½“é€‚å½“è®¾è®¡æ—¶å±•ç°åˆæˆæ•°æ®å¯¹CLçš„ä¼˜åŠ¿è¶…è¿‡çœŸå®æ•°æ®å›æ”¾
      - **å®é™…å½±å“**ï¼šå®ç°ç”Ÿäº§ä¸­é«˜æ•ˆVLMæ›´æ–°ï¼Œæ— ç¾éš¾æ€§é—å¿˜ã€å­˜å‚¨å¼€é”€æˆ–éšç§é—®é¢˜
  
  #### ğŸ”€ è·¨æ¨¡æ€è¡¨ç¤ºè½¬ç§»ï¼ˆæ— éœ€çœŸå®å›¾åƒï¼‰
  

</details>
<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2503.12999">ğŸ“„ Concept-as-Tree (CaT)</a></b><br>
<code>arXiv 2503.12999</code>
</summary>

  - **æ•°æ®åˆæˆæ–¹æ³•** - **åˆ†å±‚æ¦‚å¿µæ ‘æ¡†æ¶çš„å¯æ§åˆæˆæ•°æ®ç”Ÿæˆ**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–ä¸ªVLMä¸ªæ€§åŒ–çš„å¯æ§åˆæˆæ•°æ®æµæ°´çº¿ï¼Œä½¿ç”¨æ ‘çŠ¶æ¦‚å¿µè¡¨ç¤ºç”Ÿæˆä¸åŒéš¾åº¦å’Œå¤šæ ·æ€§çš„æ­£/è´Ÿæ ·æœ¬
      - **ä¸‰å±‚æ ‘ç»“æ„**ï¼šæ ¹èŠ‚ç‚¹ï¼ˆæ¦‚å¿µç±»åˆ«ï¼š"cat", "dog"ï¼‰ï¼Œç»´åº¦ï¼ˆå±æ€§æ–¹é¢ï¼š"appearance", "behavior", "location"ï¼‰ï¼Œå±æ€§ï¼ˆå…·ä½“ç‰¹å¾ï¼š"sitting", "lying", "climbing"ï¼‰
      - **è‡ªåŠ¨åŒ–æ ‘æ„å»º**ï¼šVLMæè¿° â†’ æ‰¹é‡æ‘˜è¦ â†’ å¤šè½®æŠ•ç¥¨æœºåˆ¶è‡ªæˆ‘ç²¾ç‚¼å®ç°æ­£äº¤æ€§å’Œå®Œæ•´æ€§
      - **æ•°æ®è§„æ¨¡**ï¼šä»…éœ€1-3å¼ ç”¨æˆ·æä¾›å›¾åƒï¼Œç”Ÿæˆå¯æ§çš„æ­£/è´Ÿæ ·æœ¬ç”¨äºä¸ªæ€§åŒ–å¾®è°ƒ
  - **å…³é”®æŠ€æœ¯ç»„ä»¶**ï¼š
      - **æ ‘ç¼–è¾‘æ“ä½œ**ï¼š(1) æ·»åŠ ç»´åº¦ - å¢åŠ å¤šæ ·æ€§å’Œå¯¹è¯èƒ½åŠ›ï¼Œ(2) åˆ é™¤ç»´åº¦ - é™ä½å¤šæ ·æ€§ä»¥ä¸“æ³¨å­¦ä¹ ï¼Œ(3) ä¿®æ”¹ç»´åº¦ - å¹³è¡¡å¤šæ ·æ€§æ§åˆ¶
      - **å¯æ§æ ·æœ¬ç”Ÿæˆ**ï¼šæ­£æ ·æœ¬é€šè¿‡åœ¨ç”¨æˆ·å›¾åƒ+æ ¹èŠ‚ç‚¹ä¸Šå¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼›ç®€å•è´Ÿæ ·æœ¬é€šè¿‡æ ¹ç±»åˆ«æ›¿æ¢ï¼›å›°éš¾è´Ÿæ ·æœ¬é€šè¿‡ç»´åº¦ä¿®æ”¹åŒæ—¶ä¿ç•™æ ¹
      - **PCSè¯„åˆ†è¿‡æ»¤**ï¼šåŸºäºæ‰°åŠ¨çš„æ¦‚å¿µç‰¹å®šè¯„åˆ†é€šè¿‡å—æ´—ç‰Œå’ŒCLIPç›¸ä¼¼åº¦å·®å¼‚åŒºåˆ†æ¦‚å¿µç‰¹å®š(CS) vs æ¦‚å¿µæ— å…³(CA)ä¿¡æ¯
      - **å¤šç±»å‹æ ·æœ¬ç­–ç•¥**ï¼šç®€å•è´Ÿæ ·æœ¬æå‡è¯†åˆ«ï¼›å›°éš¾è´Ÿæ ·æœ¬å¢å¼ºVQA/å¯¹è¯ï¼›ç»„åˆæ–¹æ³•åœ¨ä»»åŠ¡é—´å®ç°æœ€ä½³æ€§èƒ½
  - **å®éªŒæ¡†æ¶**ï¼š
      - **ç³»ç»Ÿæ€§åˆ†æ**ï¼šç ”ç©¶æ­£/è´Ÿæ ·æœ¬å½±å“å’Œè·¨è¯†åˆ«ã€VQAã€æ ‡é¢˜ã€é€‰æ‹©ä»»åŠ¡çš„å¤šæ ·æ€§è¦æ±‚
      - **è·¨æ¨¡å‹éªŒè¯**ï¼šMyVLMã€Yo'LLaVAã€MC-LLaVAåŸºçº¿æ˜¾ç¤ºåˆæˆæ•°æ®é›†æˆçš„ä¸€è‡´æ”¹è¿›
      - **å¤šæ ·æ€§ä¼˜åŒ–**ï¼šè¯†åˆ«æœ€ä½³å¤šæ ·æ€§æ°´å¹³ - è¿‡åº¦å¤šæ ·æ€§å¼•å…¥å™ªå£°ï¼Œä¸è¶³å¤šæ ·æ€§é™åˆ¶æ³›åŒ–
  - **å®éªŒç»“æœ**ï¼š
      - **MyVLMå¢å¼º**ï¼šè¯†åˆ«+3.4%ï¼ŒVQA+4.5%ï¼Œæ ‡é¢˜+2.6%ï¼ˆReal+Syn+Plusè®¾ç½®ï¼‰
      - **Yo'LLaVAå¢å¼º**ï¼šè¯†åˆ«+2.2%ï¼ŒVQA+3.9%ï¼Œæ ‡é¢˜+5.3%ï¼Œåœ¨æŸäº›åœºæ™¯è¾¾åˆ°æ¥è¿‘GPT-4oæ€§èƒ½
      - **MC-LLaVAå¢å¼º**ï¼šè¯†åˆ«+3.0%ï¼ŒVQA+4.2%ï¼Œæ ‡é¢˜+5.3%ï¼Œè·¨æ•°æ®é›†ç¨³å®šæ”¹è¿›
      - **è´¨é‡éªŒè¯**ï¼šäººå·¥è¯„ä¼°æ˜¾ç¤ºåˆæˆæ­£æ ·æœ¬ä¸åŸå§‹æ ·æœ¬ç›¸å½“ï¼Œåˆæˆå›°éš¾è´Ÿæ ·æœ¬æ˜¾è‘—ä¼˜äºæ£€ç´¢è´Ÿæ ·æœ¬
  - **æ•°æ®è´¨é‡æ´å¯Ÿ**ï¼š
      - **PCSè¯„åˆ†æœ‰æ•ˆæ€§**ï¼šé«˜PCSè¯„åˆ†ï¼ˆæ­£æ ·æœ¬>0.3ï¼Œå›°éš¾è´Ÿæ ·æœ¬>0.1ï¼‰ä¸æ¦‚å¿µç‰¹å®šä¿¡æ¯å†…å®¹ç›¸å…³
      - **åˆæˆvsæ£€ç´¢**ï¼šåˆæˆè´Ÿæ ·æœ¬ç›¸æ¯”åŸºäºæ£€ç´¢çš„è´Ÿæ ·æœ¬æ˜¾ç¤ºæ›´ä½æ¯”ä¾‹çš„ä½è´¨é‡æ ·æœ¬
      - **æ ‘æ“ä½œåˆ†æ**ï¼šæ·»åŠ æ“ä½œæœ€å¤§ç¨‹åº¦å¢åŠ å¤šæ ·æ€§ï¼Œåˆ é™¤æ“ä½œå‡å°‘å¤šæ ·æ€§ï¼Œä¿®æ”¹æä¾›å¹³è¡¡æ§åˆ¶
  - **å®ç”¨æŒ‡å—**ï¼š
      - **æœ€å°æ•°æ®è¦æ±‚**ï¼š1-3å¼ æ¦‚å¿µå›¾åƒè¶³ä»¥æœ‰æ•ˆä¸ªæ€§åŒ–ï¼ˆvsä¼ ç»Ÿ10+å¼ å›¾åƒï¼‰
      - **å¯æ§ç”Ÿæˆ**ï¼šæ ‘ç¼–è¾‘é¢‘ç‡å’Œç±»å‹ç›´æ¥æ§åˆ¶åˆæˆæ•°æ®å¤šæ ·æ€§å’Œä»»åŠ¡ç‰¹å®šæ”¹è¿›
      - **è´¨é‡ä¿è¯**ï¼šPCSè¯„åˆ†è¿‡æ»¤åœ¨æ¦‚å¿µä¸­å¿ƒæ•°æ®é€‰æ‹©æ–¹é¢æ¯”å•çº¯ä½™å¼¦ç›¸ä¼¼åº¦æ›´æœ‰æ•ˆ
      - **æ··åˆè®­ç»ƒ**ï¼šåŸå§‹+åˆæˆæ•°æ®ç»„åˆå®ç°æœ€ä½³æ€§èƒ½ï¼Œçº¯åˆæˆæ•°æ®æ˜¾ç¤ºåˆ†å¸ƒåç§»æŒ‘æˆ˜
  - **æœºæ„**ï¼šåŒ—äº¬å¤§å­¦ã€è‹±ç‰¹å°”ä¸­å›½å®éªŒå®¤ã€é¦™æ¸¯ä¸­æ–‡å¤§å­¦MMLab
  - **ä½œè€…**ï¼šå®‰ç‘å·ã€æ›¾å‡¯ã€é™†æ˜ã€æ¨æ€æ¶µã€å¼ ä»»é”ç­‰
  - **å¼€æº**ï¼šâœ… [ä»£ç ](https://github.com/zengkaiya/CaT)
  - **æ„ä¹‰**ï¼š
      - **ä¸ªæ€§åŒ–çªç ´**ï¼šé¦–ä¸ªVLMä¸ªæ€§åŒ–ç³»ç»Ÿæ¡†æ¶ï¼Œæœ€å°ç”¨æˆ·æ•°æ®éœ€æ±‚
      - **å¯æ§åˆæˆ**ï¼šé€šè¿‡å¯è§£é‡Šçš„æ ‘æ“ä½œå®ç°å¯¹åˆæˆæ•°æ®ç‰¹å¾çš„ç²¾ç¡®æ§åˆ¶
      - **è´¨é‡è¯„ä¼°åˆ›æ–°**ï¼šPCSè¯„åˆ†ä¸ºè¯„ä¼°åˆæˆå›¾åƒä¸­æ¦‚å¿µç‰¹å®šä¿¡æ¯æä¾›æ–°æ–¹æ³•
      - **å®é™…å½±å“**ï¼šä½¿VLMä¸ªæ€§åŒ–åœ¨æœ‰é™ç”¨æˆ·æä¾›ç¤ºä¾‹çš„çœŸå®ä¸–ç•Œéƒ¨ç½²ä¸­å˜å¾—å¯è¡Œ
  
  #### ğŸ”„ æŒç»­å­¦ä¹ ä¸ç¾éš¾æ€§é—å¿˜ç¼“è§£
  

</details>
---

#### ğŸ› ï¸ å·¥å…·è¾…åŠ©æ ‡æ³¨ç”Ÿæˆï¼ˆæ•°æ®åˆæˆç”¨ï¼‰

> Following tools are commonly used in data synthesis pipelines

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=All-Seeing%20Project">ğŸ“„ All-Seeing Project</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** (Section 3):
      - Uses SAM, RAM, Tag2Text and other tools to automatically generate multi-level annotations
      - Pipeline: Image â†’ Segmentation+Tags â†’ Region Description â†’ Instruction Data
      - Builds AS-1B dataset (1.2B region-text pairs)
  - **This is true data synthesis**: Uses tool combination to generate new annotations
  - **Open Source**: âœ… [Dataset](https://huggingface.co/datasets/OpenGVLab/AS-V2) | [Code](https://github.com/OpenGVLab/all-seeing)
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.09925">ğŸ“„ TaskGalaxy</a></b><br>
<code>ICLR 2025</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-ICLR_2025_--_å¿«æ‰‹ç§‘æŠ€-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **å¤§è§„æ¨¡ä»»åŠ¡ç±»å‹æ‰©å±•** - æ„å»ºåŒ…å«19,227ä¸ªå±‚çº§åŒ–ä»»åŠ¡ç±»å‹å’Œ413Kæ ·æœ¬çš„å¤šæ¨¡æ€æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–Pipelineæ˜¾è‘—æå‡ä»»åŠ¡å¤šæ ·æ€§
  - **æ•°æ®åˆæˆæ–¹æ³•** - **GPT-4oé©±åŠ¨çš„ä»»åŠ¡ç±»å‹å±‚çº§æ‰©å±• + å¤šè£åˆ¤è¿‡æ»¤Pipeline**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªä¸‡çº§ä»»åŠ¡ç±»å‹çš„å¤šæ¨¡æ€æ•°æ®é›†ï¼Œé€šè¿‡GPT-4oè‡ªåŠ¨æ‰©å±•ä»»åŠ¡åˆ†ç±»ä½“ç³»ï¼Œç»“åˆCLIPè¿‡æ»¤å’Œå¤šå¼€æºæ¨¡å‹è¯„åˆ†ç¡®ä¿è´¨é‡
      - **é—®é¢˜è¯†åˆ«**:
        - ç°æœ‰æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ä»»åŠ¡ç±»å‹æœ‰é™ï¼ˆå¦‚Vision-Flanä»…196ç±»ï¼‰ï¼Œé™åˆ¶æ¨¡å‹æ³›åŒ–èƒ½åŠ›
        - äººå·¥æ ‡æ³¨ä»»åŠ¡ç±»å‹æˆæœ¬é«˜ã€è€—æ—¶é•¿ï¼Œéš¾ä»¥è§„æ¨¡åŒ–
        - ä»»åŠ¡ç±»å‹ä¸å›¾åƒåŒ¹é…åº¦ä½å¯¼è‡´è®­ç»ƒæ•°æ®è´¨é‡ä¸ä½³
      - **äº”æ­¥è‡ªåŠ¨åŒ–ç”ŸæˆPipeline**:
        1. **å±‚çº§åŒ–ä»»åŠ¡ç±»å‹ç”Ÿæˆ**:
           - **ç§å­ä»»åŠ¡å®šä¹‰**: äººå·¥å®šä¹‰å°‘é‡ä¸€çº§ä»»åŠ¡ç±»å‹ï¼ˆå¦‚OCRã€Image Descriptionã€Logical Reasoningï¼‰
           - **GPT-4oè¿­ä»£æ‰©å±•**:
             - **ä¸€çº§ä»»åŠ¡**: ä»ç§å­ä»»åŠ¡æ‰©å±•ä¸º115ä¸ªä¸€çº§ä»»åŠ¡ç±»å‹
             - **äºŒçº§ä»»åŠ¡**: ä¸ºæ¯ä¸ªä¸€çº§ä»»åŠ¡ç”Ÿæˆ2,796ä¸ªäºŒçº§å­ä»»åŠ¡
             - **ä¸‰çº§ä»»åŠ¡**: è¿›ä¸€æ­¥ç»†åˆ†ä¸º14,370ä¸ªä¸‰çº§ä»»åŠ¡
           - **Promptè®¾è®¡**: ä¸ºä¸åŒå±‚çº§è®¾è®¡ä¸“é—¨promptï¼Œç¡®ä¿æ‰©å±•çš„ç³»ç»Ÿæ€§å’Œå®Œæ•´æ€§
           - **æœ€ç»ˆè§„æ¨¡**: 19,227ä¸ªå±‚çº§åŒ–ä»»åŠ¡ç±»å‹ï¼ˆ1:2:3æ¯”ä¾‹ = 115:2,796:14,370ï¼‰
        2. **å›¾åƒæ•°æ®æ”¶é›†**:
           - **å¤šæºå›¾åƒ**: ä»ALLaVAã€Visual Genomeã€LAIONã€DocVQAã€CLEVR-Mathç­‰å…¬å¼€æ•°æ®é›†æ”¶é›†å›¾åƒ
           - **ä¿æŒåŸå§‹åˆ†è¾¨ç‡**: ä¸è¿›è¡Œé¢å¤–é¢„å¤„ç†
           - **æ”¯æŒå¤šæ ·å›¾åƒç±»å‹**: è‡ªç„¶åœºæ™¯ã€æ–‡æ¡£ã€å›¾è¡¨ã€è‰ºæœ¯ä½œå“ã€æ°´å°å›¾åƒç­‰
        3. **ä»»åŠ¡ç±»å‹-å›¾åƒåŒ¹é…ï¼ˆCLIPè¿‡æ»¤ï¼‰**:
           - **æ–‡æœ¬-å›¾åƒç›¸ä¼¼åº¦è®¡ç®—**: ä½¿ç”¨CLIPè®¡ç®—ä»»åŠ¡ç±»å‹æ–‡æœ¬ä¸å›¾åƒçš„ç›¸ä¼¼åº¦
           - **åˆæ­¥ç­›é€‰**: ä¸ºæ¯å¼ å›¾åƒåŒ¹é…æœ€ç›¸å…³çš„ä»»åŠ¡ç±»å‹
           - **é—®é¢˜**: CLIPåŒ¹é…æ€§èƒ½æœ‰é™ï¼Œå¯èƒ½äº§ç”Ÿè¯¯åŒ¹é…
        4. **é—®ç­”å¯¹ç”Ÿæˆï¼ˆGPT-4oï¼‰**:
           - **è¾“å…¥**: å›¾åƒ + åŒ¹é…çš„ä»»åŠ¡ç±»å‹æ–‡æœ¬
           - **è¾“å‡º**: é—®é¢˜-ç­”æ¡ˆå¯¹ï¼ˆJSONæ ¼å¼ï¼‰
           - **Promptè®¾è®¡**: è¦æ±‚ç”Ÿæˆå¤æ‚é—®é¢˜å¹¶æä¾›è¯¦ç»†ç­”æ¡ˆ
           - **å¤šæ ·æ€§**: æ¯ä¸ªä»»åŠ¡ç±»å‹-å›¾åƒå¯¹ç”Ÿæˆå¤šä¸ªä¸åŒé—®é¢˜
        5. **å¤šè£åˆ¤è¯„åˆ†è¿‡æ»¤ï¼ˆReferee Screeningï¼‰**:
           - **ä¸‰æ¨¡å‹å…±è¯†æœºåˆ¶**: ä½¿ç”¨ä¸‰ä¸ªé«˜æ€§èƒ½å¼€æºå¤šæ¨¡æ€æ¨¡å‹ï¼ˆInternVLã€Qwen-VLã€å…¶ä»–MLLMï¼‰ä½œä¸ºè£åˆ¤
           - **è¯„åˆ†æ ‡å‡†**: æ¯ä¸ªæ¨¡å‹å¯¹ä»»åŠ¡ç±»å‹ã€é—®é¢˜ä¸å›¾åƒçš„åŒ¹é…åº¦æ‰“åˆ†ï¼ˆ0æˆ–1ï¼‰
           - **ç­›é€‰è§„åˆ™**: ä»…ä¿ç•™ç´¯ç§¯å¾—åˆ†â‰¥2çš„æ ·æœ¬ï¼ˆä¸‰ä¸ªæ¨¡å‹ä¸­è‡³å°‘ä¸¤ä¸ªè®¤å¯ï¼‰
           - **ä¼˜åŠ¿**: æå‡ä»»åŠ¡ç±»å‹ã€é—®é¢˜ä¸å›¾åƒçš„å¯¹é½å‡†ç¡®æ€§ï¼Œé™ä½é—­æºAPIæˆæœ¬
           - **å¹³è¡¡ç­–ç•¥**: ä¸ºä¿æŒä»»åŠ¡ç±»å‹å¹³è¡¡ï¼Œæ¯ä¸ªä»»åŠ¡ç±»å‹éšæœºé€‰æ‹©1-55ä¸ªæ ·æœ¬
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **å®Œå…¨è‡ªåŠ¨åŒ–**: é™¤å°‘é‡ç§å­ä»»åŠ¡å¤–ï¼Œæ•´ä¸ªpipelineæ— éœ€äººå·¥å¹²é¢„
        - **ä»»åŠ¡ç±»å‹æ•°é‡**: 19,227ä¸ªä»»åŠ¡ç±»å‹ï¼Œæ˜¯Vision-Flançš„98å€
        - **è´¨é‡æ§åˆ¶**: å¤šè£åˆ¤æœºåˆ¶ç¡®ä¿æ•°æ®è´¨é‡ï¼Œé¿å…å•æ¨¡å‹åå·®
        - **å¯æ‰©å±•æ€§**: Pipelineå¯é€‚åº”æ–°å›¾åƒç±»å‹å’Œä»»åŠ¡ç±»å‹
  - **TaskGalaxyæ•°æ®é›†**:
      - **æ€»è§„æ¨¡**: 413,648ä¸ªé«˜è´¨é‡é—®ç­”å¯¹
      - **ä»»åŠ¡ç±»å‹**: 19,227ä¸ªå±‚çº§åŒ–ä»»åŠ¡ç±»å‹
      - **æ ·æœ¬åˆ†å¸ƒ**: æ¯ä¸ªä»»åŠ¡ç±»å‹1-55ä¸ªæ ·æœ¬
        - 1-10æ ·æœ¬: 50.1%çš„ä»»åŠ¡ç±»å‹
        - 11-20æ ·æœ¬: 11.1%
        - 21-40æ ·æœ¬: 10.21%
        - 41-55æ ·æœ¬: 27.99%
      - **å±‚çº§åˆ†å¸ƒ**: ä¸€çº§:äºŒçº§:ä¸‰çº§ = 1:2:3 (115:2,796:14,370)
  - **å®éªŒç»“æœ** - **åœ¨æ‰€æœ‰16ä¸ªåŸºå‡†ä¸Šå‡æœ‰æå‡**:
      - **LLaVA-v1.5-7B** (åŠ å…¥TaskGalaxyå¾®è°ƒ):
        - MME: 1506â†’1533, MMBench: 64.69%â†’68.04%, ScienceQA: 69.51%â†’71.26%
        - MathVista: 26.7%â†’31.4% (+4.7%), ChartQA: 14.72%â†’20.20% (+5.48%)
        - AI2D: 25.32%â†’38.26% (+12.94%), HalluBench: 50.05%â†’51.74%
        - **å¹³å‡æå‡**: 44.46%â†’48.96% (+4.5%, ä¸å«MME)
      - **LLaVA-v1.5-13B** (åŠ å…¥TaskGalaxyå¾®è°ƒ):
        - MME: 1532â†’1600, MMBench: 68.47%â†’69.85%, MathVista: 28.1%â†’33.3% (+5.2%)
        - ChartQA: 15.56%â†’23.44% (+7.88%), AI2D: 21.13%â†’41.19% (+20.06%)
        - **å¹³å‡æå‡**: 45.21%â†’49.04% (+3.83%)
      - **InternVL-Chat-v1.0-7B** (åŠ å…¥TaskGalaxyå¾®è°ƒ):
        - MMBench: 65.29%â†’67.10%, ScienceQA: 66.4%â†’70.93%, MathVista: 27.7%â†’30.8%
        - MMMU: 27.0%â†’34.9% (+7.9%), AI2D: 35.96%â†’38.57%
        - **å¹³å‡æå‡**: 47.79%â†’50.79% (+3.0%)
      - **InternVL-Chat-v1.0-13B** (åŠ å…¥TaskGalaxyå¾®è°ƒ):
        - MMBench: 65.64%â†’69.50%, ScienceQA: 70.12%â†’72.72%, MathVista: 28.7%â†’30.5%
        - AI2D: 38.55%â†’52.60% (+14.05%), Q-Bench: 56.13%â†’58.60%
        - **å¹³å‡æå‡**: 49.90%â†’53.17% (+3.27%)
  - **æ¶ˆèç ”ç©¶å…³é”®å‘ç°**:
      - **ä»»åŠ¡ç±»å‹æ•°é‡è‡³å…³é‡è¦**:
        - å›ºå®š100Kæ ·æœ¬ï¼Œä»»åŠ¡ç±»å‹ä»2Kå¢è‡³19Kï¼Œæ€§èƒ½æŒç»­æå‡
        - è¯æ˜ä»»åŠ¡å¤šæ ·æ€§æ¯”æ•°æ®é‡æ›´é‡è¦
      - **æ ·æœ¬æ•°é‡çš„å½±å“**:
        - å›ºå®š19,227ä»»åŠ¡ç±»å‹ï¼Œæ ·æœ¬ä»76Kå¢è‡³413Kï¼Œæ€§èƒ½é€æ­¥æå‡
        - ä½†åœ¨æŸäº›åŸºå‡†ï¼ˆå¦‚LLaVA-in-the-wildï¼‰ä¸Šå­˜åœ¨æœ€ä¼˜æ ·æœ¬é‡ï¼ˆ281Kï¼‰
      - **vs. è§„åˆ™æ–¹æ³•å’Œé—­æºæ¨¡å‹**: TaskGalaxyçš„ä»»åŠ¡è¦†ç›–åº¦å’Œè´¨é‡ä¼˜äºæ‰‹å·¥è§„åˆ™æ„å»ºå’Œé—­æºæ¨¡å‹ç”Ÿæˆ
  - **ä»»åŠ¡ç±»å‹ç¤ºä¾‹**ï¼ˆå±•ç¤ºä»»åŠ¡å±‚çº§ç»“æ„ï¼‰:
      - **ä¸€çº§**: OCR, Image Description, Logical Reasoning, Suggestions, Storytelling
      - **äºŒçº§**: OCRâ†’webpage OCR / handwritten OCR, Image Descriptionâ†’location-based / historical context
      - **ä¸‰çº§**: webpage OCRâ†’extract links / recognize style, location-basedâ†’describe cityscapes / identify landmarks
  - **æœºæ„**: å¿«æ‰‹ç§‘æŠ€ï¼ˆKuaishou Technologyï¼‰
  - **ä½œè€…**: Jiankang Chen, Tianke Zhang, Changyi Liu, Haojie Ding, Yaya Shi, Feng Cheng, Huihui Xiao, Bin Wen, Fan Yang, Tingting Gao, Di Zhang
  - **å‘å¸ƒæ—¶é—´**: ICLR 2025, arXiv 2025å¹´2æœˆ
  - **è®ºæ–‡é“¾æ¥**: [arXiv:2502.09925](https://arxiv.org/abs/2502.09925)
  - **å¼€æº**: âœ… [GitHub](https://github.com/Kwai-YuanQi/TaskGalaxy)
  - **æ„ä¹‰**:
      - **ä»»åŠ¡ç±»å‹çªç ´**: é¦–æ¬¡å®ç°ä¸‡çº§ä»»åŠ¡ç±»å‹è¦†ç›–ï¼Œæ˜¯ç°æœ‰æ•°æ®é›†çš„100å€
      - **è‡ªåŠ¨åŒ–Pipeline**: å¤§å¹…é™ä½ä»»åŠ¡ç±»å‹æ‰©å±•æˆæœ¬ï¼Œæå‡å¯æ‰©å±•æ€§
      - **ä»»åŠ¡å¤šæ ·æ€§ä»·å€¼**: å®è¯è¯æ˜ä»»åŠ¡å¤šæ ·æ€§å¯¹æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§è¶…è¿‡æ•°æ®é‡
      - **å¤šè£åˆ¤æœºåˆ¶**: åˆ›æ–°çš„è´¨é‡æ§åˆ¶æ–¹æ³•ï¼Œå¹³è¡¡æˆæœ¬ä¸è´¨é‡
      - **å®ç”¨æ€§**: åœ¨16ä¸ªä¸»æµåŸºå‡†ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œè¯æ˜æ–¹æ³•çš„é€šç”¨æ€§
  

</details>
---

## ğŸ¯ VLMè‡ªæˆ‘æ”¹è¿›ä¸å¼ºåŒ–å­¦ä¹ 

This emerging category focuses on **scalable VLM self-improvement** through reinforcement learning and gamified environments, enabling models to enhance their reasoning capabilities **without human annotation**. These methods leverage competitive dynamics, strategic gameplay, and iterative policy optimization to achieve sustained performance improvements across diverse reasoning tasks.

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Chart-CoCa">ğŸ“„ Chart-CoCa</a></b><br>
<code>Paper</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-CIKM_2025-red?style=flat-square"/>
</summary>

  - **Focus**: **Chart Understanding Self-Improvement via Code-Driven Synthesis and Candidate-Conditioned Answering** - VLM self-generates codeâ†’executes to create chartsâ†’automatically extracts precise annotationsâ†’trains with candidate-conditioned answering, achieving chart understanding improvement without human annotation or external models
  - **Data Synthesis Method** - **Code-Mediated Chart Synthesis + Candidate-Conditioned Answering Training**:
      - **Core Innovation**: First fully self-improving chart understanding paradigm, using code as intermediary to ensure precision and reliability of synthetic data, without human annotation or teacher models
      - **Problem Identification**:
        - VLMs struggle with chart understanding tasks (inaccurate descriptions, insufficient reasoning complexity)
        - Traditional synthetic data methods suffer from noisy labels (direct chartâ†’text generation hard to guarantee accuracy)
        - Existing methods rely on strong teacher models (e.g., GPT-4) or extensive human annotation
      - **Code-Driven Synthesis Pipeline (Three Steps)**:
        1. **Chart Description Generation (Step 1)**:
           - **Input**: Unlabeled real chart c
           - **Output**: Chart description d (including title, x/y-axis labels, data points, legends, etc.)
           - **Model**: VLM M (initial version, e.g., InternVL2-8B)
           - **Formula**: d = M_LMM(c)
           - **Purpose**: Transform visual information into structured text description
        2. **Code Generation (Step 2)**:
           - **Input**: Chart description d
           - **Output**: Executable Python Matplotlib code p
           - **Model**: VLM's language model component M_LM
           - **Formula**: p = M_LM(d)
           - **Constraint**: Must use Python Matplotlib library (facilitates execution and information extraction)
           - **Key Advantage**: Code executability ensures generated chart precisely matches description
        3. **Code Execution and Information Extraction (Step 3)**:
           - **Chart Generation**: Execute code p to generate new chart c* (precisely matching description d)
           - **Information Extraction**: Extract chart elements through reflection during code execution:
             - **Layout**: fig, axes = plt.subplots(rows, columns)
             - **Title**: axes[i,j].get_title()
             - **X/Y Labels**: axes[i,j].get_xlabel(), get_ylabel()
             - **Legend**: axes[i,j].get_legend()
             - **Ticks**: axes[i,j].get_xticklabels(), get_yticklabels()
             - **Colorbar**: axes[i,j].get_images()[0].colorbar
             - **Lines**: axes[i,j].lines
           - **QA Pair Generation**:
             - Use CharXiv's descriptive questions as seeds (simple, no design cost, easy answer access)
             - Automatically generate precise answers based on extracted information
             - Example: Q: "What is the chart title?" A: axes[0,0].get_title() â†’ "Optimizations in SizeAware++"
             - Supports 8 question types: layout, title, labels, legends, ticks, colorbar, lines
           - **Output**: High-quality triplets âŸ¨c*, q*, a*âŸ© (chart, question, answer)
      - **Key Technical Advantages**:
        - **Zero Noisy Labels**: Code execution guarantees absolute consistency between chart and annotations (vs noise in direct generation)
        - **Full Automation**: No human annotation or external strong models needed
        - **Verifiability**: Code is traceable, each annotation has clear provenance
        - **Scalability**: Applicable to any unlabeled chart dataset
      - **Candidate-Conditioned Answering**:
        - **Motivation**: Direct fine-tuning problematic - questions simple/fixed, model struggles to handle flexible questions
        - **Inspiration**: Test-time scaling (increasing inference budget improves performance)
        - **Training Stage (Three Steps)**:
          1. **Candidate Answer Generation**: Given âŸ¨c*, q*âŸ©, initial VLM M generates k candidate responses r_1,...,r_k
             - Formula: r_1,...,k = M(c*, q*)
             - Use sampling strategy (temperature>0) for diverse candidates
          2. **Answer Model Training**: Train new answer VLM M_ANS, input (c*, q*, r_1,...,r_k), output final answer a
             - Formula: a = M_ANS(c*, q*, r_1,...,r_k)
             - M_ANS learns to synthesize multiple candidates and generate optimal answer
             - Training loss: L_answer = -log P(a* | c*, q*, r_1,...,r_k)
          3. **Iterative Update**: Use (c*, q*, a) to update initial VLM M parameters, obtaining M_ANS
        - **Inference Stage (Two Steps)**:
          1. Initial VLM M generates k candidates: r_1,...,k = M(c, q)
          2. Trained M_ANS synthesizes candidates to generate final answer: Ã¢ = M_ANS(c, q, r_1,...,k)
        - **Advantages**:
          - Enhances model's ability to handle flexible, diverse questions
          - Leverages collective wisdom of multiple candidates
          - Test-time scaling brings performance improvements
  - **Experimental Results - Significant Improvements on CharXiv Dataset**:
      - **CharXiv Benchmark**: Includes descriptive tasks (Information Extraction, Pattern Recognition, Enumeration, Counting, Compositionality) and reasoning tasks (Text in Chart/General, Number in Chart/General)
      - **InternVL2-8B Self-Improvement Effects**:
        - **Descriptive Tasks**: 54.10% â†’ **69.60%** (+15.50%)
          - Information Extraction: 69.40% â†’ 74.20% (+4.80%)
          - Pattern Recognition: 40.52% â†’ 75.46% (+34.94%, largest improvement)
          - Enumeration: 19.64% â†’ 26.79% (+7.15%)
          - Counting: 54.10% â†’ 69.60% (+15.50%)
        - **Reasoning Tasks**: 23.60% â†’ **31.60%** (+8.00%)
          - Text in Chart: 44.76% â†’ 58.95% (+14.19%)
          - Text in General: 61.83% â†’ 68.19% (+6.36%)
          - Number in Chart: 19.64% â†’ 26.79% (+7.15%)
          - Number in General: 14.85% â†’ 25.33% (+10.48%)
        - **Overall Improvement**: Average +11.75%, proving effectiveness of fully self-improving paradigm
      - **Cross-Model Generalization Verification** (using Chart-CoCa method):
        - **LLaVA-1.6-7B**: 32.77% â†’ **47.83%** (+15.06%, descriptive); 15.50% â†’ **23.10%** (+7.60%, reasoning)
        - **Qwen2VL-7B**: 59.90% â†’ **71.75%** (+11.85%, descriptive); 30.80% â†’ **36.90%** (+6.10%, reasoning)
        - **InternVL2-26B**: 61.90% â†’ **72.63%** (+10.73%, descriptive); 34.60% â†’ **39.50%** (+4.90%, reasoning)
        - **Conclusion**: Chart-CoCa method effective across different model scales and architectures
      - **Comparison with Majority Voting**:
        - Majority Voting (5 candidates): Descriptive 61.38%, Reasoning 26.70%
        - Chart-CoCa (5 candidates): Descriptive **69.60%**, Reasoning **31.60%**
        - **Improvement**: +8.22% (descriptive), +4.90% (reasoning)
        - **Reason**: Majority Voting prone to majority bias; Chart-CoCa learns to synthesize diverse information through candidate-conditioned answering
      - **Pass@K Analysis (Coverage)**:
        - **Descriptive Tasks**: Pass@1=54.1%, Pass@30=**85.95%** (+31.85%)
        - **Reasoning Tasks**: Pass@1=23.6%, Pass@30=**55.8%** (+32.2%)
        - **Conclusion**: VLMs have strong inherent capability (high accuracy with sufficient trials), but need methods to unlock this potential
      - **Code Execution Success Rate Analysis**:
        - **Overall Success Rate**: 70.7% (after up to 5 retries)
        - **Error Type Distribution**: ValueError (36.0%), IndexError (24.1%), SyntaxError (5.6%), AttributeError (5.0%), TypeError (2.9%), Others (1.5%)
        - **Retry Improvement**: Among samples failing on first attempt, 24% succeed through retries; but some samples stuck in same error
        - **Improvement Room**: Targeted error handling could further improve code execution success rate
  - **Ablation Study Key Findings**:
      - **Necessity of Code Intermediary (-Code)**:
        - Removing code generation step, directly generating QA from charts: Descriptive -9.20%, Reasoning -5.50%
        - **Conclusion**: Code intermediary ensures data precision, significantly better than direct generation
      - **Necessity of Chart Description (-Desc)**:
        - Removing chart description step, directly generating code from charts: Descriptive -4.53%, Reasoning -3.60%
        - **Conclusion**: Chart description as intermediate representation reduces difficulty of direct code generation
      - **Importance of Both Combined (-Both)**:
        - Removing both description and code steps: Descriptive -13.68%, Reasoning -7.10%
        - **Conclusion**: Complete pipeline crucial for performance
  - **Qualitative Analysis**:
      - **Candidate Answer Diversity**: 5 candidates show different reasoning paths, Chart-CoCa can synthesize to select best answer
      - **Error Cases**: Mainly concentrated in questions requiring complex reasoning or precise numerical computation (code generation or logic errors)
      - **Success Cases**: Chart-CoCa excels in most descriptive questions and moderate-difficulty reasoning questions
  - **Institution**: Hong Kong University of Science and Technology (Guangzhou)
  - **Authors**: Gongyao Jiang, Qiong Luo
  - **Publication**: CIKM 2025
  - **Code**: [To be released]
  - **Significance**:
      - **Self-Improvement Paradigm**: First fully self-improving chart understanding method without human annotation or external teacher models
      - **Code Intermediary Innovation**: Proves using code as intermediary eliminates noisy label problem in synthetic data
      - **Candidate-Conditioned Answering**: Innovative training strategy leveraging test-time scaling idea to improve model generalization
      - **Scalability**: Method applicable to any unlabeled chart data, theoretically infinitely scalable for training data
      - **Cross-Model Generalization**: Validated effectiveness across multiple VLM architectures, providing universal self-improvement framework
      - **Practical Value**: Provides low-cost, high-quality data generation and model improvement solution for chart understanding tasks
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2502.02740">ğŸ“„ VLM Dialog Games</a></b><br>
<code>arXiv 2502.02740</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **èšç„¦**: **è§†è§‰è¯­è¨€æ¨¡å‹å¯¹è¯æ¸¸æˆç”¨äºè‡ªæˆ‘æ”¹è¿›** - é€šè¿‡ä¸¤ä¸ªVLMä»£ç†åœ¨ç›®æ ‡å¯¼å‘çš„å‚è€ƒæ¸¸æˆä¸­è‡ªå¯¹å¼ˆï¼Œè‡ªåŠ¨ç­›é€‰æˆåŠŸçš„æ¸¸æˆäº¤äº’ï¼Œç”Ÿæˆé«˜è´¨é‡çš„äº¤é”™å›¾åƒ-æ–‡æœ¬æ•°æ®ç”¨äºå¾®è°ƒ
  - **æ•°æ®åˆæˆæ–¹æ³•** - **ç›®æ ‡å¯¼å‘è‡ªå¯¹å¼ˆæ¡†æ¶ + è‡ªåŠ¨æˆåŠŸæ£€æµ‹**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªåŸºäºå¯¹è¯æ¸¸æˆçš„VLMè‡ªæˆ‘æ”¹è¿›æ¡†æ¶ï¼Œé€šè¿‡ç›®æ ‡å¯¼å‘çš„è‡ªå¯¹å¼ˆç”Ÿæˆé«˜è´¨é‡åˆæˆæ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨æˆ–å¤–éƒ¨æ¨¡å‹
      - **VLMå¯¹è¯æ¸¸æˆæœºåˆ¶**:
        - **æ¸¸æˆè®¾ç½®**: ä½¿ç”¨æœªæ ‡æ³¨å›¾åƒæ„å»ºå‚è€ƒæ¸¸æˆå˜ä½“
          - **Describerï¼ˆæè¿°è€…ï¼‰**: çœ‹åˆ°å•ä¸ªç›®æ ‡å›¾åƒï¼Œè¢«æŒ‡ç¤ºå¿ å®å›ç­”å…³äºè¯¥å›¾åƒçš„é—®é¢˜
          - **Guesserï¼ˆçŒœæµ‹è€…ï¼‰**: çœ‹åˆ°Nå¼ å›¾åƒï¼ˆåŒ…æ‹¬ç›®æ ‡å›¾åƒå’Œå¤šä¸ªå¹²æ‰°å›¾åƒï¼‰ï¼Œé€šè¿‡æé—®è¯†åˆ«ç›®æ ‡å›¾åƒ
        - **æ¸¸æˆæµç¨‹**:
          - Guesseræå‡ºæ¾„æ¸…é—®é¢˜ï¼ˆå¦‚"å›¾åƒä¸­æœ‰å¤šå°‘å¯¹è±¡ï¼Ÿ"ï¼‰
          - Describerå›ç­”é—®é¢˜ï¼ˆå¦‚"æœ‰9ä¸ªå¯¹è±¡"ï¼‰
          - GuesseråŸºäºç´¯ç§¯ä¿¡æ¯åšå‡ºçŒœæµ‹ï¼ˆå¦‚"æˆ‘çŸ¥é“ç­”æ¡ˆäº†ï¼Œæ˜¯å›¾åƒ4"ï¼‰
          - å¦‚æœGuesseræ­£ç¡®è¯†åˆ«ç›®æ ‡å›¾åƒï¼Œæ¸¸æˆæˆåŠŸ
        - **æ¸¸æˆéš¾åº¦æ§åˆ¶**:
          - **å¹²æ‰°å›¾åƒæ•°é‡**: å¢åŠ å¹²æ‰°å›¾åƒæ•°é‡ç›´æ¥å¢åŠ éš¾åº¦ï¼ˆN=2åˆ°8ï¼‰
          - **å›¾åƒç›¸ä¼¼æ€§**: éšæœºé€‰æ‹©å›¾åƒåˆ›å»ºè¾ƒå®¹æ˜“çš„æ¸¸æˆï¼Œè€Œå°†è§†è§‰æˆ–è¯­ä¹‰ç›¸ä¼¼çš„å›¾åƒåˆ†ç»„å¢åŠ æŒ‘æˆ˜
          - **æœ€ä¼˜è®¾ç½®**: N=4åœ¨ç ”ç©¶ä¸­è¾¾åˆ°æœ€ä½³å¹³è¡¡
      - **è‡ªæ”¹è¿›å·¥ä½œæµç¨‹**:
        1. **æ¸¸æˆè®¾ç½®**: é…ç½®å¯¹è¯æ¸¸æˆï¼ŒæŒ‡å®šæœªæ ‡æ³¨å›¾åƒæ•°æ®é›†ï¼ˆOpenImagesã€DOCCIæˆ–é¢†åŸŸç‰¹å®šæ•°æ®é›†å¦‚æœºå™¨äººè§†é¢‘å¸§ï¼‰
        2. **å¯¹è¯ç”Ÿæˆ**: é€šè¿‡VLMä»£ç†çš„è‡ªå¯¹å¼ˆç”Ÿæˆå¯¹è¯
          - **Describerç¤ºä¾‹**: è¾“å…¥=å•ä¸ªå›¾åƒ+é—®é¢˜ï¼Œè¾“å‡º=å¯¹åº”ç­”æ¡ˆ
          - **Guesserç¤ºä¾‹**: è¾“å…¥=Nå¼ å›¾åƒ+ç›®æ ‡å›¾åƒæè¿°æ‘˜è¦ï¼Œè¾“å‡º=æ¾„æ¸…é—®é¢˜æˆ–çŒœæµ‹
          - æ¯ä¸ªæˆåŠŸçš„VLMå¯¹è¯æ¸¸æˆç”Ÿæˆå¤šä¸ªä¸¤ç§ç±»å‹çš„è®­ç»ƒç¤ºä¾‹
        3. **å¯¹è¯è¿‡æ»¤**: åŸºäºæˆåŠŸæ ‡å‡†è¿‡æ»¤ç”Ÿæˆçš„å¯¹è¯
          - **æˆåŠŸæ£€æµ‹**: å¦‚æœGuesserçš„æœ€ç»ˆé€‰æ‹©åŒ¹é…ç›®æ ‡å›¾åƒï¼Œå¯¹è¯è¢«è§†ä¸ºæˆåŠŸ
          - **éªŒè¯æ­¥éª¤**: ä¸ºé¿å…å¶ç„¶æ­£ç¡®çŒœæµ‹ï¼Œä½¿ç”¨ç›¸åŒå›¾åƒä½†æ‰“ä¹±é¡ºåºé‡æ–°è¿è¡Œå¯¹è¯ï¼ŒéªŒè¯åœ¨æ‰€æœ‰æ’åˆ—ä¸­éƒ½èƒ½æ­£ç¡®è¯†åˆ«ç›®æ ‡å›¾åƒ
          - **è®¡ç®—æ•ˆç‡**: é™åˆ¶æµ‹è¯•æ’åˆ—ä¸ºNä¸ªï¼Œç¡®ä¿ç›®æ ‡å›¾åƒå‡ºç°åœ¨æ¯ä¸ªå¯èƒ½ä½ç½®ï¼ˆ1åˆ°Nï¼‰ï¼Œå¹²æ‰°å›¾åƒé¡ºåºå¯ä¿æŒå›ºå®š
        4. **æ¨¡å‹æ”¹è¿›**: ä½¿ç”¨è¿‡æ»¤åçš„æˆåŠŸå¯¹è¯æ¸¸æˆæ•°æ®å¾®è°ƒVLM
          - **æ ‡å‡†ç›‘ç£å¾®è°ƒ**: ä½¿ç”¨è¿‡æ»¤åçš„å¯¹è¯æ•°æ®
          - **è¿­ä»£æ”¹è¿›**: æ”¹è¿›åçš„æ¨¡å‹å¯ä»¥ç”¨äºç”Ÿæˆæ–°çš„ã€æ›´é«˜è´¨é‡çš„æ•°æ®é›†ï¼Œè¿›è¡Œè¿›ä¸€æ­¥æ”¹è¿›ï¼ˆround 1, round 2ç­‰ï¼‰
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **ç›®æ ‡å¯¼å‘**: æ¸¸æˆçš„ç›®æ ‡å¯¼å‘æ€§è´¨ç¡®ä¿ç”Ÿæˆæ•°æ®çš„è´¨é‡ï¼ŒæˆåŠŸæ£€æµ‹æä¾›è‡ªåŠ¨è´¨é‡æ§åˆ¶
        - **è‡ªå¯¹å¼ˆ**: åˆ©ç”¨VLMçš„æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ï¼Œå®ç°å¯æ‰©å±•çš„æ•°æ®æ”¶é›†æ–¹æ³•
        - **æ— éœ€å¤–éƒ¨æ¨¡å‹**: ä¸éœ€è¦GPT-4Væˆ–å…¶ä»–å¤–éƒ¨æ¨¡å‹ï¼Œä»…ä½¿ç”¨åŸºç¡€VLMæœ¬èº«
        - **é¢†åŸŸé€‚åº”æ€§**: å¯é€‚åº”ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æœºå™¨äººï¼‰ï¼Œé€šè¿‡è®¾è®¡æ¸¸æˆä½¿ç”¨è¯¥é¢†åŸŸçš„å›¾åƒ
        - **å¯è¿­ä»£**: æ”¹è¿›çš„æ¨¡å‹å¯ä»¥ç”¨äºç”Ÿæˆæ›´å¥½çš„æ•°æ®é›†ï¼Œå®ç°æŒç»­æ”¹è¿›
      - **å®éªŒç»“æœ**:
        - **é€šç”¨å›¾åƒå®éªŒ**ï¼ˆDOCCIå’ŒOpenImagesæ•°æ®é›†ï¼‰:
          - **æ¸¸æˆæˆåŠŸç‡**: Gemini 1.5 Flash 20.3% â†’ VLM Dialog Games (DOCCI) 24.4% (+4.1%)
          - **VQAæ€§èƒ½**ï¼ˆVQAv2ï¼‰:
            - **Yes/Noé—®é¢˜**: 73.0% â†’ 79.8% (+6.8%ï¼ŒDOCCIï¼‰å’Œ83.4% (+10.4%ï¼ŒOpenImagesï¼‰
            - **è®¡æ•°é—®é¢˜**: 56% â†’ 58.3% (+2.3%ï¼ŒDOCCIï¼‰å’Œ56% (+0.0%ï¼ŒOpenImagesï¼‰
          - **è·¨æ•°æ®é›†æ³›åŒ–**: åœ¨DOCCIä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨OpenImagesæ¸¸æˆä¸Šè¡¨ç°æ›´å¥½ï¼ˆ21.9% vs 18.4%ï¼‰ï¼Œåä¹‹äº¦ç„¶
        - **æœºå™¨äººé¢†åŸŸå®éªŒ**ï¼ˆALOHAæ•°æ®é›†ï¼‰:
          - **æ¸¸æˆæˆåŠŸç‡**: Gemini 1.5 Flash 14.39% â†’ Round 1 40.15% (+25.76%) â†’ Round 2 53.74% (+39.35%)
          - **æˆåŠŸæ£€æµ‹å‡†ç¡®ç‡**: 56.5% â†’ Round 1 69.5% (+13.0%) â†’ Round 2 73.0% (+16.5%)
          - **è¿­ä»£æ”¹è¿›**: Round 2è¿›ä¸€æ­¥æå‡äº†æ¸¸æˆæˆåŠŸç‡å’ŒæˆåŠŸæ£€æµ‹å‡†ç¡®ç‡
          - **vsåŸºçº¿**:
            - **SFT-Description**: 65.0% (+8.5%) - ç›´æ¥å¾®è°ƒå›¾åƒ-ä»»åŠ¡æè¿°å¯¹
            - **Self-QA**: 67.0% (+10.5%) - åŸºäºé—®ç­”çš„è‡ªæˆ‘æ”¹è¿›æ–¹æ³•
            - **VLM Dialog Games (answers only)**: 68% (+12.5%) - ä»…ä½¿ç”¨Describerç­”æ¡ˆï¼Œä½†æ¸¸æˆæˆåŠŸç‡ä½ï¼ˆ17.92%ï¼‰ï¼Œæ— æ³•å®ç°è¿›ä¸€æ­¥è¿­ä»£æ”¹è¿›
        - **æ¶ˆèç ”ç©¶**:
          - **å›¾åƒæ•°é‡å½±å“**ï¼ˆNå€¼ï¼‰:
            - **N=2**: æ¸¸æˆæˆåŠŸç‡83.7%ï¼Œä½†æ¸¸æˆç®€å•ï¼Œæ•°æ®ä¿¡æ¯é‡å°‘ï¼ŒVQAå‡†ç¡®ç‡81.3% (+8.3%)
            - **N=4**: æ¸¸æˆæˆåŠŸç‡18.4%ï¼ŒVQAå‡†ç¡®ç‡83.4% (+10.4%) - **æœ€ä¼˜**
            - **N=8**: æ¸¸æˆæˆåŠŸç‡0.24%ï¼Œæ¸¸æˆè¿‡äºå›°éš¾ï¼Œç”Ÿæˆçš„å¯¹è¯æ•°æ®æå°‘ï¼ŒVQAå‡†ç¡®ç‡77.1% (+4.1%)
          - **å›¾åƒåˆ†ç»„ç­–ç•¥**:
            - **ç›¸ä¼¼å›¾åƒåˆ†ç»„**: æ¸¸æˆæˆåŠŸç‡18.4%ï¼ŒVQAå‡†ç¡®ç‡83.4% (+10.4%)
            - **éšæœºå›¾åƒåˆ†ç»„**: æ¸¸æˆæˆåŠŸç‡24.7%ï¼ŒVQAå‡†ç¡®ç‡82.6% (+9.6%)
            - **ç»“è®º**: ä¸¤ç§ç­–ç•¥éƒ½æ˜¾è‘—æ”¹è¿›ï¼Œç›¸ä¼¼å›¾åƒåˆ†ç»„ç•¥å¥½ï¼Œä½†éšæœºåˆ†ç»„ä¹Ÿèƒ½æœ‰æ•ˆå·¥ä½œ
      - **å…³é”®å‘ç°**:
        - **è‡ªå¯¹å¼ˆæœ‰æ•ˆæ€§**: å½“å‰VLMçš„æŒ‡ä»¤è·Ÿéšèƒ½åŠ›ä½¿å…¶èƒ½å¤Ÿåœ¨å¯¹è¯æ¸¸æˆä¸­å®ç°éé›¶æˆåŠŸç‡ï¼Œä¸ºå¯æ‰©å±•æ•°æ®ç”Ÿæˆæä¾›åŸºç¡€
        - **ç›®æ ‡å¯¼å‘ä¼˜åŠ¿**: æ¸¸æˆçš„ç›®æ ‡å¯¼å‘æ€§è´¨ç¡®ä¿ç”Ÿæˆçš„æ•°æ®è´¨é‡ï¼ŒæˆåŠŸæ£€æµ‹æä¾›è‡ªåŠ¨è´¨é‡æ§åˆ¶
        - **è¿­ä»£æ”¹è¿›èƒ½åŠ›**: æ”¹è¿›çš„æ¨¡å‹å¯ä»¥ç”¨äºç”Ÿæˆæ›´å¥½çš„æ•°æ®é›†ï¼Œå®ç°æŒç»­æ”¹è¿›ï¼ˆRound 1 â†’ Round 2ï¼‰
        - **é¢†åŸŸé€‚åº”æ€§**: æ–¹æ³•å¯é€‚åº”ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æœºå™¨äººï¼‰ï¼Œåœ¨é«˜è´¨é‡æ•°æ®ç¨€ç¼ºçš„é¢†åŸŸç‰¹åˆ«æœ‰æ•ˆ
        - **Guesseré—®é¢˜çš„é‡è¦æ€§**: ä»…ä½¿ç”¨Describerç­”æ¡ˆè™½ç„¶èƒ½æå‡æˆåŠŸæ£€æµ‹ï¼Œä½†æ— æ³•æå‡æ¸¸æˆæˆåŠŸç‡ï¼Œé™åˆ¶äº†è¿›ä¸€æ­¥è¿­ä»£æ”¹è¿›
      - **æœºæ„**: Google DeepMind
      - **ä½œè€…**: Ksenia Konyushkova, Christos Kaplanis, Serkan Cabi, Misha Denil
      - **å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´2æœˆï¼ˆv1ï¼‰
      - **å¼€æº**: âš ï¸ è®ºæ–‡ä¸­æœªæ˜ç¡®è¯´æ˜ä»£ç /æ•°æ®å¯ç”¨æ€§
      - **æ„ä¹‰**:
        - **æ–¹æ³•åˆ›æ–°**: é¦–ä¸ªåŸºäºå¯¹è¯æ¸¸æˆçš„VLMè‡ªæˆ‘æ”¹è¿›æ¡†æ¶ï¼Œé€šè¿‡ç›®æ ‡å¯¼å‘çš„è‡ªå¯¹å¼ˆç”Ÿæˆé«˜è´¨é‡æ•°æ®
        - **å¯æ‰©å±•æ€§**: åˆ©ç”¨VLMè‡ªèº«èƒ½åŠ›ï¼Œæ— éœ€å¤–éƒ¨æ¨¡å‹æˆ–äººå·¥æ ‡æ³¨ï¼Œå®ç°å¯æ‰©å±•çš„æ•°æ®ç”Ÿæˆ
        - **é¢†åŸŸé€‚åº”æ€§**: å¯é€‚åº”ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æœºå™¨äººï¼‰ï¼Œåœ¨é«˜è´¨é‡æ•°æ®ç¨€ç¼ºçš„é¢†åŸŸç‰¹åˆ«æœ‰æ•ˆ
        - **å®ç”¨ä»·å€¼**: åœ¨é€šç”¨VQAå’Œæœºå™¨äººæˆåŠŸæ£€æµ‹ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡æ€§èƒ½ï¼Œè¯æ˜æ–¹æ³•çš„æœ‰æ•ˆæ€§
  

</details>
---

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2405.14622">ğŸ“„ CSR (Calibrated Self-Rewarding)</a></b><br>
<code>arXiv 2405.14622</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
<img src="https://img.shields.io/badge/Institution-NeurIPS_2024-red?style=flat-square"/>
</summary>

  - **èšç„¦**: **æ ¡å‡†è‡ªå¥–åŠ±è§†è§‰è¯­è¨€æ¨¡å‹** - é€šè¿‡åœ¨æ ¡å‡†çš„è‡ªå¥–åŠ±è¿‡ç¨‹ä¸­å¼•å…¥è§†è§‰çº¦æŸæ¥æ”¹å–„LVLMçš„æ¨¡æ€å¯¹é½ï¼Œå‡å°‘å¹»è§‰å¹¶æå‡æ€§èƒ½
  - **æ•°æ®åˆæˆæ–¹æ³•** - **è¿­ä»£åå¥½ä¼˜åŒ–æ¡†æ¶ + æ ¡å‡†å¥–åŠ±æ¨¡å‹**:
      - **æ ¸å¿ƒåˆ›æ–°**: é¦–ä¸ªå°†è§†è§‰çº¦æŸæ•´åˆåˆ°è‡ªå¥–åŠ±èŒƒå¼ä¸­çš„æ–¹æ³•ï¼Œé€šè¿‡æ ¡å‡†å¥–åŠ±æ¨¡å‹è§£å†³LVLMåœ¨å“åº”ç”Ÿæˆå’Œåå¥½å»ºæ¨¡é˜¶æ®µçš„æ¨¡æ€å¯¹é½é—®é¢˜
      - **é—®é¢˜è¯†åˆ«**: LVLMå­˜åœ¨æ¨¡æ€å¯¹é½é—®é¢˜ï¼Œæ¨¡å‹å€¾å‘äºä¼˜å…ˆè€ƒè™‘æ–‡æœ¬ä¿¡æ¯è€Œå¿½ç•¥è§†è§‰è¾“å…¥ï¼Œå¯¼è‡´å¹»è§‰ç°è±¡
      - **CSRæ¡†æ¶ï¼ˆä¸¤ä¸ªäº¤æ›¿é˜¶æ®µï¼‰**:
        1. **å€™é€‰å“åº”ç”Ÿæˆé˜¶æ®µ**:
           - **å¥å­çº§Beam Search**: ä½¿ç”¨å¥å­çº§beam searchä¸ºæ¯ä¸ªè¾“å…¥æç¤ºç”Ÿæˆç»†ç²’åº¦å€™é€‰å“åº”
           - **å¥–åŠ±è®¡ç®—æµç¨‹**:
             - **åˆå§‹å¥–åŠ±**: è¯­è¨€è§£ç å™¨ç¡®å®šæ¯ä¸ªç”Ÿæˆå¥å­çš„åˆå§‹å¥–åŠ± R_T(s)ï¼ˆå¥å­çº§ç´¯ç§¯æ¦‚ç‡ï¼‰
             - **å›¾åƒ-å“åº”ç›¸å…³æ€§åˆ†æ•°**: ä½¿ç”¨CLIP-scoreè®¡ç®— R_I(s) = max(100Ã—cos(F_I(x_v), F_T(s)), 0)
             - **æ ¡å‡†å¥–åŠ±**: R(s) = Î»Â·R_I(s) + (1-Î»)Â·R_T(s)ï¼Œå…¶ä¸­Î»=0.9ï¼ˆå¼ºè°ƒè§†è§‰æ ¡å‡†ï¼‰
           - **è¿­ä»£ç”Ÿæˆ**: æ ¹æ®æ ¡å‡†å¥–åŠ±åˆ†æ•°é€‰æ‹©top-kå’Œbottom-kå¥å­ï¼Œç»§ç»­ä¸‹ä¸€è½®beam search
           - **ç´¯ç§¯å¥–åŠ±**: å“åº”yçš„ç´¯ç§¯å¥–åŠ± R(y) = Î£ R(s_i)
        2. **åå¥½ç­–åˆ’ä¸å¾®è°ƒé˜¶æ®µ**:
           - **åå¥½æ•°æ®æ„å»º**: é€‰æ‹©ç´¯ç§¯æ ¡å‡†å¥–åŠ±æœ€é«˜å’Œæœ€ä½çš„å“åº”ä½œä¸ºåå¥½å’Œååå¥½å“åº”
           - **DPOä¼˜åŒ–**: ä½¿ç”¨ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œå¾®è°ƒ
           - **å‚è€ƒæ¨¡å‹**: æ¯æ¬¡è¿­ä»£ä½¿ç”¨ä¸Šä¸€è½®å¾®è°ƒåçš„æ¨¡å‹ä½œä¸ºå‚è€ƒæ¨¡å‹
           - **æŸå¤±å‡½æ•°**: L_t = -E log Ïƒ(Î± log(Ï€_Î¸(y_w,t|x)/Ï€_Î¸t-1(y_w,t|x)) - Î± log(Ï€_Î¸(y_l,t|x)/Ï€_Î¸t-1(y_l,t|x)))
      - **å…³é”®æŠ€æœ¯ä¼˜åŠ¿**:
        - **è§†è§‰çº¦æŸå¥–åŠ±**: é€šè¿‡æ•´åˆå›¾åƒ-å“åº”ç›¸å…³æ€§ä¿¡æ¯ï¼Œè§£å†³LVLMåœ¨ç”Ÿæˆåå¥½æ—¶å¿½ç•¥è§†è§‰è¾“å…¥çš„é—®é¢˜
        - **é€æ­¥å¥–åŠ±**: å¥å­çº§å¥–åŠ±æä¾›æ›´ç»†ç²’åº¦çš„æŒ‡å¯¼å’Œæ›´å¼ºçš„é²æ£’æ€§
        - **è‡ªå¥–åŠ±èŒƒå¼**: æ— éœ€å¤–éƒ¨æ¨¡å‹æˆ–äººå·¥æ ‡æ³¨ï¼Œåˆ©ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆåå¥½æ•°æ®
        - **è¿­ä»£æ”¹è¿›**: é€šè¿‡å¤šè½®è¿­ä»£æŒç»­æå‡æ¨¡å‹æ€§èƒ½å’Œæ¨¡æ€å¯¹é½èƒ½åŠ›
      - **è®­ç»ƒè®¾ç½®**:
        - **åŸºç¡€æ¨¡å‹**: LLaVA-1.5 7Bå’Œ13B
        - **è®­ç»ƒæ•°æ®**: ä»LLaVA150kæ•°æ®é›†çš„è¯¦ç»†æè¿°å’Œå¤æ‚æ¨ç†å­ç±»ä¸­éšæœºé‡‡æ ·çº¦13,000ä¸ªæ ·æœ¬
        - **å¾®è°ƒæ–¹æ³•**: LoRAå¾®è°ƒ
        - **è¿­ä»£æ¬¡æ•°**: 3è½®è¿­ä»£ï¼ˆæ¯è½®çº¦3.5-5å°æ—¶ï¼Œ1Ã—A100 80GBï¼‰
        - **è¶…å‚æ•°**: Î»=0.9ï¼ˆCLIPåˆ†æ•°æƒé‡ï¼‰ï¼ŒÎ±=0.1ï¼ˆè¯­è¨€åˆ†æ•°æƒé‡ï¼‰
      - **å®éªŒç»“æœ**:
        - **ç»¼åˆåŸºå‡†**ï¼ˆMMEã€SEEDã€LLaVAWã€MMBenchã€MM-Vetï¼‰:
          - **LLaVA-1.5-7B + CSR**: å¹³å‡æå‡7.62%ï¼ˆè¿­ä»£3è½®ï¼‰
          - **LLaVA-1.5-13B + CSR**: å¹³å‡æå‡5.25%ï¼ˆè¿­ä»£3è½®ï¼‰
          - **æ˜¾è‘—æ”¹è¿›**: LLaVAW +8.9%ï¼ŒCHAIR +49.50%
        - **é€šç”¨VQA**ï¼ˆScienceQAã€VizWizã€GQAï¼‰:
          - **7Bæ¨¡å‹**: ScienceQA +2.9%ï¼ŒVizWiz +4.1%ï¼ŒGQA +0.3%
          - **13Bæ¨¡å‹**: ScienceQA +3.5%ï¼ŒVizWiz +3.2%ï¼ŒGQA +0.4%
        - **å¹»è§‰åŸºå‡†**ï¼ˆPOPEã€CHAIRï¼‰:
          - **POPE**: 7Bæ¨¡å‹ 85.90%â†’87.01%ï¼ˆ+1.11%ï¼‰ï¼Œ13Bæ¨¡å‹ 85.90%â†’87.30%ï¼ˆ+1.40%ï¼‰
          - **CHAIR_S**: 7Bæ¨¡å‹ 48.8%â†’21.0%ï¼ˆ-27.8%ï¼Œè¶Šä½è¶Šå¥½ï¼‰ï¼Œ13Bæ¨¡å‹ 48.3%â†’28.0%ï¼ˆ-20.3%ï¼‰
          - **CHAIR_I**: 7Bæ¨¡å‹ 14.9%â†’6.0%ï¼ˆ-8.9%ï¼‰ï¼Œ13Bæ¨¡å‹ 14.1%â†’7.3%ï¼ˆ-6.8%ï¼‰
        - **vs. ç«äº‰æ–¹æ³•**:
          - **è¶…è¶Šè‡ªå¥–åŠ±åŸºçº¿**: å¹³å‡æå‡2.43%
          - **è¶…è¶Šå¤–éƒ¨åå¥½æ–¹æ³•**: ä¼˜äºPOVIDã€RLHF-Vã€Silkieç­‰ä¾èµ–GPT-4æˆ–äººå·¥æ ‡æ³¨çš„æ–¹æ³•
          - **vs. SOTAå¼€æºVLM**: åœ¨10ä¸ªåŸºå‡†ä¸­çš„9ä¸ªä¸Šè¶…è¶ŠInstructBLIPã€Qwen-VL-Chatã€mPLUG-Owl2ç­‰
        - **è¿­ä»£æ”¹è¿›åˆ†æ**:
          - **å¥–åŠ±åˆ†æ•°å˜åŒ–**: åå¥½å“åº”å¥–åŠ±ä»0.4885ï¼ˆè¿­ä»£1ï¼‰æå‡è‡³0.5066ï¼ˆè¿­ä»£5ï¼‰
          - **å›¾åƒ-å“åº”ç›¸å…³æ€§**: åå¥½å’Œååå¥½å“åº”çš„å›¾åƒç›¸å…³æ€§åˆ†æ•°å‡æå‡ï¼Œä¸”å·®è·é€æ¸ç¼©å°
          - **æ³¨æ„åŠ›åˆ†æ**: CSRå¢å¼ºäº†å¯¹è§†è§‰tokençš„æ³¨æ„åŠ›ï¼Œå‡å°‘äº†å¯¹æ–‡æœ¬ä¸Šä¸‹æ–‡çš„è¿‡åº¦ä¾èµ–
        - **å…¼å®¹æ€§éªŒè¯**ï¼ˆVila 7Bï¼‰:
          - **æ•´ä½“æå‡**: 3è½®è¿­ä»£åå¹³å‡æå‡3.37%
          - **æ˜¾è‘—æ”¹è¿›**: VizWiz +8.48%ï¼ŒMM-Vet +14.0%
      - **æ¶ˆèç ”ç©¶**:
        - **ä»…R_Tï¼ˆè¯­è¨€åˆ†æ•°ï¼‰**: 68.46%ï¼ˆ7Bï¼‰ï¼Œ68.12%ï¼ˆ13Bï¼‰
        - **ä»…R_Iï¼ˆå›¾åƒåˆ†æ•°ï¼‰**: 67.49%ï¼ˆ7Bï¼‰ï¼Œ69.23%ï¼ˆ13Bï¼‰
        - **CSRï¼ˆç»„åˆï¼‰**: 72.39%ï¼ˆ7Bï¼‰ï¼Œ71.95%ï¼ˆ13Bï¼‰
        - **ç»“è®º**: ç»„åˆä½¿ç”¨ä¸¤ç§åˆ†æ•°æ•ˆæœæœ€ä½³
        - **Î»å€¼åˆ†æ**: Î»=0.9ä¼˜äº0.5å’Œ0.1ï¼Œè¯æ˜è§†è§‰æ ¡å‡†çš„é‡è¦æ€§
      - **ç†è®ºåˆ†æ**:
        - **å®šç†5.1**: åœ¨æ¸©å’Œå‡è®¾ä¸‹ï¼Œå¼•å…¥å›¾åƒ-å“åº”ç›¸å…³æ€§åˆ†æ•°å¯ä»¥æ ¡å‡†è‡ªå¥–åŠ±è¿‡ç¨‹ï¼Œæå‡ç”Ÿæˆå‡†ç¡®æ€§
        - **å…³é”®æ¡ä»¶**: å½“æ¨¡å‹å€¾å‘äºä¼˜å…ˆè€ƒè™‘æ–‡æœ¬ä¿¡æ¯è€Œéè§†è§‰è¾“å…¥æ—¶ï¼ˆâˆ¥Î²*^T V_1*âˆ¥ â‰ª âˆ¥Î²*^T V_2*âˆ¥ï¼‰ï¼Œé€šè¿‡è§†è§‰çº¦æŸï¼ˆÎ»<1ï¼‰å¯ä»¥å¢åŠ å¯¹å›¾åƒä¿¡å·çš„å…³æ³¨
      - **å…³é”®å‘ç°**:
        - **è‡ªå¥–åŠ±æœ‰æ•ˆæ€§**: è‡ªç”Ÿæˆçš„åå¥½æ•°æ®æ¯”å¤–éƒ¨æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ç”Ÿæˆçš„åå¥½æ•°æ®æ›´æœ‰æ•ˆï¼Œå› ä¸ºæ›´ç¬¦åˆç›®æ ‡LVLMçš„å›ºæœ‰åå¥½
        - **è§†è§‰çº¦æŸå¿…è¦æ€§**: ç›´æ¥åº”ç”¨è‡ªå¥–åŠ±åˆ°LVLMæ— æ³•è§£å†³æ¨¡æ€å¯¹é½é—®é¢˜ï¼Œéœ€è¦å¼•å…¥è§†è§‰çº¦æŸ
        - **è¿­ä»£æ”¹è¿›èƒ½åŠ›**: CSRèƒ½å¤Ÿé€šè¿‡è¿­ä»£å¾®è°ƒæŒç»­æå‡æ€§èƒ½ï¼Œé€æ­¥æ”¶æ•›
        - **è·¨æ¨¡å‹å…¼å®¹æ€§**: æ–¹æ³•é€‚ç”¨äºä¸åŒçš„LVLMæ¶æ„ï¼ˆLLaVA-1.5ã€Vilaï¼‰
      - **æœºæ„**: åŒ—å¡ç½—æ¥çº³å¤§å­¦æ•™å ‚å±±åˆ†æ ¡ã€èŠåŠ å“¥å¤§å­¦ã€é©¬é‡Œå…°å¤§å­¦ã€ç½—æ ¼æ–¯å¤§å­¦ã€é¦™æ¸¯ç§‘æŠ€å¤§å­¦ã€é¦™æ¸¯ç†å·¥å¤§å­¦ã€å—æ´‹ç†å·¥å¤§å­¦ã€æ–°åŠ å¡å›½ç«‹å¤§å­¦
      - **ä½œè€…**: Yiyang Zhou, Zhiyuan Fan, Dongjie Cheng, Sihan Yang, Zhaorun Chen, Chenhang Cui, Xiyao Wang, Yun Li, Linjun Zhang, Huaxiu Yao
      - **å‘å¸ƒæ—¶é—´**: arXiv 2024å¹´5æœˆ (v4) | NeurIPS 2024
      - **å¼€æº**: âœ… [ä»£ç å’Œæ•°æ®](https://github.com/YiyangZhou/CSR)
      - **é‡è¦æ„ä¹‰**:
        - **èŒƒå¼åˆ›æ–°**: é¦–æ¬¡å°†è§†è§‰çº¦æŸæ•´åˆåˆ°è‡ªå¥–åŠ±èŒƒå¼ä¸­ï¼Œè§£å†³LVLMç‰¹æœ‰çš„æ¨¡æ€å¯¹é½é—®é¢˜
        - **æˆæœ¬é™ä½**: æ— éœ€å¤–éƒ¨æ¨¡å‹æˆ–äººå·¥æ ‡æ³¨ï¼Œä»…ä½¿ç”¨æ¨¡å‹è‡ªèº«è¿›è¡Œè‡ªæˆ‘æ”¹è¿›
        - **æ€§èƒ½æå‡**: åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—æå‡æ€§èƒ½å¹¶å‡å°‘å¹»è§‰ï¼Œå¹³å‡æå‡7.62%
        - **ç†è®ºæ”¯æ’‘**: æä¾›ä¸¥æ ¼çš„ç†è®ºåˆ†æéªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§
        - **å®ç”¨ä»·å€¼**: ä¸ºLVLMçš„è‡ªæˆ‘æ”¹è¿›æä¾›å¯æ‰©å±•ä¸”ç»æµé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆ
  

</details>
---

<details>
<summary>
<b><b><a href="https://scholar.google.com/scholar?q=Vision-Zero">ğŸ“„ Vision-Zero</a></b><br>
<code>Paper</code>
</summary>

  - **Data Synthesis Method** - **Strategic Gamified Self-Play Framework**:
      - **Core Innovation**: First **zero-human-in-the-loop** training paradigm for VLMs using "Who Is the Spy" style visual games
      - **Label-Free & Domain-Agnostic**: Accepts arbitrary image pairs (CLEVR synthetic, charts, real-world) to generate strategic reasoning games
      - **Iterative Self-Play Policy Optimization (Iterative-SPO)**: Novel algorithm alternating between self-play and RLVR to prevent performance plateaus
      - **Strategic Environment**: Models compete in two-stage games (Clue Stage: provide visual clues, Decision Stage: identify the spy)
      - **Data Scale**: 2K CLEVR pairs (~6 GPU hours), 1K chart pairs, 1K real-world pairs - minimal cost compared to traditional human annotation
      - **Quality Assurance**: Zero-sum reward design with Role-Advantage Estimation (RAE) to handle asymmetric role information
  - **Key Technical Components**:
      - **Game Environment**: Civilians vs. Spy setup with subtly different image pairs (missing/added/modified objects)
      - **Reward System**: Clue stage uses zero-sum rewards based on votes received; Decision stage uses discrete +1/-0.5/-1 rewards
      - **Training Algorithm**: Dynamic stage switching based on performance thresholds (accuracy â‰¥0.9 or "n/a" rates)
      - **Domain Flexibility**: Automated image editing pipeline supports procedural generation (CLEVR) and tool-based editing (Gemini2.5-Flash)
  - **Experimental Results**:
      - **Reasoning & Math**: MathVista 68.2â†’72.6% (+4.4%), MathVision 25.4â†’28.1% (+2.7%), WeMath 36.1â†’39.8% (+3.7%)
      - **Chart/OCR**: ChartQA 86.1â†’87.2% (+1.1%), OCRBench 88.3â†’89.0% (+0.7%)
      - **Vision-Centric**: MMVP 76.8â†’79.5% (+2.7%), RealWorldQA 68.1â†’68.5% (+0.4%)
      - **Cross-Capability Transfer**: Mitigates negative transfer common in traditional RL methods (vs. 10% decline in MM-Eureka)
      - **Model Generalization**: Effective across Qwen2.5-VL-7B, InternVL3-8B, InternVL3-14B architectures
  - **Cost Efficiency**:
      - **Dataset Construction**: Orders of magnitude cheaper than traditional methods (6 GPU hours vs. months/years)
      - **Performance**: Outperforms SOTA methods trained on expensive human-labeled datasets (MM-Eureka, VLAA-Thinker, R1-OneVision)
      - **Sustainable Growth**: Win rates improve from 50% to 71% during training with increasing reasoning complexity
  - **Open Source**: âœ… [Code](https://github.com/wangqinsi1/Vision-Zero) | Models & datasets promised
  - **Significance**:
      - **Paradigm Shift**: Eliminates dependency on human-curated datasets through competitive self-play
      - **Scalable Framework**: Domain-agnostic approach enables rapid dataset construction for specific domains
      - **Strategic Reasoning**: Joint visual-linguistic analysis strengthens spatial understanding and mitigates text shortcut bias
      - **Practical Impact**: Provides economical, accessible training paradigm for VLM development
  

</details>
---

## ğŸ§  è·¨é¢†åŸŸæ–¹æ³•è®ºæ´å¯Ÿ

> **Note**: This section includes influential works from adjacent domains (e.g., LLM reasoning, mathematical data curation) whose **data curation and quality assessment methodologies** provide valuable frameworks transferable to multimodal settings. While not directly VLM papers, their systematic approaches to data quality evaluation, mixture optimization, and efficient filtering pipelines offer important insights for multimodal data practitioners.

### ğŸ“š Foundation Model Mid-training & Data Curation

<details>
<summary><b>OctoThinker: ä¸­æœŸè®­ç»ƒæ¿€åŠ±å¼ºåŒ–å­¦ä¹ æ‰©å±•</b> - ç³»ç»ŸåŒ–çš„æ•°æ®ç­›é€‰ã€è´¨é‡è¯„ä¼°ä¸æ··åˆä¼˜åŒ–</summary>

**è®ºæ–‡**: [OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling](https://arxiv.org/abs/2506.20512)

**æœºæ„**: ä¸Šæµ·äº¤é€šå¤§å­¦ GAIR Lab (Wangç­‰)

**å‘å¸ƒæ—¶é—´**: arXiv 2025å¹´6æœˆ

**é¢†åŸŸ**: æ•°å­¦æ¨ç† / LLMä¸­æœŸè®­ç»ƒ

**ğŸ”¬ ä¸ºä½•ä¸VLMæ•°æ®ç­›é€‰ç›¸å…³ï¼Ÿ**

**æ ¸å¿ƒè´¡çŒ®**: æœ¬æ–‡**å¹¶éå…³äºæ•°æ®åˆæˆ/ç”Ÿæˆ**ï¼Œè€Œæ˜¯å…³äº**ç³»ç»ŸåŒ–çš„æ•°æ®è´¨é‡è¯„ä¼°ã€å¤§è§„æ¨¡è¿‡æ»¤/ç­›é€‰å’Œæ··åˆä¼˜åŒ–**ã€‚è™½ç„¶ä¸“æ³¨äºæ–‡æœ¬é¢†åŸŸçš„æ•°å­¦æ¨ç†ï¼ŒOctoThinkeræä¾›äº†ä¸€ä¸ªä¸¥è°¨çš„å®éªŒæ¡†æ¶ï¼Œç”¨äºä»ç°æœ‰è¯­æ–™ä¸­è¯„ä¼°å’Œé€‰æ‹©é«˜è´¨é‡æ•°æ®â€”â€”è¿™äº›æ–¹æ³•é«˜åº¦å¯è¿ç§»åˆ°å¤šæ¨¡æ€åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯ä»å™ªå£°ç½‘ç»œæºä¸­ç­›é€‰åäº¿çº§æ•°æ®é›†æ—¶ã€‚

---

**ğŸ“Š æ ¸å¿ƒå¯è¿ç§»æ´å¯Ÿ**:

**1. ä¸¤é˜¶æ®µè´¨é‡è¯„ä¼°ç®¡é“**
- **æ–¹æ³•**: LLMæ ‡æ³¨(0-5åˆ†) â†’ è®­ç»ƒé«˜æ•ˆåˆ†ç±»å™¨(FastText) â†’ å¤§è§„æ¨¡è¿‡æ»¤(é˜ˆå€¼0.4) â†’ å¯é€‰LLMç²¾ç‚¼
- **å…³é”®å‘ç°**: é¢„å¤„ç†è‡³å…³é‡è¦ï¼›é˜ˆå€¼0.4å¹³è¡¡è´¨é‡-æ•°é‡æƒè¡¡ï¼ˆå‰äººä½¿ç”¨0.9ï¼‰
- **æˆæœ**: MegaMath-Web-Pro-Max (73.8B tokens, æ˜¯MegaMath-Web-Pro 13Bçš„5.5å€)
- **VLMè¿ç§»**: æ„å»ºå¤šæ¨¡æ€æ ‡æ³¨schemaä»¥è¯„ä¼°è§†è§‰-è¯­è¨€å¯¹é½è´¨é‡ã€ä¿¡æ¯å¯†åº¦å’Œç»„åˆæ¨ç†å¤æ‚åº¦ï¼›è®­ç»ƒè½»é‡çº§è·¨æ¨¡æ€åˆ¤åˆ«å™¨ï¼ˆå†»ç»“è§†è§‰ç¼–ç å™¨ï¼‰å®ç°æˆæœ¬å¯æ§çš„åäº¿çº§æ•°æ®ç­›é€‰ï¼ŒåŒæ—¶ä¿æŒé«˜ä¿çœŸè¿‡æ»¤èƒ½åŠ›

**2. ç³»ç»ŸåŒ–æ•°æ®æ··åˆä¼˜åŒ–**
- **ä¸¥æ ¼æµ‹è¯•**: è·¨å¤šä¸ªç»´åº¦æµ‹è¯•10%ã€20%ã€30%ã€40%æ¯”ä¾‹
- **æœ€ä¼˜å‘ç°**: 30% QAæ•°æ®ï¼ˆè¶…è¿‡åå› å†—ä½™è€Œæ”¶ç›Šé€’å‡ï¼‰
- **æ ¸å¿ƒæ´å¯Ÿ**: *"è®­ç»ƒæ•°æ®ä¸ä¸‹æ¸¸ä»»åŠ¡çš„åˆ†å¸ƒå·®è·æ˜¾è‘—å½±å“æ€§èƒ½"*
- **VLMè¿ç§»**: å»ºç«‹å—æ§å®éªŒæ¡†æ¶ï¼Œç³»ç»Ÿæ€§å˜åŒ–captionç²’åº¦ï¼ˆå®ä½“çº§ vs åœºæ™¯çº§ vs æ¨ç†çº§ï¼‰ã€æ•°æ®æ¥æºï¼ˆç½‘é¡µçˆ¬å– vs äººå·¥æ ‡æ³¨ vs æ¨¡å‹åˆæˆï¼‰å’Œè·¨æ¨¡æ€äº¤äº’æ¨¡å¼ï¼›é‡‡ç”¨ç½‘æ ¼æœç´¢ç»“åˆä¸¥æ ¼ä¸‹æ¸¸è¯„ä¼°ï¼Œè€Œéå¯å‘å¼æ··åˆ

**3. åˆ†å¸ƒå¯¹é½ > æ•°æ®è§„æ¨¡**
- **è§‚å¯Ÿ**: ç»“æ„åŒ–QAæ•°æ®é›†(OpenR1, OMI2)åœ¨ç«èµ›é£æ ¼åŸºå‡†ä¸Šä¼˜äºç½‘é¡µæ¥æºQA(MegaMath-QA)ï¼ŒåŸå› æ˜¯åˆ†å¸ƒå¯¹é½è€Œéæ•°æ®ä½“é‡
- **åŸåˆ™**: åŒ¹é…é¢„è®­ç»ƒåˆ†å¸ƒåˆ°ä¸‹æ¸¸ä»»åŠ¡æ ¼å¼ï¼Œè€Œéä»…åŒ¹é…é¢†åŸŸ
- **VLMè¿ç§»**: ä¼˜å…ˆè€ƒè™‘åˆ†å¸ƒæ„ŸçŸ¥çš„æ•°æ®ç­›é€‰è€Œéä½“é‡æœ€å¤§åŒ–â€”â€”æ–‡æ¡£ç†è§£å—ç›Šäºæ–‡æœ¬å¯†é›†çš„å¤šæ ·æ’ç‰ˆå¸ƒå±€è€Œéè‡ªç„¶å›¾åƒï¼›è§†è§‰æ¨ç†éœ€è¦å¤šè·³å…³ç³»æ ‡æ³¨è€Œéæè¿°æ€§captionsï¼›é¢†åŸŸç‰¹å®šåº”ç”¨è¦æ±‚æ¨¡æ€ä¸€è‡´ä¸”ç»“æ„å¯¹é½çš„é¢„è®­ç»ƒè¯­æ–™

**4. å°‘é‡"ç¨³å®šå‰‚"æ•°æ®å½±å“å·¨å¤§**
- **å‘ç°**: å°‘é‡(1-10%)é«˜è´¨é‡æŒ‡ä»¤æ•°æ®è§£é”å…¶ä»–æ•°æ®ç±»å‹çš„æ½œåŠ›
- **æ•ˆæœ**: ç¨³å®šè®­ç»ƒï¼Œå‡å°‘é•¿æ ¼å¼æ•°æ®ä¸ç¨³å®šæ€§ï¼Œä½¿RLæ‰©å±•æˆåŠŸ
- **VLMè¿ç§»**: å¼•å…¥å°æ¯”ä¾‹é«˜è´¨é‡è§†è§‰-è¯­è¨€å¯¹é½æ•°æ®(1-10%)ä»¥æ­£åˆ™åŒ–è®­ç»ƒåŠ¨æ€ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‰©å±•åˆ°å¯†é›†é•¿æ–‡æœ¬captionsæˆ–å¤æ‚å¤šå›¾æ¨ç†åœºæ™¯æ—¶ï¼›å……å½“åˆ†å¸ƒé”šç‚¹é˜²æ­¢æ¨¡å¼åå¡Œå’Œè¡¨å¾æ¼‚ç§»

---

**ğŸ¯ æ€»ç»“: VLMæ•°æ®ä»ä¸šè€…çš„å…³é”®è¦ç‚¹**

| # | åŸåˆ™ | OctoThinkeræ–¹æ³• | VLMåº”ç”¨ |
|---|------|----------------|---------|
| 1 | **è´¨é‡ > æ•°é‡** | è¿‡æ»¤åçš„MegaMath-Web-Pro-Max >> åŸå§‹è¯­æ–™ | ç²¾ç­›é€‰çš„é«˜ç²¾åº¦æ•°æ®å¯¹åœ¨ä¸‹æ¸¸è¿ç§»ä¸­æ˜¾è‘—ä¼˜äºåŸå§‹ç½‘ç»œè§„æ¨¡å™ªå£°è¯­æ–™ |
| 2 | **é«˜æ•ˆè¿‡æ»¤** | LLMæ ‡æ³¨ â†’ FastTextåˆ†ç±»å™¨ â†’ è§„æ¨¡åŒ– | å¯æ‰©å±•ä¸¤é˜¶æ®µç®¡é“å®ç°åäº¿çº§ç­›é€‰å¹¶ä¿æŒè®¡ç®—æ•ˆç‡ |
| 3 | **ç³»ç»ŸåŒ–å®éªŒ** | æµ‹è¯•10%, 20%, 30%, 40%æ¯”ä¾‹ | åœ¨æ•°æ®æ··åˆè¶…å‚æ•°ç©ºé—´è¿›è¡Œç½‘æ ¼æœç´¢ä¸ä¸¥æ ¼æ¶ˆèç ”ç©¶ |
| 4 | **æ”¶ç›Šé€’å‡** | è¶…è¿‡30% QAï¼Œå†—ä½™æœ‰å®³ | è¯†åˆ«è¾¹é™…æ•ˆç”¨å› åˆ†å¸ƒå†—ä½™è€Œé€’å‡çš„é¥±å’Œç‚¹ |
| 5 | **åˆ†å¸ƒå¯¹é½** | åŒ¹é…ä¸‹æ¸¸ä»»åŠ¡æ ¼å¼ | æ•°æ®æ ¼å¼ä¸ä»»åŠ¡å¯¹é½æ¯”é¢†åŸŸåŒ¹é…æ›´é‡è¦ |
| 6 | **ç¨³å®šå‰‚æ•°æ®** | 1-10%æŒ‡ä»¤æ•°æ®è§£é”QAæ½œåŠ› | å°æ¯”ä¾‹æ­£åˆ™åŒ–æ•°æ®é˜²æ­¢è®­ç»ƒä¸ç¨³å®šå¹¶å®ç°æ‰©å±• |
| 7 | **æ ¼å¼æ„è¯†** | é•¿CoT = é«˜èƒ½åŠ› + ä¸ç¨³å®šæ€§ | é«˜å®¹é‡å¯†é›†è¾“å‡ºéœ€è¦ç¨³å®šæœºåˆ¶ä»¥é˜²æ­¢æ¨¡å¼åå¡Œ |
| 8 | **ä¸¤é˜¶æ®µå“²å­¦** | åŸºç¡€ (90%) â†’ ä¸“é—¨åŒ– (10%) | å¹¿æ³›çš„åˆ†å¸ƒè¦†ç›–åè¿›è¡Œé’ˆå¯¹æ€§èƒ½åŠ›ä¸“é—¨åŒ– |
| 9 | **é¢„å¤„ç†å¾ˆé‡è¦** | å¯¹åˆ†ç±»å™¨æ€§èƒ½è‡³å…³é‡è¦ | ç³»ç»ŸåŒ–å½’ä¸€åŒ–å’Œä¼ªå½±æ¶ˆé™¤å¯¹åˆ¤åˆ«å™¨æ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ |
| 10 | **å®è¯éªŒè¯** | é˜ˆå€¼åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸ŠéªŒè¯ | è¶…å‚æ•°é€‰æ‹©ç”±ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æŒ‡å¯¼è€Œéä»£ç†æŒ‡æ ‡ |

---

**ğŸ“ˆ è§„æ¨¡ä¸èµ„æº**:
- **åŸºç¡€æ¨¡å‹**: Llama-3.2-1B/3B/8B
- **ä¸­æœŸè®­ç»ƒé¢„ç®—**: æœ€å¤š200B tokens (ç¨³å®šé˜¶æ®µ) + 20B tokens (è¡°å‡é˜¶æ®µ)
- **æœ€ç»ˆè¯­æ–™**: MegaMath-Web-Pro-Max (73.8B tokens, æ˜¯MegaMath-Web-Proçš„5.5å€)
- **æ¶ˆèç ”ç©¶**: ç³»ç»ŸåŒ–çš„å—æ§å®éªŒï¼Œæ¶µç›–æ•°æ®è´¨é‡ã€æ··åˆæ¯”ä¾‹ã€QAæ¥æºå’Œæ ¼å¼ç‰¹å¾
- **æ€§èƒ½æå‡**: æ¯”åŸºç¡€æ¨¡å‹æå‡10-20%ï¼ŒRLååŒ¹é…Qwen2.5

**ğŸ”— èµ„æº**:
- âœ… **è®ºæ–‡**: [arXiv:2506.20512](https://arxiv.org/abs/2506.20512)
- âœ… **ä»£ç **: [GitHub - GAIR-NLP/OctoThinker](https://github.com/GAIR-NLP/OctoThinker)
- âœ… **æ¨¡å‹**: [HuggingFace - OctoThinker](https://huggingface.co/OctoThinker)
- âœ… **æ•°æ®é›†**: MegaMath-Web-Pro-Max (70B+ tokens, æ‰¿è¯ºå¼€æº)
- âœ… **å®Œå…¨å…¬å¼€**: è®ºæ–‡é™„å½•è¯¦è¿°æ‰€æœ‰promptså’Œæ–¹æ³•

**ğŸ’¡ æ½œåœ¨çš„VLMåç»­å·¥ä½œ**:
- ç³»ç»ŸåŒ–çš„è§†è§‰-è¯­è¨€æ•°æ®æ··åˆä¼˜åŒ–
- é«˜æ•ˆå¤šæ¨¡æ€è´¨é‡åˆ†ç±»å™¨
- é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„åˆ†å¸ƒå¯¹é½åˆæˆcaptionç”Ÿæˆ
- å¸¦æœ‰ä¸“é—¨åŒ–åˆ†æ”¯çš„ä¸¤é˜¶æ®µVLMé¢„è®­ç»ƒ

</details>

### ğŸ”„ Multi-Modal Model Collapse & Synthetic Data Robustness

<details>
<summary>
<b><b><a href="https://arxiv.org/abs/2505.08803">ğŸ“„ å¤šæ¨¡æ€åˆæˆæ•°æ®è®­ç»ƒä¸æ¨¡å‹åå¡Œ</a></b><br>
<code>arXiv 2505.08803</code>
<img src="https://img.shields.io/badge/Method-âœ“-brightgreen?style=flat-square"/>
<img src="https://img.shields.io/badge/Data-âœ“-blue?style=flat-square"/>
</summary>

  - **ç ”ç©¶ç„¦ç‚¹** - **å¤šæ¨¡æ€ç”Ÿæˆç³»ç»Ÿä¸­çš„æ¨¡å‹åå¡Œç°è±¡è°ƒæŸ¥**ï¼š
      - **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§è°ƒæŸ¥å¤šæ¨¡æ€ç”Ÿæˆç³»ç»Ÿï¼ˆVLMå’Œæ‰©æ•£æ¨¡å‹ï¼‰åœ¨åˆæˆæ•°æ®è®­ç»ƒä¸­çš„æ¨¡å‹åå¡Œç°è±¡ï¼Œè¯†åˆ«å¤šæ¨¡æ€åå¡Œç›¸æ¯”å•æ¨¡æ€çš„ç‹¬ç‰¹ç‰¹å¾
      - **ç ”ç©¶èƒŒæ™¯**ï¼šéšç€åˆæˆæ•°æ®åœ¨è®­ç»ƒä¸‹ä¸€ä»£æ¨¡å‹ä¸­ä½¿ç”¨å¢åŠ ï¼Œç†è§£"æ¨¡å‹åå¡Œ"ï¼ˆmodel collapseï¼‰ç°è±¡åŠå…¶åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­çš„è¡¨ç°å˜å¾—è‡³å…³é‡è¦
      - **åŒæ¨¡æ€åå¡Œåˆ†æ**ï¼šåœ¨VLMå›¾åƒæ ‡é¢˜ç”Ÿæˆå’Œæ‰©æ•£æ¨¡å‹å›¾åƒç”Ÿæˆä¸­æ£€éªŒåå¡Œæ¨¡å¼ï¼Œå‘ç°å¤šæ¨¡æ€ç³»ç»Ÿå±•ç°ä¸å•æ¨¡æ€ç³»ç»Ÿä¸åŒçš„åå¡Œç‰¹å¾
  - **å…³é”®å‘ç°**ï¼š
      - **VLMåå¡Œç‰¹å¾**ï¼šä¸LLMåå¡Œä¸åŒï¼ŒVLMå›¾åƒæ ‡é¢˜ä»»åŠ¡ä¸­æ–¹å·®å¯èƒ½å¢åŠ ï¼Œè¿èƒŒä¼ ç»Ÿåå¡Œæ¨¡å¼
      - **åå·®-æ–¹å·®æƒè¡¡**ï¼šå¤šæ¨¡æ€åå¡Œä¸­å¹³è¡¡åå·®-æ–¹å·®æƒè¡¡æ¯”å•æ¨¡æ€æƒ…å†µæ›´ä¸ºå…³é”®
      - **æ‰©æ•£æ¨¡å‹éŸ§æ€§**ï¼šæ‰©æ•£æ¨¡å‹åœ¨åˆæˆæ•°æ®è®­ç»ƒä¸­è¡¨ç°å‡ºæ¯”VLMæ›´å¼ºçš„æŠ—åå¡Œèƒ½åŠ›
      - **é€’å½’è®­ç»ƒé£é™©**ï¼šå¤šæ™ºèƒ½ä½“é€’å½’è®­ç»ƒå¾ªç¯ä¸­çš„åŠ é€Ÿåå¡Œé£é™©è¯†åˆ«
  - **ç¼“è§£ç­–ç•¥**ï¼š
      - **å¢åŠ è§£ç é¢„ç®—**ï¼šæ›´å¤§çš„é‡‡æ ·é¢„ç®—å’Œå¤šæ ·æ€§å‚æ•°æœ‰åŠ©äºç»´æŒç”Ÿæˆè´¨é‡
      - **æ›´å¤§æ¨¡å‹å¤šæ ·æ€§**ï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨å¤šæ ·åŒ–çš„æ¨¡å‹æ¶æ„å’Œå‚æ•°è®¾ç½®
      - **å†»ç»“æ¨¡å‹é‡æ ‡æ³¨**ï¼šåœ¨é€’å½’è®­ç»ƒä¸­è‡³å°‘ç»´æŒä¸€ä¸ªå†»ç»“æ¨¡å‹è¿›è¡Œé‡æ ‡æ³¨ï¼Œé˜²æ­¢ç´¯ç§¯é”™è¯¯
      - **å¹³è¡¡è®­ç»ƒç­–ç•¥**ï¼šæ··åˆçœŸå®å’Œåˆæˆæ•°æ®ï¼Œé¿å…å®Œå…¨ä¾èµ–åˆæˆæ•°æ®
  - **å®éªŒè®¾è®¡**ï¼š
      - **å—æ§å®éªŒ**ï¼šè®¾è®¡å—æ§çš„å¤šä»£è®­ç»ƒå®éªŒï¼Œç³»ç»Ÿæ€§åœ°æµ‹é‡åå¡ŒæŒ‡æ ‡
      - **å¤šæŒ‡æ ‡è¯„ä¼°**ï¼šä½¿ç”¨å¤šæ ·åŒ–çš„è´¨é‡æŒ‡æ ‡ï¼ˆCLIPåˆ†æ•°ã€FIDã€BLEUç­‰ï¼‰å…¨é¢è¯„ä¼°åå¡Œç°è±¡
      - **è·¨æ¶æ„éªŒè¯**ï¼šåœ¨ä¸åŒçš„VLMå’Œæ‰©æ•£æ¨¡å‹æ¶æ„ä¸ŠéªŒè¯å‘ç°çš„æ™®éæ€§
  - **ç†è®ºæ´å¯Ÿ**ï¼š
      - **å¤šæ¨¡æ€å¤æ‚æ€§**ï¼šå¤šæ¨¡æ€ç³»ç»Ÿç”±äºè·¨æ¨¡æ€äº¤äº’çš„é¢å¤–å¤æ‚æ€§ï¼Œåå¡Œæ¨¡å¼æ›´åŠ å¾®å¦™
      - **ä¿¡æ¯æµåŠ¨**ï¼šè·¨æ¨¡æ€ä¿¡æ¯æµåŠ¨å¦‚ä½•å½±å“åå¡Œä¼ æ’­å’Œç´¯ç§¯é”™è¯¯
      - **ç¨³å®šæ€§åˆ†æ**ï¼šä¸åŒæ¨¡æ€é—´çš„ç¨³å®šæ€§ç›¸äº’ä¾èµ–å…³ç³»åˆ†æ
  - **å®é™…æ„ä¹‰**ï¼š
      - **è®­ç»ƒæŒ‡å¯¼**ï¼šä¸ºä½¿ç”¨åˆæˆæ•°æ®è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹æä¾›å®ç”¨æŒ‡å¯¼åŸåˆ™
      - **è´¨é‡æ§åˆ¶**ï¼šå»ºç«‹å¤šæ¨¡æ€åˆæˆæ•°æ®è´¨é‡è¯„ä¼°çš„åŸºå‡†æ–¹æ³•
      - **é£é™©ç¼“è§£**ï¼šè¯†åˆ«å’Œé¢„é˜²å¤šæ¨¡æ€è®­ç»ƒä¸­çš„åå¡Œé£é™©
  - **æœºæ„**ï¼šæœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºï¼Œéœ€è¦æŸ¥é˜…å®Œæ•´è®ºæ–‡
  - **å¼€æºçŠ¶æ€**ï¼šâš ï¸ éœ€è¦ç¡®è®¤å…·ä½“çš„ä»£ç å’Œæ•°æ®å¯ç”¨æ€§
  - **é‡è¦ä»·å€¼**ï¼š
      - **ç†è®ºè´¡çŒ®**ï¼šä¸ºç†è§£å¤šæ¨¡æ€ç”Ÿæˆç³»ç»Ÿçš„ç¨³å®šæ€§æä¾›é‡è¦ç†è®ºåŸºç¡€
      - **å®è·µæŒ‡å¯¼**ï¼šä¸ºå¤šæ¨¡æ€AIç³»ç»Ÿçš„å®‰å…¨å’Œå¯é è®­ç»ƒæä¾›å…³é”®æ´å¯Ÿ
      - **æœªæ¥ç ”ç©¶**ï¼šä¸ºå¤šæ¨¡æ€åˆæˆæ•°æ®ç ”ç©¶å»ºç«‹é‡è¦çš„ç†è®ºæ¡†æ¶
      - **è¡Œä¸šå½±å“**ï¼šå¯¹ä¾èµ–åˆæˆæ•°æ®çš„å¤šæ¨¡æ€AIäº§å“å¼€å‘å…·æœ‰é‡è¦æŒ‡å¯¼æ„ä¹‰
  

</details>
---

## ğŸ“¦ å…¸å‹å¤šæ¨¡æ€æ•°æ®é›†

> **Note**: This section lists influential large-scale multimodal datasets that serve as foundations for training vision-language models. These are typically curated from multiple sources and represent significant data aggregation/curation efforts.

### ğŸ“¦ Interleaved Image-Text Datasets

These datasets consist of documents with images and text interleaved in natural reading order, preserving the original structure of web pages, articles, and documents. They are essential for training models on long-context multimodal understanding and generation.

| Dataset | Scale | Description | Links |
|---------|-------|-------------|-------|
| **OmniCorpus** | 8.6B images<br/>1,696B tokens | Massive interleaved image-text corpus emphasizing **unified data engine** and **multi-lingual, multi-source** coverage. Includes comprehensive web-scale data from diverse domains and languages. | [ğŸ“„ Paper](https://arxiv.org/abs/2506.03448) |
| **OBELICS** | 141M documents<br/>353M images<br/>115B tokens | Open web-scale filtered dataset from CommonCrawl. Features **comprehensive filtering strategies** and **preserves original web page structure**. Extraction and filtering pipeline fully documented. | [ğŸ“„ Paper (NeurIPS 2023 D&B)](https://arxiv.org/abs/2306.16527) |
| **MMC4 (Multimodal C4)** | 101.2M documents<br/>571M images<br/>43B tokens | Augmentation of text-only C4 corpus with images. Uses **linear assignment algorithm** with **CLIP features** for image-sentence alignment. Currently partially re-hosted with dataset splits available. | [ğŸ“„ Paper (NeurIPS 2023 D&B)](https://arxiv.org/abs/2304.06939) |
| **CoMM** | 227K documents<br/>2.28M images<br/>139M tokens | High-quality **coherent** interleaved dataset with **multi-perspective filtering** (text coherence, image consistency, alignment). Emphasizes quality over quantity. See [Methods](#-methods-by-image-processing-type) for detailed methodology. | [ğŸ“„ Paper (CVPR 2025)](https://arxiv.org/abs/2406.10462) |

| **VLM Dialog Games for Selfâ€‘Improvement** | Method-focused dataset | **Dialog-game-based self-improvement data synthesis** â€” Two VLM agents play a reference game on unlabeled images; successful dialogs are filtered and used for fine-tuning, enabling iterative self-improvement. Key: self-play data generation with automatic quality control, difficulty control. | [ğŸ“„ Paper (arXiv 2502.02740)](https://arxiv.org/abs/2502.02740) |

### ğŸ“Š Domain-Specific & Knowledge-Oriented Datasets

These datasets target specific domains (e.g., remote sensing, entities) or knowledge-intensive tasks, often involving specialized data construction pipelines tailored to domain requirements.

| Dataset | Scale | Description | Links |
|---------|-------|-------------|-------|
| **MMM-RS** | 2.1M text-image pairs | **Remote sensing** multimodal dataset for text-to-image generation. Features **multi-modal** (optical, SAR), **multi-GSD** (ground sampling distance), **multi-scene** (fog, snow, low-light) coverage. Standardizes 9 public RS datasets with automated captioning and synthetic scene augmentation. | [ğŸ“„ Paper (NeurIPS 2024 D&B)](https://arxiv.org/abs/2307.14878) |
| **MESED** | 14,489 entities<br/>434,675 image-text pairs | **Multi-modal Entity Set Expansion** dataset with **fine-grained semantic classes** and **hard negative entities**. Designed for knowledge/entity-centric tasks. Includes baseline model MultiExpan. | [ğŸ“„ Paper (AAAI 2024)](https://arxiv.org/abs/2406.08418) |

### ğŸ“ Large-Scale General Training Datasets

| Dataset | Scale | Description | Links |
|---------|-------|-------------|-------|
| **FineVision** | 24.3M samples<br/>17.3M images | Comprehensive multimodal dataset from 200+ sources, covering 9 categories: General VQA, OCR, Chart/Table, Document, Grounding, Math, Science, Vision-Centric, and World Knowledge | [ğŸ¤— HuggingFace](https://huggingface.co/datasets/HuggingFaceM4/FineVision) \| [ğŸ“„ Paper](https://arxiv.org/abs/2510.17269) |
| **LLaVA-OneVision** | ~4M samples | Unified high-quality dataset covering single-image, multi-image, and video scenarios | [ğŸ¤— HuggingFace](https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data) \| [ğŸ“„ Paper](https://arxiv.org/abs/2408.03326) |
| **PixMo** | Multiple subsets | Suite of datasets (PixMo-Cap, PixMo-AskModelAnything, etc.) for training open vision-language models | [ğŸ¤— HuggingFace](https://huggingface.co/collections/allenai/pixmo-674746ea613028006285687b) \| [ğŸ“„ Paper](https://arxiv.org/abs/2409.17146) |
| **MAmmoTH-VL** | 12M samples | Large-scale multimodal instruction tuning dataset for enhancing reasoning abilities of MLLMs | [ğŸ¤— HuggingFace](https://huggingface.co/datasets/MAmmoTH-VL/MAmmoTH-VL-Instruct-12M) \| [ğŸ“„ Paper](https://arxiv.org/abs/2412.05237) |

### ğŸ¨ Image Editing Datasets

| Dataset | Scale | Description | Cross-Reference |
|---------|-------|-------------|-----------------|
| **ByteMorph-6M** | 6M editing triplets | **Non-rigid motion editing** dataset (camera motion, object deformation, human articulation, HOI). Motion-guided layered compositing + GPT-4o captioning. | See [Methods â†’ Image Editing](#-image-editing-method--data) |
| **ImgEdit** | 1.2M editing triplets | **Unified editing dataset** covering 8 editing categories. VLM + detection + segmentation + in-painting pipeline. Strong on multi-turn editing with identity consistency. | See [Methods â†’ Image Editing](#-image-editing-method--data) |
| **RefEdit** | 20K editing triplets | **Referring expression-guided editing**. High-quality synthetic data via GPT-4o + Grounded-SAM + FlowChef. Demonstrates quality > quantity (outperforms million-scale baselines). | See [Methods â†’ Image Editing](#-image-editing-method--data) |
| **RefCOCO-Edit** | Small-scale benchmark | **Early RIE benchmark** derived from RefCOCO. First systematic formulation of Referring Image Editing task. | See [Methods â†’ Image Editing](#-image-editing-method--data) \| [Benchmark Datasets](#-benchmark-datasets) |

---

## ğŸ“Š åŸºå‡†æ•°æ®é›†

### ğŸ¯ æŒ‡ä»¤éµå¾ªåŸºå‡†

| Benchmark | Description | Link |
|-----------|-------------|------|
| MMBench | Comprehensive multimodal capability evaluation | [GitHub](https://github.com/open-compass/MMBench) |
| SEED-Bench | Hierarchical multimodal understanding evaluation | [GitHub](https://github.com/AILab-CVC/SEED-Bench) |
| LLaVA-Bench | Evaluates conversation, detailed description, and complex reasoning in-the-wild | [ğŸ¤— HuggingFace](https://huggingface.co/datasets/lmms-lab/llava-bench-in-the-wild) |

### ğŸ“ Task-Specific Benchmarks

| Benchmark | Description | Link |
|-----------|-------------|------|
| VQAv2 | Visual question answering | [Website](https://visualqa.org/) |
| GQA | Compositional reasoning evaluation | [Website](https://cs.stanford.edu/people/dorarad/gqa/) |
| MMMU | Massive multi-discipline multimodal understanding and reasoning | [Website](https://mmmu-benchmark.github.io/) |

---

## ğŸ“ èµ„æº

### ğŸ’¡ å…·æœ‰å¯å‘æ€§çš„é‡è¦å·¥ä½œ

| Paper | Year | Significance | Link |
|-------|------|--------------|------|
| Magpie: Alignment Data Synthesis from Scratch | 2024 | Core inspiration for Oasis, self-aligned instruction generation in text domain | [arXiv](https://arxiv.org/abs/2406.08464) |

> âš ï¸ **Note**: Magpie itself is a pure text LLM method, not multimodal data synthesis

### ğŸ“– Survey Papers (Covering Data Synthesis)

| Paper | Year | Focus | Link |
|-------|------|-------|------|
| A Survey on Multimodal Large Language Models | 2023 | Section 3.2 specifically discusses training data construction | [arXiv](https://arxiv.org/abs/2306.13549) |
| Multimodal Foundation Models: From Specialists to General-Purpose Assistants | 2024 | Includes survey of data collection and synthesis methods | [arXiv](https://arxiv.org/abs/2309.10020) |

### ğŸ”— Related Awesome Lists

| List | Description | Link |
|------|-------------|------|
| Awesome Data for LLM | LLM data engineering (text domain) | [GitHub](https://github.com/weAIDB/awesome-data-llm) |
| Awesome Scientific Datasets and LLMs | Scientific domain datasets | [GitHub](https://github.com/open-sciencelab/Awesome-Scientific-Datasets-and-LLMs) |
| Awesome Multimodal ML | Comprehensive multimodal ML resources | [GitHub](https://github.com/pliang279/awesome-multimodal-ml) |

### ğŸ“ Important Blogs

| Blog | Description | Link |
|------|-------------|------|
| LLaVA Blog | Detailed explanation of LLaVA series data generation methods | [Website](https://llava-vl.github.io/) |
| HuggingFace Blog | Multimodal data and model tutorials | [Website](https://huggingface.co/blog) |

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

We welcome contributions of all forms! Including but not limited to:

- ğŸ†• Adding new papers, tools, or datasets
- ğŸ“ Improving descriptions of existing entries
- ğŸ› Fixing errors or outdated information
- ğŸ’¡ Suggesting improvements

### How to Contribute

1. Fork this repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Contribution Guidelines

- When adding new entries, please ensure they include:
  - ğŸ“„ Paper/tool name and link
  - ğŸ“ Clear and concise description (1-2 sentences)
  - ğŸ”— Related links (code, dataset, blog, etc.)
- Maintain entries in alphabetical or importance order
- Ensure links are valid and point to official resources
- Use English for descriptions

---

## â­ Starå†å²

If this project helps you, please give us a Star â­ï¸!

[![Star History Chart](https://api.star-history.com/svg?repos=opendatalab-raiser/awesome-multimodal-data-recipe&type=Date)](https://star-history.com/#opendatalab-raiser/awesome-multimodal-data-recipe&Date)

---

## ğŸ“„ è®¸å¯è¯

This project is licensed under [MIT License](LICENSE).

---

## ğŸ™ è‡´è°¢

Thanks to all researchers and engineers who have contributed to the field of multimodal data synthesis!

Special thanks to the following projects for inspiration:
- [awesome-data-llm](https://github.com/weAIDB/awesome-data-llm)
- [Awesome-Scientific-Datasets-and-LLMs](https://github.com/open-sciencelab/Awesome-Scientific-Datasets-and-LLMs)

---

<p align="center">
  Made with â¤ï¸ by the multimodal research community
</p>
